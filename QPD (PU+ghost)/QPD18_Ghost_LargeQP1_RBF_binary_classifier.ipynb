{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)  # DataFrameを改行せずに表示\n",
    "pd.set_option('display.max_columns', None)  # すべての列を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single_train_csv_path1_list:  270\n",
      "single_train_csv_path2_list:  270\n",
      "second_train_csv_path1_list:  270\n",
      "second_train_csv_path2_list:  270\n",
      "single_test_csv_path1_list:  30\n",
      "single_test_csv_path2_list:  30\n",
      "second_test_csv_path1_list:  30\n",
      "second_test_csv_path2_list:  30\n"
     ]
    }
   ],
   "source": [
    "rootpath = \"/Prove/Yoshihisa/HEIF_ghost/QPD/\"\n",
    "\n",
    "single_train_csv_path1 = os.path.join(rootpath, 'QPD18_HEIF_images_single_csv', 'TRAINING')\n",
    "single_train_csv_path2 = os.path.join(rootpath, 'QPD18_HEIF_images_second_sameQP_csv', 'TRAINING')\n",
    "\n",
    "second_train_csv_path1 = os.path.join(rootpath, 'QPD18_HEIF_images_second_csv', 'TRAINING')\n",
    "second_train_csv_path2 = os.path.join(rootpath, 'QPD18_HEIF_images_triple_csv', 'TRAINING')\n",
    "\n",
    "single_test_csv_path1 = os.path.join(rootpath, 'QPD18_HEIF_images_single_csv', 'TEST')\n",
    "single_test_csv_path2 = os.path.join(rootpath, 'QPD18_HEIF_images_second_sameQP_csv', 'TEST')\n",
    "\n",
    "second_test_csv_path1 = os.path.join(rootpath, 'QPD18_HEIF_images_second_csv', 'TEST')\n",
    "second_test_csv_path2 = os.path.join(rootpath, 'QPD18_HEIF_images_triple_csv', 'TEST')\n",
    "\n",
    "\n",
    "single_train_csv_path1_list = [os.path.join(single_train_csv_path1, file) for file in sorted(os.listdir(single_train_csv_path1))]\n",
    "single_train_csv_path2_list = [os.path.join(single_train_csv_path2, file) for file in sorted(os.listdir(single_train_csv_path2))]\n",
    "\n",
    "second_train_csv_path1_list = [os.path.join(second_train_csv_path1, file) for file in sorted(os.listdir(second_train_csv_path1))]\n",
    "second_train_csv_path2_list = [os.path.join(second_train_csv_path2, file) for file in sorted(os.listdir(second_train_csv_path2))]\n",
    "\n",
    "single_test_csv_path1_list = [os.path.join(single_test_csv_path1, file) for file in sorted(os.listdir(single_test_csv_path1))]\n",
    "single_test_csv_path2_list = [os.path.join(single_test_csv_path2, file) for file in sorted(os.listdir(single_test_csv_path2))]\n",
    "\n",
    "second_test_csv_path1_list = [os.path.join(second_test_csv_path1, file) for file in sorted(os.listdir(second_test_csv_path1))]\n",
    "second_test_csv_path2_list = [os.path.join(second_test_csv_path2, file) for file in sorted(os.listdir(second_test_csv_path2))]\n",
    "\n",
    "\n",
    "print(\"single_train_csv_path1_list: \", len(single_train_csv_path1_list))\n",
    "print(\"single_train_csv_path2_list: \", len(single_train_csv_path2_list))\n",
    "\n",
    "print(\"second_train_csv_path1_list: \", len(second_train_csv_path1_list))\n",
    "print(\"second_train_csv_path2_list: \", len(second_train_csv_path2_list))\n",
    "\n",
    "print(\"single_test_csv_path1_list: \", len(single_test_csv_path1_list))\n",
    "print(\"single_test_csv_path2_list: \", len(single_test_csv_path2_list))\n",
    "\n",
    "print(\"second_test_csv_path1_list: \", len(second_test_csv_path1_list))\n",
    "print(\"second_test_csv_path2_list: \", len(second_test_csv_path2_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single_train_pkl_path1_list:  270\n",
      "single_train_pkl_path2_list:  270\n",
      "second_train_pkl_path1_list:  270\n",
      "second_train_pkl_path2_list:  270\n",
      "single_test_pkl_path1_list:  30\n",
      "single_test_pkl_path2_list:  30\n",
      "second_test_pkl_path1_list:  30\n",
      "second_test_pkl_path2_list:  30\n"
     ]
    }
   ],
   "source": [
    "rootpath = \"/Prove/Yoshihisa/HEIF_ghost/QPD/\"\n",
    "\n",
    "single_train_pkl_path1 = os.path.join(rootpath, 'QPD18_pkl_single', 'TRAINING')\n",
    "single_train_pkl_path2 = os.path.join(rootpath, 'QPD18_pkl_second_sameQP', 'TRAINING')\n",
    "\n",
    "second_train_pkl_path1 = os.path.join(rootpath, 'QPD18_pkl_second', 'TRAINING')\n",
    "second_train_pkl_path2 = os.path.join(rootpath, 'QPD18_pkl_triple', 'TRAINING')\n",
    "\n",
    "single_test_pkl_path1 = os.path.join(rootpath, 'QPD18_pkl_single', 'TEST')\n",
    "single_test_pkl_path2 = os.path.join(rootpath, 'QPD18_pkl_second_sameQP', 'TEST')\n",
    "\n",
    "second_test_pkl_path1 = os.path.join(rootpath, 'QPD18_pkl_second', 'TEST')\n",
    "second_test_pkl_path2 = os.path.join(rootpath, 'QPD18_pkl_triple', 'TEST')\n",
    "\n",
    "\n",
    "single_train_pkl_path1_list = [os.path.join(single_train_pkl_path1, file) for file in sorted(os.listdir(single_train_pkl_path1))]\n",
    "single_train_pkl_path2_list = [os.path.join(single_train_pkl_path2, file) for file in sorted(os.listdir(single_train_pkl_path2))]\n",
    "\n",
    "second_train_pkl_path1_list = [os.path.join(second_train_pkl_path1, file) for file in sorted(os.listdir(second_train_pkl_path1))]\n",
    "second_train_pkl_path2_list = [os.path.join(second_train_pkl_path2, file) for file in sorted(os.listdir(second_train_pkl_path2))]\n",
    "\n",
    "single_test_pkl_path1_list = [os.path.join(single_test_pkl_path1, file) for file in sorted(os.listdir(single_test_pkl_path1))]\n",
    "single_test_pkl_path2_list = [os.path.join(single_test_pkl_path2, file) for file in sorted(os.listdir(single_test_pkl_path2))]\n",
    "\n",
    "second_test_pkl_path1_list = [os.path.join(second_test_pkl_path1, file) for file in sorted(os.listdir(second_test_pkl_path1))]\n",
    "second_test_pkl_path2_list = [os.path.join(second_test_pkl_path2, file) for file in sorted(os.listdir(second_test_pkl_path2))]\n",
    "\n",
    "\n",
    "print(\"single_train_pkl_path1_list: \", len(single_train_pkl_path1_list))\n",
    "print(\"single_train_pkl_path2_list: \", len(single_train_pkl_path2_list))\n",
    "\n",
    "print(\"second_train_pkl_path1_list: \", len(second_train_pkl_path1_list))\n",
    "print(\"second_train_pkl_path2_list: \", len(second_train_pkl_path2_list))\n",
    "\n",
    "print(\"single_test_pkl_path1_list: \", len(single_test_pkl_path1_list))\n",
    "print(\"single_test_pkl_path2_list: \", len(single_test_pkl_path2_list))\n",
    "\n",
    "print(\"second_test_pkl_path1_list: \", len(second_test_pkl_path1_list))\n",
    "print(\"second_test_pkl_path2_list: \", len(second_test_pkl_path2_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_csv_list:  540\n",
      "test_csv_list:  60\n"
     ]
    }
   ],
   "source": [
    "single_train_csv = list(zip(single_train_csv_path1_list, single_train_pkl_path1_list, single_train_csv_path2_list, single_train_pkl_path2_list))\n",
    "second_train_csv = list(zip(second_train_csv_path1_list, second_train_pkl_path1_list, second_train_csv_path2_list, second_train_pkl_path2_list))\n",
    "second_train_csv = random.sample(second_train_csv, len(single_train_csv))\n",
    "\n",
    "single_test_csv = list(zip(single_test_csv_path1_list, single_test_pkl_path1_list, single_test_csv_path2_list, single_test_pkl_path2_list))\n",
    "second_test_csv = list(zip(second_test_csv_path1_list, second_test_pkl_path1_list, second_test_csv_path2_list, second_test_pkl_path2_list))\n",
    "second_test_csv = random.sample(second_test_csv, len(single_test_csv))\n",
    "\n",
    "train_csv_list = single_train_csv + second_train_csv\n",
    "test_csv_list = single_test_csv + second_test_csv\n",
    "\n",
    "print(\"train_csv_list: \", len(train_csv_list))\n",
    "print(\"test_csv_list: \", len(test_csv_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540\n"
     ]
    }
   ],
   "source": [
    "# new_df = pd.DataFrame(columns=[\"QP\", \"CU_64\", \"CU_32\", \"CU_16\", \"CU_8\", \"PU_64\", \"PU_32\", \"PU_16\", \"PU_8\", \"PU_4\", \"LUM_A\", \"LUM_B\", \"LUM_C\", \"CRM_34\", \"LABEL\"])\n",
    "train_df1 = pd.DataFrame(columns=[\"PU1_64\", \"PU1_32\", \"PU1_16\", \"PU1_8\", \"PU1_4\",  \"PU2_64\",\"PU2_32\", \"PU2_16\", \"PU2_8\", \"PU2_4\"])\n",
    "train_df2 = pd.DataFrame(columns=[\"LABEL\"])\n",
    "\n",
    "train_df3 = pd.DataFrame(columns=[\"MAE1_0\", \"MAE1_1\", \"MAE1_2\", \"MAE1_3\", \"MAE1_4\", \"MAE1_5\", \"MAE1_6\", \"MAE1_7\", \"MAE1_8\", \"MAE1_9\", \"MAE1_10\",\n",
    "                                  \"MAE1_11\", \"MAE1_12\", \"MAE1_13\", \"MAE1_14\", \"MAE1_15\", \"MAE1_16\", \"MAE1_17\", \"MAE1_18\", \"MAE1_19\", \"MAE1_20\", \n",
    "                                  \"MAE1_21\", \"MAE1_22\", \"MAE1_23\", \"MAE1_24\", \"MAE1_25\", \"MAE1_26\", \"MAE1_27\", \"MAE1_28\", \"MAE1_29\", \"MAE1_30\", \n",
    "                                  \"MAE1_31\", \"MAE1_32\", \"MAE1_33\", \"MAE1_34\", \"MAE1_35\", \"MAE1_36\", \"MAE1_37\", \"MAE1_38\", \"MAE1_39\", \"MAE1_40\", \n",
    "                                  \"MAE1_41\", \"MAE1_42\", \"MAE1_43\", \"MAE1_44\", \"MAE1_45\", \"MAE1_46\", \"MAE1_47\", \"MAE1_48\", \"MAE1_49\", \"MAE1_50\", \n",
    "                                  \"MAE1_51\"])\n",
    "\n",
    "train_df4 = pd.DataFrame(columns=[\"MAE2_0\", \"MAE2_1\", \"MAE2_2\", \"MAE2_3\", \"MAE2_4\", \"MAE2_5\", \"MAE2_6\", \"MAE2_7\", \"MAE2_8\", \"MAE2_9\", \"MAE2_10\",\n",
    "                                  \"MAE2_11\", \"MAE2_12\", \"MAE2_13\", \"MAE2_14\", \"MAE2_15\", \"MAE2_16\", \"MAE2_17\", \"MAE2_18\", \"MAE2_19\", \"MAE2_20\", \n",
    "                                  \"MAE2_21\", \"MAE2_22\", \"MAE2_23\", \"MAE2_24\", \"MAE2_25\", \"MAE2_26\", \"MAE2_27\", \"MAE2_28\", \"MAE2_29\", \"MAE2_30\", \n",
    "                                  \"MAE2_31\", \"MAE2_32\", \"MAE2_33\", \"MAE2_34\", \"MAE2_35\", \"MAE2_36\", \"MAE2_37\", \"MAE2_38\", \"MAE2_39\", \"MAE2_40\", \n",
    "                                  \"MAE2_41\", \"MAE2_42\", \"MAE2_43\", \"MAE2_44\", \"MAE2_45\", \"MAE2_46\", \"MAE2_47\", \"MAE2_48\", \"MAE2_49\", \"MAE2_50\", \n",
    "                                  \"MAE2_51\"])\n",
    "\n",
    "train_df5 = pd.DataFrame(columns=[\"MAE1_1\", \"MAE1_2\"])\n",
    "train_df6 = pd.DataFrame(columns=[\"MAE2_1\", \"MAE2_2\"])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for path1, path2, path3, path4 in train_csv_list:\n",
    "    label = 1 if (\"2ndQP\" in path1) and (\"3rdQP\" in path3) else 0\n",
    "    df1 = pd.read_csv(path1)\n",
    "    df2 = pd.read_csv(path3)\n",
    "    train_pkl_list = [path2, path4]\n",
    "    \n",
    "    pu1_64 = df1.loc[0, \"pu_counts\"]\n",
    "    pu1_32 = df1.loc[1, \"pu_counts\"]\n",
    "    pu1_16 = df1.loc[2, \"pu_counts\"]\n",
    "    pu1_8 = df1.loc[3, \"pu_counts\"]\n",
    "    pu1_4 = df1.loc[4, \"pu_counts\"]\n",
    "    \n",
    "    pu2_64 = df2.loc[0, \"pu_counts\"]\n",
    "    pu2_32 = df2.loc[1, \"pu_counts\"]\n",
    "    pu2_16 = df2.loc[2, \"pu_counts\"]\n",
    "    pu2_8 = df2.loc[3, \"pu_counts\"]\n",
    "    pu2_4 = df2.loc[4, \"pu_counts\"]\n",
    "    \n",
    "    train_df1 = pd.concat([train_df1, pd.DataFrame({\n",
    "                                          \"PU1_64\": [pu1_64],\n",
    "                                          \"PU1_32\": [pu1_32],\n",
    "                                          \"PU1_16\": [pu1_16],\n",
    "                                          \"PU1_8\": [pu1_8],\n",
    "                                          \"PU1_4\": [pu1_4],\n",
    "                                          \n",
    "                                          \"PU2_64\": [pu2_64],\n",
    "                                          \"PU2_32\": [pu2_32],\n",
    "                                          \"PU2_16\": [pu2_16],\n",
    "                                          \"PU2_8\": [pu2_8],\n",
    "                                          \"PU2_4\": [pu2_4],\n",
    "\n",
    "                                          })], \n",
    "                   ignore_index=True)\n",
    "    \n",
    "    train_df2 = pd.concat([train_df2, pd.DataFrame({\n",
    "\n",
    "                                          \"LABEL\": [label]})], \n",
    "                   ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    with open(train_pkl_list[0], 'rb') as file1:\n",
    "        loaded_data1 = pickle.load(file1)\n",
    "        \n",
    "    with open(train_pkl_list[1], 'rb') as file2:\n",
    "        loaded_data2 = pickle.load(file2)\n",
    "    \n",
    "    # 読み込んだデータからMAE結果を取得\n",
    "    ghost_results1, ghost_results_shifted1 = loaded_data1\n",
    "    ghost_results2, ghost_results_shifted2 = loaded_data2\n",
    "\n",
    "    # タプル内のリストを抽出\n",
    "    original_mae1 = ghost_results1\n",
    "    shifted_mae1 = ghost_results_shifted1\n",
    "    \n",
    "    original_mae2 = ghost_results2\n",
    "    shifted_mae2 = ghost_results_shifted2\n",
    "\n",
    "    mae_d1 = [shifted - original for original, shifted in zip(original_mae1, shifted_mae1)]\n",
    "    mae_d2 = [shifted - original for original, shifted in zip(original_mae2, shifted_mae2)]\n",
    "    mae_d1 = [0 if val <= 0 else val for val in mae_d1]\n",
    "    mae_d2 = [0 if val <= 0 else val for val in mae_d2]\n",
    "    \n",
    "    peaks_mae_d1, _ = find_peaks(mae_d1)\n",
    "    peaks_mae_d2, _ = find_peaks(mae_d2)\n",
    "\n",
    "    # peaks_mae_d1が空の場合、0を代入\n",
    "    max_peak_index_mae_d1 = peaks_mae_d1[np.argmax([mae_d1[i] for i in peaks_mae_d1])] if peaks_mae_d1.size > 0 else 0\n",
    "\n",
    "    # peaks_mae_d2が空の場合、0を代入\n",
    "    max_peak_index_mae_d2 = peaks_mae_d2[np.argmax([mae_d2[i] for i in peaks_mae_d2])] if peaks_mae_d2.size > 0 else 0\n",
    "\n",
    "    # ２番目に大きいピーク値のインデックスを取得\n",
    "    sorted_peaks_mae_d1 = np.argsort([mae_d1[i] for i in peaks_mae_d1])\n",
    "    second_max_peak_index_mae_d1 = peaks_mae_d1[sorted_peaks_mae_d1[-2]] if sorted_peaks_mae_d1.size >= 2 else 0\n",
    "\n",
    "    sorted_peaks_mae_d2 = np.argsort([mae_d2[i] for i in peaks_mae_d2])\n",
    "    second_max_peak_index_mae_d2 = peaks_mae_d2[sorted_peaks_mae_d2[-2]] if sorted_peaks_mae_d2.size >= 2 else 0\n",
    "\n",
    "    \n",
    "    \n",
    "    train_df5 = pd.concat([train_df5, pd.DataFrame({\n",
    "                                          \"MAE1_1\": [mae_d1[max_peak_index_mae_d1]],\n",
    "                                          \"MAE1_2\": [mae_d1[second_max_peak_index_mae_d1]],\n",
    "        })],\n",
    "\n",
    "                   ignore_index=True)\n",
    "    \n",
    "    train_df6 = pd.concat([train_df6, pd.DataFrame({\n",
    "                                          \"MAE2_1\": [mae_d2[max_peak_index_mae_d2]],\n",
    "                                          \"MAE2_2\": [mae_d2[second_max_peak_index_mae_d2]],\n",
    "        })],\n",
    "\n",
    "                   ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    train_df3 = pd.concat([train_df3, pd.DataFrame({\n",
    "                                      \"MAE1_0\": [mae_d1[0]], \n",
    "                                      \"MAE1_1\": [mae_d1[1]],\n",
    "                                      \"MAE1_2\": [mae_d1[2]], \n",
    "                                      \"MAE1_3\": [mae_d1[3]], \n",
    "                                      \"MAE1_4\": [mae_d1[4]], \n",
    "                                      \"MAE1_5\": [mae_d1[5]], \n",
    "                                      \"MAE1_6\": [mae_d1[6]], \n",
    "                                      \"MAE1_7\": [mae_d1[7]], \n",
    "                                      \"MAE1_8\": [mae_d1[8]], \n",
    "                                      \"MAE1_9\": [mae_d1[9]], \n",
    "                                      \"MAE1_10\": [mae_d1[10]],\n",
    "                                      \"MAE1_11\": [mae_d1[11]], \n",
    "                                      \"MAE1_12\": [mae_d1[12]], \n",
    "                                      \"MAE1_13\": [mae_d1[13]], \n",
    "                                      \"MAE1_14\": [mae_d1[14]], \n",
    "                                      \"MAE1_15\": [mae_d1[15]], \n",
    "                                      \"MAE1_16\": [mae_d1[16]], \n",
    "                                      \"MAE1_17\": [mae_d1[17]], \n",
    "                                      \"MAE1_18\": [mae_d1[18]], \n",
    "                                      \"MAE1_19\": [mae_d1[19]], \n",
    "                                      \"MAE1_20\": [mae_d1[20]], \n",
    "                                      \"MAE1_21\": [mae_d1[21]], \n",
    "                                      \"MAE1_22\": [mae_d1[22]], \n",
    "                                      \"MAE1_23\": [mae_d1[23]], \n",
    "                                      \"MAE1_24\": [mae_d1[24]], \n",
    "                                      \"MAE1_25\": [mae_d1[25]], \n",
    "                                      \"MAE1_26\": [mae_d1[26]], \n",
    "                                      \"MAE1_27\": [mae_d1[27]], \n",
    "                                      \"MAE1_28\": [mae_d1[28]], \n",
    "                                      \"MAE1_29\": [mae_d1[29]], \n",
    "                                      \"MAE1_30\": [mae_d1[30]], \n",
    "                                      \"MAE1_31\": [mae_d1[31]], \n",
    "                                      \"MAE1_32\": [mae_d1[32]], \n",
    "                                      \"MAE1_33\": [mae_d1[33]], \n",
    "                                      \"MAE1_34\": [mae_d1[34]], \n",
    "                                      \"MAE1_35\": [mae_d1[35]], \n",
    "                                      \"MAE1_36\": [mae_d1[36]], \n",
    "                                      \"MAE1_37\": [mae_d1[37]], \n",
    "                                      \"MAE1_38\": [mae_d1[38]], \n",
    "                                      \"MAE1_39\": [mae_d1[39]], \n",
    "                                      \"MAE1_40\": [mae_d1[40]], \n",
    "                                      \"MAE1_41\": [mae_d1[41]], \n",
    "                                      \"MAE1_42\": [mae_d1[42]], \n",
    "                                      \"MAE1_43\": [mae_d1[43]], \n",
    "                                      \"MAE1_44\": [mae_d1[44]], \n",
    "                                      \"MAE1_45\": [mae_d1[45]], \n",
    "                                      \"MAE1_46\": [mae_d1[46]], \n",
    "                                      \"MAE1_47\": [mae_d1[47]], \n",
    "                                      \"MAE1_48\": [mae_d1[48]], \n",
    "                                      \"MAE1_49\": [mae_d1[49]], \n",
    "                                      \"MAE1_50\": [mae_d1[50]], \n",
    "                                      \"MAE1_51\": [mae_d1[51]],\n",
    "                                        })],\n",
    "        ignore_index=True)\n",
    "    \n",
    "    train_df4 = pd.concat([train_df4, pd.DataFrame({\n",
    "                                  \"MAE2_0\": [mae_d2[0]], \n",
    "                                  \"MAE2_1\": [mae_d2[1]],\n",
    "                                  \"MAE2_2\": [mae_d2[2]], \n",
    "                                  \"MAE2_3\": [mae_d2[3]], \n",
    "                                  \"MAE2_4\": [mae_d2[4]], \n",
    "                                  \"MAE2_5\": [mae_d2[5]], \n",
    "                                  \"MAE2_6\": [mae_d2[6]], \n",
    "                                  \"MAE2_7\": [mae_d2[7]], \n",
    "                                  \"MAE2_8\": [mae_d2[8]], \n",
    "                                  \"MAE2_9\": [mae_d2[9]], \n",
    "                                  \"MAE2_10\": [mae_d2[10]],\n",
    "                                  \"MAE2_11\": [mae_d2[11]], \n",
    "                                  \"MAE2_12\": [mae_d2[12]], \n",
    "                                  \"MAE2_13\": [mae_d2[13]], \n",
    "                                  \"MAE2_14\": [mae_d2[14]], \n",
    "                                  \"MAE2_15\": [mae_d2[15]], \n",
    "                                  \"MAE2_16\": [mae_d2[16]], \n",
    "                                  \"MAE2_17\": [mae_d2[17]], \n",
    "                                  \"MAE2_18\": [mae_d2[18]], \n",
    "                                  \"MAE2_19\": [mae_d2[19]], \n",
    "                                  \"MAE2_20\": [mae_d2[20]], \n",
    "                                  \"MAE2_21\": [mae_d2[21]], \n",
    "                                  \"MAE2_22\": [mae_d2[22]], \n",
    "                                  \"MAE2_23\": [mae_d2[23]], \n",
    "                                  \"MAE2_24\": [mae_d2[24]], \n",
    "                                  \"MAE2_25\": [mae_d2[25]], \n",
    "                                  \"MAE2_26\": [mae_d2[26]], \n",
    "                                  \"MAE2_27\": [mae_d2[27]], \n",
    "                                  \"MAE2_28\": [mae_d2[28]], \n",
    "                                  \"MAE2_29\": [mae_d2[29]], \n",
    "                                  \"MAE2_30\": [mae_d2[30]], \n",
    "                                  \"MAE2_31\": [mae_d2[31]], \n",
    "                                  \"MAE2_32\": [mae_d2[32]], \n",
    "                                  \"MAE2_33\": [mae_d2[33]], \n",
    "                                  \"MAE2_34\": [mae_d2[34]], \n",
    "                                  \"MAE2_35\": [mae_d2[35]], \n",
    "                                  \"MAE2_36\": [mae_d2[36]], \n",
    "                                  \"MAE2_37\": [mae_d2[37]], \n",
    "                                  \"MAE2_38\": [mae_d2[38]], \n",
    "                                  \"MAE2_39\": [mae_d2[39]], \n",
    "                                  \"MAE2_40\": [mae_d2[40]], \n",
    "                                  \"MAE2_41\": [mae_d2[41]], \n",
    "                                  \"MAE2_42\": [mae_d2[42]], \n",
    "                                  \"MAE2_43\": [mae_d2[43]], \n",
    "                                  \"MAE2_44\": [mae_d2[44]], \n",
    "                                  \"MAE2_45\": [mae_d2[45]], \n",
    "                                  \"MAE2_46\": [mae_d2[46]], \n",
    "                                  \"MAE2_47\": [mae_d2[47]], \n",
    "                                  \"MAE2_48\": [mae_d2[48]], \n",
    "                                  \"MAE2_49\": [mae_d2[49]], \n",
    "                                  \"MAE2_50\": [mae_d2[50]], \n",
    "                                  \"MAE2_51\": [mae_d2[51]],\n",
    "                                    })],\n",
    "        ignore_index=True)\n",
    "\n",
    "    train_df = pd.concat([train_df1, train_df3, train_df4], axis=1)\n",
    "    \n",
    "print(len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "# new_df = pd.DataFrame(columns=[\"QP\", \"CU_64\", \"CU_32\", \"CU_16\", \"CU_8\", \"PU_64\", \"PU_32\", \"PU_16\", \"PU_8\", \"PU_4\", \"LUM_A\", \"LUM_B\", \"LUM_C\", \"CRM_34\", \"LABEL\"])\n",
    "test_df1 = pd.DataFrame(columns=[\"PU1_64\", \"PU1_32\", \"PU1_16\", \"PU1_8\", \"PU1_4\",  \"PU2_64\",\"PU2_32\", \"PU2_16\", \"PU2_8\", \"PU2_4\"])\n",
    "test_df2 = pd.DataFrame(columns=[\"LABEL\"])\n",
    "\n",
    "test_df3 = pd.DataFrame(columns=[\"MAE1_0\", \"MAE1_1\", \"MAE1_2\", \"MAE1_3\", \"MAE1_4\", \"MAE1_5\", \"MAE1_6\", \"MAE1_7\", \"MAE1_8\", \"MAE1_9\", \"MAE1_10\",\n",
    "                                  \"MAE1_11\", \"MAE1_12\", \"MAE1_13\", \"MAE1_14\", \"MAE1_15\", \"MAE1_16\", \"MAE1_17\", \"MAE1_18\", \"MAE1_19\", \"MAE1_20\", \n",
    "                                  \"MAE1_21\", \"MAE1_22\", \"MAE1_23\", \"MAE1_24\", \"MAE1_25\", \"MAE1_26\", \"MAE1_27\", \"MAE1_28\", \"MAE1_29\", \"MAE1_30\", \n",
    "                                  \"MAE1_31\", \"MAE1_32\", \"MAE1_33\", \"MAE1_34\", \"MAE1_35\", \"MAE1_36\", \"MAE1_37\", \"MAE1_38\", \"MAE1_39\", \"MAE1_40\", \n",
    "                                  \"MAE1_41\", \"MAE1_42\", \"MAE1_43\", \"MAE1_44\", \"MAE1_45\", \"MAE1_46\", \"MAE1_47\", \"MAE1_48\", \"MAE1_49\", \"MAE1_50\", \n",
    "                                  \"MAE1_51\"])\n",
    "\n",
    "test_df4 = pd.DataFrame(columns=[\"MAE2_0\", \"MAE2_1\", \"MAE2_2\", \"MAE2_3\", \"MAE2_4\", \"MAE2_5\", \"MAE2_6\", \"MAE2_7\", \"MAE2_8\", \"MAE2_9\", \"MAE2_10\",\n",
    "                                  \"MAE2_11\", \"MAE2_12\", \"MAE2_13\", \"MAE2_14\", \"MAE2_15\", \"MAE2_16\", \"MAE2_17\", \"MAE2_18\", \"MAE2_19\", \"MAE2_20\", \n",
    "                                  \"MAE2_21\", \"MAE2_22\", \"MAE2_23\", \"MAE2_24\", \"MAE2_25\", \"MAE2_26\", \"MAE2_27\", \"MAE2_28\", \"MAE2_29\", \"MAE2_30\", \n",
    "                                  \"MAE2_31\", \"MAE2_32\", \"MAE2_33\", \"MAE2_34\", \"MAE2_35\", \"MAE2_36\", \"MAE2_37\", \"MAE2_38\", \"MAE2_39\", \"MAE2_40\", \n",
    "                                  \"MAE2_41\", \"MAE2_42\", \"MAE2_43\", \"MAE2_44\", \"MAE2_45\", \"MAE2_46\", \"MAE2_47\", \"MAE2_48\", \"MAE2_49\", \"MAE2_50\", \n",
    "                                  \"MAE2_51\"])\n",
    "test_df5 = pd.DataFrame(columns=[\"MAE1_1\", \"MAE1_2\"])\n",
    "test_df6 = pd.DataFrame(columns=[\"MAE2_1\", \"MAE2_2\"])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for path1, path2, path3, path4 in test_csv_list:\n",
    "    label = 1 if (\"2ndQP\" in path1) and (\"3rdQP\" in path3) else 0\n",
    "    df1 = pd.read_csv(path1)\n",
    "    df2 = pd.read_csv(path3)\n",
    "    test_pkl_list = [path2, path4]\n",
    "    \n",
    "    pu1_64 = df1.loc[0, \"pu_counts\"]\n",
    "    pu1_32 = df1.loc[1, \"pu_counts\"]\n",
    "    pu1_16 = df1.loc[2, \"pu_counts\"]\n",
    "    pu1_8 = df1.loc[3, \"pu_counts\"]\n",
    "    pu1_4 = df1.loc[4, \"pu_counts\"]\n",
    "    \n",
    "    pu2_64 = df2.loc[0, \"pu_counts\"]\n",
    "    pu2_32 = df2.loc[1, \"pu_counts\"]\n",
    "    pu2_16 = df2.loc[2, \"pu_counts\"]\n",
    "    pu2_8 = df2.loc[3, \"pu_counts\"]\n",
    "    pu2_4 = df2.loc[4, \"pu_counts\"]\n",
    "    \n",
    "    test_df1 = pd.concat([test_df1, pd.DataFrame({\n",
    "                                          \"PU1_64\": [pu1_64],\n",
    "                                          \"PU1_32\": [pu1_32],\n",
    "                                          \"PU1_16\": [pu1_16],\n",
    "                                          \"PU1_8\": [pu1_8],\n",
    "                                          \"PU1_4\": [pu1_4],\n",
    "                                          \n",
    "                                          \"PU2_64\": [pu2_64],\n",
    "                                          \"PU2_32\": [pu2_32],\n",
    "                                          \"PU2_16\": [pu2_16],\n",
    "                                          \"PU2_8\": [pu2_8],\n",
    "                                          \"PU2_4\": [pu2_4],\n",
    "\n",
    "                                          })], \n",
    "                   ignore_index=True)\n",
    "    \n",
    "    test_df2 = pd.concat([test_df2, pd.DataFrame({\n",
    "                                          \"LABEL\": [label]})], \n",
    "                   ignore_index=True)\n",
    "    \n",
    "    \n",
    "    with open(test_pkl_list[0], 'rb') as file1:\n",
    "        loaded_data1 = pickle.load(file1)\n",
    "        \n",
    "    with open(test_pkl_list[1], 'rb') as file2:\n",
    "        loaded_data2 = pickle.load(file2)\n",
    "    \n",
    "    # 読み込んだデータからMAE結果を取得\n",
    "    ghost_results1, ghost_results_shifted1 = loaded_data1\n",
    "    ghost_results2, ghost_results_shifted2 = loaded_data2\n",
    "\n",
    "    # タプル内のリストを抽出\n",
    "    original_mae1 = ghost_results1\n",
    "    shifted_mae1 = ghost_results_shifted1\n",
    "    \n",
    "    original_mae2 = ghost_results2\n",
    "    shifted_mae2 = ghost_results_shifted2\n",
    "\n",
    "    mae_d1 = [shifted - original for original, shifted in zip(original_mae1, shifted_mae1)]\n",
    "    mae_d2 = [shifted - original for original, shifted in zip(original_mae2, shifted_mae2)]\n",
    "    mae_d1 = [0 if val <= 0 else val for val in mae_d1]\n",
    "    mae_d2 = [0 if val <= 0 else val for val in mae_d2]\n",
    "    \n",
    "    peaks_mae_d1, _ = find_peaks(mae_d1)\n",
    "    peaks_mae_d2, _ = find_peaks(mae_d2)\n",
    "\n",
    "    # peaks_mae_d1が空の場合、0を代入\n",
    "    max_peak_index_mae_d1 = peaks_mae_d1[np.argmax([mae_d1[i] for i in peaks_mae_d1])] if peaks_mae_d1.size > 0 else 0\n",
    "\n",
    "    # peaks_mae_d2が空の場合、0を代入\n",
    "    max_peak_index_mae_d2 = peaks_mae_d2[np.argmax([mae_d2[i] for i in peaks_mae_d2])] if peaks_mae_d2.size > 0 else 0\n",
    "\n",
    "    # ２番目に大きいピーク値のインデックスを取得\n",
    "    sorted_peaks_mae_d1 = np.argsort([mae_d1[i] for i in peaks_mae_d1])\n",
    "    second_max_peak_index_mae_d1 = peaks_mae_d1[sorted_peaks_mae_d1[-2]] if sorted_peaks_mae_d1.size >= 2 else 0\n",
    "\n",
    "\n",
    "    sorted_peaks_mae_d2 = np.argsort([mae_d2[i] for i in peaks_mae_d2])\n",
    "    second_max_peak_index_mae_d2 = peaks_mae_d2[sorted_peaks_mae_d2[-2]] if sorted_peaks_mae_d2.size >= 2 else 0\n",
    "\n",
    "\n",
    "    \n",
    "    test_df5 = pd.concat([test_df5, pd.DataFrame({\n",
    "                                          \"MAE1_1\": [mae_d1[max_peak_index_mae_d1]],\n",
    "                                          \"MAE1_2\": [mae_d1[second_max_peak_index_mae_d1]],\n",
    "                                          \n",
    "        })],\n",
    "\n",
    "                   ignore_index=True)\n",
    "    \n",
    "    test_df6 = pd.concat([test_df6, pd.DataFrame({\n",
    "                                          \"MAE2_1\": [mae_d2[max_peak_index_mae_d2]],\n",
    "                                          \"MAE2_2\": [mae_d2[second_max_peak_index_mae_d2]],\n",
    "                                          \n",
    "        })],\n",
    "\n",
    "                   ignore_index=True)\n",
    "        \n",
    "    test_df3 = pd.concat([test_df3, pd.DataFrame({\n",
    "                                      \"MAE1_0\": [mae_d1[0]], \n",
    "                                      \"MAE1_1\": [mae_d1[1]],\n",
    "                                      \"MAE1_2\": [mae_d1[2]], \n",
    "                                      \"MAE1_3\": [mae_d1[3]], \n",
    "                                      \"MAE1_4\": [mae_d1[4]], \n",
    "                                      \"MAE1_5\": [mae_d1[5]], \n",
    "                                      \"MAE1_6\": [mae_d1[6]], \n",
    "                                      \"MAE1_7\": [mae_d1[7]], \n",
    "                                      \"MAE1_8\": [mae_d1[8]], \n",
    "                                      \"MAE1_9\": [mae_d1[9]], \n",
    "                                      \"MAE1_10\": [mae_d1[10]],\n",
    "                                      \"MAE1_11\": [mae_d1[11]], \n",
    "                                      \"MAE1_12\": [mae_d1[12]], \n",
    "                                      \"MAE1_13\": [mae_d1[13]], \n",
    "                                      \"MAE1_14\": [mae_d1[14]], \n",
    "                                      \"MAE1_15\": [mae_d1[15]], \n",
    "                                      \"MAE1_16\": [mae_d1[16]], \n",
    "                                      \"MAE1_17\": [mae_d1[17]], \n",
    "                                      \"MAE1_18\": [mae_d1[18]], \n",
    "                                      \"MAE1_19\": [mae_d1[19]], \n",
    "                                      \"MAE1_20\": [mae_d1[20]], \n",
    "                                      \"MAE1_21\": [mae_d1[21]], \n",
    "                                      \"MAE1_22\": [mae_d1[22]], \n",
    "                                      \"MAE1_23\": [mae_d1[23]], \n",
    "                                      \"MAE1_24\": [mae_d1[24]], \n",
    "                                      \"MAE1_25\": [mae_d1[25]], \n",
    "                                      \"MAE1_26\": [mae_d1[26]], \n",
    "                                      \"MAE1_27\": [mae_d1[27]], \n",
    "                                      \"MAE1_28\": [mae_d1[28]], \n",
    "                                      \"MAE1_29\": [mae_d1[29]], \n",
    "                                      \"MAE1_30\": [mae_d1[30]], \n",
    "                                      \"MAE1_31\": [mae_d1[31]], \n",
    "                                      \"MAE1_32\": [mae_d1[32]], \n",
    "                                      \"MAE1_33\": [mae_d1[33]], \n",
    "                                      \"MAE1_34\": [mae_d1[34]], \n",
    "                                      \"MAE1_35\": [mae_d1[35]], \n",
    "                                      \"MAE1_36\": [mae_d1[36]], \n",
    "                                      \"MAE1_37\": [mae_d1[37]], \n",
    "                                      \"MAE1_38\": [mae_d1[38]], \n",
    "                                      \"MAE1_39\": [mae_d1[39]], \n",
    "                                      \"MAE1_40\": [mae_d1[40]], \n",
    "                                      \"MAE1_41\": [mae_d1[41]], \n",
    "                                      \"MAE1_42\": [mae_d1[42]], \n",
    "                                      \"MAE1_43\": [mae_d1[43]], \n",
    "                                      \"MAE1_44\": [mae_d1[44]], \n",
    "                                      \"MAE1_45\": [mae_d1[45]], \n",
    "                                      \"MAE1_46\": [mae_d1[46]], \n",
    "                                      \"MAE1_47\": [mae_d1[47]], \n",
    "                                      \"MAE1_48\": [mae_d1[48]], \n",
    "                                      \"MAE1_49\": [mae_d1[49]], \n",
    "                                      \"MAE1_50\": [mae_d1[50]], \n",
    "                                      \"MAE1_51\": [mae_d1[51]],\n",
    "                                        })],\n",
    "        ignore_index=True)\n",
    "    \n",
    "    test_df4 = pd.concat([test_df4, pd.DataFrame({\n",
    "                                  \"MAE2_0\": [mae_d2[0]], \n",
    "                                  \"MAE2_1\": [mae_d2[1]],\n",
    "                                  \"MAE2_2\": [mae_d2[2]], \n",
    "                                  \"MAE2_3\": [mae_d2[3]], \n",
    "                                  \"MAE2_4\": [mae_d2[4]], \n",
    "                                  \"MAE2_5\": [mae_d2[5]], \n",
    "                                  \"MAE2_6\": [mae_d2[6]], \n",
    "                                  \"MAE2_7\": [mae_d2[7]], \n",
    "                                  \"MAE2_8\": [mae_d2[8]], \n",
    "                                  \"MAE2_9\": [mae_d2[9]], \n",
    "                                  \"MAE2_10\": [mae_d2[10]],\n",
    "                                  \"MAE2_11\": [mae_d2[11]], \n",
    "                                  \"MAE2_12\": [mae_d2[12]], \n",
    "                                  \"MAE2_13\": [mae_d2[13]], \n",
    "                                  \"MAE2_14\": [mae_d2[14]], \n",
    "                                  \"MAE2_15\": [mae_d2[15]], \n",
    "                                  \"MAE2_16\": [mae_d2[16]], \n",
    "                                  \"MAE2_17\": [mae_d2[17]], \n",
    "                                  \"MAE2_18\": [mae_d2[18]], \n",
    "                                  \"MAE2_19\": [mae_d2[19]], \n",
    "                                  \"MAE2_20\": [mae_d2[20]], \n",
    "                                  \"MAE2_21\": [mae_d2[21]], \n",
    "                                  \"MAE2_22\": [mae_d2[22]], \n",
    "                                  \"MAE2_23\": [mae_d2[23]], \n",
    "                                  \"MAE2_24\": [mae_d2[24]], \n",
    "                                  \"MAE2_25\": [mae_d2[25]], \n",
    "                                  \"MAE2_26\": [mae_d2[26]], \n",
    "                                  \"MAE2_27\": [mae_d2[27]], \n",
    "                                  \"MAE2_28\": [mae_d2[28]], \n",
    "                                  \"MAE2_29\": [mae_d2[29]], \n",
    "                                  \"MAE2_30\": [mae_d2[30]], \n",
    "                                  \"MAE2_31\": [mae_d2[31]], \n",
    "                                  \"MAE2_32\": [mae_d2[32]], \n",
    "                                  \"MAE2_33\": [mae_d2[33]], \n",
    "                                  \"MAE2_34\": [mae_d2[34]], \n",
    "                                  \"MAE2_35\": [mae_d2[35]], \n",
    "                                  \"MAE2_36\": [mae_d2[36]], \n",
    "                                  \"MAE2_37\": [mae_d2[37]], \n",
    "                                  \"MAE2_38\": [mae_d2[38]], \n",
    "                                  \"MAE2_39\": [mae_d2[39]], \n",
    "                                  \"MAE2_40\": [mae_d2[40]], \n",
    "                                  \"MAE2_41\": [mae_d2[41]], \n",
    "                                  \"MAE2_42\": [mae_d2[42]], \n",
    "                                  \"MAE2_43\": [mae_d2[43]], \n",
    "                                  \"MAE2_44\": [mae_d2[44]], \n",
    "                                  \"MAE2_45\": [mae_d2[45]], \n",
    "                                  \"MAE2_46\": [mae_d2[46]], \n",
    "                                  \"MAE2_47\": [mae_d2[47]], \n",
    "                                  \"MAE2_48\": [mae_d2[48]], \n",
    "                                  \"MAE2_49\": [mae_d2[49]], \n",
    "                                  \"MAE2_50\": [mae_d2[50]], \n",
    "                                  \"MAE2_51\": [mae_d2[51]],\n",
    "                                    })],\n",
    "        ignore_index=True)\n",
    "\n",
    "    test_df = pd.concat([test_df1, test_df3, test_df4], axis=1)\n",
    "\n",
    "print(len(test_df))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "# print(len(combined_df))\n",
    "\n",
    "# スケーラーを使って結合したデータをスケーリング\n",
    "combined_scaled_data = scaler.fit_transform(combined_df)\n",
    "\n",
    "# トレーニングデータとテストデータに再分割\n",
    "X_train = combined_scaled_data[:len(train_df)]\n",
    "X_test = combined_scaled_data[len(train_df):]\n",
    "# print(len(X_train))\n",
    "# print(len(X_test))\n",
    "\n",
    "# ラベルの準備\n",
    "Y_train = train_df2['LABEL'].astype(int)\n",
    "Y_test = test_df2['LABEL'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.2032967  0.48690476 0.6967001  0.38760362 0.\n",
      "  0.20374449 0.49177438 0.69549667 0.37220281 0.14939417 0.05316783\n",
      "  0.01639331 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06095473 0.         0.         0.         0.13398968\n",
      "  0.24082305 0.32356057 0.22154304 0.13319378 0.00295752 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.00830975 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.0118259  0.1284793\n",
      "  0.         0.         0.         0.18234999 0.26023825 0.37229591\n",
      "  0.25140557 0.15680302 0.02014168 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.00490196 0.00395566]]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0:1])\n",
    "print(X_train[1350:1351])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 1.64835165e-01 7.73214286e-01 6.99288256e-01\n",
      "  2.54578755e-01 0.00000000e+00 1.69603524e-01 7.70857814e-01\n",
      "  6.92407739e-01 2.41431404e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.92429475e-01\n",
      "  2.30784149e-01 2.47742431e-01 1.71152734e-01 6.22571026e-02\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  5.19066574e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.44384629e-01\n",
      "  2.75277858e-01 3.02830090e-01 2.13671027e-01 8.26934040e-02\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.15998543e-05 7.99485252e-03\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0:1])\n",
    "print(X_test[150:151])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       C  k=1  k=2  k=3       k=4  k=5       k=6  k=7  k=8  k=9  Mean_Val_Score\n",
      "0   0.01  1.0  1.0  1.0  0.983333  1.0  0.983333  1.0  1.0  1.0        0.996296\n",
      "1    0.1  1.0  1.0  1.0  0.983333  1.0  1.000000  1.0  1.0  1.0        0.998148\n",
      "2      1  1.0  1.0  1.0  1.000000  1.0  1.000000  1.0  1.0  1.0        1.000000\n",
      "3     10  1.0  1.0  1.0  1.000000  1.0  1.000000  1.0  1.0  1.0        1.000000\n",
      "4    100  1.0  1.0  1.0  1.000000  1.0  1.000000  1.0  1.0  1.0        1.000000\n",
      "5   1000  1.0  1.0  1.0  1.000000  1.0  1.000000  1.0  1.0  1.0        1.000000\n",
      "6   1500  1.0  1.0  1.0  1.000000  1.0  1.000000  1.0  1.0  1.0        1.000000\n",
      "7   2000  1.0  1.0  1.0  1.000000  1.0  1.000000  1.0  1.0  1.0        1.000000\n",
      "8   2500  1.0  1.0  1.0  1.000000  1.0  1.000000  1.0  1.0  1.0        1.000000\n",
      "9   3000  1.0  1.0  1.0  1.000000  1.0  1.000000  1.0  1.0  1.0        1.000000\n",
      "10  3500  1.0  1.0  1.0  1.000000  1.0  1.000000  1.0  1.0  1.0        1.000000\n",
      "11  4000  1.0  1.0  1.0  1.000000  1.0  1.000000  1.0  1.0  1.0        1.000000\n",
      "12  4500  1.0  1.0  1.0  1.000000  1.0  1.000000  1.0  1.0  1.0        1.000000\n",
      "13  5000  1.0  1.0  1.0  1.000000  1.0  1.000000  1.0  1.0  1.0        1.000000\n",
      "14  5500  1.0  1.0  1.0  1.000000  1.0  1.000000  1.0  1.0  1.0        1.000000\n",
      "15  6000  1.0  1.0  1.0  1.000000  1.0  1.000000  1.0  1.0  1.0        1.000000\n",
      "Best Parameters:  {'C': 1}\n",
      "Accuracy on Test Set: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Cの範囲を指定\n",
    "C_values = {'C': [0.01, 0.1, 1, 10, 100, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000]}\n",
    "\n",
    "# SVMモデルのインスタンスを作成\n",
    "svm_model = SVC(kernel='rbf')\n",
    "\n",
    "# グリッドサーチのインスタンスを作成\n",
    "grid_search = GridSearchCV(svm_model, C_values, cv=9, scoring='accuracy')\n",
    "\n",
    "# グリッドサーチを実行\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# 結果のデータフレームを作成\n",
    "# 結果のデータフレームを作成\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "# print(results)\n",
    "\n",
    "# 新しい列名のマッピングを作成\n",
    "new_column_names = {\n",
    "    'param_C': 'C',\n",
    "    'split0_test_score': 'k=1',\n",
    "    'split1_test_score': 'k=2',\n",
    "    'split2_test_score': 'k=3',\n",
    "    'split3_test_score': 'k=4',\n",
    "    'split4_test_score': 'k=5',\n",
    "    'split5_test_score': 'k=6',\n",
    "    'split6_test_score': 'k=7',\n",
    "    'split7_test_score': 'k=8',\n",
    "    'split8_test_score': 'k=9',\n",
    "    'mean_test_score': 'Mean_Val_Score'\n",
    "}\n",
    "\n",
    "# 列名を変更\n",
    "results = results.rename(columns=new_column_names)\n",
    "\n",
    "# 変更後の表を表示\n",
    "print(results[['C', 'k=1', 'k=2', 'k=3', 'k=4', 'k=5', 'k=6', 'k=7', 'k=8', 'k=9', 'Mean_Val_Score']])\n",
    "    \n",
    "# # 最適なハイパーパラメータを表示\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "\n",
    "# # 最適なモデルを取得\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "\n",
    "# # テストデータで評価\n",
    "accuracy = best_svm_model.score(X_test, Y_test)\n",
    "print(\"Accuracy on Test Set: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation performance of 9-fold: 1.0\n",
      "Summary:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           1.00        60\n",
      "   macro avg       1.00      1.00      1.00        60\n",
      "weighted avg       1.00      1.00      1.00        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PU1 + PU2\n",
    "\n",
    "k = 9\n",
    "\n",
    "# SVMモデルを初期化（RBFカーネルを使用）\n",
    "svm_model = SVC(kernel='rbf', C=1, gamma='scale')  # Cとgammaはハイパーパラメータで調整可能\n",
    "\n",
    "\n",
    "# K-fold cross validation\n",
    "cv_scores = cross_val_score(svm_model, X_train, Y_train, cv=k)\n",
    "average_accuracy = np.round(cv_scores.mean(), 4)\n",
    "print(f'Average validation performance of {k}-fold: {average_accuracy}')\n",
    "\n",
    "svm_model.fit(X_train, Y_train)\n",
    "Y_pred = svm_model.predict(X_test)\n",
    "\n",
    "report = classification_report(Y_test, Y_pred)\n",
    "\n",
    "print(f'Summary:\\n{report}')\n",
    "\n",
    "# svm_model._gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
