{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import os.path as osp\n",
    "import re\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.signal import find_peaks\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import torch\n",
    "import glob\n",
    "from scipy.stats import entropy\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)  # DataFrameを改行せずに表示\n",
    "pd.set_option('display.max_columns', None)  # すべての列を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_finalQP(filename):\n",
    "    match = re.search(r'2ndQP(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    match = re.search(r'1stQP(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_1stQP(filename):\n",
    "    match = re.search(r'1stQP(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def ratio_double_compressed(mean_difference, final_QP):\n",
    "    # mean_difference = mean_difference[0]\n",
    "    # final_QP = final_QP[0]\n",
    "    clamped_mean_difference = np.maximum(mean_difference, -0.01)\n",
    "    \n",
    "    #全体のエネルギーを計算\n",
    "    energy = np.sum(np.square(clamped_mean_difference))\n",
    "    # energy = np.sum(np.square(mean_difference))\n",
    "    \n",
    "    #QP2より右側のエネルギーを計算\n",
    "    right_energy = np.sum(np.square(clamped_mean_difference[final_QP+1:52]))\n",
    "\n",
    "        \n",
    "    # エネルギー比を計算して閾値と比較\n",
    "    if energy > 0:\n",
    "        return right_energy / energy\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def is_double_compressed(mean_difference, final_QP, threshold):\n",
    "    mean_difference = mean_difference[0]\n",
    "    final_QP = final_QP[0]\n",
    "    clamped_mean_difference = np.maximum(mean_difference, -0.01)\n",
    "    \n",
    "    #全体のエネルギーを計算\n",
    "    energy = np.sum(np.square(clamped_mean_difference))\n",
    "    # energy = np.sum(np.square(mean_difference))\n",
    "    \n",
    "    #QP2より右側のエネルギーを計算\n",
    "    right_energy = np.sum(np.square(clamped_mean_difference[final_QP+1:52]))\n",
    "    # right_energy = np.sum(np.square(mean_difference[final_QP+1:52]))\n",
    "    \n",
    "    # print('energy: ', energy)\n",
    "    # print('R-energy: ', right_energy)\n",
    "    # print('Ratio: ', right_energy / energy)\n",
    "    \n",
    "    \n",
    "    # エネルギー比を計算して閾値と比較\n",
    "    if energy <= 0:\n",
    "        return -1\n",
    "    \n",
    "    elif (right_energy / energy) != 0 and (right_energy / energy) > threshold:\n",
    "        return True\n",
    "    \n",
    "    elif (right_energy / energy) != 0 and (right_energy / energy) <= threshold:\n",
    "        return False\n",
    "    \n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def calculate_mae(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            loaded_data, loaded_data_shifted = pickle.load(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # タプル内のリストを抽出\n",
    "    original_mae = np.array(loaded_data)\n",
    "    shifted_mae = np.array(loaded_data_shifted)\n",
    "\n",
    "    # Coding ghostを計算してリストに格納する\n",
    "    mae_difference = shifted_mae - original_mae\n",
    "    \n",
    "    # mae_differenceの各要素においてマイナスの値を0に変換\n",
    "    # mae_difference_positive = np.maximum(mae_difference, 0)\n",
    "    \n",
    "    return mae_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['264', '118', '32', '298', '110', '174', '184', '250', '115', '16', '274', '104', '211', '186', '290', '231', '258', '31', '197', '23', '35', '106', '277', '58', '28', '21', '74', '181', '15', '206'], ['44', '25', '123', '50', '102', '27', '194', '84', '133', '182', '69', '202', '144', '299', '286', '262', '34', '159', '107', '165', '269', '33', '237', '48', '147', '61', '225', '72', '66', '190'], ['83', '67', '191', '150', '82', '64', '79', '2', '149', '42', '214', '263', '142', '132', '207', '130', '241', '276', '37', '77', '180', '88', '249', '163', '259', '60', '285', '177', '90', '45'], ['154', '136', '291', '246', '256', '62', '170', '227', '289', '162', '65', '255', '230', '108', '205', '96', '252', '247', '173', '24', '143', '122', '226', '296', '51', '78', '55', '38', '155', '292'], ['179', '243', '71', '134', '8', '261', '117', '148', '199', '1', '300', '273', '251', '224', '267', '228', '164', '56', '195', '13', '200', '188', '75', '43', '124', '116', '126', '5', '216', '175'], ['235', '14', '103', '220', '92', '215', '10', '18', '140', '172', '169', '63', '121', '281', '229', '49', '208', '203', '125', '85', '293', '80', '209', '278', '95', '3', '213', '29', '201', '146'], ['22', '239', '266', '9', '98', '260', '283', '257', '12', '112', '47', '160', '171', '131', '97', '81', '282', '53', '17', '93', '113', '217', '152', '68', '76', '105', '57', '218', '4', '167'], ['161', '70', '129', '59', '271', '176', '204', '223', '189', '39', '41', '54', '100', '234', '245', '222', '109', '219', '236', '87', '270', '119', '158', '128', '248', '242', '253', '232', '279', '138'], ['139', '151', '192', '46', '7', '26', '254', '73', '233', '294', '111', '185', '272', '178', '275', '86', '127', '212', '135', '193', '295', '157', '40', '20', '196', '284', '91', '187', '198', '210'], ['297', '153', '30', '166', '183', '52', '101', '89', '137', '221', '265', '268', '141', '240', '168', '36', '287', '11', '6', '145', '114', '238', '244', '19', '156', '280', '288', '94', '99', '120']]\n",
      "\n",
      "CSV Single ListsA:\n",
      "CSV List 1A: 300\n",
      "CSV List 2A: 300\n",
      "CSV List 3A: 300\n",
      "CSV List 4A: 300\n",
      "CSV List 5A: 300\n",
      "CSV List 6A: 300\n",
      "CSV List 7A: 300\n",
      "CSV List 8A: 300\n",
      "CSV List 9A: 300\n",
      "CSV List 10A: 300\n",
      "\n",
      "CSV Single Recompress ListsA:\n",
      "CSV List 1A: 300\n",
      "CSV List 2A: 300\n",
      "CSV List 3A: 300\n",
      "CSV List 4A: 300\n",
      "CSV List 5A: 300\n",
      "CSV List 6A: 300\n",
      "CSV List 7A: 300\n",
      "CSV List 8A: 300\n",
      "CSV List 9A: 300\n",
      "CSV List 10A: 300\n",
      "\n",
      "CSV Second Large QP1 ListsA:\n",
      "CSV List 1A: 1710\n",
      "CSV List 2A: 1710\n",
      "CSV List 3A: 1710\n",
      "CSV List 4A: 1710\n",
      "CSV List 5A: 1710\n",
      "CSV List 6A: 1710\n",
      "CSV List 7A: 1710\n",
      "CSV List 8A: 1710\n",
      "CSV List 9A: 1710\n",
      "CSV List 10A: 1710\n",
      "\n",
      "CSV Second Recompress Large QP1 ListsA:\n",
      "CSV List 1A: 1710\n",
      "CSV List 2A: 1710\n",
      "CSV List 3A: 1710\n",
      "CSV List 4A: 1710\n",
      "CSV List 5A: 1710\n",
      "CSV List 6A: 1710\n",
      "CSV List 7A: 1710\n",
      "CSV List 8A: 1710\n",
      "CSV List 9A: 1710\n",
      "CSV List 10A: 1710\n",
      "\n",
      "CSV Second Same QP ListsA:\n",
      "CSV List 1A: 300\n",
      "CSV List 2A: 300\n",
      "CSV List 3A: 300\n",
      "CSV List 4A: 300\n",
      "CSV List 5A: 300\n",
      "CSV List 6A: 300\n",
      "CSV List 7A: 300\n",
      "CSV List 8A: 300\n",
      "CSV List 9A: 300\n",
      "CSV List 10A: 300\n",
      "\n",
      "CSV Second Recompress Same QP ListsA:\n",
      "CSV List 1A: 300\n",
      "CSV List 2A: 300\n",
      "CSV List 3A: 300\n",
      "CSV List 4A: 300\n",
      "CSV List 5A: 300\n",
      "CSV List 6A: 300\n",
      "CSV List 7A: 300\n",
      "CSV List 8A: 300\n",
      "CSV List 9A: 300\n",
      "CSV List 10A: 300\n",
      "\n",
      "CSV Second Large QP2 ListsA:\n",
      "CSV List 1A: 1170\n",
      "CSV List 2A: 1170\n",
      "CSV List 3A: 1170\n",
      "CSV List 4A: 1170\n",
      "CSV List 5A: 1170\n",
      "CSV List 6A: 1170\n",
      "CSV List 7A: 1170\n",
      "CSV List 8A: 1170\n",
      "CSV List 9A: 1170\n",
      "CSV List 10A: 1170\n",
      "\n",
      "CSV Second Recompress Large QP2 ListsA:\n",
      "CSV List 1A: 1170\n",
      "CSV List 2A: 1170\n",
      "CSV List 3A: 1170\n",
      "CSV List 4A: 1170\n",
      "CSV List 5A: 1170\n",
      "CSV List 6A: 1170\n",
      "CSV List 7A: 1170\n",
      "CSV List 8A: 1170\n",
      "CSV List 9A: 1170\n",
      "CSV List 10A: 1170\n",
      "\n",
      "PKL Single ListsA:\n",
      "PKL List 1A: 300\n",
      "PKL List 2A: 300\n",
      "PKL List 3A: 300\n",
      "PKL List 4A: 300\n",
      "PKL List 5A: 300\n",
      "PKL List 6A: 300\n",
      "PKL List 7A: 300\n",
      "PKL List 8A: 300\n",
      "PKL List 9A: 300\n",
      "PKL List 10A: 300\n",
      "\n",
      "PKL Single Recompress ListsA:\n",
      "PKL List 1A: 300\n",
      "PKL List 2A: 300\n",
      "PKL List 3A: 300\n",
      "PKL List 4A: 300\n",
      "PKL List 5A: 300\n",
      "PKL List 6A: 300\n",
      "PKL List 7A: 300\n",
      "PKL List 8A: 300\n",
      "PKL List 9A: 300\n",
      "PKL List 10A: 300\n",
      "\n",
      "PKL Second Large QP1 ListsA:\n",
      "PKL List 1A: 1710\n",
      "PKL List 2A: 1710\n",
      "PKL List 3A: 1710\n",
      "PKL List 4A: 1710\n",
      "PKL List 5A: 1710\n",
      "PKL List 6A: 1710\n",
      "PKL List 7A: 1710\n",
      "PKL List 8A: 1710\n",
      "PKL List 9A: 1710\n",
      "PKL List 10A: 1710\n",
      "\n",
      "PKL Second Recompress Large QP1 ListsA:\n",
      "PKL List 1A: 1710\n",
      "PKL List 2A: 1710\n",
      "PKL List 3A: 1710\n",
      "PKL List 4A: 1710\n",
      "PKL List 5A: 1710\n",
      "PKL List 6A: 1710\n",
      "PKL List 7A: 1710\n",
      "PKL List 8A: 1710\n",
      "PKL List 9A: 1710\n",
      "PKL List 10A: 1710\n",
      "\n",
      "PKL Second Same QP ListsA:\n",
      "PKL List 1A: 300\n",
      "PKL List 2A: 300\n",
      "PKL List 3A: 300\n",
      "PKL List 4A: 300\n",
      "PKL List 5A: 300\n",
      "PKL List 6A: 300\n",
      "PKL List 7A: 300\n",
      "PKL List 8A: 300\n",
      "PKL List 9A: 300\n",
      "PKL List 10A: 300\n",
      "\n",
      "PKL Second Recompress Same QP ListsA:\n",
      "PKL List 1A: 300\n",
      "PKL List 2A: 300\n",
      "PKL List 3A: 300\n",
      "PKL List 4A: 300\n",
      "PKL List 5A: 300\n",
      "PKL List 6A: 300\n",
      "PKL List 7A: 300\n",
      "PKL List 8A: 300\n",
      "PKL List 9A: 300\n",
      "PKL List 10A: 300\n",
      "\n",
      "PKL Second Large QP2 ListsA:\n",
      "PKL List 1A: 1170\n",
      "PKL List 2A: 1170\n",
      "PKL List 3A: 1170\n",
      "PKL List 4A: 1170\n",
      "PKL List 5A: 1170\n",
      "PKL List 6A: 1170\n",
      "PKL List 7A: 1170\n",
      "PKL List 8A: 1170\n",
      "PKL List 9A: 1170\n",
      "PKL List 10A: 1170\n",
      "\n",
      "PKL Second Recompress Large QP2 ListsA:\n",
      "PKL List 1A: 1170\n",
      "PKL List 2A: 1170\n",
      "PKL List 3A: 1170\n",
      "PKL List 4A: 1170\n",
      "PKL List 5A: 1170\n",
      "PKL List 6A: 1170\n",
      "PKL List 7A: 1170\n",
      "PKL List 8A: 1170\n",
      "PKL List 9A: 1170\n",
      "PKL List 10A: 1170\n"
     ]
    }
   ],
   "source": [
    "rootpath_csv = \"/Prove/Yoshihisa/HEIF_ghost/HEIF_IMAGES_CSV/\"\n",
    "rootpath_pkl = \"/Prove/Yoshihisa/HEIF_ghost/PKL/\"\n",
    "\n",
    "train_list1 = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\"]\n",
    "train_list2 = [\"31\", \"32\", \"33\", \"34\", \"35\", \"36\", \"37\", \"38\", \"39\", \"40\", \"41\", \"42\", \"43\", \"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"50\", \"51\", \"52\", \"53\", \"54\", \"55\", \"56\", \"57\", \"58\", \"59\", \"60\"]\n",
    "train_list3 = [\"61\", \"62\", \"63\", \"64\", \"65\", \"66\", \"67\", \"68\", \"69\", \"70\", \"71\", \"72\", \"73\", \"74\", \"75\", \"76\", \"77\", \"78\", \"79\", \"80\", \"81\", \"82\", \"83\", \"84\", \"85\", \"86\", \"87\", \"88\", \"89\", \"90\"]\n",
    "train_list4 = [\"91\", \"92\", \"93\", \"94\", \"95\", \"96\", \"97\", \"98\", \"99\", \"100\", \"101\", \"102\", \"103\", \"104\", \"105\", \"106\", \"107\", \"108\", \"109\", \"110\", \"111\", \"112\", \"113\", \"114\", \"115\", \"116\", \"117\", \"118\", \"119\", \"120\"]\n",
    "train_list5 = [\"121\", \"122\", \"123\", \"124\", \"125\", \"126\", \"127\", \"128\", \"129\", \"130\", \"131\", \"132\", \"133\", \"134\", \"135\", \"136\", \"137\", \"138\", \"139\", \"140\", \"141\", \"142\", \"143\", \"144\", \"145\", \"146\", \"147\", \"148\", \"149\", \"150\"]\n",
    "train_list6 = [\"151\", \"152\", \"153\", \"154\", \"155\", \"156\", \"157\", \"158\", \"159\", \"160\", \"161\", \"162\", \"163\", \"164\", \"165\", \"166\", \"167\", \"168\", \"169\", \"170\", \"171\", \"172\", \"173\", \"174\", \"175\", \"176\", \"177\", \"178\", \"179\", \"180\"]\n",
    "train_list7 = [\"181\", \"182\", \"183\", \"184\", \"185\", \"186\", \"187\", \"188\", \"189\", \"190\", \"191\", \"192\", \"193\", \"194\", \"195\", \"196\", \"197\", \"198\", \"199\", \"200\", \"201\", \"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\"]\n",
    "train_list8 = [\"211\", \"212\", \"213\", \"214\", \"215\", \"216\", \"217\", \"218\", \"219\", \"220\", \"221\", \"222\", \"223\", \"224\", \"225\", \"226\", \"227\", \"228\", \"229\", \"230\", \"231\", \"232\", \"233\", \"234\", \"235\", \"236\", \"237\", \"238\", \"239\", \"240\"]\n",
    "train_list9 = [\"241\", \"242\", \"243\", \"244\", \"245\", \"246\", \"247\", \"248\", \"249\", \"250\", \"251\", \"252\", \"253\", \"254\", \"255\", \"256\", \"257\", \"258\", \"259\", \"260\", \"261\", \"262\", \"263\", \"264\", \"265\", \"266\", \"267\", \"268\", \"269\", \"270\"]\n",
    "train_list10 = [\"271\", \"272\", \"273\", \"274\", \"275\", \"276\", \"277\", \"278\", \"279\", \"280\", \"281\", \"282\", \"283\", \"284\", \"285\", \"286\", \"287\", \"288\", \"289\", \"290\", \"291\", \"292\", \"293\", \"294\", \"295\", \"296\", \"297\", \"298\", \"299\", \"300\"]\n",
    "\n",
    "all_train_lists = [train_list1, train_list2, train_list3, train_list4, train_list5,\n",
    "                   train_list6, train_list7, train_list8, train_list9, train_list10]\n",
    "\n",
    "# すべてのリストを1つのリストに結合する\n",
    "combined_train_list = sum(all_train_lists, [])\n",
    "\n",
    "# リストの順序をランダムにシャッフルする\n",
    "random.shuffle(combined_train_list)\n",
    "\n",
    "# シャッフルされたリストを10個のグループに分割する\n",
    "train_lists = [combined_train_list[i:i+30] for i in range(0, len(combined_train_list), 30)]\n",
    "print(train_lists)\n",
    "\n",
    "\n",
    "\n",
    "# CSV関連のリストを生成\n",
    "csv_single_listsA = [[] for _ in range(10)]\n",
    "csv_single_recompress_listsA = [[] for _ in range(10)]\n",
    "csv_second_largeQP1_listsA = [[] for _ in range(10)]\n",
    "csv_second_recompress_largeQP1_listsA = [[] for _ in range(10)]\n",
    "csv_second_sameQP_listsA = [[] for _ in range(10)]\n",
    "csv_second_recompress_sameQP_listsA = [[] for _ in range(10)]\n",
    "csv_second_largeQP2_listsA = [[] for _ in range(10)]\n",
    "csv_second_recompress_largeQP2_listsA = [[] for _ in range(10)]\n",
    "\n",
    "def process_csv_lists(rootpath, train_list, single_list, single_recompress_list, \n",
    "                      second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                      second_sameQP_list, second_recompress_sameQP_list,\n",
    "                      second_largeQP2_list, second_recompress_largeQP2_list):\n",
    "    \n",
    "    for image in train_list:\n",
    "        single_path = osp.join(rootpath, f'HEIF_images_single_csv/{image}_*')\n",
    "        single_recompress_path = osp.join(rootpath, f'HEIF_images_second_sameQP_csv/{image}_*')\n",
    "        \n",
    "        second_largeQP1_path = osp.join(rootpath, f'HEIF_images_second_csv/{image}_*')\n",
    "        second_recompress_largeQP1_path = osp.join(rootpath, f'HEIF_images_triple_csv/{image}_*')\n",
    "        \n",
    "        second_sameQP_path = osp.join(rootpath, f'HEIF_images_second_sameQP_csv/{image}_*')\n",
    "        second_recompress_sameQP_path = osp.join(rootpath, f'HEIF_images_triple_sameQP_csv/{image}_*')\n",
    "        \n",
    "        second_largeQP2_path = osp.join(rootpath, f'HEIF_images_second_largeQP_csv/{image}_*')\n",
    "        second_recompress_largeQP2_path = osp.join(rootpath, f'HEIF_images_triple_largeQP_csv/{image}_*')\n",
    "        \n",
    "        for path in sorted(glob.glob(single_path)):\n",
    "            single_list.append(path)\n",
    "        for path in sorted(glob.glob(single_recompress_path)):\n",
    "            single_recompress_list.append(path)\n",
    "        for path in sorted(glob.glob(second_largeQP1_path)):\n",
    "            second_largeQP1_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP1_path)):\n",
    "            second_recompress_largeQP1_list.append(path)\n",
    "        for path in sorted(glob.glob(second_sameQP_path)):\n",
    "            second_sameQP_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_sameQP_path)):\n",
    "            second_recompress_sameQP_list.append(path)\n",
    "        for path in sorted(glob.glob(second_largeQP2_path)):\n",
    "            second_largeQP2_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP2_path)):\n",
    "            second_recompress_largeQP2_list.append(path)\n",
    "\n",
    "# 各カテゴリのCSVリストを生成\n",
    "for train_list, single_list, single_recompress_list in zip(train_lists, \n",
    "                                                           csv_single_listsA,\n",
    "                                                           csv_single_recompress_listsA):\n",
    "    process_csv_lists(rootpath_csv, train_list, single_list, single_recompress_list, \n",
    "                      [], [], [], [], [], [])\n",
    "\n",
    "\n",
    "for train_list, second_largeQP1_list, second_recompress_largeQP1_list, second_sameQP_list, second_recompress_sameQP_list, second_largeQP2_list, second_recompress_largeQP2_list in zip(train_lists, \n",
    "                                                                                                                                                                                                                   csv_second_largeQP1_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_recompress_largeQP1_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_sameQP_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_recompress_sameQP_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_largeQP2_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_recompress_largeQP2_listsA):\n",
    "    process_csv_lists(rootpath_csv, train_list, [], [], \n",
    "                      second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                      second_sameQP_list, second_recompress_sameQP_list,\n",
    "                      second_largeQP2_list, second_recompress_largeQP2_list)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "# 出力リストを初期化\n",
    "pkl_single_listsA = [[] for _ in range(10)]\n",
    "pkl_single_recompress_listsA = [[] for _ in range(10)]\n",
    "pkl_second_largeQP1_listsA = [[] for _ in range(10)]\n",
    "pkl_second_recompress_largeQP1_listsA = [[] for _ in range(10)]\n",
    "pkl_second_sameQP_listsA = [[] for _ in range(10)]\n",
    "pkl_second_recompress_sameQP_listsA = [[] for _ in range(10)]\n",
    "pkl_second_largeQP2_listsA = [[] for _ in range(10)]\n",
    "pkl_second_recompress_largeQP2_listsA = [[] for _ in range(10)]    \n",
    "\n",
    "def process_train_lists_pkl(rootpath, train_list, single_list, single_recompress_list, \n",
    "                            second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                            second_sameQP_list, second_recompress_sameQP_list,\n",
    "                            second_largeQP2_list, second_recompress_largeQP2_list):\n",
    "    \n",
    "    for image in train_list:\n",
    "        single_path = osp.join(rootpath, f'pkl_single/{image}_*')\n",
    "        single_recompress_path = osp.join(rootpath, f'pkl_second_sameQP/{image}_*')\n",
    "        \n",
    "        second_largeQP1_path = osp.join(rootpath, f'pkl_second/{image}_*')\n",
    "        second_recompress_largeQP1_path = osp.join(rootpath, f'pkl_triple/{image}_*')\n",
    "        \n",
    "        second_sameQP_path = osp.join(rootpath, f'pkl_second_sameQP/{image}_*')\n",
    "        second_recompress_sameQP_path = osp.join(rootpath, f'pkl_triple_sameQP/{image}_*')\n",
    "        \n",
    "        second_largeQP2_path = osp.join(rootpath, f'pkl_second_largeQP/{image}_*')\n",
    "        second_recompress_largeQP2_path = osp.join(rootpath, f'pkl_triple_largeQP/{image}_*')\n",
    "        \n",
    "\n",
    "        for path in sorted(glob.glob(single_path)):\n",
    "            single_list.append(path)\n",
    "        for path in sorted(glob.glob(single_recompress_path)):\n",
    "            single_recompress_list.append(path)\n",
    "            \n",
    "        for path in sorted(glob.glob(second_largeQP1_path)):\n",
    "            second_largeQP1_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP1_path)):\n",
    "            second_recompress_largeQP1_list.append(path)\n",
    "                \n",
    "        for path in sorted(glob.glob(second_sameQP_path)):\n",
    "            second_sameQP_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_sameQP_path)):\n",
    "            second_recompress_sameQP_list.append(path)\n",
    "            \n",
    "        for path in sorted(glob.glob(second_largeQP2_path)):\n",
    "            second_largeQP2_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP2_path)):\n",
    "            second_recompress_largeQP2_list.append(path)\n",
    "\n",
    "# 各カテゴリのリストを生成\n",
    "for train_list, single_list, single_recompress_list in zip(train_lists, \n",
    "                                                           pkl_single_listsA,\n",
    "                                                           pkl_single_recompress_listsA):\n",
    "    process_train_lists_pkl(rootpath_pkl, train_list, single_list, single_recompress_list, \n",
    "                            [], [], [], [], [], [])\n",
    "\n",
    "\n",
    "for train_list, second_largeQP1_list, second_recompress_largeQP1_list, second_sameQP_list, second_recompress_sameQP_list, second_largeQP2_list, second_recompress_largeQP2_list in zip(train_lists, \n",
    "                                                                                                                                                                                                                   pkl_second_largeQP1_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_recompress_largeQP1_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_sameQP_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_recompress_sameQP_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_largeQP2_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_recompress_largeQP2_listsA):\n",
    "    process_train_lists_pkl(rootpath_pkl, train_list, [], [], \n",
    "                            second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                            second_sameQP_list, second_recompress_sameQP_list,\n",
    "                            second_largeQP2_list, second_recompress_largeQP2_list)\n",
    "\n",
    "\n",
    "print(\"\\nCSV Single ListsA:\")\n",
    "for i, lst in enumerate(csv_single_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Single Recompress ListsA:\")\n",
    "for i, lst in enumerate(csv_single_recompress_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Large QP1 ListsA:\")\n",
    "for i, lst in enumerate(csv_second_largeQP1_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Recompress Large QP1 ListsA:\")\n",
    "for i, lst in enumerate(csv_second_recompress_largeQP1_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Same QP ListsA:\")\n",
    "for i, lst in enumerate(csv_second_sameQP_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Recompress Same QP ListsA:\")\n",
    "for i, lst in enumerate(csv_second_recompress_sameQP_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Large QP2 ListsA:\")\n",
    "for i, lst in enumerate(csv_second_largeQP2_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Recompress Large QP2 ListsA:\")\n",
    "for i, lst in enumerate(csv_second_recompress_largeQP2_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "# 出力リストを表示\n",
    "print(\"\\nPKL Single ListsA:\")\n",
    "for i, lst in enumerate(pkl_single_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Single Recompress ListsA:\")\n",
    "for i, lst in enumerate(pkl_single_recompress_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Large QP1 ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_largeQP1_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Recompress Large QP1 ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_recompress_largeQP1_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Same QP ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_sameQP_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Recompress Same QP ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_recompress_sameQP_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Large QP2 ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_largeQP2_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Recompress Large QP2 ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_recompress_largeQP2_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "# single_listsおよびsingle_recompress_listsは初期化されている前提\n",
    "single_csv1 = list(zip(csv_single_listsA[0], pkl_single_listsA[0], csv_single_recompress_listsA[0], pkl_single_recompress_listsA[0]))\n",
    "single_csv2 = list(zip(csv_single_listsA[1], pkl_single_listsA[1], csv_single_recompress_listsA[1], pkl_single_recompress_listsA[1]))\n",
    "single_csv3 = list(zip(csv_single_listsA[2], pkl_single_listsA[2], csv_single_recompress_listsA[2], pkl_single_recompress_listsA[2]))\n",
    "single_csv4 = list(zip(csv_single_listsA[3], pkl_single_listsA[3], csv_single_recompress_listsA[3], pkl_single_recompress_listsA[3]))\n",
    "single_csv5 = list(zip(csv_single_listsA[4], pkl_single_listsA[4], csv_single_recompress_listsA[4], pkl_single_recompress_listsA[4]))\n",
    "single_csv6 = list(zip(csv_single_listsA[5], pkl_single_listsA[5], csv_single_recompress_listsA[5], pkl_single_recompress_listsA[5]))\n",
    "single_csv7 = list(zip(csv_single_listsA[6], pkl_single_listsA[6], csv_single_recompress_listsA[6], pkl_single_recompress_listsA[6]))\n",
    "single_csv8 = list(zip(csv_single_listsA[7], pkl_single_listsA[7], csv_single_recompress_listsA[7], pkl_single_recompress_listsA[7]))\n",
    "single_csv9 = list(zip(csv_single_listsA[8], pkl_single_listsA[8], csv_single_recompress_listsA[8], pkl_single_recompress_listsA[8]))\n",
    "single_csv10 = list(zip(csv_single_listsA[9], pkl_single_listsA[9], csv_single_recompress_listsA[9], pkl_single_recompress_listsA[9]))\n",
    "print(len(single_csv10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1710\n",
      "\n",
      "double images train by QP1>QP2:  100\n",
      "\n",
      "double images test by QP1>QP2:  300\n"
     ]
    }
   ],
   "source": [
    "# Large_QP1\n",
    "second_largeQP1_csv1 = list(zip(csv_second_largeQP1_listsA[0], pkl_second_largeQP1_listsA[0], csv_second_recompress_largeQP1_listsA[0], pkl_second_recompress_largeQP1_listsA[0]))\n",
    "second_largeQP1_csv2 = list(zip(csv_second_largeQP1_listsA[1], pkl_second_largeQP1_listsA[1], csv_second_recompress_largeQP1_listsA[1], pkl_second_recompress_largeQP1_listsA[1]))\n",
    "second_largeQP1_csv3 = list(zip(csv_second_largeQP1_listsA[2], pkl_second_largeQP1_listsA[2], csv_second_recompress_largeQP1_listsA[2], pkl_second_recompress_largeQP1_listsA[2]))\n",
    "second_largeQP1_csv4 = list(zip(csv_second_largeQP1_listsA[3], pkl_second_largeQP1_listsA[3], csv_second_recompress_largeQP1_listsA[3], pkl_second_recompress_largeQP1_listsA[3]))\n",
    "second_largeQP1_csv5 = list(zip(csv_second_largeQP1_listsA[4], pkl_second_largeQP1_listsA[4], csv_second_recompress_largeQP1_listsA[4], pkl_second_recompress_largeQP1_listsA[4]))\n",
    "second_largeQP1_csv6 = list(zip(csv_second_largeQP1_listsA[5], pkl_second_largeQP1_listsA[5], csv_second_recompress_largeQP1_listsA[5], pkl_second_recompress_largeQP1_listsA[5]))\n",
    "second_largeQP1_csv7 = list(zip(csv_second_largeQP1_listsA[6], pkl_second_largeQP1_listsA[6], csv_second_recompress_largeQP1_listsA[6], pkl_second_recompress_largeQP1_listsA[6]))\n",
    "second_largeQP1_csv8 = list(zip(csv_second_largeQP1_listsA[7], pkl_second_largeQP1_listsA[7], csv_second_recompress_largeQP1_listsA[7], pkl_second_recompress_largeQP1_listsA[7]))\n",
    "second_largeQP1_csv9 = list(zip(csv_second_largeQP1_listsA[8], pkl_second_largeQP1_listsA[8], csv_second_recompress_largeQP1_listsA[8], pkl_second_recompress_largeQP1_listsA[8]))\n",
    "second_largeQP1_csv10 = list(zip(csv_second_largeQP1_listsA[9], pkl_second_largeQP1_listsA[9], csv_second_recompress_largeQP1_listsA[9], pkl_second_recompress_largeQP1_listsA[9]))\n",
    "print(len(second_largeQP1_csv1))\n",
    "\n",
    "\n",
    "second_largeQP1_csv1 = random.sample(second_largeQP1_csv1, 100)\n",
    "second_largeQP1_csv2 = random.sample(second_largeQP1_csv2, 100)\n",
    "second_largeQP1_csv3 = random.sample(second_largeQP1_csv3, 100)\n",
    "second_largeQP1_csv4 = random.sample(second_largeQP1_csv4, 100)\n",
    "second_largeQP1_csv5 = random.sample(second_largeQP1_csv5, 100)\n",
    "second_largeQP1_csv6 = random.sample(second_largeQP1_csv6, 100)\n",
    "second_largeQP1_csv7 = random.sample(second_largeQP1_csv7, 100)\n",
    "second_largeQP1_csv8 = random.sample(second_largeQP1_csv8, 100)\n",
    "second_largeQP1_csv9 = random.sample(second_largeQP1_csv9, 100)\n",
    "# second_largeQP1_csv10 = selected_data[9]\n",
    "print('\\ndouble images train by QP1>QP2: ', len(second_largeQP1_csv1))\n",
    "\n",
    "\n",
    "second_largeQP1_csv10 = random.sample(second_largeQP1_csv10, 300)\n",
    "print('\\ndouble images test by QP1>QP2: ', len(second_largeQP1_csv10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "\n",
      "double images train by QP1=QP2:  100\n",
      "\n",
      "double images test by QP1=QP2:  300\n"
     ]
    }
   ],
   "source": [
    "# sameQP\n",
    "second_sameQP_csv1 = list(zip(csv_second_sameQP_listsA[0], pkl_second_sameQP_listsA[0], csv_second_recompress_sameQP_listsA[0], pkl_second_recompress_sameQP_listsA[0]))\n",
    "second_sameQP_csv2 = list(zip(csv_second_sameQP_listsA[1], pkl_second_sameQP_listsA[1], csv_second_recompress_sameQP_listsA[1], pkl_second_recompress_sameQP_listsA[1]))\n",
    "second_sameQP_csv3 = list(zip(csv_second_sameQP_listsA[2], pkl_second_sameQP_listsA[2], csv_second_recompress_sameQP_listsA[2], pkl_second_recompress_sameQP_listsA[2]))\n",
    "second_sameQP_csv4 = list(zip(csv_second_sameQP_listsA[3], pkl_second_sameQP_listsA[3], csv_second_recompress_sameQP_listsA[3], pkl_second_recompress_sameQP_listsA[3]))\n",
    "second_sameQP_csv5 = list(zip(csv_second_sameQP_listsA[4], pkl_second_sameQP_listsA[4], csv_second_recompress_sameQP_listsA[4], pkl_second_recompress_sameQP_listsA[4]))\n",
    "second_sameQP_csv6 = list(zip(csv_second_sameQP_listsA[5], pkl_second_sameQP_listsA[5], csv_second_recompress_sameQP_listsA[5], pkl_second_recompress_sameQP_listsA[5]))\n",
    "second_sameQP_csv7 = list(zip(csv_second_sameQP_listsA[6], pkl_second_sameQP_listsA[6], csv_second_recompress_sameQP_listsA[6], pkl_second_recompress_sameQP_listsA[6]))\n",
    "second_sameQP_csv8 = list(zip(csv_second_sameQP_listsA[7], pkl_second_sameQP_listsA[7], csv_second_recompress_sameQP_listsA[7], pkl_second_recompress_sameQP_listsA[7]))\n",
    "second_sameQP_csv9 = list(zip(csv_second_sameQP_listsA[8], pkl_second_sameQP_listsA[8], csv_second_recompress_sameQP_listsA[8], pkl_second_recompress_sameQP_listsA[8]))\n",
    "second_sameQP_csv10 = list(zip(csv_second_sameQP_listsA[9], pkl_second_sameQP_listsA[9], csv_second_recompress_sameQP_listsA[9], pkl_second_recompress_sameQP_listsA[9]))\n",
    "print(len(second_sameQP_csv10))\n",
    "\n",
    "second_sameQP_csv1 = random.sample(second_sameQP_csv1, 100)\n",
    "second_sameQP_csv2 = random.sample(second_sameQP_csv2, 100)\n",
    "second_sameQP_csv3 = random.sample(second_sameQP_csv3, 100)\n",
    "second_sameQP_csv4 = random.sample(second_sameQP_csv4, 100)\n",
    "second_sameQP_csv5 = random.sample(second_sameQP_csv5, 100)\n",
    "second_sameQP_csv6 = random.sample(second_sameQP_csv6, 100)\n",
    "second_sameQP_csv7 = random.sample(second_sameQP_csv7, 100)\n",
    "second_sameQP_csv8 = random.sample(second_sameQP_csv8, 100)\n",
    "second_sameQP_csv9 = random.sample(second_sameQP_csv9, 100)\n",
    "print('\\ndouble images train by QP1=QP2: ',len(second_sameQP_csv9))\n",
    "\n",
    "second_sameQP_csv10 = random.sample(second_sameQP_csv10, 300)\n",
    "print('\\ndouble images test by QP1=QP2: ',len(second_sameQP_csv10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1170\n",
      "\n",
      "double images train by QP1<QP2:  100\n",
      "\n",
      "double images test by QP1<QP2:  300\n"
     ]
    }
   ],
   "source": [
    "# Large_QP2\n",
    "second_largeQP2_csv1 = list(zip(csv_second_largeQP2_listsA[0], pkl_second_largeQP2_listsA[0], csv_second_recompress_largeQP2_listsA[0], pkl_second_recompress_largeQP2_listsA[0]))\n",
    "second_largeQP2_csv2 = list(zip(csv_second_largeQP2_listsA[1], pkl_second_largeQP2_listsA[1], csv_second_recompress_largeQP2_listsA[1], pkl_second_recompress_largeQP2_listsA[1]))\n",
    "second_largeQP2_csv3 = list(zip(csv_second_largeQP2_listsA[2], pkl_second_largeQP2_listsA[2], csv_second_recompress_largeQP2_listsA[2], pkl_second_recompress_largeQP2_listsA[2]))\n",
    "second_largeQP2_csv4 = list(zip(csv_second_largeQP2_listsA[3], pkl_second_largeQP2_listsA[3], csv_second_recompress_largeQP2_listsA[3], pkl_second_recompress_largeQP2_listsA[3]))\n",
    "second_largeQP2_csv5 = list(zip(csv_second_largeQP2_listsA[4], pkl_second_largeQP2_listsA[4], csv_second_recompress_largeQP2_listsA[4], pkl_second_recompress_largeQP2_listsA[4]))\n",
    "second_largeQP2_csv6 = list(zip(csv_second_largeQP2_listsA[5], pkl_second_largeQP2_listsA[5], csv_second_recompress_largeQP2_listsA[5], pkl_second_recompress_largeQP2_listsA[5]))\n",
    "second_largeQP2_csv7 = list(zip(csv_second_largeQP2_listsA[6], pkl_second_largeQP2_listsA[6], csv_second_recompress_largeQP2_listsA[6], pkl_second_recompress_largeQP2_listsA[6]))\n",
    "second_largeQP2_csv8 = list(zip(csv_second_largeQP2_listsA[7], pkl_second_largeQP2_listsA[7], csv_second_recompress_largeQP2_listsA[7], pkl_second_recompress_largeQP2_listsA[7]))\n",
    "second_largeQP2_csv9 = list(zip(csv_second_largeQP2_listsA[8], pkl_second_largeQP2_listsA[8], csv_second_recompress_largeQP2_listsA[8], pkl_second_recompress_largeQP2_listsA[8]))\n",
    "second_largeQP2_csv10 = list(zip(csv_second_largeQP2_listsA[9], pkl_second_largeQP2_listsA[9], csv_second_recompress_largeQP2_listsA[9], pkl_second_recompress_largeQP2_listsA[9]))\n",
    "print(len(second_largeQP2_csv1))\n",
    "\n",
    "second_largeQP2_csv1 = random.sample(second_largeQP2_csv1, 100)\n",
    "second_largeQP2_csv2 = random.sample(second_largeQP2_csv2, 100)\n",
    "second_largeQP2_csv3 = random.sample(second_largeQP2_csv3, 100)\n",
    "second_largeQP2_csv4 = random.sample(second_largeQP2_csv4, 100)\n",
    "second_largeQP2_csv5 = random.sample(second_largeQP2_csv5, 100)\n",
    "second_largeQP2_csv6 = random.sample(second_largeQP2_csv6, 100)\n",
    "second_largeQP2_csv7 = random.sample(second_largeQP2_csv7, 100)\n",
    "second_largeQP2_csv8 = random.sample(second_largeQP2_csv8, 100)\n",
    "second_largeQP2_csv9 = random.sample(second_largeQP2_csv9, 100)\n",
    "# second_largeQP2_csv10 = selected_data[9]\n",
    "print('\\ndouble images train by QP1<QP2: ', len(second_largeQP2_csv1))\n",
    "\n",
    "second_largeQP2_csv10 = random.sample(second_largeQP2_csv10, 300)\n",
    "print('\\ndouble images test by QP1<QP2: ', len(second_largeQP2_csv10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_csv_list:  600\n",
      "\n",
      "test_csv_largeQP1 600\n",
      "test_csv_sameQP 600\n",
      "test_csv_largeQP2 600\n"
     ]
    }
   ],
   "source": [
    "train_csv_list1 = single_csv1 + second_largeQP1_csv1 + second_sameQP_csv1 + second_largeQP2_csv1\n",
    "train_csv_list2 = single_csv2 + second_largeQP1_csv2 + second_sameQP_csv2 + second_largeQP2_csv2\n",
    "train_csv_list3 = single_csv3 + second_largeQP1_csv3 + second_sameQP_csv3 + second_largeQP2_csv3\n",
    "train_csv_list4 = single_csv4 + second_largeQP1_csv4 + second_sameQP_csv4 + second_largeQP2_csv4\n",
    "train_csv_list5 = single_csv5 + second_largeQP1_csv5 + second_sameQP_csv5 + second_largeQP2_csv5\n",
    "train_csv_list6 = single_csv6 + second_largeQP1_csv6 + second_sameQP_csv6 + second_largeQP2_csv6\n",
    "train_csv_list7 = single_csv7 + second_largeQP1_csv7 + second_sameQP_csv7 + second_largeQP2_csv7\n",
    "train_csv_list8 = single_csv8 + second_largeQP1_csv8 + second_sameQP_csv8 + second_largeQP2_csv8\n",
    "train_csv_list9 = single_csv9 + second_largeQP1_csv9 + second_sameQP_csv9 + second_largeQP2_csv9\n",
    "print(\"train_csv_list: \", len(train_csv_list9))\n",
    "\n",
    "test_csv_largeQP1 = single_csv10 + second_largeQP1_csv10\n",
    "test_csv_sameQP = single_csv10 + second_sameQP_csv10\n",
    "test_csv_largeQP2 = single_csv10 + second_largeQP2_csv10\n",
    "\n",
    "print(\"\\ntest_csv_largeQP1\", len(test_csv_largeQP1))\n",
    "print(\"test_csv_sameQP\", len(test_csv_sameQP))\n",
    "print(\"test_csv_largeQP2\", len(test_csv_largeQP2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_smoothing(probabilities, alpha=1):\n",
    "    \"\"\"\n",
    "    ラプラス平滑化を行う関数\n",
    "    \n",
    "    Args:\n",
    "    probabilities (list): 平滑化する確率分布のリスト\n",
    "    alpha (float): 平滑化パラメータ\n",
    "    \n",
    "    Returns:\n",
    "    smoothed_probabilities (list): 平滑化された確率分布のリスト\n",
    "    \"\"\"\n",
    "    total_count = sum(probabilities)\n",
    "    num_elements = len(probabilities)\n",
    "    \n",
    "    smoothed_probabilities = [(count + alpha) / (total_count + alpha * num_elements) for count in probabilities]\n",
    "    \n",
    "    return smoothed_probabilities\n",
    "\n",
    "\n",
    "def process_train_csv_lists(train_csv_list):\n",
    "    pu_columns = [\"PU1_64\", \"PU1_32\", \"PU1_16\", \"PU1_8\", \"PU1_4\",  \n",
    "                  \"PU2_64\",\"PU2_32\", \"PU2_16\", \"PU2_8\", \"PU2_4\"]\n",
    "\n",
    "#     luminance_columns = [\"LU1_0\",\"LU1_1\",\"LU1_2\",\"LU1_3\",\n",
    "#                          \"LU1_4\",\"LU1_5\",\"LU1_6\",\"LU1_7\",\n",
    "#                          \"LU1_8\",\"LU1_9\",\"LU1_10\",\"LU1_11\",\n",
    "#                          \"LU1_12\",\"LU1_13\",\"LU1_14\",\"LU1_15\",\n",
    "#                          \"LU1_16\",\"LU1_17\",\"LU1_18\",\"LU1_19\",\n",
    "#                          \"LU1_20\",\"LU1_21\",\"LU1_22\",\"LU1_23\",\n",
    "#                          \"LU1_24\",\"LU1_25\",\"LU1_26\",\"LU1_27\",\n",
    "#                          \"LU1_28\",\"LU1_29\",\"LU1_30\",\"LU1_31\",\n",
    "#                          \"LU1_32\",\"LU1_33\",\"LU1_34\",\n",
    "                         \n",
    "#                          \"LU2_0\",\"LU2_1\",\"LU2_2\",\"LU2_3\",\n",
    "#                          \"LU2_4\",\"LU2_5\",\"LU2_6\",\"LU2_7\",\n",
    "#                          \"LU2_8\",\"LU2_9\",\"LU2_10\",\"LU2_11\",\n",
    "#                          \"LU2_12\",\"LU2_13\",\"LU2_14\",\"LU2_15\",\n",
    "#                          \"LU2_16\",\"LU2_17\",\"LU2_18\",\"LU2_19\",\n",
    "#                          \"LU2_20\",\"LU2_21\",\"LU2_22\",\"LU2_23\",\n",
    "#                          \"LU2_24\",\"LU2_25\",\"LU2_26\",\"LU2_27\",\n",
    "#                          \"LU2_28\",\"LU2_29\",\"LU2_30\",\"LU2_31\",\n",
    "#                          \"LU2_32\",\"LU2_33\",\"LU2_34\"]\n",
    "    \n",
    "    luminance_columns = [\"LU1_0\",\"LU1_1\",\"LU1_9\",\"LU1_10\",\"LU1_11\",\"LU1_25\",\"LU1_26\",\"LU1_27\",\n",
    "                         \"LU2_0\",\"LU2_1\",\"LU2_9\",\"LU2_10\",\"LU2_11\", \"LU2_25\",\"LU2_26\",\"LU2_27\"]\n",
    "\n",
    "    chrominance_columns = [\"CH1_0\", \"CH1_1\", \"CH1_10\", \"CH1_26\", \"CH1_34\", \"CH1_36\", \n",
    "                           \"CH2_0\", \"CH2_1\", \"CH2_10\", \"CH2_26\", \"CH2_34\", \"CH2_36\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    label_columns = [\"LABEL\"]\n",
    "    mae1_columns = [f\"MAE1_{i}\" for i in range(52)]\n",
    "    mae2_columns = [f\"MAE2_{i}\" for i in range(52)]\n",
    "    mae_columns = [\"MAE\"]\n",
    "    final_qp_columns = [\"FINAL_QP\"]\n",
    "    kl_divergence1 = [\"KLD_PU\"]\n",
    "    kl_divergence2 = [\"KLD_LUMA\"]\n",
    "    kl_divergence3 = [\"KLD_CHROMA\"]\n",
    "    ratio_columns1 = [\"RATIO1\"]\n",
    "    ratio_columns2 = [\"RATIO2\"]\n",
    "    \n",
    "    train_df1_1 = pd.DataFrame(columns=pu_columns)\n",
    "    train_df1_2 = pd.DataFrame(columns=luminance_columns)\n",
    "    train_df1_3 = pd.DataFrame(columns=chrominance_columns)\n",
    "    LABEL = pd.DataFrame(columns=label_columns)\n",
    "    RATIO1 = pd.DataFrame(columns=ratio_columns1)\n",
    "    RATIO2 = pd.DataFrame(columns=ratio_columns2)\n",
    "    train_df3 = pd.DataFrame(columns=mae1_columns)\n",
    "    train_df4 = pd.DataFrame(columns=mae2_columns)\n",
    "    MAE = pd.DataFrame(columns=mae_columns)\n",
    "    FINAL_QP = pd.DataFrame(columns=final_qp_columns)\n",
    "    kl_divergence_df1 = pd.DataFrame(columns=kl_divergence1)\n",
    "    kl_divergence_df2 = pd.DataFrame(columns=kl_divergence2)\n",
    "    kl_divergence_df3 = pd.DataFrame(columns=kl_divergence3)\n",
    "\n",
    "    for path1, path2, path3, path4 in train_csv_list:\n",
    "        label = 1 if (\"2ndQP\" in path1) and (\"3rdQP\" in path3) else 0\n",
    "        train_pkl_list = [path2, path4]\n",
    "        df1 = pd.read_csv(path1)\n",
    "        df2 = pd.read_csv(path3)\n",
    "        \n",
    "        # 平滑化を行う\n",
    "        probabilities_df1 = laplace_smoothing([df1.loc[i, \"pu_counts\"] for i in [0,1,2,3,4]])\n",
    "        probabilities_df2 = laplace_smoothing([df2.loc[i, \"pu_counts\"] for i in [0,1,2,3,4]])\n",
    "        kl_divergence1 = entropy(probabilities_df1, probabilities_df2)\n",
    "        \n",
    "        probabilities_df3 = laplace_smoothing([df1.loc[i, \"luminance_counts\"] for i in [0,1,9,10,11,25,26,27]])\n",
    "        probabilities_df4 = laplace_smoothing([df2.loc[i, \"luminance_counts\"] for i in [0,1,9,10,11,25,26,27]])\n",
    "        kl_divergence2 = entropy(probabilities_df3, probabilities_df4)\n",
    "        \n",
    "        probabilities_df5 = laplace_smoothing([df1.loc[i, \"chroma_counts\"] for i in [0,1,10,26,34,36]])\n",
    "        probabilities_df6 = laplace_smoothing([df2.loc[i, \"chroma_counts\"] for i in [0,1,10,26,34,36]])\n",
    "        kl_divergence3 = entropy(probabilities_df5, probabilities_df6)\n",
    "        \n",
    "        \n",
    "        pu_values = [df1.loc[i, \"pu_counts\"] for i in range(5)] + [df2.loc[i, \"pu_counts\"] for i in range(5)]\n",
    "        # lu_values = [df1.loc[i, \"luminance_counts\"] for i in range(35)] + [df2.loc[i, \"luminance_counts\"] for i in range(35)]\n",
    "        lu_values = [df1.loc[i, \"luminance_counts\"] for i in [0,1,9,10,11,25,26,27]] + [df2.loc[i, \"luminance_counts\"] for i in [0,1,9,10,11,25,26,27]]\n",
    "        ch_values = [df1.loc[i, \"chroma_counts\"] for i in [0,1,10,26,34,36]] + [df2.loc[i, \"chroma_counts\"] for i in [0,1,10,26,34,36]]\n",
    "        \n",
    "        train_df1_1 = pd.concat([train_df1_1, pd.DataFrame([pu_values], columns=pu_columns)], ignore_index=True)\n",
    "        train_df1_2= pd.concat([train_df1_2, pd.DataFrame([lu_values], columns=luminance_columns)], ignore_index=True)\n",
    "        train_df1_3 = pd.concat([train_df1_3, pd.DataFrame([ch_values], columns=chrominance_columns)], ignore_index=True)\n",
    "        \n",
    "        kl_divergence_df1 = pd.concat([kl_divergence_df1, pd.DataFrame({\"KLD_PU\": [kl_divergence1]})], ignore_index=True)\n",
    "        kl_divergence_df2 = pd.concat([kl_divergence_df2, pd.DataFrame({\"KLD_LUMA\": [kl_divergence2]})], ignore_index=True)\n",
    "        kl_divergence_df3 = pd.concat([kl_divergence_df3, pd.DataFrame({\"KLD_CHROMA\": [kl_divergence3]})], ignore_index=True)\n",
    "\n",
    "\n",
    "        LABEL = pd.concat([LABEL, pd.DataFrame({\"LABEL\": [label]})], ignore_index=True)\n",
    "\n",
    "        final_QP = extract_finalQP(train_pkl_list[0])\n",
    "\n",
    "        mae_d1 = calculate_mae(train_pkl_list[0])\n",
    "        mae_d2 = calculate_mae(train_pkl_list[1])\n",
    "        ratio1 = ratio_double_compressed(mae_d1, final_QP)\n",
    "        ratio2 = ratio_double_compressed(mae_d2, final_QP)\n",
    "\n",
    "        RATIO1 = pd.concat([RATIO1, pd.DataFrame({\"RATIO1\": [ratio1]})], ignore_index=True)\n",
    "        RATIO2 = pd.concat([RATIO2, pd.DataFrame({\"RATIO2\": [ratio2]})], ignore_index=True)\n",
    "\n",
    "        train_df3 = pd.concat([train_df3, pd.DataFrame({f\"MAE1_{i}\": [mae_d1[i]] for i in range(52)})], ignore_index=True)\n",
    "        train_df4 = pd.concat([train_df4, pd.DataFrame({f\"MAE2_{i}\": [mae_d2[i]] for i in range(52)})], ignore_index=True)\n",
    "        MAE = pd.concat([MAE, pd.DataFrame({\"MAE\": [mae_d1]})], ignore_index=True)\n",
    "        FINAL_QP = pd.concat([FINAL_QP, pd.DataFrame({\"FINAL_QP\": [final_QP]})], ignore_index=True)\n",
    "\n",
    "    train_df1_1.reset_index(drop=True, inplace=True)\n",
    "    train_df1_2.reset_index(drop=True, inplace=True)\n",
    "    train_df1_3.reset_index(drop=True, inplace=True)\n",
    "    LABEL.reset_index(drop=True, inplace=True)\n",
    "    RATIO1.reset_index(drop=True, inplace=True)\n",
    "    RATIO2.reset_index(drop=True, inplace=True)\n",
    "    kl_divergence_df1.reset_index(drop=True, inplace=True)\n",
    "    kl_divergence_df2.reset_index(drop=True, inplace=True)\n",
    "    kl_divergence_df3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # train_df = pd.concat([train_df1_1, train_df1_2, train_df1_3, train_df3, train_df4], axis=1)\n",
    "    train_df = pd.concat([FINAL_QP, train_df1_1, train_df1_2, train_df1_3, kl_divergence_df1, kl_divergence_df2, kl_divergence_df3, RATIO1, RATIO2], axis=1)\n",
    "    train_df_onlyGhost = pd.concat([FINAL_QP, kl_divergence_df1, kl_divergence_df2, kl_divergence_df3, RATIO1, RATIO2], axis=1)\n",
    "\n",
    "    return train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1, train_df_onlyGhost1, LABEL1, MAE1, FINAL_QP1 = process_train_csv_lists(train_csv_list1)\n",
    "train_df2, train_df_onlyGhost2, LABEL2, MAE2, FINAL_QP2 = process_train_csv_lists(train_csv_list2)\n",
    "train_df3, train_df_onlyGhost3, LABEL3, MAE3, FINAL_QP3 = process_train_csv_lists(train_csv_list3)\n",
    "train_df4, train_df_onlyGhost4, LABEL4, MAE4, FINAL_QP4 = process_train_csv_lists(train_csv_list4)\n",
    "train_df5, train_df_onlyGhost5, LABEL5, MAE5, FINAL_QP5 = process_train_csv_lists(train_csv_list5)\n",
    "train_df6, train_df_onlyGhost6, LABEL6, MAE6, FINAL_QP6 = process_train_csv_lists(train_csv_list6)\n",
    "train_df7, train_df_onlyGhost7, LABEL7, MAE7, FINAL_QP7 = process_train_csv_lists(train_csv_list7)\n",
    "train_df8, train_df_onlyGhost8, LABEL8, MAE8, FINAL_QP8 = process_train_csv_lists(train_csv_list8)\n",
    "train_df9, train_df_onlyGhost9, LABEL9, MAE9, FINAL_QP9 = process_train_csv_lists(train_csv_list9)\n",
    "\n",
    "test_df1, test_df_onlyGhost1, LABEL_t1, MAE_t1, FINAL_QP_t1 = process_train_csv_lists(test_csv_largeQP1)\n",
    "test_df2, test_df_onlyGhost2, LABEL_t2, MAE_t2, FINAL_QP_t2 = process_train_csv_lists(test_csv_sameQP)\n",
    "test_df3, test_df_onlyGhost3, LABEL_t3, MAE_t3, FINAL_QP_t3 = process_train_csv_lists(test_csv_largeQP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各データフレームを結合\n",
    "combined_train_df = pd.concat([train_df1, train_df2, train_df3, train_df4, train_df5, train_df6, train_df7, train_df8, train_df9], ignore_index=True)\n",
    "combined_train_df_onlyGhost = pd.concat([train_df_onlyGhost1, train_df_onlyGhost2, train_df_onlyGhost3, train_df_onlyGhost4, train_df_onlyGhost5, train_df_onlyGhost6, train_df_onlyGhost7, train_df_onlyGhost8, train_df_onlyGhost9], ignore_index=True)\n",
    "combined_LABEL = pd.concat([LABEL1, LABEL2, LABEL3, LABEL4, LABEL5, LABEL6, LABEL7, LABEL8, LABEL9], ignore_index=True)\n",
    "combined_MAE = pd.concat([MAE1, MAE2, MAE3, MAE4, MAE5, MAE6, MAE7, MAE8, MAE9], ignore_index=True)\n",
    "combined_FINAL_QP = pd.concat([FINAL_QP1, FINAL_QP2, FINAL_QP3, FINAL_QP4, FINAL_QP5, FINAL_QP6, FINAL_QP7, FINAL_QP8, FINAL_QP9], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5400, 44)\n",
      "(5400, 6)\n",
      "(5400, 1)\n",
      "(5400, 1)\n",
      "(5400, 1)\n",
      "(600, 44)\n",
      "(600, 6)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 44)\n",
      "(600, 6)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 44)\n",
      "(600, 6)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 1)\n"
     ]
    }
   ],
   "source": [
    "print(combined_train_df.shape)\n",
    "print(combined_train_df_onlyGhost.shape)\n",
    "print(combined_LABEL.shape)\n",
    "print(combined_MAE.shape)\n",
    "print(combined_FINAL_QP.shape)\n",
    "\n",
    "print(test_df1.shape)\n",
    "print(test_df_onlyGhost1.shape)\n",
    "print(LABEL_t1.shape)\n",
    "print(MAE_t1.shape)\n",
    "print(FINAL_QP_t1.shape)\n",
    "\n",
    "print(test_df2.shape)\n",
    "print(test_df_onlyGhost2.shape)\n",
    "print(LABEL_t2.shape)\n",
    "print(MAE_t2.shape)\n",
    "print(FINAL_QP_t2.shape)\n",
    "\n",
    "print(test_df3.shape)\n",
    "print(test_df_onlyGhost3.shape)\n",
    "print(LABEL_t3.shape)\n",
    "print(MAE_t3.shape)\n",
    "print(FINAL_QP_t3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling:\n",
      "Combined Train DF:\n",
      "  FINAL_QP PU1_64 PU1_32 PU1_16  PU1_8  PU1_4 PU2_64 PU2_32 PU2_16  PU2_8  PU2_4  LU1_0  LU1_1 LU1_9 LU1_10 LU1_11 LU1_25 LU1_26 LU1_27  LU2_0  LU2_1 LU2_9 LU2_10 LU2_11 LU2_25 LU2_26 LU2_27  CH1_0  CH1_1 CH1_10 CH1_26 CH1_34 CH1_36  CH2_0  CH2_1 CH2_10 CH2_26 CH2_34 CH2_36    KLD_PU  KLD_LUMA KLD_CHROMA    RATIO1    RATIO2\n",
      "0       10      0    128   1936  12980  44956      0    128   1920  11756  46196   9444   6169  1471   2421   1397   1423   2103   1288   9389   6435  1488   2426   1365   1417   2149   1285  18760  11308   7924   6528   1764  13716  18912  11852   8064   6624   1664  12884  0.001308  0.000219   0.000741  0.028141  0.021918\n",
      "1       16      0   1344   3632  19104  35920      0   1344   3600  18464  36592  10004   7635  1394   2359   1364   1314   2103   1350  10107   7641  1400   2338   1385   1308   2066   1334  18472   9956   6156   5164   1660  18592  18240  11016   6268   4980   1504  17992  0.000289  0.000043   0.001271  0.010647   0.00711\n",
      "2       20      0   3776   6688  19600  29936      0   3712   6544  19236  30508  11117   9067  1296   2145   1295   1340   2123   1185  11148   9172  1337   2119   1250   1245   2240   1181  16784   9160   6076   4468   1604  21908  16980   9224   6256   4472   1456  21612  0.000182  0.000292   0.000221  0.022154  0.016684\n",
      "3       24      0   6784   8480  19652  25084      0   6784   8416  18916  25884  12769  11294  1277   1837   1082    992   1978    939  12918  11374  1265   1790   1091    995   2048    885  14672   6560   5768   3932   2056  27012  14068   6632   5744   3640   1812  28104  0.000448  0.000127   0.001031  0.004564  0.002751\n",
      "4       27      0  10624  11408  16644  21324      0  10496  11504  16164  21836  15197  13073  1289   1675    883    960   1844    846  15323  13464  1303   1597    910    953   1837    839  12868   5772   5000   3580   1980  30800  12108   5284   4272   2888   1644  33804  0.000238  0.000161   0.005845   0.26171  0.219067\n",
      "Combined Train DF Only Ghost:\n",
      "  FINAL_QP    KLD_PU  KLD_LUMA KLD_CHROMA    RATIO1    RATIO2\n",
      "0       10  0.001308  0.000219   0.000741  0.028141  0.021918\n",
      "1       16  0.000289  0.000043   0.001271  0.010647   0.00711\n",
      "2       20  0.000182  0.000292   0.000221  0.022154  0.016684\n",
      "3       24  0.000448  0.000127   0.001031  0.004564  0.002751\n",
      "4       27  0.000238  0.000161   0.005845   0.26171  0.219067\n",
      "\n",
      "Before scaling:\n",
      "Combined Test DF:\n",
      "  FINAL_QP PU1_64 PU1_32 PU1_16  PU1_8  PU1_4 PU2_64 PU2_32 PU2_16  PU2_8  PU2_4 LU1_0 LU1_1 LU1_9 LU1_10 LU1_11 LU1_25 LU1_26 LU1_27 LU2_0 LU2_1 LU2_9 LU2_10 LU2_11 LU2_25 LU2_26 LU2_27  CH1_0  CH1_1 CH1_10 CH1_26 CH1_34 CH1_36  CH2_0  CH2_1 CH2_10 CH2_26 CH2_34 CH2_36    KLD_PU  KLD_LUMA KLD_CHROMA    RATIO1    RATIO2\n",
      "0       10      0   1088   5488  18948  34476      0   1024   5536  17660  35780  7237  5201  3526   5124   4668    925   1643    957  7260  5411  3435   5137   4681    900   1720    982  14716  10468   9216   4404   1360  19836  14768  10944   9524   4516   1264  18984  0.001201  0.000232   0.000657  0.036296  0.025688\n",
      "1       16      0   8384   6288  17140  28188      0   8384   6304  16240  29072  7367  6166  3798   4980   4966    989   1733    957  7394  6294  3824   4956   4961    982   1733    992  13180   9548   6508   3384   1500  25880  12660  10468   6504   3156   1228  25984  0.000635  0.000053   0.001476   0.01721  0.010179\n",
      "2       20      0  10240   9712  16328  23720      0  10240   9680  15464  24616  7596  7975  3090   4871   5080    972   1713   1244  7786  8062  3032   4792   5205    965   1684   1269  13148   7060   5220   2944   1228  30400  12604   7188   4912   2852   1060  31384  0.000671  0.000155   0.000865  0.011421  0.008689\n",
      "3       24      0  13248  10144  15392  21216      0  13248  10064  15012  21676  9307  7353  3238   4649   5619    913   1438   1492  9643  7549  3213   4562   5726    910   1359   1504  10824   5004   4072   2456   1324  36320  10308   5056   3788   2524   1336  36988  0.000167  0.000284   0.000507  0.006422  0.003509\n",
      "4       27      0  14272  10912  16820  17996      0  14272  11056  16212  18460  9056  7543  3663   4173   5370   1076   1487   1399  9116  7712  3686   4057   5496   1055   1495   1365   9752   3540   3648   2488   1380  39192   9104   3452   2872   2324   1204  41044  0.000301  0.000154   0.003007   0.21288  0.177539\n",
      "Combined Test DF Only Ghost:\n",
      "  FINAL_QP    KLD_PU  KLD_LUMA KLD_CHROMA    RATIO1    RATIO2\n",
      "0       10  0.001201  0.000232   0.000657  0.036296  0.025688\n",
      "1       16  0.000635  0.000053   0.001476   0.01721  0.010179\n",
      "2       20  0.000671  0.000155   0.000865  0.011421  0.008689\n",
      "3       24  0.000167  0.000284   0.000507  0.006422  0.003509\n",
      "4       27  0.000301  0.000154   0.003007   0.21288  0.177539\n"
     ]
    }
   ],
   "source": [
    "print(\"Before scaling:\")\n",
    "print(\"Combined Train DF:\")\n",
    "print(combined_train_df.head())\n",
    "print(\"Combined Train DF Only Ghost:\")\n",
    "print(combined_train_df_onlyGhost.head())\n",
    "\n",
    "print(\"\\nBefore scaling:\")\n",
    "print(\"Combined Test DF:\")\n",
    "print(test_df1.head())\n",
    "print(\"Combined Test DF Only Ghost:\")\n",
    "print(test_df_onlyGhost1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After scaling:\n",
      "X_train:\n",
      "      0    1         2         3         4         5    6         7         8         9         10        11        12        13        14        15        16        17        18        19        20        21        22        23        24        25        26        27        28        29        30        31        32        33        34        35        36        37        38        39        40        41        42        43\n",
      "0  0.125  0.0  0.002174  0.062893  0.452391  0.790255  0.0  0.002172  0.062665  0.401283  0.805426  0.198165  0.149605  0.111934  0.120123  0.114403  0.101080  0.071502  0.186775  0.216149  0.151496  0.114228  0.116396  0.113511  0.095530  0.066384  0.162329  0.607434  0.446957  0.381402  0.368647  0.160247  0.151437  0.629393  0.466320  0.362851  0.364597  0.160062  0.147438  0.058560  0.001235  0.007529  0.026047  0.020472\n",
      "1  0.275  0.0  0.022826  0.118449  0.665830  0.631416  0.0  0.022801  0.117957  0.630257  0.637980  0.216133  0.202024  0.106055  0.117042  0.111687  0.093337  0.071502  0.195766  0.241733  0.194647  0.107446  0.112072  0.115179  0.088182  0.063423  0.168519  0.598109  0.393518  0.296303  0.291620  0.150799  0.240833  0.607029  0.433428  0.282037  0.274108  0.144671  0.239867  0.012922  0.000220  0.012960  0.008516  0.005641\n",
      "2  0.375  0.0  0.064130  0.218553  0.683117  0.526227  0.0  0.062975  0.214850  0.656608  0.531906  0.251845  0.253227  0.098572  0.106406  0.106008  0.095184  0.072298  0.171839  0.278827  0.249428  0.102590  0.101312  0.103920  0.083934  0.069630  0.149192  0.543453  0.362055  0.292453  0.252315  0.145712  0.301628  0.565096  0.362921  0.281497  0.246147  0.140054  0.305371  0.008164  0.001656  0.002202  0.020047  0.015230\n",
      "3  0.475  0.0  0.115217  0.277254  0.684930  0.440937  0.0  0.115092  0.276461  0.645685  0.451287  0.304851  0.332857  0.097121  0.091099  0.088477  0.070465  0.066529  0.136166  0.341897  0.328217  0.097040  0.085147  0.090659  0.067080  0.062781  0.111799  0.475068  0.259289  0.277628  0.222047  0.186773  0.395204  0.468184  0.260938  0.258459  0.200352  0.174298  0.422843  0.020052  0.000703  0.010501  0.002420  0.001276\n",
      "4  0.550  0.0  0.180435  0.373166  0.580092  0.374842  0.0  0.178067  0.378094  0.551748  0.380710  0.382757  0.396467  0.098038  0.083048  0.072099  0.068192  0.061197  0.122680  0.427594  0.402998  0.099969  0.075665  0.075563  0.064249  0.055254  0.105988  0.416656  0.228142  0.240662  0.202169  0.179869  0.464652  0.402955  0.207901  0.192225  0.158961  0.158138  0.525984  0.010661  0.000901  0.059840  0.260122  0.217918\n",
      "X_train_onlyGhost:\n",
      "       0         1         2         3         4         5\n",
      "0  0.125  0.058560  0.001235  0.007529  0.026047  0.020472\n",
      "1  0.275  0.012922  0.000220  0.012960  0.008516  0.005641\n",
      "2  0.375  0.008164  0.001656  0.002202  0.020047  0.015230\n",
      "3  0.475  0.020052  0.000703  0.010501  0.002420  0.001276\n",
      "4  0.550  0.010661  0.000901  0.059840  0.260122  0.217918\n",
      "\n",
      "Test data after scaling:\n",
      "X_test_list1:\n",
      "      0    1         2         3         4         5    6         7         8         9         10        11        12        13        14        15        16        17        18        19        20        21        22        23        24        25        26        27        28        29        30        31        32        33        34        35        36        37        38        39        40        41        42        43\n",
      "0  0.125  0.0  0.018478  0.179245  0.660393  0.606033  0.0  0.017372  0.181675  0.602813  0.623823  0.127350  0.114993  0.268840  0.254461  0.383621  0.065705  0.053199  0.138776  0.140286  0.114856  0.264298  0.249595  0.390075  0.060676  0.051081  0.124053  0.476493  0.413755  0.443589  0.248701  0.123547  0.263640  0.491480  0.430595  0.428546  0.248569  0.121585  0.257817  0.053795  0.001310  0.006669  0.034220  0.024247\n",
      "1  0.275  0.0  0.142391  0.205451  0.597379  0.495500  0.0  0.142237  0.206951  0.554342  0.506869  0.131522  0.149498  0.289608  0.247304  0.408148  0.070251  0.056780  0.138776  0.145061  0.146451  0.294281  0.240702  0.413428  0.066204  0.051545  0.125316  0.426758  0.377391  0.313246  0.191100  0.136265  0.374450  0.421326  0.411867  0.292657  0.173712  0.118122  0.384482  0.028423  0.000278  0.015059  0.015093  0.008715\n",
      "2  0.375  0.0  0.173913  0.317610  0.569078  0.416960  0.0  0.173724  0.318062  0.527854  0.429179  0.138869  0.214181  0.235550  0.241887  0.417531  0.069044  0.055984  0.180394  0.159029  0.209711  0.233236  0.232644  0.433778  0.065058  0.049797  0.160308  0.425722  0.279051  0.251251  0.166253  0.111555  0.457319  0.419462  0.282814  0.221022  0.156979  0.101962  0.482195  0.030043  0.000869  0.008798  0.009292  0.007223\n",
      "3  0.475  0.0  0.225000  0.331761  0.536456  0.372943  0.0  0.224756  0.330700  0.512425  0.377920  0.193769  0.191941  0.246850  0.230853  0.461893  0.064853  0.045042  0.216357  0.225200  0.191355  0.247187  0.221343  0.477231  0.061350  0.038204  0.189995  0.350473  0.197787  0.195995  0.138694  0.120276  0.565855  0.343051  0.198930  0.170446  0.138926  0.128511  0.583599  0.007464  0.001614  0.005129  0.004282  0.002035\n",
      "4  0.550  0.0  0.242391  0.356918  0.586226  0.316341  0.0  0.242128  0.363349  0.553386  0.321850  0.185715  0.198734  0.279301  0.207196  0.441399  0.076431  0.046992  0.202871  0.206421  0.197188  0.283644  0.196531  0.458048  0.071125  0.043055  0.172436  0.315762  0.139921  0.175587  0.140501  0.125363  0.618510  0.302982  0.135820  0.129230  0.127917  0.115814  0.656992  0.013494  0.000861  0.030755  0.211186  0.176328\n",
      "X_test_onlyGhost_list1:\n",
      "       0         1         2         3         4         5\n",
      "0  0.125  0.053795  0.001310  0.006669  0.034220  0.024247\n",
      "1  0.275  0.028423  0.000278  0.015059  0.015093  0.008715\n",
      "2  0.375  0.030043  0.000869  0.008798  0.009292  0.007223\n",
      "3  0.475  0.007464  0.001614  0.005129  0.004282  0.002035\n",
      "4  0.550  0.013494  0.000861  0.030755  0.211186  0.176328\n"
     ]
    }
   ],
   "source": [
    "def process_results_to_lists(train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP, scaler_main=None, scaler_ghost=None, fit_scaler=True):\n",
    "    if fit_scaler:\n",
    "        scaler_main = MinMaxScaler()\n",
    "        scaler_ghost = MinMaxScaler()\n",
    "        X_train = scaler_main.fit_transform(train_df)\n",
    "        X_train_onlyGhost = scaler_ghost.fit_transform(train_df_onlyGhost)\n",
    "    else:\n",
    "        X_train = scaler_main.transform(train_df)\n",
    "        X_train_onlyGhost = scaler_ghost.transform(train_df_onlyGhost)\n",
    "\n",
    "    MAE_array = MAE.values\n",
    "    FINAL_QP_array = FINAL_QP.values\n",
    "    Y_train = LABEL['LABEL'].astype(int).values\n",
    "\n",
    "    return X_train, X_train_onlyGhost, MAE_array, FINAL_QP_array, Y_train, scaler_main, scaler_ghost\n",
    "\n",
    "# 訓練データのスケーリング\n",
    "X_train, X_train_onlyGhost, MAE_array, FINAL_QP_array, Y_train, scaler_main, scaler_ghost = process_results_to_lists(\n",
    "    combined_train_df, combined_train_df_onlyGhost, combined_LABEL, combined_MAE, combined_FINAL_QP, fit_scaler=True\n",
    ")\n",
    "\n",
    "# スケーリング後のデータを表示（任意）\n",
    "print(\"After scaling:\")\n",
    "print(\"X_train:\")\n",
    "print(pd.DataFrame(X_train).head())\n",
    "print(\"X_train_onlyGhost:\")\n",
    "print(pd.DataFrame(X_train_onlyGhost).head())\n",
    "\n",
    "# データを元に戻すための関数\n",
    "def restore_data_to_original_order(data, original_lengths):\n",
    "    restored_data = []\n",
    "    start_index = 0\n",
    "    for length in original_lengths:\n",
    "        restored_data.append(data[start_index:start_index + length])\n",
    "        start_index += length\n",
    "    return restored_data\n",
    "\n",
    "# 元のデータフレームの長さ\n",
    "original_lengths = [len(train_df1), len(train_df2), len(train_df3), len(train_df4), len(train_df5), \n",
    "                    len(train_df6), len(train_df7), len(train_df8), len(train_df9)]\n",
    "\n",
    "# データを元の順序に戻す\n",
    "X_train_list = restore_data_to_original_order(X_train, original_lengths)\n",
    "X_train_onlyGhost_list = restore_data_to_original_order(X_train_onlyGhost, original_lengths)\n",
    "MAE_list = restore_data_to_original_order(MAE_array, original_lengths)\n",
    "FINAL_QP_list = restore_data_to_original_order(FINAL_QP_array, original_lengths)\n",
    "Y_train_list = restore_data_to_original_order(Y_train, original_lengths)\n",
    "\n",
    "# テストデータのスケーリング関数\n",
    "def append_results_to_lists(train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP, X_train_list, X_train_onlyGhost_list, MAE_list, FINAL_QP_list, Y_train_list, scaler_main=None, scaler_ghost=None, fit_scaler=True):\n",
    "    X_train, X_train_onlyGhost, MAE_array, FINAL_QP_array, Y_train, _, _ = process_results_to_lists(\n",
    "        train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP, scaler_main, scaler_ghost, fit_scaler)\n",
    "    X_train_list.append(X_train)\n",
    "    X_train_onlyGhost_list.append(X_train_onlyGhost)\n",
    "    MAE_list.append(MAE_array)\n",
    "    FINAL_QP_list.append(FINAL_QP_array)\n",
    "    Y_train_list.append(Y_train)\n",
    "    return X_train_list, X_train_onlyGhost_list, MAE_list, FINAL_QP_list, Y_train_list\n",
    "\n",
    "# テストデータ用のリストの初期化\n",
    "X_test_list1 = []\n",
    "X_test_onlyGhost_list1 = []\n",
    "MAE_list_t1 = []\n",
    "FINAL_QP_list_t1 = []\n",
    "Y_test_list1 = []\n",
    "\n",
    "X_test_list2 = []\n",
    "X_test_onlyGhost_list2 = []\n",
    "MAE_list_t2 = []\n",
    "FINAL_QP_list_t2 = []\n",
    "Y_test_list2 = []\n",
    "\n",
    "X_test_list3 = []\n",
    "X_test_onlyGhost_list3 = []\n",
    "MAE_list_t3 = []\n",
    "FINAL_QP_list_t3 = []\n",
    "Y_test_list3 = []\n",
    "\n",
    "# テストデータの処理とスケーリング\n",
    "X_test_list1, X_test_onlyGhost_list1, MAE_list_t1, FINAL_QP_list_t1, Y_test_list1 = append_results_to_lists(\n",
    "    test_df1, test_df_onlyGhost1, LABEL_t1, MAE_t1, FINAL_QP_t1, X_test_list1, X_test_onlyGhost_list1, MAE_list_t1, FINAL_QP_list_t1, Y_test_list1, scaler_main, scaler_ghost, fit_scaler=False\n",
    ")\n",
    "X_test_list2, X_test_onlyGhost_list2, MAE_list_t2, FINAL_QP_list_t2, Y_test_list2 = append_results_to_lists(\n",
    "    test_df2, test_df_onlyGhost2, LABEL_t2, MAE_t2, FINAL_QP_t2, X_test_list2, X_test_onlyGhost_list2, MAE_list_t2, FINAL_QP_list_t2, Y_test_list2, scaler_main, scaler_ghost, fit_scaler=False\n",
    ")\n",
    "X_test_list3, X_test_onlyGhost_list3, MAE_list_t3, FINAL_QP_list_t3, Y_test_list3 = append_results_to_lists(\n",
    "    test_df3, test_df_onlyGhost3, LABEL_t3, MAE_t3, FINAL_QP_t3, X_test_list3, X_test_onlyGhost_list3, MAE_list_t3, FINAL_QP_list_t3, Y_test_list3, scaler_main, scaler_ghost, fit_scaler=False\n",
    ")\n",
    "\n",
    "# 確認用の出力\n",
    "print(\"\\nTest data after scaling:\")\n",
    "print(\"X_test_list1:\")\n",
    "print(pd.DataFrame(X_test_list1[0]).head())\n",
    "print(\"X_test_onlyGhost_list1:\")\n",
    "print(pd.DataFrame(X_test_onlyGhost_list1[0]).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Fold-1>\n",
      "Train indices: [0 1 2 3 4 5 6 8]\n",
      "Test indices: [7]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.875\n",
      "0.5\n",
      "0.57\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9446    0.8533    0.8967       300\n",
      "           1     0.8663    0.9500    0.9062       300\n",
      "\n",
      "    accuracy                         0.9017       600\n",
      "   macro avg     0.9055    0.9017    0.9014       600\n",
      "weighted avg     0.9055    0.9017    0.9014       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9766    0.8333    0.8993       300\n",
      "           1     0.8547    0.9800    0.9130       300\n",
      "\n",
      "    accuracy                         0.9067       600\n",
      "   macro avg     0.9156    0.9067    0.9062       600\n",
      "weighted avg     0.9156    0.9067    0.9062       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8767    0.8533    0.8649       300\n",
      "           1     0.8571    0.8800    0.8684       300\n",
      "\n",
      "    accuracy                         0.8667       600\n",
      "   macro avg     0.8669    0.8667    0.8666       600\n",
      "weighted avg     0.8669    0.8667    0.8666       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9225    0.8333    0.8757       300\n",
      "           1     0.8480    0.9300    0.8871       300\n",
      "\n",
      "    accuracy                         0.8817       600\n",
      "   macro avg     0.8853    0.8817    0.8814       600\n",
      "weighted avg     0.8853    0.8817    0.8814       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5995    0.8533    0.7043       300\n",
      "           1     0.7457    0.4300    0.5455       300\n",
      "\n",
      "    accuracy                         0.6417       600\n",
      "   macro avg     0.6726    0.6417    0.6249       600\n",
      "weighted avg     0.6726    0.6417    0.6249       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6378    0.8333    0.7225       300\n",
      "           1     0.7596    0.5267    0.6220       300\n",
      "\n",
      "    accuracy                         0.6800       600\n",
      "   macro avg     0.6987    0.6800    0.6723       600\n",
      "weighted avg     0.6987    0.6800    0.6723       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9389    0.8200    0.8754       300\n",
      "           1     0.8402    0.9467    0.8903       300\n",
      "\n",
      "    accuracy                         0.8833       600\n",
      "   macro avg     0.8896    0.8833    0.8829       600\n",
      "weighted avg     0.8896    0.8833    0.8829       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8465    0.7167    0.7762       300\n",
      "           1     0.7543    0.8700    0.8080       300\n",
      "\n",
      "    accuracy                         0.7933       600\n",
      "   macro avg     0.8004    0.7933    0.7921       600\n",
      "weighted avg     0.8004    0.7933    0.7921       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8849    0.8200    0.8512       300\n",
      "           1     0.8323    0.8933    0.8617       300\n",
      "\n",
      "    accuracy                         0.8567       600\n",
      "   macro avg     0.8586    0.8567    0.8565       600\n",
      "weighted avg     0.8586    0.8567    0.8565       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5972    0.7167    0.6515       300\n",
      "           1     0.6458    0.5167    0.5741       300\n",
      "\n",
      "    accuracy                         0.6167       600\n",
      "   macro avg     0.6215    0.6167    0.6128       600\n",
      "weighted avg     0.6215    0.6167    0.6128       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5104    0.8200    0.6292       300\n",
      "           1     0.5424    0.2133    0.3062       300\n",
      "\n",
      "    accuracy                         0.5167       600\n",
      "   macro avg     0.5264    0.5167    0.4677       600\n",
      "weighted avg     0.5264    0.5167    0.4677       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5584    0.7167    0.6277       300\n",
      "           1     0.6047    0.4333    0.5049       300\n",
      "\n",
      "    accuracy                         0.5750       600\n",
      "   macro avg     0.5815    0.5750    0.5663       600\n",
      "weighted avg     0.5815    0.5750    0.5663       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8319    0.9400    0.8826       300\n",
      "           1     0.9310    0.8100    0.8663       300\n",
      "\n",
      "    accuracy                         0.8750       600\n",
      "   macro avg     0.8814    0.8750    0.8745       600\n",
      "weighted avg     0.8814    0.8750    0.8745       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       300\n",
      "           1     0.5000    1.0000    0.6667       300\n",
      "\n",
      "    accuracy                         0.5000       600\n",
      "   macro avg     0.2500    0.5000    0.3333       600\n",
      "weighted avg     0.2500    0.5000    0.3333       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6544    0.2967    0.4083       300\n",
      "           1     0.5453    0.8433    0.6623       300\n",
      "\n",
      "    accuracy                         0.5700       600\n",
      "   macro avg     0.5998    0.5700    0.5353       600\n",
      "weighted avg     0.5998    0.5700    0.5353       600\n",
      "\n",
      "<Fold-2>\n",
      "Train indices: [0 2 3 4 5 6 7 8]\n",
      "Test indices: [1]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.875\n",
      "0.5\n",
      "0.57\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9361    0.8300    0.8799       300\n",
      "           1     0.8473    0.9433    0.8927       300\n",
      "\n",
      "    accuracy                         0.8867       600\n",
      "   macro avg     0.8917    0.8867    0.8863       600\n",
      "weighted avg     0.8917    0.8867    0.8863       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9802    0.8267    0.8969       300\n",
      "           1     0.8501    0.9833    0.9119       300\n",
      "\n",
      "    accuracy                         0.9050       600\n",
      "   macro avg     0.9152    0.9050    0.9044       600\n",
      "weighted avg     0.9152    0.9050    0.9044       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9055    0.8300    0.8661       300\n",
      "           1     0.8431    0.9133    0.8768       300\n",
      "\n",
      "    accuracy                         0.8717       600\n",
      "   macro avg     0.8743    0.8717    0.8714       600\n",
      "weighted avg     0.8743    0.8717    0.8714       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9118    0.8267    0.8671       300\n",
      "           1     0.8415    0.9200    0.8790       300\n",
      "\n",
      "    accuracy                         0.8733       600\n",
      "   macro avg     0.8766    0.8733    0.8731       600\n",
      "weighted avg     0.8766    0.8733    0.8731       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6336    0.8300    0.7186       300\n",
      "           1     0.7536    0.5200    0.6154       300\n",
      "\n",
      "    accuracy                         0.6750       600\n",
      "   macro avg     0.6936    0.6750    0.6670       600\n",
      "weighted avg     0.6936    0.6750    0.6670       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6294    0.8267    0.7147       300\n",
      "           1     0.7476    0.5133    0.6087       300\n",
      "\n",
      "    accuracy                         0.6700       600\n",
      "   macro avg     0.6885    0.6700    0.6617       600\n",
      "weighted avg     0.6885    0.6700    0.6617       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9323    0.8267    0.8763       300\n",
      "           1     0.8443    0.9400    0.8896       300\n",
      "\n",
      "    accuracy                         0.8833       600\n",
      "   macro avg     0.8883    0.8833    0.8830       600\n",
      "weighted avg     0.8883    0.8833    0.8830       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8493    0.7700    0.8077       300\n",
      "           1     0.7896    0.8633    0.8248       300\n",
      "\n",
      "    accuracy                         0.8167       600\n",
      "   macro avg     0.8194    0.8167    0.8163       600\n",
      "weighted avg     0.8194    0.8167    0.8163       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8857    0.8267    0.8552       300\n",
      "           1     0.8375    0.8933    0.8645       300\n",
      "\n",
      "    accuracy                         0.8600       600\n",
      "   macro avg     0.8616    0.8600    0.8598       600\n",
      "weighted avg     0.8616    0.8600    0.8598       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5908    0.7700    0.6686       300\n",
      "           1     0.6699    0.4667    0.5501       300\n",
      "\n",
      "    accuracy                         0.6183       600\n",
      "   macro avg     0.6303    0.6183    0.6093       600\n",
      "weighted avg     0.6303    0.6183    0.6093       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5156    0.8267    0.6351       300\n",
      "           1     0.5630    0.2233    0.3198       300\n",
      "\n",
      "    accuracy                         0.5250       600\n",
      "   macro avg     0.5393    0.5250    0.4774       600\n",
      "weighted avg     0.5393    0.5250    0.4774       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5526    0.7700    0.6435       300\n",
      "           1     0.6209    0.3767    0.4689       300\n",
      "\n",
      "    accuracy                         0.5733       600\n",
      "   macro avg     0.5868    0.5733    0.5562       600\n",
      "weighted avg     0.5868    0.5733    0.5562       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8319    0.9400    0.8826       300\n",
      "           1     0.9310    0.8100    0.8663       300\n",
      "\n",
      "    accuracy                         0.8750       600\n",
      "   macro avg     0.8814    0.8750    0.8745       600\n",
      "weighted avg     0.8814    0.8750    0.8745       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       300\n",
      "           1     0.5000    1.0000    0.6667       300\n",
      "\n",
      "    accuracy                         0.5000       600\n",
      "   macro avg     0.2500    0.5000    0.3333       600\n",
      "weighted avg     0.2500    0.5000    0.3333       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6544    0.2967    0.4083       300\n",
      "           1     0.5453    0.8433    0.6623       300\n",
      "\n",
      "    accuracy                         0.5700       600\n",
      "   macro avg     0.5998    0.5700    0.5353       600\n",
      "weighted avg     0.5998    0.5700    0.5353       600\n",
      "\n",
      "<Fold-3>\n",
      "Train indices: [0 1 2 3 4 6 7 8]\n",
      "Test indices: [5]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.875\n",
      "0.5\n",
      "0.57\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9451    0.8600    0.9005       300\n",
      "           1     0.8716    0.9500    0.9091       300\n",
      "\n",
      "    accuracy                         0.9050       600\n",
      "   macro avg     0.9083    0.9050    0.9048       600\n",
      "weighted avg     0.9083    0.9050    0.9048       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9764    0.8267    0.8953       300\n",
      "           1     0.8497    0.9800    0.9102       300\n",
      "\n",
      "    accuracy                         0.9033       600\n",
      "   macro avg     0.9130    0.9033    0.9028       600\n",
      "weighted avg     0.9130    0.9033    0.9028       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8746    0.8600    0.8672       300\n",
      "           1     0.8623    0.8767    0.8694       300\n",
      "\n",
      "    accuracy                         0.8683       600\n",
      "   macro avg     0.8684    0.8683    0.8683       600\n",
      "weighted avg     0.8684    0.8683    0.8683       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9084    0.8267    0.8656       300\n",
      "           1     0.8410    0.9167    0.8772       300\n",
      "\n",
      "    accuracy                         0.8717       600\n",
      "   macro avg     0.8747    0.8717    0.8714       600\n",
      "weighted avg     0.8747    0.8717    0.8714       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5986    0.8600    0.7059       300\n",
      "           1     0.7515    0.4233    0.5416       300\n",
      "\n",
      "    accuracy                         0.6417       600\n",
      "   macro avg     0.6750    0.6417    0.6237       600\n",
      "weighted avg     0.6750    0.6417    0.6237       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6458    0.8267    0.7251       300\n",
      "           1     0.7593    0.5467    0.6357       300\n",
      "\n",
      "    accuracy                         0.6867       600\n",
      "   macro avg     0.7025    0.6867    0.6804       600\n",
      "weighted avg     0.7025    0.6867    0.6804       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9275    0.8100    0.8648       300\n",
      "           1     0.8314    0.9367    0.8809       300\n",
      "\n",
      "    accuracy                         0.8733       600\n",
      "   macro avg     0.8794    0.8733    0.8728       600\n",
      "weighted avg     0.8794    0.8733    0.8728       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8511    0.8000    0.8247       300\n",
      "           1     0.8113    0.8600    0.8350       300\n",
      "\n",
      "    accuracy                         0.8300       600\n",
      "   macro avg     0.8312    0.8300    0.8298       600\n",
      "weighted avg     0.8312    0.8300    0.8298       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8967    0.8100    0.8511       300\n",
      "           1     0.8267    0.9067    0.8649       300\n",
      "\n",
      "    accuracy                         0.8583       600\n",
      "   macro avg     0.8617    0.8583    0.8580       600\n",
      "weighted avg     0.8617    0.8583    0.8580       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5882    0.8000    0.6780       300\n",
      "           1     0.6875    0.4400    0.5366       300\n",
      "\n",
      "    accuracy                         0.6200       600\n",
      "   macro avg     0.6379    0.6200    0.6073       600\n",
      "weighted avg     0.6379    0.6200    0.6073       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5215    0.8100    0.6345       300\n",
      "           1     0.5746    0.2567    0.3548       300\n",
      "\n",
      "    accuracy                         0.5333       600\n",
      "   macro avg     0.5480    0.5333    0.4947       600\n",
      "weighted avg     0.5480    0.5333    0.4947       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5442    0.8000    0.6478       300\n",
      "           1     0.6226    0.3300    0.4314       300\n",
      "\n",
      "    accuracy                         0.5650       600\n",
      "   macro avg     0.5834    0.5650    0.5396       600\n",
      "weighted avg     0.5834    0.5650    0.5396       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8319    0.9400    0.8826       300\n",
      "           1     0.9310    0.8100    0.8663       300\n",
      "\n",
      "    accuracy                         0.8750       600\n",
      "   macro avg     0.8814    0.8750    0.8745       600\n",
      "weighted avg     0.8814    0.8750    0.8745       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       300\n",
      "           1     0.5000    1.0000    0.6667       300\n",
      "\n",
      "    accuracy                         0.5000       600\n",
      "   macro avg     0.2500    0.5000    0.3333       600\n",
      "weighted avg     0.2500    0.5000    0.3333       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6544    0.2967    0.4083       300\n",
      "           1     0.5453    0.8433    0.6623       300\n",
      "\n",
      "    accuracy                         0.5700       600\n",
      "   macro avg     0.5998    0.5700    0.5353       600\n",
      "weighted avg     0.5998    0.5700    0.5353       600\n",
      "\n",
      "<Fold-4>\n",
      "Train indices: [1 2 3 4 5 6 7 8]\n",
      "Test indices: [0]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.875\n",
      "0.5\n",
      "0.57\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9549    0.8467    0.8975       300\n",
      "           1     0.8623    0.9600    0.9085       300\n",
      "\n",
      "    accuracy                         0.9033       600\n",
      "   macro avg     0.9086    0.9033    0.9030       600\n",
      "weighted avg     0.9086    0.9033    0.9030       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9801    0.8200    0.8929       300\n",
      "           1     0.8453    0.9833    0.9091       300\n",
      "\n",
      "    accuracy                         0.9017       600\n",
      "   macro avg     0.9127    0.9017    0.9010       600\n",
      "weighted avg     0.9127    0.9017    0.9010       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8819    0.8467    0.8639       300\n",
      "           1     0.8526    0.8867    0.8693       300\n",
      "\n",
      "    accuracy                         0.8667       600\n",
      "   macro avg     0.8673    0.8667    0.8666       600\n",
      "weighted avg     0.8673    0.8667    0.8666       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9145    0.8200    0.8647       300\n",
      "           1     0.8369    0.9233    0.8780       300\n",
      "\n",
      "    accuracy                         0.8717       600\n",
      "   macro avg     0.8757    0.8717    0.8713       600\n",
      "weighted avg     0.8757    0.8717    0.8713       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6165    0.8467    0.7135       300\n",
      "           1     0.7553    0.4733    0.5820       300\n",
      "\n",
      "    accuracy                         0.6600       600\n",
      "   macro avg     0.6859    0.6600    0.6477       600\n",
      "weighted avg     0.6859    0.6600    0.6477       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6423    0.8200    0.7204       300\n",
      "           1     0.7512    0.5433    0.6306       300\n",
      "\n",
      "    accuracy                         0.6817       600\n",
      "   macro avg     0.6967    0.6817    0.6755       600\n",
      "weighted avg     0.6967    0.6817    0.6755       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9356    0.8233    0.8759       300\n",
      "           1     0.8423    0.9433    0.8899       300\n",
      "\n",
      "    accuracy                         0.8833       600\n",
      "   macro avg     0.8889    0.8833    0.8829       600\n",
      "weighted avg     0.8889    0.8833    0.8829       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8487    0.7667    0.8056       300\n",
      "           1     0.7872    0.8633    0.8235       300\n",
      "\n",
      "    accuracy                         0.8150       600\n",
      "   macro avg     0.8180    0.8150    0.8146       600\n",
      "weighted avg     0.8180    0.8150    0.8146       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8821    0.8233    0.8517       300\n",
      "           1     0.8344    0.8900    0.8613       300\n",
      "\n",
      "    accuracy                         0.8567       600\n",
      "   macro avg     0.8583    0.8567    0.8565       600\n",
      "weighted avg     0.8583    0.8567    0.8565       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5928    0.7667    0.6686       300\n",
      "           1     0.6698    0.4733    0.5547       300\n",
      "\n",
      "    accuracy                         0.6200       600\n",
      "   macro avg     0.6313    0.6200    0.6116       600\n",
      "weighted avg     0.6313    0.6200    0.6116       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5146    0.8233    0.6333       300\n",
      "           1     0.5583    0.2233    0.3190       300\n",
      "\n",
      "    accuracy                         0.5233       600\n",
      "   macro avg     0.5365    0.5233    0.4762       600\n",
      "weighted avg     0.5365    0.5233    0.4762       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5596    0.7667    0.6470       300\n",
      "           1     0.6296    0.3967    0.4867       300\n",
      "\n",
      "    accuracy                         0.5817       600\n",
      "   macro avg     0.5946    0.5817    0.5668       600\n",
      "weighted avg     0.5946    0.5817    0.5668       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8319    0.9400    0.8826       300\n",
      "           1     0.9310    0.8100    0.8663       300\n",
      "\n",
      "    accuracy                         0.8750       600\n",
      "   macro avg     0.8814    0.8750    0.8745       600\n",
      "weighted avg     0.8814    0.8750    0.8745       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       300\n",
      "           1     0.5000    1.0000    0.6667       300\n",
      "\n",
      "    accuracy                         0.5000       600\n",
      "   macro avg     0.2500    0.5000    0.3333       600\n",
      "weighted avg     0.2500    0.5000    0.3333       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6544    0.2967    0.4083       300\n",
      "           1     0.5453    0.8433    0.6623       300\n",
      "\n",
      "    accuracy                         0.5700       600\n",
      "   macro avg     0.5998    0.5700    0.5353       600\n",
      "weighted avg     0.5998    0.5700    0.5353       600\n",
      "\n",
      "<Fold-5>\n",
      "Train indices: [0 1 2 3 4 5 6 7]\n",
      "Test indices: [8]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.875\n",
      "0.5\n",
      "0.57\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9582    0.8400    0.8952       300\n",
      "           1     0.8576    0.9633    0.9074       300\n",
      "\n",
      "    accuracy                         0.9017       600\n",
      "   macro avg     0.9079    0.9017    0.9013       600\n",
      "weighted avg     0.9079    0.9017    0.9013       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9728    0.8333    0.8977       300\n",
      "           1     0.8542    0.9767    0.9114       300\n",
      "\n",
      "    accuracy                         0.9050       600\n",
      "   macro avg     0.9135    0.9050    0.9045       600\n",
      "weighted avg     0.9135    0.9050    0.9045       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9000    0.8400    0.8690       300\n",
      "           1     0.8500    0.9067    0.8774       300\n",
      "\n",
      "    accuracy                         0.8733       600\n",
      "   macro avg     0.8750    0.8733    0.8732       600\n",
      "weighted avg     0.8750    0.8733    0.8732       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8993    0.8333    0.8651       300\n",
      "           1     0.8447    0.9067    0.8746       300\n",
      "\n",
      "    accuracy                         0.8700       600\n",
      "   macro avg     0.8720    0.8700    0.8698       600\n",
      "weighted avg     0.8720    0.8700    0.8698       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6316    0.8400    0.7210       300\n",
      "           1     0.7612    0.5100    0.6108       300\n",
      "\n",
      "    accuracy                         0.6750       600\n",
      "   macro avg     0.6964    0.6750    0.6659       600\n",
      "weighted avg     0.6964    0.6750    0.6659       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6345    0.8333    0.7205       300\n",
      "           1     0.7573    0.5200    0.6166       300\n",
      "\n",
      "    accuracy                         0.6767       600\n",
      "   macro avg     0.6959    0.6767    0.6685       600\n",
      "weighted avg     0.6959    0.6767    0.6685       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9326    0.8300    0.8783       300\n",
      "           1     0.8468    0.9400    0.8910       300\n",
      "\n",
      "    accuracy                         0.8850       600\n",
      "   macro avg     0.8897    0.8850    0.8847       600\n",
      "weighted avg     0.8897    0.8850    0.8847       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8552    0.8267    0.8407       300\n",
      "           1     0.8323    0.8600    0.8459       300\n",
      "\n",
      "    accuracy                         0.8433       600\n",
      "   macro avg     0.8437    0.8433    0.8433       600\n",
      "weighted avg     0.8437    0.8433    0.8433       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8768    0.8300    0.8527       300\n",
      "           1     0.8386    0.8833    0.8604       300\n",
      "\n",
      "    accuracy                         0.8567       600\n",
      "   macro avg     0.8577    0.8567    0.8566       600\n",
      "weighted avg     0.8577    0.8567    0.8566       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5947    0.8267    0.6918       300\n",
      "           1     0.7158    0.4367    0.5424       300\n",
      "\n",
      "    accuracy                         0.6317       600\n",
      "   macro avg     0.6553    0.6317    0.6171       600\n",
      "weighted avg     0.6553    0.6317    0.6171       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5166    0.8300    0.6368       300\n",
      "           1     0.5678    0.2233    0.3206       300\n",
      "\n",
      "    accuracy                         0.5267       600\n",
      "   macro avg     0.5422    0.5267    0.4787       600\n",
      "weighted avg     0.5422    0.5267    0.4787       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5439    0.8267    0.6561       300\n",
      "           1     0.6389    0.3067    0.4144       300\n",
      "\n",
      "    accuracy                         0.5667       600\n",
      "   macro avg     0.5914    0.5667    0.5352       600\n",
      "weighted avg     0.5914    0.5667    0.5352       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8319    0.9400    0.8826       300\n",
      "           1     0.9310    0.8100    0.8663       300\n",
      "\n",
      "    accuracy                         0.8750       600\n",
      "   macro avg     0.8814    0.8750    0.8745       600\n",
      "weighted avg     0.8814    0.8750    0.8745       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       300\n",
      "           1     0.5000    1.0000    0.6667       300\n",
      "\n",
      "    accuracy                         0.5000       600\n",
      "   macro avg     0.2500    0.5000    0.3333       600\n",
      "weighted avg     0.2500    0.5000    0.3333       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6544    0.2967    0.4083       300\n",
      "           1     0.5453    0.8433    0.6623       300\n",
      "\n",
      "    accuracy                         0.5700       600\n",
      "   macro avg     0.5998    0.5700    0.5353       600\n",
      "weighted avg     0.5998    0.5700    0.5353       600\n",
      "\n",
      "<Fold-6>\n",
      "Train indices: [0 1 3 4 5 6 7 8]\n",
      "Test indices: [2]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.875\n",
      "0.5\n",
      "0.57\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9583    0.8433    0.8972       300\n",
      "           1     0.8601    0.9633    0.9088       300\n",
      "\n",
      "    accuracy                         0.9033       600\n",
      "   macro avg     0.9092    0.9033    0.9030       600\n",
      "weighted avg     0.9092    0.9033    0.9030       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9766    0.8333    0.8993       300\n",
      "           1     0.8547    0.9800    0.9130       300\n",
      "\n",
      "    accuracy                         0.9067       600\n",
      "   macro avg     0.9156    0.9067    0.9062       600\n",
      "weighted avg     0.9156    0.9067    0.9062       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8908    0.8433    0.8664       300\n",
      "           1     0.8513    0.8967    0.8734       300\n",
      "\n",
      "    accuracy                         0.8700       600\n",
      "   macro avg     0.8711    0.8700    0.8699       600\n",
      "weighted avg     0.8711    0.8700    0.8699       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9158    0.8333    0.8726       300\n",
      "           1     0.8471    0.9233    0.8836       300\n",
      "\n",
      "    accuracy                         0.8783       600\n",
      "   macro avg     0.8814    0.8783    0.8781       600\n",
      "weighted avg     0.8814    0.8783    0.8781       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6278    0.8433    0.7198       300\n",
      "           1     0.7614    0.5000    0.6036       300\n",
      "\n",
      "    accuracy                         0.6717       600\n",
      "   macro avg     0.6946    0.6717    0.6617       600\n",
      "weighted avg     0.6946    0.6717    0.6617       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6443    0.8333    0.7267       300\n",
      "           1     0.7642    0.5400    0.6328       300\n",
      "\n",
      "    accuracy                         0.6867       600\n",
      "   macro avg     0.7042    0.6867    0.6798       600\n",
      "weighted avg     0.7042    0.6867    0.6798       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9351    0.8167    0.8719       300\n",
      "           1     0.8373    0.9433    0.8871       300\n",
      "\n",
      "    accuracy                         0.8800       600\n",
      "   macro avg     0.8862    0.8800    0.8795       600\n",
      "weighted avg     0.8862    0.8800    0.8795       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8576    0.8433    0.8504       300\n",
      "           1     0.8459    0.8600    0.8529       300\n",
      "\n",
      "    accuracy                         0.8517       600\n",
      "   macro avg     0.8518    0.8517    0.8517       600\n",
      "weighted avg     0.8518    0.8517    0.8517       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8781    0.8167    0.8463       300\n",
      "           1     0.8287    0.8867    0.8567       300\n",
      "\n",
      "    accuracy                         0.8517       600\n",
      "   macro avg     0.8534    0.8517    0.8515       600\n",
      "weighted avg     0.8534    0.8517    0.8515       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5967    0.8433    0.6989       300\n",
      "           1     0.7330    0.4300    0.5420       300\n",
      "\n",
      "    accuracy                         0.6367       600\n",
      "   macro avg     0.6648    0.6367    0.6205       600\n",
      "weighted avg     0.6648    0.6367    0.6205       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5094    0.8167    0.6274       300\n",
      "           1     0.5378    0.2133    0.3055       300\n",
      "\n",
      "    accuracy                         0.5150       600\n",
      "   macro avg     0.5236    0.5150    0.4664       600\n",
      "weighted avg     0.5236    0.5150    0.4664       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5453    0.8433    0.6623       300\n",
      "           1     0.6544    0.2967    0.4083       300\n",
      "\n",
      "    accuracy                         0.5700       600\n",
      "   macro avg     0.5998    0.5700    0.5353       600\n",
      "weighted avg     0.5998    0.5700    0.5353       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8319    0.9400    0.8826       300\n",
      "           1     0.9310    0.8100    0.8663       300\n",
      "\n",
      "    accuracy                         0.8750       600\n",
      "   macro avg     0.8814    0.8750    0.8745       600\n",
      "weighted avg     0.8814    0.8750    0.8745       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       300\n",
      "           1     0.5000    1.0000    0.6667       300\n",
      "\n",
      "    accuracy                         0.5000       600\n",
      "   macro avg     0.2500    0.5000    0.3333       600\n",
      "weighted avg     0.2500    0.5000    0.3333       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6544    0.2967    0.4083       300\n",
      "           1     0.5453    0.8433    0.6623       300\n",
      "\n",
      "    accuracy                         0.5700       600\n",
      "   macro avg     0.5998    0.5700    0.5353       600\n",
      "weighted avg     0.5998    0.5700    0.5353       600\n",
      "\n",
      "<Fold-7>\n",
      "Train indices: [0 1 2 3 5 6 7 8]\n",
      "Test indices: [4]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.875\n",
      "0.5\n",
      "0.57\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9424    0.8733    0.9066       300\n",
      "           1     0.8820    0.9467    0.9132       300\n",
      "\n",
      "    accuracy                         0.9100       600\n",
      "   macro avg     0.9122    0.9100    0.9099       600\n",
      "weighted avg     0.9122    0.9100    0.9099       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9765    0.8300    0.8973       300\n",
      "           1     0.8522    0.9800    0.9116       300\n",
      "\n",
      "    accuracy                         0.9050       600\n",
      "   macro avg     0.9143    0.9050    0.9045       600\n",
      "weighted avg     0.9143    0.9050    0.9045       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8452    0.8733    0.8590       300\n",
      "           1     0.8690    0.8400    0.8542       300\n",
      "\n",
      "    accuracy                         0.8567       600\n",
      "   macro avg     0.8571    0.8567    0.8566       600\n",
      "weighted avg     0.8571    0.8567    0.8566       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9055    0.8300    0.8661       300\n",
      "           1     0.8431    0.9133    0.8768       300\n",
      "\n",
      "    accuracy                         0.8717       600\n",
      "   macro avg     0.8743    0.8717    0.8714       600\n",
      "weighted avg     0.8743    0.8717    0.8714       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5955    0.8733    0.7081       300\n",
      "           1     0.7625    0.4067    0.5304       300\n",
      "\n",
      "    accuracy                         0.6400       600\n",
      "   macro avg     0.6790    0.6400    0.6193       600\n",
      "weighted avg     0.6790    0.6400    0.6193       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6368    0.8300    0.7207       300\n",
      "           1     0.7560    0.5267    0.6208       300\n",
      "\n",
      "    accuracy                         0.6783       600\n",
      "   macro avg     0.6964    0.6783    0.6708       600\n",
      "weighted avg     0.6964    0.6783    0.6708       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9273    0.8500    0.8870       300\n",
      "           1     0.8615    0.9333    0.8960       300\n",
      "\n",
      "    accuracy                         0.8917       600\n",
      "   macro avg     0.8944    0.8917    0.8915       600\n",
      "weighted avg     0.8944    0.8917    0.8915       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8506    0.7400    0.7914       300\n",
      "           1     0.7699    0.8700    0.8169       300\n",
      "\n",
      "    accuracy                         0.8050       600\n",
      "   macro avg     0.8102    0.8050    0.8042       600\n",
      "weighted avg     0.8102    0.8050    0.8042       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8703    0.8500    0.8600       300\n",
      "           1     0.8534    0.8733    0.8633       300\n",
      "\n",
      "    accuracy                         0.8617       600\n",
      "   macro avg     0.8619    0.8617    0.8616       600\n",
      "weighted avg     0.8619    0.8617    0.8616       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5984    0.7400    0.6617       300\n",
      "           1     0.6594    0.5033    0.5709       300\n",
      "\n",
      "    accuracy                         0.6217       600\n",
      "   macro avg     0.6289    0.6217    0.6163       600\n",
      "weighted avg     0.6289    0.6217    0.6163       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5193    0.8500    0.6448       300\n",
      "           1     0.5872    0.2133    0.3130       300\n",
      "\n",
      "    accuracy                         0.5317       600\n",
      "   macro avg     0.5533    0.5317    0.4789       600\n",
      "weighted avg     0.5533    0.5317    0.4789       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5592    0.7400    0.6370       300\n",
      "           1     0.6158    0.4167    0.4970       300\n",
      "\n",
      "    accuracy                         0.5783       600\n",
      "   macro avg     0.5875    0.5783    0.5670       600\n",
      "weighted avg     0.5875    0.5783    0.5670       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8319    0.9400    0.8826       300\n",
      "           1     0.9310    0.8100    0.8663       300\n",
      "\n",
      "    accuracy                         0.8750       600\n",
      "   macro avg     0.8814    0.8750    0.8745       600\n",
      "weighted avg     0.8814    0.8750    0.8745       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       300\n",
      "           1     0.5000    1.0000    0.6667       300\n",
      "\n",
      "    accuracy                         0.5000       600\n",
      "   macro avg     0.2500    0.5000    0.3333       600\n",
      "weighted avg     0.2500    0.5000    0.3333       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6544    0.2967    0.4083       300\n",
      "           1     0.5453    0.8433    0.6623       300\n",
      "\n",
      "    accuracy                         0.5700       600\n",
      "   macro avg     0.5998    0.5700    0.5353       600\n",
      "weighted avg     0.5998    0.5700    0.5353       600\n",
      "\n",
      "<Fold-8>\n",
      "Train indices: [0 1 2 4 5 6 7 8]\n",
      "Test indices: [3]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.875\n",
      "0.5\n",
      "0.57\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9542    0.8333    0.8897       300\n",
      "           1     0.8521    0.9600    0.9028       300\n",
      "\n",
      "    accuracy                         0.8967       600\n",
      "   macro avg     0.9031    0.8967    0.8963       600\n",
      "weighted avg     0.9031    0.8967    0.8963       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9727    0.8300    0.8957       300\n",
      "           1     0.8517    0.9767    0.9099       300\n",
      "\n",
      "    accuracy                         0.9033       600\n",
      "   macro avg     0.9122    0.9033    0.9028       600\n",
      "weighted avg     0.9122    0.9033    0.9028       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9158    0.8333    0.8726       300\n",
      "           1     0.8471    0.9233    0.8836       300\n",
      "\n",
      "    accuracy                         0.8783       600\n",
      "   macro avg     0.8814    0.8783    0.8781       600\n",
      "weighted avg     0.8814    0.8783    0.8781       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9055    0.8300    0.8661       300\n",
      "           1     0.8431    0.9133    0.8768       300\n",
      "\n",
      "    accuracy                         0.8717       600\n",
      "   macro avg     0.8743    0.8717    0.8714       600\n",
      "weighted avg     0.8743    0.8717    0.8714       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6234    0.8333    0.7133       300\n",
      "           1     0.7487    0.4967    0.5972       300\n",
      "\n",
      "    accuracy                         0.6650       600\n",
      "   macro avg     0.6861    0.6650    0.6552       600\n",
      "weighted avg     0.6861    0.6650    0.6552       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6451    0.8300    0.7259       300\n",
      "           1     0.7617    0.5433    0.6342       300\n",
      "\n",
      "    accuracy                         0.6867       600\n",
      "   macro avg     0.7034    0.6867    0.6801       600\n",
      "weighted avg     0.7034    0.6867    0.6801       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9326    0.8300    0.8783       300\n",
      "           1     0.8468    0.9400    0.8910       300\n",
      "\n",
      "    accuracy                         0.8850       600\n",
      "   macro avg     0.8897    0.8850    0.8847       600\n",
      "weighted avg     0.8897    0.8850    0.8847       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8516    0.7267    0.7842       300\n",
      "           1     0.7616    0.8733    0.8137       300\n",
      "\n",
      "    accuracy                         0.8000       600\n",
      "   macro avg     0.8066    0.8000    0.7989       600\n",
      "weighted avg     0.8066    0.8000    0.7989       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8586    0.8300    0.8441       300\n",
      "           1     0.8355    0.8633    0.8492       300\n",
      "\n",
      "    accuracy                         0.8467       600\n",
      "   macro avg     0.8471    0.8467    0.8466       600\n",
      "weighted avg     0.8471    0.8467    0.8466       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6006    0.7267    0.6576       300\n",
      "           1     0.6540    0.5167    0.5773       300\n",
      "\n",
      "    accuracy                         0.6217       600\n",
      "   macro avg     0.6273    0.6217    0.6174       600\n",
      "weighted avg     0.6273    0.6217    0.6174       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5102    0.8300    0.6320       300\n",
      "           1     0.5446    0.2033    0.2961       300\n",
      "\n",
      "    accuracy                         0.5167       600\n",
      "   macro avg     0.5274    0.5167    0.4640       600\n",
      "weighted avg     0.5274    0.5167    0.4640       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5575    0.7267    0.6310       300\n",
      "           1     0.6077    0.4233    0.4990       300\n",
      "\n",
      "    accuracy                         0.5750       600\n",
      "   macro avg     0.5826    0.5750    0.5650       600\n",
      "weighted avg     0.5826    0.5750    0.5650       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8319    0.9400    0.8826       300\n",
      "           1     0.9310    0.8100    0.8663       300\n",
      "\n",
      "    accuracy                         0.8750       600\n",
      "   macro avg     0.8814    0.8750    0.8745       600\n",
      "weighted avg     0.8814    0.8750    0.8745       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       300\n",
      "           1     0.5000    1.0000    0.6667       300\n",
      "\n",
      "    accuracy                         0.5000       600\n",
      "   macro avg     0.2500    0.5000    0.3333       600\n",
      "weighted avg     0.2500    0.5000    0.3333       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6544    0.2967    0.4083       300\n",
      "           1     0.5453    0.8433    0.6623       300\n",
      "\n",
      "    accuracy                         0.5700       600\n",
      "   macro avg     0.5998    0.5700    0.5353       600\n",
      "weighted avg     0.5998    0.5700    0.5353       600\n",
      "\n",
      "<Fold-9>\n",
      "Train indices: [0 1 2 3 4 5 7 8]\n",
      "Test indices: [6]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.875\n",
      "0.5\n",
      "0.57\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.8333    0.8961       300\n",
      "           1     0.8538    0.9733    0.9097       300\n",
      "\n",
      "    accuracy                         0.9033       600\n",
      "   macro avg     0.9114    0.9033    0.9029       600\n",
      "weighted avg     0.9114    0.9033    0.9029       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9765    0.8300    0.8973       300\n",
      "           1     0.8522    0.9800    0.9116       300\n",
      "\n",
      "    accuracy                         0.9050       600\n",
      "   macro avg     0.9143    0.9050    0.9045       600\n",
      "weighted avg     0.9143    0.9050    0.9045       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9158    0.8333    0.8726       300\n",
      "           1     0.8471    0.9233    0.8836       300\n",
      "\n",
      "    accuracy                         0.8783       600\n",
      "   macro avg     0.8814    0.8783    0.8781       600\n",
      "weighted avg     0.8814    0.8783    0.8781       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9154    0.8300    0.8706       300\n",
      "           1     0.8445    0.9233    0.8822       300\n",
      "\n",
      "    accuracy                         0.8767       600\n",
      "   macro avg     0.8800    0.8767    0.8764       600\n",
      "weighted avg     0.8800    0.8767    0.8764       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6345    0.8333    0.7205       300\n",
      "           1     0.7573    0.5200    0.6166       300\n",
      "\n",
      "    accuracy                         0.6767       600\n",
      "   macro avg     0.6959    0.6767    0.6685       600\n",
      "weighted avg     0.6959    0.6767    0.6685       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6418    0.8300    0.7238       300\n",
      "           1     0.7594    0.5367    0.6289       300\n",
      "\n",
      "    accuracy                         0.6833       600\n",
      "   macro avg     0.7006    0.6833    0.6764       600\n",
      "weighted avg     0.7006    0.6833    0.6764       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9283    0.8200    0.8708       300\n",
      "           1     0.8388    0.9367    0.8850       300\n",
      "\n",
      "    accuracy                         0.8783       600\n",
      "   macro avg     0.8836    0.8783    0.8779       600\n",
      "weighted avg     0.8836    0.8783    0.8779       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8505    0.7967    0.8227       300\n",
      "           1     0.8088    0.8600    0.8336       300\n",
      "\n",
      "    accuracy                         0.8283       600\n",
      "   macro avg     0.8297    0.8283    0.8282       600\n",
      "weighted avg     0.8297    0.8283    0.8282       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8849    0.8200    0.8512       300\n",
      "           1     0.8323    0.8933    0.8617       300\n",
      "\n",
      "    accuracy                         0.8567       600\n",
      "   macro avg     0.8586    0.8567    0.8565       600\n",
      "weighted avg     0.8586    0.8567    0.8565       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5887    0.7967    0.6771       300\n",
      "           1     0.6856    0.4433    0.5385       300\n",
      "\n",
      "    accuracy                         0.6200       600\n",
      "   macro avg     0.6371    0.6200    0.6078       600\n",
      "weighted avg     0.6371    0.6200    0.6078       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5168    0.8200    0.6340       300\n",
      "           1     0.5645    0.2333    0.3302       300\n",
      "\n",
      "    accuracy                         0.5267       600\n",
      "   macro avg     0.5407    0.5267    0.4821       600\n",
      "weighted avg     0.5407    0.5267    0.4821       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5469    0.7967    0.6486       300\n",
      "           1     0.6258    0.3400    0.4406       300\n",
      "\n",
      "    accuracy                         0.5683       600\n",
      "   macro avg     0.5863    0.5683    0.5446       600\n",
      "weighted avg     0.5863    0.5683    0.5446       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8319    0.9400    0.8826       300\n",
      "           1     0.9310    0.8100    0.8663       300\n",
      "\n",
      "    accuracy                         0.8750       600\n",
      "   macro avg     0.8814    0.8750    0.8745       600\n",
      "weighted avg     0.8814    0.8750    0.8745       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       300\n",
      "           1     0.5000    1.0000    0.6667       300\n",
      "\n",
      "    accuracy                         0.5000       600\n",
      "   macro avg     0.2500    0.5000    0.3333       600\n",
      "weighted avg     0.2500    0.5000    0.3333       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6544    0.2967    0.4083       300\n",
      "           1     0.5453    0.8433    0.6623       300\n",
      "\n",
      "    accuracy                         0.5700       600\n",
      "   macro avg     0.5998    0.5700    0.5353       600\n",
      "weighted avg     0.5998    0.5700    0.5353       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cの範囲を指定\n",
    "C_values = {'C': [0.01, 0.1, 1, 10, 100, 1000, 2000, 3000, 4000, 5000]}\n",
    "# C_values = {'C': [100]}\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "kfold = KFold(n_splits=9, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "results = pd.DataFrame(columns=['C_RBF_LQP1','Score_RBF_LQP1', 'tnr_rbf_lqp1', 'tpr_rbf_lqp1',\n",
    "                                'C_RBF_SQP','Score_RBF_SQP', 'tnr_rbf_sqp', 'tpr_rbf_sqp',\n",
    "                                'C_RBF_LQP2','Score_RBF_LQP2', 'tnr_rbf_lqp2', 'tpr_rbf_lqp2',\n",
    "                                'C_LINEAR_LQP1','Score_LINEAR_LQP1', 'tnr_linear_lqp1', 'tpr_linear_lqp1',\n",
    "                                'C_LINEAR_SQP','Score_LINEAR_SQP', 'tnr_linear_sqp', 'tpr_linear_sqp',\n",
    "                                'C_LINEAR_LQP2','Score_LINEAR_LQP2', 'tnr_linear_lqp2', 'tpr_linear_lqp2',\n",
    "                                \n",
    "                                'C_RBF2_LQP1','Score_RBF2_LQP1', 'tnr_rbf2_lqp1', 'tpr_rbf2_lqp1',\n",
    "                                'C_RBF2_SQP','Score_RBF2_SQP', 'tnr_rbf2_sqp', 'tpr_rbf2_sqp',\n",
    "                                'C_RBF2_LQP2','Score_RBF2_LQP2', 'tnr_rbf2_lqp2', 'tpr_rbf2_lqp2',\n",
    "                                'C_LINEAR2_LQP1','Score_LINEAR2_LQP1', 'tnr_linear2_lqp1', 'tpr_linear2_lqp1',\n",
    "                                'C_LINEAR2_SQP','Score_LINEAR2_SQP', 'tnr_linear2_sqp2', 'tpr_linear2_sqp',\n",
    "                                'C_LINEAR2_LQP2','Score_LINEAR2_LQP2', 'tnr_linear2_lqp2', 'tpr_linear2_lqp2',\n",
    "                                \n",
    "                                'Threshold_LQP1', 'LQP1_old', 'tnr_old_lqp1', 'tpr_old_lqp1',\n",
    "                                'Threshold_SQP', 'SQP_old', 'tnr_old_sqp', 'tpr_old_sqp',\n",
    "                                'Threshold_LQP2', 'LQP2_old', 'tnr_old_lqp2', 'tpr_old_lqp2'])\n",
    "\n",
    "\n",
    "# results = pd.DataFrame(columns=['C_RBF_LQP1','Score_RBF_LQP1', 'tnr_rbf_lqp1', 'tpr_rbf_lqp1',\n",
    "#                                 'C_RBF_SQP','Score_RBF_SQP', 'tnr_rbf_sqp', 'tpr_rbf_sqp',\n",
    "#                                 'C_RBF_LQP2','Score_RBF_LQP2', 'tnr_rbf_lqp2', 'tpr_rbf_lqp2',\n",
    "#                                 'C_LINEAR_LQP1','Score_LINEAR_LQP1', 'tnr_linear_lqp1', 'tpr_linear_lqp1',\n",
    "#                                 'C_LINEAR_SQP','Score_LINEAR_SQP', 'tnr_linear_sqp', 'tpr_linear_sqp',\n",
    "#                                 'C_LINEAR_LQP2','Score_LINEAR_LQP2', 'tnr_linear_lqp2', 'tpr_linear_lqp2',\n",
    "                                                        \n",
    "#                                 'Threshold_LQP1', 'LQP1_old', 'tnr_old_lqp1', 'tpr_old_lqp1',\n",
    "#                                 'Threshold_SQP', 'SQP_old', 'tnr_old_sqp', 'tpr_old_sqp',\n",
    "#                                 'Threshold_LQP2', 'LQP2_old', 'tnr_old_lqp2', 'tpr_old_lqp2'])\n",
    "\n",
    "    \n",
    "X_index = np.arange(9)  # インデックスとして0から8までの数字を用意\n",
    "\n",
    "# ループで各分割のtrain_idsとtest_idsを取得\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(X_index)):\n",
    "    print(f\"<Fold-{fold+1}>\")\n",
    "    print(\"Train indices:\", train_ids)\n",
    "    print(\"Test indices:\", test_ids)\n",
    "    \n",
    "    train_data = [X_train_list[i] for i in train_ids]\n",
    "    train_data_OG = [X_train_onlyGhost_list[i] for i in train_ids]\n",
    "    train_label = [Y_train_list[i] for i in train_ids]\n",
    "    \n",
    "    val_data = [X_train_list[i] for i in test_ids]\n",
    "    val_data_OG = [X_train_onlyGhost_list[i] for i in test_ids]\n",
    "    val_label = [Y_train_list[i] for i in test_ids]\n",
    "    \n",
    "    X_train = [item for data in train_data for item in data]\n",
    "    X_train_OG = [item for data in train_data_OG for item in data]\n",
    "    Y_train = [item for data in train_label for item in data]\n",
    "    \n",
    "    X_val = [item for data in val_data for item in data]\n",
    "    X_val_OG = [item for data in val_data_OG for item in data]\n",
    "    Y_val = [item for data in val_label for item in data]\n",
    "    \n",
    "    # print(len(Y_train))\n",
    "    # print(len(Y_val))\n",
    "    \n",
    "    test_data1 = [item for data in X_test_list1 for item in data]\n",
    "    test_data_OG1 = [item for data in X_test_onlyGhost_list1 for item in data]\n",
    "    test_label1 = [item for data in Y_test_list1 for item in data]\n",
    "    MAE_data1 = [item for data in MAE_list_t1 for item in data]\n",
    "    FINAL_QP_data1 = [item for data in FINAL_QP_list_t1 for item in data]\n",
    "    \n",
    "    test_data2 = [item for data in X_test_list2 for item in data]\n",
    "    test_data_OG2 = [item for data in X_test_onlyGhost_list2 for item in data]\n",
    "    test_label2 = [item for data in Y_test_list2 for item in data]\n",
    "    MAE_data2 = [item for data in MAE_list_t2 for item in data]\n",
    "    FINAL_QP_data2 = [item for data in FINAL_QP_list_t2 for item in data]\n",
    "    \n",
    "    test_data3 = [item for data in X_test_list3 for item in data]\n",
    "    test_data_OG3 = [item for data in X_test_onlyGhost_list3 for item in data]\n",
    "    test_label3 = [item for data in Y_test_list3 for item in data]\n",
    "    MAE_data3 = [item for data in MAE_list_t3 for item in data]\n",
    "    FINAL_QP_data3 = [item for data in FINAL_QP_list_t3 for item in data]\n",
    "    \n",
    "    print(len(MAE_data1))\n",
    "    print(len(MAE_data2))\n",
    "    print(len(MAE_data3))\n",
    "    \n",
    "                                                                                   \n",
    "    best_threshold = 0\n",
    "    best_accuracy = 0\n",
    "    best_predicted_labels = []\n",
    "    best_ground_truth_labels = []\n",
    "    \n",
    "    sameQP_best_threshold = 0\n",
    "    sameQP_best_accuracy = 0\n",
    "    sameQP_best_predicted_labels = []\n",
    "    sameQP_best_ground_truth_labels = []\n",
    "    \n",
    "    largeQP_best_threshold = 0\n",
    "    largeQP_best_accuracy = 0\n",
    "    largeQP_best_predicted_labels = []\n",
    "    largeQP_best_ground_truth_labels = []\n",
    "            \n",
    "    for threshold in np.arange(0.00, 1.01, 0.01):\n",
    "        test_old = np.array([is_double_compressed(MAE_data1[i], FINAL_QP_data1[i], threshold) for i in range(600)])\n",
    "        predicted_labels = test_old.astype(int)\n",
    "        ground_truth_labels = np.array(test_label1)\n",
    "        accuracy = np.sum(ground_truth_labels == predicted_labels) / len(ground_truth_labels)\n",
    "    \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_threshold = threshold\n",
    "            best_predicted_labels = predicted_labels\n",
    "            best_ground_truth_labels = ground_truth_labels\n",
    "            \n",
    "    for threshold in np.arange(0.00, 1.01, 0.01):\n",
    "        test_sameQP_old = np.array([is_double_compressed(MAE_data2[i], FINAL_QP_data2[i], threshold) for i in range(600)])\n",
    "        same_predicted_labels = test_sameQP_old.astype(int)\n",
    "        same_ground_truth_labels = np.array(test_label2)\n",
    "        same_accuracy = np.sum(same_ground_truth_labels == same_predicted_labels) / len(same_ground_truth_labels)\n",
    "    \n",
    "        if same_accuracy > sameQP_best_accuracy:\n",
    "            sameQP_best_accuracy = same_accuracy\n",
    "            sameQP_best_threshold = threshold\n",
    "            sameQP_best_predicted_labels = same_predicted_labels\n",
    "            sameQP_best_ground_truth_labels = same_ground_truth_labels\n",
    "                        \n",
    "    for threshold in np.arange(0.00, 1.01, 0.01):\n",
    "        test_largeQP_old = np.array([is_double_compressed(MAE_data3[i], FINAL_QP_data3[i], threshold) for i in range(600)])\n",
    "        large_predicted_labels = test_largeQP_old.astype(int)\n",
    "        large_ground_truth_labels = np.array(test_label3)\n",
    "        large_accuracy = np.sum(large_ground_truth_labels == large_predicted_labels) / len(large_ground_truth_labels)\n",
    "    \n",
    "        if large_accuracy > largeQP_best_accuracy:\n",
    "            largeQP_best_accuracy = large_accuracy\n",
    "            largeQP_best_threshold = threshold\n",
    "            largeQP_best_predicted_labels = large_predicted_labels\n",
    "            largeQP_best_ground_truth_labels = large_ground_truth_labels       \n",
    "            \n",
    "            \n",
    "    print(best_accuracy)\n",
    "    print(sameQP_best_accuracy)\n",
    "    print(largeQP_best_accuracy)\n",
    "            \n",
    "            \n",
    "    best_val_score_RBF, best_svm_model_RBF, best_c_value_RBF = 0, None, None\n",
    "    best_val_score_onlyGhost_RBF, best_svm_model_onlyGhost_RBF, best_c_value_onlyGhost_RBF = 0, None, None\n",
    "    \n",
    "    best_val_score_LINEAR, best_svm_model_LINEAR, best_c_value_LINEAR = 0, None, None\n",
    "    best_val_score_onlyGhost_LINEAR, best_svm_model_onlyGhost_LINEAR, best_c_value_onlyGhost_LINEAR = 0, None, None\n",
    "        \n",
    "    for C_value in C_values['C']:    \n",
    "        # SVMモデルのインスタンスを作成\n",
    "        svm_model_RBF = SVC(kernel='rbf', C=C_value)\n",
    "        svm_model_onlyGhost_RBF = SVC(kernel='rbf', C=C_value)\n",
    "        \n",
    "        svm_model_LINEAR = SVC(kernel='linear', C=C_value)\n",
    "        svm_model_onlyGhost_LINEAR = SVC(kernel='linear', C=C_value)\n",
    "\n",
    "        # 訓練データで訓練\n",
    "        svm_model_RBF.fit(X_train, Y_train)\n",
    "        svm_model_onlyGhost_RBF.fit(X_train_OG, Y_train)\n",
    "        \n",
    "        svm_model_LINEAR.fit(X_train, Y_train)\n",
    "        svm_model_onlyGhost_LINEAR.fit(X_train_OG, Y_train)\n",
    "\n",
    "        \n",
    "        val_accuracy_RBF = accuracy_score(Y_val, svm_model_RBF.predict(X_val))\n",
    "        val_accuracy_onlyGhost_RBF = accuracy_score(Y_val, svm_model_onlyGhost_RBF.predict(X_val_OG))\n",
    "        \n",
    "        val_accuracy_LINEAR = accuracy_score(Y_val, svm_model_LINEAR.predict(X_val))\n",
    "        val_accuracy_onlyGhost_LINEAR = accuracy_score(Y_val, svm_model_onlyGhost_LINEAR.predict(X_val_OG))\n",
    "        \n",
    "\n",
    "        # 検証データでの精度が最も高かった場合、そのモデルを保存\n",
    "        if val_accuracy_RBF > best_val_score_RBF:\n",
    "            best_val_score_RBF, best_svm_model_RBF, best_c_value_RBF = val_accuracy_RBF, svm_model_RBF, C_value\n",
    "\n",
    "        if val_accuracy_onlyGhost_RBF > best_val_score_onlyGhost_RBF:\n",
    "            best_val_score_onlyGhost_RBF, best_svm_model_onlyGhost_RBF, best_c_value_onlyGhost_RBF = val_accuracy_onlyGhost_RBF, svm_model_onlyGhost_RBF, C_value\n",
    "            \n",
    "        if val_accuracy_LINEAR > best_val_score_LINEAR:\n",
    "            best_val_score_LINEAR, best_svm_model_LINEAR, best_c_value_LINEAR = val_accuracy_LINEAR, svm_model_LINEAR, C_value\n",
    "\n",
    "        if val_accuracy_onlyGhost_LINEAR > best_val_score_onlyGhost_LINEAR:\n",
    "            best_val_score_onlyGhost_LINEAR, best_svm_model_onlyGhost_LINEAR, best_c_value_onlyGhost_LINEAR = val_accuracy_onlyGhost_LINEAR, svm_model_onlyGhost_LINEAR, C_value\n",
    "\n",
    "\n",
    "    # テストデータで評価    \n",
    "    predictions_RBF = best_svm_model_RBF.predict(test_data1)\n",
    "    # predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test)\n",
    "    accuracy_RBF = accuracy_score(test_label1, predictions_RBF)\n",
    "    report_RBF = classification_report(test_label1, predictions_RBF, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label1, predictions_RBF)\n",
    "    tnr_rbf_lqp1 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_rbf_lqp1 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'report_RBF:\\n{report_RBF}')\n",
    "    \n",
    "    predictions_LINEAR = best_svm_model_LINEAR.predict(test_data1)\n",
    "    # predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test)\n",
    "    accuracy_LINEAR = accuracy_score(test_label1, predictions_LINEAR)\n",
    "    report_LINEAR = classification_report(test_label1, predictions_LINEAR, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label1, predictions_LINEAR)\n",
    "    tnr_linear_lqp1 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_linear_lqp1 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'report_LINEAR:\\n{report_LINEAR}')\n",
    "    \n",
    "    same_predictions_RBF = best_svm_model_RBF.predict(test_data2)\n",
    "    # same_predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test_sameQP)\n",
    "    same_accuracy_RBF = accuracy_score(test_label2, same_predictions_RBF)\n",
    "    same_report_RBF = classification_report(test_label2, same_predictions_RBF, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label2, same_predictions_RBF)\n",
    "    tnr_rbf_sqp = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_rbf_sqp = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'same_report_RBF:\\n{same_report_RBF}')\n",
    "    \n",
    "    same_predictions_LINEAR = best_svm_model_LINEAR.predict(test_data2)\n",
    "    # same_predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test_sameQP)\n",
    "    same_accuracy_LINEAR = accuracy_score(test_label2, same_predictions_LINEAR)\n",
    "    same_report_LINEAR = classification_report(test_label2, same_predictions_LINEAR, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label2, same_predictions_LINEAR)\n",
    "    tnr_linear_sqp = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_linear_sqp = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'same_report_LINEAR:\\n{same_report_LINEAR}')\n",
    "    \n",
    "    large_predictions_RBF = best_svm_model_RBF.predict(test_data3)\n",
    "    # large_predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test_largeQP)\n",
    "    large_accuracy_RBF = accuracy_score(test_label3, large_predictions_RBF)\n",
    "    large_report_RBF = classification_report(test_label3, large_predictions_RBF, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label3, large_predictions_RBF)\n",
    "    tnr_rbf_lqp2 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_rbf_lqp2 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'large_report_RBF:\\n{large_report_RBF}')\n",
    "    \n",
    "    large_predictions_LINEAR = best_svm_model_LINEAR.predict(test_data3)\n",
    "    # large_predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test_largeQP)\n",
    "    large_accuracy_LINEAR = accuracy_score(test_label3, large_predictions_LINEAR)\n",
    "    large_report_LINEAR = classification_report(test_label3, large_predictions_LINEAR, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label3, large_predictions_LINEAR)\n",
    "    tnr_linear_lqp2 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_linear_lqp2 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'large_report_LINEAR:\\n{large_report_LINEAR}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # テストデータで評価    \n",
    "    predictions_RBF2 = best_svm_model_onlyGhost_RBF.predict(test_data_OG1)\n",
    "    # predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test)\n",
    "    accuracy_RBF2 = accuracy_score(test_label1, predictions_RBF2)\n",
    "    report_RBF2 = classification_report(test_label1, predictions_RBF2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label1, predictions_RBF2)\n",
    "    tnr_rbf2_lqp1 = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_rbf2_lqp1 = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'report_RBF2:\\n{report_RBF2}')\n",
    "    \n",
    "    predictions_LINEAR2 = best_svm_model_onlyGhost_LINEAR.predict(test_data_OG1)\n",
    "    # predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test)\n",
    "    accuracy_LINEAR2 = accuracy_score(test_label1, predictions_LINEAR2)\n",
    "    report_LINEAR2 = classification_report(test_label1, predictions_LINEAR2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label1, predictions_LINEAR2)\n",
    "    tnr_linear2_lqp1 = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_linear2_lqp1 = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'report_LINEAR2:\\n{report_LINEAR2}')\n",
    "    \n",
    "    same_predictions_RBF2 = best_svm_model_onlyGhost_RBF.predict(test_data_OG2)\n",
    "    # same_predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test_sameQP)\n",
    "    same_accuracy_RBF2 = accuracy_score(test_label2, same_predictions_RBF2)\n",
    "    same_report_RBF2 = classification_report(test_label2, same_predictions_RBF2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label2, same_predictions_RBF2)\n",
    "    tnr_rbf2_sqp = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_rbf2_sqp = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'same_report_RBF2:\\n{same_report_RBF2}')\n",
    "    \n",
    "    same_predictions_LINEAR2 = best_svm_model_onlyGhost_LINEAR.predict(test_data_OG2)\n",
    "    # same_predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test_sameQP)\n",
    "    same_accuracy_LINEAR2 = accuracy_score(test_label2, same_predictions_LINEAR2)\n",
    "    same_report_LINEAR2 = classification_report(test_label2, same_predictions_LINEAR2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label2, same_predictions_LINEAR2)\n",
    "    tnr_linear2_sqp = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_linear2_sqp = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'same_report_LINEAR2:\\n{same_report_LINEAR2}')\n",
    "    \n",
    "    large_predictions_RBF2 = best_svm_model_onlyGhost_RBF.predict(test_data_OG3)\n",
    "    # large_predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test_largeQP)\n",
    "    large_accuracy_RBF2 = accuracy_score(test_label3, large_predictions_RBF2)\n",
    "    large_report_RBF2 = classification_report(test_label3, large_predictions_RBF2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label3, large_predictions_RBF2)\n",
    "    tnr_rbf2_lqp2 = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_rbf2_lqp2 = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'large_report_RBF2:\\n{large_report_RBF2}')\n",
    "    \n",
    "    large_predictions_LINEAR2 = best_svm_model_onlyGhost_LINEAR.predict(test_data_OG3)\n",
    "    # large_predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test_largeQP)\n",
    "    large_accuracy_LINEAR2 = accuracy_score(test_label3, large_predictions_LINEAR2)\n",
    "    large_report_LINEAR2 = classification_report(test_label3, large_predictions_LINEAR2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label3, large_predictions_LINEAR2)\n",
    "    tnr_linear2_lqp2 = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_linear2_lqp2 = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'large_report_LINEAR2:\\n{large_report_LINEAR2}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # テストデータで評価\n",
    "    test_old = classification_report(best_ground_truth_labels, best_predicted_labels, labels=[0,1], target_names=['0', '1'], zero_division=0, digits=4)\n",
    "    conf_matrix = confusion_matrix(best_ground_truth_labels, best_predicted_labels)\n",
    "    tnr_old_lqp1 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_old_lqp1 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'Summary old_model:\\n{test_old}')\n",
    "    \n",
    "    test_sameQP_old = classification_report(sameQP_best_ground_truth_labels, sameQP_best_predicted_labels, labels=[0,1], target_names=['0', '1'], zero_division=0, digits=4)\n",
    "    conf_matrix = confusion_matrix(sameQP_best_ground_truth_labels, sameQP_best_predicted_labels)\n",
    "    tnr_old_sqp = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_old_sqp = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'Summary old_model:\\n{test_sameQP_old}')\n",
    "    \n",
    "    test_largeQP_old = classification_report(largeQP_best_ground_truth_labels, largeQP_best_predicted_labels, labels=[0,1], target_names=['0', '1'], zero_division=0, digits=4)\n",
    "    conf_matrix = confusion_matrix(largeQP_best_ground_truth_labels, largeQP_best_predicted_labels)\n",
    "    tnr_old_lqp2 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_old_lqp2 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'Summary old_model:\\n{test_largeQP_old}')\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Test結果を保存\n",
    "    \n",
    "    result_row ={'C_RBF_LQP1':best_c_value_RBF,'Score_RBF_LQP1': accuracy_RBF, 'tnr_rbf_lqp1':tnr_rbf_lqp1, 'tpr_rbf_lqp1':tpr_rbf_lqp1,\n",
    "                'C_RBF_SQP': best_c_value_RBF, 'Score_RBF_SQP': same_accuracy_RBF, 'tnr_rbf_sqp':tnr_rbf_sqp, 'tpr_rbf_sqp':tpr_rbf_sqp,\n",
    "                'C_RBF_LQP2': best_c_value_RBF,'Score_RBF_LQP2': large_accuracy_RBF, 'tnr_rbf_lqp2':tnr_rbf_lqp2, 'tpr_rbf_lqp2':tpr_rbf_lqp2,\n",
    "                                    \n",
    "                'C_LINEAR_LQP1': best_c_value_LINEAR,'Score_LINEAR_LQP1':accuracy_LINEAR, 'tnr_linear_lqp1':tnr_linear_lqp1, 'tpr_linear_lqp1':tpr_linear_lqp1,\n",
    "                'C_LINEAR_SQP': best_c_value_LINEAR,'Score_LINEAR_SQP':same_accuracy_LINEAR, 'tnr_linear_sqp':tnr_linear_sqp, 'tpr_linear_sqp':tpr_linear_sqp,\n",
    "                'C_LINEAR_LQP2': best_c_value_LINEAR,'Score_LINEAR_LQP2':large_accuracy_LINEAR, 'tnr_linear_lqp2':tnr_linear_lqp2, 'tpr_linear_lqp2':tpr_linear_lqp2,\n",
    "                 \n",
    "                'C_RBF2_LQP1':best_c_value_onlyGhost_RBF,'Score_RBF2_LQP1': accuracy_RBF2, 'tnr_rbf2_lqp1':tnr_rbf2_lqp1, 'tpr_rbf2_lqp1':tpr_rbf2_lqp1,\n",
    "                'C_RBF2_SQP': best_c_value_onlyGhost_RBF, 'Score_RBF2_SQP': same_accuracy_RBF2, 'tnr_rbf2_sqp':tnr_rbf2_sqp, 'tpr_rbf2_sqp':tpr_rbf2_sqp,\n",
    "                'C_RBF2_LQP2': best_c_value_onlyGhost_RBF,'Score_RBF2_LQP2': large_accuracy_RBF2, 'tnr_rbf2_lqp2':tnr_rbf2_lqp2, 'tpr_rbf2_lqp2':tpr_rbf2_lqp2,\n",
    "                                    \n",
    "                'C_LINEAR2_LQP1': best_c_value_onlyGhost_LINEAR,'Score_LINEAR2_LQP1':accuracy_LINEAR2, 'tnr_linear2_lqp1':tnr_linear2_lqp1, 'tpr_linear2_lqp1':tpr_linear2_lqp1,\n",
    "                'C_LINEAR2_SQP': best_c_value_onlyGhost_LINEAR,'Score_LINEAR2_SQP':same_accuracy_LINEAR2, 'tnr_linear2_sqp':tnr_linear2_sqp, 'tpr_linear2_sqp':tpr_linear2_sqp,\n",
    "                'C_LINEAR2_LQP2': best_c_value_onlyGhost_LINEAR,'Score_LINEAR2_LQP2':large_accuracy_LINEAR2, 'tnr_linear2_lqp2':tnr_linear2_lqp2, 'tpr_linear2_lqp2':tpr_linear2_lqp2,\n",
    "                                                        \n",
    "                'Threshold_LQP1':best_threshold, 'LQP1_old':best_accuracy, 'tnr_old_lqp1':tnr_old_lqp1, 'tpr_old_lqp1':tpr_old_lqp1,\n",
    "                'Threshold_SQP':sameQP_best_threshold, 'SQP_old':sameQP_best_accuracy, 'tnr_old_sqp':tnr_old_sqp, 'tpr_old_sqp':tpr_old_sqp,\n",
    "                'Threshold_LQP2':largeQP_best_threshold, 'LQP2_old':largeQP_best_accuracy, 'tnr_old_lqp2':tnr_old_lqp2, 'tpr_old_lqp2':tpr_old_lqp2}\n",
    "\n",
    "\n",
    "    results = pd.concat([results, pd.DataFrame([result_row])], ignore_index=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Average TNR  Average TPR  Average Test Score  Standard Deviation  Max Test Score  Min Test Score\n",
      "0     RBF_LQP1        84.59        95.67               90.13                0.65           91.00           88.67\n",
      "1      RBF_SQP        84.59        89.41               87.00                0.67           87.83           85.67\n",
      "2     RBF_LQP2        84.59        47.56               66.07                1.56           67.67           64.00\n",
      "3  LINEAR_LQP1        82.93        98.00               90.46                0.16           90.67           90.17\n",
      "4   LINEAR_SQP        82.93        91.89               87.41                0.39           88.17           87.00\n",
      "5  LINEAR_LQP2        82.93        53.30               68.11                0.56           68.67           67.00\n",
      "6     OLD_LQP1        94.00        81.00               87.50                0.00           87.50           87.50\n",
      "7      OLD_SQP         0.00       100.00               50.00                0.00           50.00           50.00\n",
      "8     OLD_LQP2        29.67        84.33               57.00                0.00           57.00           57.00\n"
     ]
    }
   ],
   "source": [
    "# 各統計情報を100倍して小数点第4位までの表記に変更\n",
    "statistics_data = {\n",
    "    'Model': ['RBF_LQP1', 'RBF_SQP', 'RBF_LQP2', 'LINEAR_LQP1', 'LINEAR_SQP', 'LINEAR_LQP2', 'OLD_LQP1', 'OLD_SQP', 'OLD_LQP2'],\n",
    "    'Average TNR': [round(results['tnr_rbf_lqp1'].mean() * 100, 2), round(results['tnr_rbf_sqp'].mean() * 100, 2), round(results['tnr_rbf_lqp2'].mean() * 100, 2), round(results['tnr_linear_lqp1'].mean() * 100, 2), round(results['tnr_linear_sqp'].mean() * 100, 2), round(results['tnr_linear_lqp2'].mean() * 100, 2),round(results['tnr_old_lqp1'].mean() * 100, 2), round(results['tnr_old_sqp'].mean() * 100, 2), round(results['tnr_old_lqp2'].mean() * 100, 2)],\n",
    "    'Average TPR': [round(results['tpr_rbf_lqp1'].mean() * 100, 2), round(results['tpr_rbf_sqp'].mean() * 100, 2), round(results['tpr_rbf_lqp2'].mean() * 100, 2), round(results['tpr_linear_lqp1'].mean() * 100, 2), round(results['tpr_linear_sqp'].mean() * 100, 2), round(results['tpr_linear_lqp2'].mean() * 100, 2),round(results['tpr_old_lqp1'].mean() * 100, 2), round(results['tpr_old_sqp'].mean() * 100, 2), round(results['tpr_old_lqp2'].mean() * 100, 2)],\n",
    "    'Average Test Score': [round(results['Score_RBF_LQP1'].mean() * 100, 2), round(results['Score_RBF_SQP'].mean() * 100, 2), round(results['Score_RBF_LQP2'].mean() * 100, 2), round(results['Score_LINEAR_LQP1'].mean() * 100, 2), round(results['Score_LINEAR_SQP'].mean() * 100, 2), round(results['Score_LINEAR_LQP2'].mean() * 100, 2),round(results['LQP1_old'].mean() * 100, 2), round(results['SQP_old'].mean() * 100, 2), round(results['LQP2_old'].mean() * 100, 2)],\n",
    "    'Standard Deviation': [round(results['Score_RBF_LQP1'].std() * 100, 2), round(results['Score_RBF_SQP'].std() * 100, 2), round(results['Score_RBF_LQP2'].std() * 100, 2), round(results['Score_LINEAR_LQP1'].std() * 100, 2), round(results['Score_LINEAR_SQP'].std() * 100, 2), round(results['Score_LINEAR_LQP2'].std() * 100, 2),round(results['LQP1_old'].std() * 100, 2), round(results['SQP_old'].std() * 100, 2), round(results['LQP2_old'].std() * 100, 2)],\n",
    "    'Max Test Score': [round(results['Score_RBF_LQP1'].max() * 100, 2), round(results['Score_RBF_SQP'].max() * 100, 2), round(results['Score_RBF_LQP2'].max() * 100, 2), round(results['Score_LINEAR_LQP1'].max() * 100, 2), round(results['Score_LINEAR_SQP'].max() * 100, 2), round(results['Score_LINEAR_LQP2'].max() * 100, 2),round(results['LQP1_old'].max() * 100, 2), round(results['SQP_old'].max() * 100, 2), round(results['LQP2_old'].max() * 100, 2)],\n",
    "    'Min Test Score': [round(results['Score_RBF_LQP1'].min() * 100, 2), round(results['Score_RBF_SQP'].min() * 100, 2), round(results['Score_RBF_LQP2'].min() * 100, 2), round(results['Score_LINEAR_LQP1'].min() * 100, 2), round(results['Score_LINEAR_SQP'].min() * 100, 2), round(results['Score_LINEAR_LQP2'].min() * 100, 2),round(results['LQP1_old'].min() * 100, 2), round(results['SQP_old'].min() * 100, 2), round(results['LQP2_old'].min() * 100, 2)],\n",
    "}\n",
    "\n",
    "# DataFrameを作成\n",
    "statistics_df = pd.DataFrame(statistics_data)\n",
    "\n",
    "# 表示\n",
    "print(statistics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Average TNR  Average TPR  Average Test Score  Standard Deviation  Max Test Score  Min Test Score\n",
      "0     RBF_LQP1        82.52        94.00               88.26                0.51           89.17           87.33\n",
      "1      RBF_SQP        82.52        88.70               85.61                0.45           86.17           84.67\n",
      "2     RBF_LQP2        82.52        22.26               52.39                0.66           53.33           51.50\n",
      "3  LINEAR_LQP1        77.63        86.44               82.04                1.96           85.17           79.33\n",
      "4   LINEAR_SQP        77.63        46.96               62.30                0.67           63.67           61.67\n",
      "5  LINEAR_LQP2        77.63        36.89               57.26                0.55           58.17           56.50\n",
      "6     OLD_LQP1        94.00        81.00               87.50                0.00           87.50           87.50\n",
      "7      OLD_SQP         0.00       100.00               50.00                0.00           50.00           50.00\n",
      "8     OLD_LQP2        29.67        84.33               57.00                0.00           57.00           57.00\n"
     ]
    }
   ],
   "source": [
    "# 各統計情報を100倍して小数点第4位までの表記に変更\n",
    "statistics_data2 = {\n",
    "    'Model': ['RBF_LQP1', 'RBF_SQP', 'RBF_LQP2', 'LINEAR_LQP1', 'LINEAR_SQP', 'LINEAR_LQP2', 'OLD_LQP1', 'OLD_SQP', 'OLD_LQP2'],\n",
    "    'Average TNR': [round(results['tnr_rbf2_lqp1'].mean() * 100, 2), round(results['tnr_rbf2_sqp'].mean() * 100, 2), round(results['tnr_rbf2_lqp2'].mean() * 100, 2), round(results['tnr_linear2_lqp1'].mean() * 100, 2), round(results['tnr_linear2_sqp'].mean() * 100, 2), round(results['tnr_linear2_lqp2'].mean() * 100, 2),round(results['tnr_old_lqp1'].mean() * 100, 2), round(results['tnr_old_sqp'].mean() * 100, 2), round(results['tnr_old_lqp2'].mean() * 100, 2)],\n",
    "    'Average TPR': [round(results['tpr_rbf2_lqp1'].mean() * 100, 2), round(results['tpr_rbf2_sqp'].mean() * 100, 2), round(results['tpr_rbf2_lqp2'].mean() * 100, 2), round(results['tpr_linear2_lqp1'].mean() * 100, 2), round(results['tpr_linear2_sqp'].mean() * 100, 2), round(results['tpr_linear2_lqp2'].mean() * 100, 2),round(results['tpr_old_lqp1'].mean() * 100, 2), round(results['tpr_old_sqp'].mean() * 100, 2), round(results['tpr_old_lqp2'].mean() * 100, 2)],\n",
    "    'Average Test Score': [round(results['Score_RBF2_LQP1'].mean() * 100, 2), round(results['Score_RBF2_SQP'].mean() * 100, 2), round(results['Score_RBF2_LQP2'].mean() * 100, 2), round(results['Score_LINEAR2_LQP1'].mean() * 100, 2), round(results['Score_LINEAR2_SQP'].mean() * 100, 2), round(results['Score_LINEAR2_LQP2'].mean() * 100, 2),round(results['LQP1_old'].mean() * 100, 2), round(results['SQP_old'].mean() * 100, 2), round(results['LQP2_old'].mean() * 100, 2)],\n",
    "    'Standard Deviation': [round(results['Score_RBF2_LQP1'].std() * 100, 2), round(results['Score_RBF2_SQP'].std() * 100, 2), round(results['Score_RBF2_LQP2'].std() * 100, 2), round(results['Score_LINEAR2_LQP1'].std() * 100, 2), round(results['Score_LINEAR2_SQP'].std() * 100, 2), round(results['Score_LINEAR2_LQP2'].std() * 100, 2),round(results['LQP1_old'].std() * 100, 2), round(results['SQP_old'].std() * 100, 2), round(results['LQP2_old'].std() * 100, 2)],\n",
    "    'Max Test Score': [round(results['Score_RBF2_LQP1'].max() * 100, 2), round(results['Score_RBF2_SQP'].max() * 100, 2), round(results['Score_RBF2_LQP2'].max() * 100, 2), round(results['Score_LINEAR2_LQP1'].max() * 100, 2), round(results['Score_LINEAR2_SQP'].max() * 100, 2), round(results['Score_LINEAR2_LQP2'].max() * 100, 2),round(results['LQP1_old'].max() * 100, 2), round(results['SQP_old'].max() * 100, 2), round(results['LQP2_old'].max() * 100, 2)],\n",
    "    'Min Test Score': [round(results['Score_RBF2_LQP1'].min() * 100, 2), round(results['Score_RBF2_SQP'].min() * 100, 2), round(results['Score_RBF2_LQP2'].min() * 100, 2), round(results['Score_LINEAR2_LQP1'].min() * 100, 2), round(results['Score_LINEAR2_SQP'].min() * 100, 2), round(results['Score_LINEAR2_LQP2'].min() * 100, 2),round(results['LQP1_old'].min() * 100, 2), round(results['SQP_old'].min() * 100, 2), round(results['LQP2_old'].min() * 100, 2)],\n",
    "}\n",
    "\n",
    "# DataFrameを作成\n",
    "statistics_df2 = pd.DataFrame(statistics_data2)\n",
    "\n",
    "# 表示\n",
    "print(statistics_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     10\n",
      "1    100\n",
      "2     10\n",
      "3    100\n",
      "4    100\n",
      "5    100\n",
      "6     10\n",
      "7    100\n",
      "8    100\n",
      "Name: C_RBF_LQP1, dtype: object\n",
      "0     100\n",
      "1    4000\n",
      "2    1000\n",
      "3    3000\n",
      "4     100\n",
      "5     100\n",
      "6    2000\n",
      "7    1000\n",
      "8    1000\n",
      "Name: C_LINEAR_LQP1, dtype: object\n",
      "\n",
      "0    2000\n",
      "1    2000\n",
      "2     100\n",
      "3    2000\n",
      "4    3000\n",
      "5    3000\n",
      "6    4000\n",
      "7    3000\n",
      "8    1000\n",
      "Name: C_RBF2_LQP1, dtype: object\n",
      "0    100\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "5      1\n",
      "6    100\n",
      "7     10\n",
      "8      1\n",
      "Name: C_LINEAR2_LQP1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(results['C_RBF_LQP1'])\n",
    "print(results['C_LINEAR_LQP1'])\n",
    "print()\n",
    "print(results['C_RBF2_LQP1'])\n",
    "print(results['C_LINEAR2_LQP1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df.to_csv('statistics_data7.csv', index=False)\n",
    "statistics_df2.to_csv('statistics2_data7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
