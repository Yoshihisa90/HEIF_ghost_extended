{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import os.path as osp\n",
    "import re\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.signal import find_peaks\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import torch\n",
    "import glob\n",
    "from scipy.stats import entropy\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)  # DataFrameを改行せずに表示\n",
    "pd.set_option('display.max_columns', None)  # すべての列を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_finalQP(filename):\n",
    "    match = re.search(r'2ndQP(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    match = re.search(r'1stQP(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_1stQP(filename):\n",
    "    match = re.search(r'1stQP(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def ratio_double_compressed(mean_difference, final_QP):\n",
    "    # mean_difference = mean_difference[0]\n",
    "    # final_QP = final_QP[0]\n",
    "    clamped_mean_difference = np.maximum(mean_difference, -0.01)\n",
    "    \n",
    "    #全体のエネルギーを計算\n",
    "    energy = np.sum(np.square(clamped_mean_difference))\n",
    "    # energy = np.sum(np.square(mean_difference))\n",
    "    \n",
    "    #QP2より右側のエネルギーを計算\n",
    "    right_energy = np.sum(np.square(clamped_mean_difference[final_QP+1:52]))\n",
    "\n",
    "        \n",
    "    # エネルギー比を計算して閾値と比較\n",
    "    if energy > 0:\n",
    "        return right_energy / energy\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def is_double_compressed(mean_difference, final_QP, threshold):\n",
    "    mean_difference = mean_difference[0]\n",
    "    final_QP = final_QP[0]\n",
    "    clamped_mean_difference = np.maximum(mean_difference, -0.01)\n",
    "    \n",
    "    #全体のエネルギーを計算\n",
    "    energy = np.sum(np.square(clamped_mean_difference))\n",
    "    # energy = np.sum(np.square(mean_difference))\n",
    "    \n",
    "    #QP2より右側のエネルギーを計算\n",
    "    right_energy = np.sum(np.square(clamped_mean_difference[final_QP+1:52]))\n",
    "    # right_energy = np.sum(np.square(mean_difference[final_QP+1:52]))\n",
    "    \n",
    "    # print('energy: ', energy)\n",
    "    # print('R-energy: ', right_energy)\n",
    "    # print('Ratio: ', right_energy / energy)\n",
    "    \n",
    "    \n",
    "    # エネルギー比を計算して閾値と比較\n",
    "    if energy <= 0:\n",
    "        return -1\n",
    "    \n",
    "    elif (right_energy / energy) != 0 and (right_energy / energy) > threshold:\n",
    "        return True\n",
    "    \n",
    "    elif (right_energy / energy) != 0 and (right_energy / energy) <= threshold:\n",
    "        return False\n",
    "    \n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def calculate_mae(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            loaded_data, loaded_data_shifted = pickle.load(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # タプル内のリストを抽出\n",
    "    original_mae = np.array(loaded_data)\n",
    "    shifted_mae = np.array(loaded_data_shifted)\n",
    "\n",
    "    # Coding ghostを計算してリストに格納する\n",
    "    mae_difference = shifted_mae - original_mae\n",
    "    \n",
    "    # mae_differenceの各要素においてマイナスの値を0に変換\n",
    "    # mae_difference_positive = np.maximum(mae_difference, 0)\n",
    "    \n",
    "    return mae_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['168', '216', '88', '252', '37', '238', '150', '275', '35', '155', '38', '17', '293', '3', '145', '220', '82', '166', '22', '236', '232', '251', '10', '123', '282', '189', '191', '92', '185', '77'], ['27', '188', '261', '42', '267', '43', '278', '223', '146', '9', '157', '263', '192', '78', '53', '132', '58', '25', '111', '247', '246', '6', '250', '245', '28', '229', '234', '98', '260', '241'], ['289', '70', '19', '169', '30', '153', '69', '2', '122', '23', '202', '222', '21', '177', '90', '128', '182', '288', '148', '156', '102', '249', '283', '129', '49', '18', '160', '103', '178', '262'], ['7', '13', '175', '266', '39', '186', '12', '197', '284', '99', '144', '165', '101', '80', '221', '196', '61', '274', '242', '276', '20', '75', '224', '296', '52', '84', '5', '85', '231', '115'], ['95', '297', '1', '204', '147', '211', '240', '273', '68', '287', '203', '114', '243', '154', '195', '248', '121', '138', '257', '254', '16', '268', '200', '8', '214', '83', '227', '264', '258', '255'], ['26', '67', '40', '290', '176', '244', '34', '45', '65', '56', '271', '205', '233', '199', '119', '140', '112', '285', '181', '281', '60', '131', '62', '76', '24', '164', '71', '124', '158', '127'], ['59', '292', '72', '269', '79', '230', '107', '120', '225', '210', '235', '108', '161', '272', '201', '118', '280', '226', '183', '64', '73', '100', '206', '50', '139', '15', '126', '11', '89', '133'], ['4', '32', '291', '300', '259', '116', '36', '55', '167', '194', '130', '110', '134', '125', '33', '152', '299', '48', '47', '286', '179', '277', '265', '212', '97', '29', '237', '113', '142', '218'], ['137', '93', '193', '174', '180', '44', '162', '295', '279', '94', '54', '239', '141', '135', '104', '170', '63', '219', '187', '87', '171', '159', '228', '298', '51', '213', '294', '57', '173', '106'], ['208', '143', '209', '207', '31', '86', '46', '151', '96', '81', '109', '217', '215', '184', '163', '256', '91', '136', '66', '253', '74', '190', '117', '105', '172', '149', '198', '14', '41', '270']]\n",
      "\n",
      "CSV Single ListsA:\n",
      "CSV List 1A: 300\n",
      "CSV List 2A: 300\n",
      "CSV List 3A: 300\n",
      "CSV List 4A: 300\n",
      "CSV List 5A: 300\n",
      "CSV List 6A: 300\n",
      "CSV List 7A: 300\n",
      "CSV List 8A: 300\n",
      "CSV List 9A: 300\n",
      "CSV List 10A: 300\n",
      "\n",
      "CSV Single Recompress ListsA:\n",
      "CSV List 1A: 300\n",
      "CSV List 2A: 300\n",
      "CSV List 3A: 300\n",
      "CSV List 4A: 300\n",
      "CSV List 5A: 300\n",
      "CSV List 6A: 300\n",
      "CSV List 7A: 300\n",
      "CSV List 8A: 300\n",
      "CSV List 9A: 300\n",
      "CSV List 10A: 300\n",
      "\n",
      "CSV Second Large QP1 ListsA:\n",
      "CSV List 1A: 1710\n",
      "CSV List 2A: 1710\n",
      "CSV List 3A: 1710\n",
      "CSV List 4A: 1710\n",
      "CSV List 5A: 1710\n",
      "CSV List 6A: 1710\n",
      "CSV List 7A: 1710\n",
      "CSV List 8A: 1710\n",
      "CSV List 9A: 1710\n",
      "CSV List 10A: 1710\n",
      "\n",
      "CSV Second Recompress Large QP1 ListsA:\n",
      "CSV List 1A: 1710\n",
      "CSV List 2A: 1710\n",
      "CSV List 3A: 1710\n",
      "CSV List 4A: 1710\n",
      "CSV List 5A: 1710\n",
      "CSV List 6A: 1710\n",
      "CSV List 7A: 1710\n",
      "CSV List 8A: 1710\n",
      "CSV List 9A: 1710\n",
      "CSV List 10A: 1710\n",
      "\n",
      "CSV Second Same QP ListsA:\n",
      "CSV List 1A: 300\n",
      "CSV List 2A: 300\n",
      "CSV List 3A: 300\n",
      "CSV List 4A: 300\n",
      "CSV List 5A: 300\n",
      "CSV List 6A: 300\n",
      "CSV List 7A: 300\n",
      "CSV List 8A: 300\n",
      "CSV List 9A: 300\n",
      "CSV List 10A: 300\n",
      "\n",
      "CSV Second Recompress Same QP ListsA:\n",
      "CSV List 1A: 300\n",
      "CSV List 2A: 300\n",
      "CSV List 3A: 300\n",
      "CSV List 4A: 300\n",
      "CSV List 5A: 300\n",
      "CSV List 6A: 300\n",
      "CSV List 7A: 300\n",
      "CSV List 8A: 300\n",
      "CSV List 9A: 300\n",
      "CSV List 10A: 300\n",
      "\n",
      "CSV Second Large QP2 ListsA:\n",
      "CSV List 1A: 1170\n",
      "CSV List 2A: 1170\n",
      "CSV List 3A: 1170\n",
      "CSV List 4A: 1170\n",
      "CSV List 5A: 1170\n",
      "CSV List 6A: 1170\n",
      "CSV List 7A: 1170\n",
      "CSV List 8A: 1170\n",
      "CSV List 9A: 1170\n",
      "CSV List 10A: 1170\n",
      "\n",
      "CSV Second Recompress Large QP2 ListsA:\n",
      "CSV List 1A: 1170\n",
      "CSV List 2A: 1170\n",
      "CSV List 3A: 1170\n",
      "CSV List 4A: 1170\n",
      "CSV List 5A: 1170\n",
      "CSV List 6A: 1170\n",
      "CSV List 7A: 1170\n",
      "CSV List 8A: 1170\n",
      "CSV List 9A: 1170\n",
      "CSV List 10A: 1170\n",
      "\n",
      "PKL Single ListsA:\n",
      "PKL List 1A: 300\n",
      "PKL List 2A: 300\n",
      "PKL List 3A: 300\n",
      "PKL List 4A: 300\n",
      "PKL List 5A: 300\n",
      "PKL List 6A: 300\n",
      "PKL List 7A: 300\n",
      "PKL List 8A: 300\n",
      "PKL List 9A: 300\n",
      "PKL List 10A: 300\n",
      "\n",
      "PKL Single Recompress ListsA:\n",
      "PKL List 1A: 300\n",
      "PKL List 2A: 300\n",
      "PKL List 3A: 300\n",
      "PKL List 4A: 300\n",
      "PKL List 5A: 300\n",
      "PKL List 6A: 300\n",
      "PKL List 7A: 300\n",
      "PKL List 8A: 300\n",
      "PKL List 9A: 300\n",
      "PKL List 10A: 300\n",
      "\n",
      "PKL Second Large QP1 ListsA:\n",
      "PKL List 1A: 1710\n",
      "PKL List 2A: 1710\n",
      "PKL List 3A: 1710\n",
      "PKL List 4A: 1710\n",
      "PKL List 5A: 1710\n",
      "PKL List 6A: 1710\n",
      "PKL List 7A: 1710\n",
      "PKL List 8A: 1710\n",
      "PKL List 9A: 1710\n",
      "PKL List 10A: 1710\n",
      "\n",
      "PKL Second Recompress Large QP1 ListsA:\n",
      "PKL List 1A: 1710\n",
      "PKL List 2A: 1710\n",
      "PKL List 3A: 1710\n",
      "PKL List 4A: 1710\n",
      "PKL List 5A: 1710\n",
      "PKL List 6A: 1710\n",
      "PKL List 7A: 1710\n",
      "PKL List 8A: 1710\n",
      "PKL List 9A: 1710\n",
      "PKL List 10A: 1710\n",
      "\n",
      "PKL Second Same QP ListsA:\n",
      "PKL List 1A: 300\n",
      "PKL List 2A: 300\n",
      "PKL List 3A: 300\n",
      "PKL List 4A: 300\n",
      "PKL List 5A: 300\n",
      "PKL List 6A: 300\n",
      "PKL List 7A: 300\n",
      "PKL List 8A: 300\n",
      "PKL List 9A: 300\n",
      "PKL List 10A: 300\n",
      "\n",
      "PKL Second Recompress Same QP ListsA:\n",
      "PKL List 1A: 300\n",
      "PKL List 2A: 300\n",
      "PKL List 3A: 300\n",
      "PKL List 4A: 300\n",
      "PKL List 5A: 300\n",
      "PKL List 6A: 300\n",
      "PKL List 7A: 300\n",
      "PKL List 8A: 300\n",
      "PKL List 9A: 300\n",
      "PKL List 10A: 300\n",
      "\n",
      "PKL Second Large QP2 ListsA:\n",
      "PKL List 1A: 1170\n",
      "PKL List 2A: 1170\n",
      "PKL List 3A: 1170\n",
      "PKL List 4A: 1170\n",
      "PKL List 5A: 1170\n",
      "PKL List 6A: 1170\n",
      "PKL List 7A: 1170\n",
      "PKL List 8A: 1170\n",
      "PKL List 9A: 1170\n",
      "PKL List 10A: 1170\n",
      "\n",
      "PKL Second Recompress Large QP2 ListsA:\n",
      "PKL List 1A: 1170\n",
      "PKL List 2A: 1170\n",
      "PKL List 3A: 1170\n",
      "PKL List 4A: 1170\n",
      "PKL List 5A: 1170\n",
      "PKL List 6A: 1170\n",
      "PKL List 7A: 1170\n",
      "PKL List 8A: 1170\n",
      "PKL List 9A: 1170\n",
      "PKL List 10A: 1170\n"
     ]
    }
   ],
   "source": [
    "rootpath_csv = \"/Prove/Yoshihisa/HEIF_ghost/HEIF_IMAGES_CSV/\"\n",
    "rootpath_pkl = \"/Prove/Yoshihisa/HEIF_ghost/PKL/\"\n",
    "\n",
    "train_list1 = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\"]\n",
    "train_list2 = [\"31\", \"32\", \"33\", \"34\", \"35\", \"36\", \"37\", \"38\", \"39\", \"40\", \"41\", \"42\", \"43\", \"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"50\", \"51\", \"52\", \"53\", \"54\", \"55\", \"56\", \"57\", \"58\", \"59\", \"60\"]\n",
    "train_list3 = [\"61\", \"62\", \"63\", \"64\", \"65\", \"66\", \"67\", \"68\", \"69\", \"70\", \"71\", \"72\", \"73\", \"74\", \"75\", \"76\", \"77\", \"78\", \"79\", \"80\", \"81\", \"82\", \"83\", \"84\", \"85\", \"86\", \"87\", \"88\", \"89\", \"90\"]\n",
    "train_list4 = [\"91\", \"92\", \"93\", \"94\", \"95\", \"96\", \"97\", \"98\", \"99\", \"100\", \"101\", \"102\", \"103\", \"104\", \"105\", \"106\", \"107\", \"108\", \"109\", \"110\", \"111\", \"112\", \"113\", \"114\", \"115\", \"116\", \"117\", \"118\", \"119\", \"120\"]\n",
    "train_list5 = [\"121\", \"122\", \"123\", \"124\", \"125\", \"126\", \"127\", \"128\", \"129\", \"130\", \"131\", \"132\", \"133\", \"134\", \"135\", \"136\", \"137\", \"138\", \"139\", \"140\", \"141\", \"142\", \"143\", \"144\", \"145\", \"146\", \"147\", \"148\", \"149\", \"150\"]\n",
    "train_list6 = [\"151\", \"152\", \"153\", \"154\", \"155\", \"156\", \"157\", \"158\", \"159\", \"160\", \"161\", \"162\", \"163\", \"164\", \"165\", \"166\", \"167\", \"168\", \"169\", \"170\", \"171\", \"172\", \"173\", \"174\", \"175\", \"176\", \"177\", \"178\", \"179\", \"180\"]\n",
    "train_list7 = [\"181\", \"182\", \"183\", \"184\", \"185\", \"186\", \"187\", \"188\", \"189\", \"190\", \"191\", \"192\", \"193\", \"194\", \"195\", \"196\", \"197\", \"198\", \"199\", \"200\", \"201\", \"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\"]\n",
    "train_list8 = [\"211\", \"212\", \"213\", \"214\", \"215\", \"216\", \"217\", \"218\", \"219\", \"220\", \"221\", \"222\", \"223\", \"224\", \"225\", \"226\", \"227\", \"228\", \"229\", \"230\", \"231\", \"232\", \"233\", \"234\", \"235\", \"236\", \"237\", \"238\", \"239\", \"240\"]\n",
    "train_list9 = [\"241\", \"242\", \"243\", \"244\", \"245\", \"246\", \"247\", \"248\", \"249\", \"250\", \"251\", \"252\", \"253\", \"254\", \"255\", \"256\", \"257\", \"258\", \"259\", \"260\", \"261\", \"262\", \"263\", \"264\", \"265\", \"266\", \"267\", \"268\", \"269\", \"270\"]\n",
    "train_list10 = [\"271\", \"272\", \"273\", \"274\", \"275\", \"276\", \"277\", \"278\", \"279\", \"280\", \"281\", \"282\", \"283\", \"284\", \"285\", \"286\", \"287\", \"288\", \"289\", \"290\", \"291\", \"292\", \"293\", \"294\", \"295\", \"296\", \"297\", \"298\", \"299\", \"300\"]\n",
    "\n",
    "all_train_lists = [train_list1, train_list2, train_list3, train_list4, train_list5,\n",
    "                   train_list6, train_list7, train_list8, train_list9, train_list10]\n",
    "\n",
    "# すべてのリストを1つのリストに結合する\n",
    "combined_train_list = sum(all_train_lists, [])\n",
    "\n",
    "# リストの順序をランダムにシャッフルする\n",
    "random.shuffle(combined_train_list)\n",
    "\n",
    "# シャッフルされたリストを10個のグループに分割する\n",
    "train_lists = [combined_train_list[i:i+30] for i in range(0, len(combined_train_list), 30)]\n",
    "print(train_lists)\n",
    "\n",
    "\n",
    "\n",
    "# CSV関連のリストを生成\n",
    "csv_single_listsA = [[] for _ in range(10)]\n",
    "csv_single_recompress_listsA = [[] for _ in range(10)]\n",
    "csv_second_largeQP1_listsA = [[] for _ in range(10)]\n",
    "csv_second_recompress_largeQP1_listsA = [[] for _ in range(10)]\n",
    "csv_second_sameQP_listsA = [[] for _ in range(10)]\n",
    "csv_second_recompress_sameQP_listsA = [[] for _ in range(10)]\n",
    "csv_second_largeQP2_listsA = [[] for _ in range(10)]\n",
    "csv_second_recompress_largeQP2_listsA = [[] for _ in range(10)]\n",
    "\n",
    "def process_csv_lists(rootpath, train_list, single_list, single_recompress_list, \n",
    "                      second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                      second_sameQP_list, second_recompress_sameQP_list,\n",
    "                      second_largeQP2_list, second_recompress_largeQP2_list):\n",
    "    \n",
    "    for image in train_list:\n",
    "        single_path = osp.join(rootpath, f'HEIF_images_single_csv/{image}_*')\n",
    "        single_recompress_path = osp.join(rootpath, f'HEIF_images_second_sameQP_csv/{image}_*')\n",
    "        \n",
    "        second_largeQP1_path = osp.join(rootpath, f'HEIF_images_second_csv/{image}_*')\n",
    "        second_recompress_largeQP1_path = osp.join(rootpath, f'HEIF_images_triple_csv/{image}_*')\n",
    "        \n",
    "        second_sameQP_path = osp.join(rootpath, f'HEIF_images_second_sameQP_csv/{image}_*')\n",
    "        second_recompress_sameQP_path = osp.join(rootpath, f'HEIF_images_triple_sameQP_csv/{image}_*')\n",
    "        \n",
    "        second_largeQP2_path = osp.join(rootpath, f'HEIF_images_second_largeQP_csv/{image}_*')\n",
    "        second_recompress_largeQP2_path = osp.join(rootpath, f'HEIF_images_triple_largeQP_csv/{image}_*')\n",
    "        \n",
    "        for path in sorted(glob.glob(single_path)):\n",
    "            single_list.append(path)\n",
    "        for path in sorted(glob.glob(single_recompress_path)):\n",
    "            single_recompress_list.append(path)\n",
    "        for path in sorted(glob.glob(second_largeQP1_path)):\n",
    "            second_largeQP1_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP1_path)):\n",
    "            second_recompress_largeQP1_list.append(path)\n",
    "        for path in sorted(glob.glob(second_sameQP_path)):\n",
    "            second_sameQP_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_sameQP_path)):\n",
    "            second_recompress_sameQP_list.append(path)\n",
    "        for path in sorted(glob.glob(second_largeQP2_path)):\n",
    "            second_largeQP2_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP2_path)):\n",
    "            second_recompress_largeQP2_list.append(path)\n",
    "\n",
    "# 各カテゴリのCSVリストを生成\n",
    "for train_list, single_list, single_recompress_list in zip(train_lists, \n",
    "                                                           csv_single_listsA,\n",
    "                                                           csv_single_recompress_listsA):\n",
    "    process_csv_lists(rootpath_csv, train_list, single_list, single_recompress_list, \n",
    "                      [], [], [], [], [], [])\n",
    "\n",
    "\n",
    "for train_list, second_largeQP1_list, second_recompress_largeQP1_list, second_sameQP_list, second_recompress_sameQP_list, second_largeQP2_list, second_recompress_largeQP2_list in zip(train_lists, \n",
    "                                                                                                                                                                                                                   csv_second_largeQP1_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_recompress_largeQP1_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_sameQP_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_recompress_sameQP_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_largeQP2_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_recompress_largeQP2_listsA):\n",
    "    process_csv_lists(rootpath_csv, train_list, [], [], \n",
    "                      second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                      second_sameQP_list, second_recompress_sameQP_list,\n",
    "                      second_largeQP2_list, second_recompress_largeQP2_list)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "# 出力リストを初期化\n",
    "pkl_single_listsA = [[] for _ in range(10)]\n",
    "pkl_single_recompress_listsA = [[] for _ in range(10)]\n",
    "pkl_second_largeQP1_listsA = [[] for _ in range(10)]\n",
    "pkl_second_recompress_largeQP1_listsA = [[] for _ in range(10)]\n",
    "pkl_second_sameQP_listsA = [[] for _ in range(10)]\n",
    "pkl_second_recompress_sameQP_listsA = [[] for _ in range(10)]\n",
    "pkl_second_largeQP2_listsA = [[] for _ in range(10)]\n",
    "pkl_second_recompress_largeQP2_listsA = [[] for _ in range(10)]    \n",
    "\n",
    "def process_train_lists_pkl(rootpath, train_list, single_list, single_recompress_list, \n",
    "                            second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                            second_sameQP_list, second_recompress_sameQP_list,\n",
    "                            second_largeQP2_list, second_recompress_largeQP2_list):\n",
    "    \n",
    "    for image in train_list:\n",
    "        single_path = osp.join(rootpath, f'pkl_single/{image}_*')\n",
    "        single_recompress_path = osp.join(rootpath, f'pkl_second_sameQP/{image}_*')\n",
    "        \n",
    "        second_largeQP1_path = osp.join(rootpath, f'pkl_second/{image}_*')\n",
    "        second_recompress_largeQP1_path = osp.join(rootpath, f'pkl_triple/{image}_*')\n",
    "        \n",
    "        second_sameQP_path = osp.join(rootpath, f'pkl_second_sameQP/{image}_*')\n",
    "        second_recompress_sameQP_path = osp.join(rootpath, f'pkl_triple_sameQP/{image}_*')\n",
    "        \n",
    "        second_largeQP2_path = osp.join(rootpath, f'pkl_second_largeQP/{image}_*')\n",
    "        second_recompress_largeQP2_path = osp.join(rootpath, f'pkl_triple_largeQP/{image}_*')\n",
    "        \n",
    "\n",
    "        for path in sorted(glob.glob(single_path)):\n",
    "            single_list.append(path)\n",
    "        for path in sorted(glob.glob(single_recompress_path)):\n",
    "            single_recompress_list.append(path)\n",
    "            \n",
    "        for path in sorted(glob.glob(second_largeQP1_path)):\n",
    "            second_largeQP1_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP1_path)):\n",
    "            second_recompress_largeQP1_list.append(path)\n",
    "                \n",
    "        for path in sorted(glob.glob(second_sameQP_path)):\n",
    "            second_sameQP_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_sameQP_path)):\n",
    "            second_recompress_sameQP_list.append(path)\n",
    "            \n",
    "        for path in sorted(glob.glob(second_largeQP2_path)):\n",
    "            second_largeQP2_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP2_path)):\n",
    "            second_recompress_largeQP2_list.append(path)\n",
    "\n",
    "# 各カテゴリのリストを生成\n",
    "for train_list, single_list, single_recompress_list in zip(train_lists, \n",
    "                                                           pkl_single_listsA,\n",
    "                                                           pkl_single_recompress_listsA):\n",
    "    process_train_lists_pkl(rootpath_pkl, train_list, single_list, single_recompress_list, \n",
    "                            [], [], [], [], [], [])\n",
    "\n",
    "\n",
    "for train_list, second_largeQP1_list, second_recompress_largeQP1_list, second_sameQP_list, second_recompress_sameQP_list, second_largeQP2_list, second_recompress_largeQP2_list in zip(train_lists, \n",
    "                                                                                                                                                                                                                   pkl_second_largeQP1_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_recompress_largeQP1_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_sameQP_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_recompress_sameQP_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_largeQP2_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_recompress_largeQP2_listsA):\n",
    "    process_train_lists_pkl(rootpath_pkl, train_list, [], [], \n",
    "                            second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                            second_sameQP_list, second_recompress_sameQP_list,\n",
    "                            second_largeQP2_list, second_recompress_largeQP2_list)\n",
    "\n",
    "\n",
    "print(\"\\nCSV Single ListsA:\")\n",
    "for i, lst in enumerate(csv_single_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Single Recompress ListsA:\")\n",
    "for i, lst in enumerate(csv_single_recompress_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Large QP1 ListsA:\")\n",
    "for i, lst in enumerate(csv_second_largeQP1_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Recompress Large QP1 ListsA:\")\n",
    "for i, lst in enumerate(csv_second_recompress_largeQP1_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Same QP ListsA:\")\n",
    "for i, lst in enumerate(csv_second_sameQP_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Recompress Same QP ListsA:\")\n",
    "for i, lst in enumerate(csv_second_recompress_sameQP_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Large QP2 ListsA:\")\n",
    "for i, lst in enumerate(csv_second_largeQP2_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Recompress Large QP2 ListsA:\")\n",
    "for i, lst in enumerate(csv_second_recompress_largeQP2_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "# 出力リストを表示\n",
    "print(\"\\nPKL Single ListsA:\")\n",
    "for i, lst in enumerate(pkl_single_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Single Recompress ListsA:\")\n",
    "for i, lst in enumerate(pkl_single_recompress_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Large QP1 ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_largeQP1_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Recompress Large QP1 ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_recompress_largeQP1_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Same QP ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_sameQP_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Recompress Same QP ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_recompress_sameQP_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Large QP2 ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_largeQP2_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Recompress Large QP2 ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_recompress_largeQP2_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "# single_listsおよびsingle_recompress_listsは初期化されている前提\n",
    "single_csv1 = list(zip(csv_single_listsA[0], pkl_single_listsA[0], csv_single_recompress_listsA[0], pkl_single_recompress_listsA[0]))\n",
    "single_csv2 = list(zip(csv_single_listsA[1], pkl_single_listsA[1], csv_single_recompress_listsA[1], pkl_single_recompress_listsA[1]))\n",
    "single_csv3 = list(zip(csv_single_listsA[2], pkl_single_listsA[2], csv_single_recompress_listsA[2], pkl_single_recompress_listsA[2]))\n",
    "single_csv4 = list(zip(csv_single_listsA[3], pkl_single_listsA[3], csv_single_recompress_listsA[3], pkl_single_recompress_listsA[3]))\n",
    "single_csv5 = list(zip(csv_single_listsA[4], pkl_single_listsA[4], csv_single_recompress_listsA[4], pkl_single_recompress_listsA[4]))\n",
    "single_csv6 = list(zip(csv_single_listsA[5], pkl_single_listsA[5], csv_single_recompress_listsA[5], pkl_single_recompress_listsA[5]))\n",
    "single_csv7 = list(zip(csv_single_listsA[6], pkl_single_listsA[6], csv_single_recompress_listsA[6], pkl_single_recompress_listsA[6]))\n",
    "single_csv8 = list(zip(csv_single_listsA[7], pkl_single_listsA[7], csv_single_recompress_listsA[7], pkl_single_recompress_listsA[7]))\n",
    "single_csv9 = list(zip(csv_single_listsA[8], pkl_single_listsA[8], csv_single_recompress_listsA[8], pkl_single_recompress_listsA[8]))\n",
    "single_csv10 = list(zip(csv_single_listsA[9], pkl_single_listsA[9], csv_single_recompress_listsA[9], pkl_single_recompress_listsA[9]))\n",
    "print(len(single_csv10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1710\n",
      "\n",
      "double images train by QP1>QP2:  100\n",
      "\n",
      "double images test by QP1>QP2:  300\n"
     ]
    }
   ],
   "source": [
    "# Large_QP1\n",
    "second_largeQP1_csv1 = list(zip(csv_second_largeQP1_listsA[0], pkl_second_largeQP1_listsA[0], csv_second_recompress_largeQP1_listsA[0], pkl_second_recompress_largeQP1_listsA[0]))\n",
    "second_largeQP1_csv2 = list(zip(csv_second_largeQP1_listsA[1], pkl_second_largeQP1_listsA[1], csv_second_recompress_largeQP1_listsA[1], pkl_second_recompress_largeQP1_listsA[1]))\n",
    "second_largeQP1_csv3 = list(zip(csv_second_largeQP1_listsA[2], pkl_second_largeQP1_listsA[2], csv_second_recompress_largeQP1_listsA[2], pkl_second_recompress_largeQP1_listsA[2]))\n",
    "second_largeQP1_csv4 = list(zip(csv_second_largeQP1_listsA[3], pkl_second_largeQP1_listsA[3], csv_second_recompress_largeQP1_listsA[3], pkl_second_recompress_largeQP1_listsA[3]))\n",
    "second_largeQP1_csv5 = list(zip(csv_second_largeQP1_listsA[4], pkl_second_largeQP1_listsA[4], csv_second_recompress_largeQP1_listsA[4], pkl_second_recompress_largeQP1_listsA[4]))\n",
    "second_largeQP1_csv6 = list(zip(csv_second_largeQP1_listsA[5], pkl_second_largeQP1_listsA[5], csv_second_recompress_largeQP1_listsA[5], pkl_second_recompress_largeQP1_listsA[5]))\n",
    "second_largeQP1_csv7 = list(zip(csv_second_largeQP1_listsA[6], pkl_second_largeQP1_listsA[6], csv_second_recompress_largeQP1_listsA[6], pkl_second_recompress_largeQP1_listsA[6]))\n",
    "second_largeQP1_csv8 = list(zip(csv_second_largeQP1_listsA[7], pkl_second_largeQP1_listsA[7], csv_second_recompress_largeQP1_listsA[7], pkl_second_recompress_largeQP1_listsA[7]))\n",
    "second_largeQP1_csv9 = list(zip(csv_second_largeQP1_listsA[8], pkl_second_largeQP1_listsA[8], csv_second_recompress_largeQP1_listsA[8], pkl_second_recompress_largeQP1_listsA[8]))\n",
    "second_largeQP1_csv10 = list(zip(csv_second_largeQP1_listsA[9], pkl_second_largeQP1_listsA[9], csv_second_recompress_largeQP1_listsA[9], pkl_second_recompress_largeQP1_listsA[9]))\n",
    "print(len(second_largeQP1_csv1))\n",
    "\n",
    "\n",
    "second_largeQP1_csv1 = random.sample(second_largeQP1_csv1, 100)\n",
    "second_largeQP1_csv2 = random.sample(second_largeQP1_csv2, 100)\n",
    "second_largeQP1_csv3 = random.sample(second_largeQP1_csv3, 100)\n",
    "second_largeQP1_csv4 = random.sample(second_largeQP1_csv4, 100)\n",
    "second_largeQP1_csv5 = random.sample(second_largeQP1_csv5, 100)\n",
    "second_largeQP1_csv6 = random.sample(second_largeQP1_csv6, 100)\n",
    "second_largeQP1_csv7 = random.sample(second_largeQP1_csv7, 100)\n",
    "second_largeQP1_csv8 = random.sample(second_largeQP1_csv8, 100)\n",
    "second_largeQP1_csv9 = random.sample(second_largeQP1_csv9, 100)\n",
    "# second_largeQP1_csv10 = selected_data[9]\n",
    "print('\\ndouble images train by QP1>QP2: ', len(second_largeQP1_csv1))\n",
    "\n",
    "\n",
    "second_largeQP1_csv10 = random.sample(second_largeQP1_csv10, 300)\n",
    "print('\\ndouble images test by QP1>QP2: ', len(second_largeQP1_csv10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "\n",
      "double images train by QP1=QP2:  100\n",
      "\n",
      "double images test by QP1=QP2:  300\n"
     ]
    }
   ],
   "source": [
    "# sameQP\n",
    "second_sameQP_csv1 = list(zip(csv_second_sameQP_listsA[0], pkl_second_sameQP_listsA[0], csv_second_recompress_sameQP_listsA[0], pkl_second_recompress_sameQP_listsA[0]))\n",
    "second_sameQP_csv2 = list(zip(csv_second_sameQP_listsA[1], pkl_second_sameQP_listsA[1], csv_second_recompress_sameQP_listsA[1], pkl_second_recompress_sameQP_listsA[1]))\n",
    "second_sameQP_csv3 = list(zip(csv_second_sameQP_listsA[2], pkl_second_sameQP_listsA[2], csv_second_recompress_sameQP_listsA[2], pkl_second_recompress_sameQP_listsA[2]))\n",
    "second_sameQP_csv4 = list(zip(csv_second_sameQP_listsA[3], pkl_second_sameQP_listsA[3], csv_second_recompress_sameQP_listsA[3], pkl_second_recompress_sameQP_listsA[3]))\n",
    "second_sameQP_csv5 = list(zip(csv_second_sameQP_listsA[4], pkl_second_sameQP_listsA[4], csv_second_recompress_sameQP_listsA[4], pkl_second_recompress_sameQP_listsA[4]))\n",
    "second_sameQP_csv6 = list(zip(csv_second_sameQP_listsA[5], pkl_second_sameQP_listsA[5], csv_second_recompress_sameQP_listsA[5], pkl_second_recompress_sameQP_listsA[5]))\n",
    "second_sameQP_csv7 = list(zip(csv_second_sameQP_listsA[6], pkl_second_sameQP_listsA[6], csv_second_recompress_sameQP_listsA[6], pkl_second_recompress_sameQP_listsA[6]))\n",
    "second_sameQP_csv8 = list(zip(csv_second_sameQP_listsA[7], pkl_second_sameQP_listsA[7], csv_second_recompress_sameQP_listsA[7], pkl_second_recompress_sameQP_listsA[7]))\n",
    "second_sameQP_csv9 = list(zip(csv_second_sameQP_listsA[8], pkl_second_sameQP_listsA[8], csv_second_recompress_sameQP_listsA[8], pkl_second_recompress_sameQP_listsA[8]))\n",
    "second_sameQP_csv10 = list(zip(csv_second_sameQP_listsA[9], pkl_second_sameQP_listsA[9], csv_second_recompress_sameQP_listsA[9], pkl_second_recompress_sameQP_listsA[9]))\n",
    "print(len(second_sameQP_csv10))\n",
    "\n",
    "second_sameQP_csv1 = random.sample(second_sameQP_csv1, 100)\n",
    "second_sameQP_csv2 = random.sample(second_sameQP_csv2, 100)\n",
    "second_sameQP_csv3 = random.sample(second_sameQP_csv3, 100)\n",
    "second_sameQP_csv4 = random.sample(second_sameQP_csv4, 100)\n",
    "second_sameQP_csv5 = random.sample(second_sameQP_csv5, 100)\n",
    "second_sameQP_csv6 = random.sample(second_sameQP_csv6, 100)\n",
    "second_sameQP_csv7 = random.sample(second_sameQP_csv7, 100)\n",
    "second_sameQP_csv8 = random.sample(second_sameQP_csv8, 100)\n",
    "second_sameQP_csv9 = random.sample(second_sameQP_csv9, 100)\n",
    "print('\\ndouble images train by QP1=QP2: ',len(second_sameQP_csv9))\n",
    "\n",
    "second_sameQP_csv10 = random.sample(second_sameQP_csv10, 300)\n",
    "print('\\ndouble images test by QP1=QP2: ',len(second_sameQP_csv10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1170\n",
      "\n",
      "double images train by QP1<QP2:  100\n",
      "\n",
      "double images test by QP1<QP2:  300\n"
     ]
    }
   ],
   "source": [
    "# Large_QP2\n",
    "second_largeQP2_csv1 = list(zip(csv_second_largeQP2_listsA[0], pkl_second_largeQP2_listsA[0], csv_second_recompress_largeQP2_listsA[0], pkl_second_recompress_largeQP2_listsA[0]))\n",
    "second_largeQP2_csv2 = list(zip(csv_second_largeQP2_listsA[1], pkl_second_largeQP2_listsA[1], csv_second_recompress_largeQP2_listsA[1], pkl_second_recompress_largeQP2_listsA[1]))\n",
    "second_largeQP2_csv3 = list(zip(csv_second_largeQP2_listsA[2], pkl_second_largeQP2_listsA[2], csv_second_recompress_largeQP2_listsA[2], pkl_second_recompress_largeQP2_listsA[2]))\n",
    "second_largeQP2_csv4 = list(zip(csv_second_largeQP2_listsA[3], pkl_second_largeQP2_listsA[3], csv_second_recompress_largeQP2_listsA[3], pkl_second_recompress_largeQP2_listsA[3]))\n",
    "second_largeQP2_csv5 = list(zip(csv_second_largeQP2_listsA[4], pkl_second_largeQP2_listsA[4], csv_second_recompress_largeQP2_listsA[4], pkl_second_recompress_largeQP2_listsA[4]))\n",
    "second_largeQP2_csv6 = list(zip(csv_second_largeQP2_listsA[5], pkl_second_largeQP2_listsA[5], csv_second_recompress_largeQP2_listsA[5], pkl_second_recompress_largeQP2_listsA[5]))\n",
    "second_largeQP2_csv7 = list(zip(csv_second_largeQP2_listsA[6], pkl_second_largeQP2_listsA[6], csv_second_recompress_largeQP2_listsA[6], pkl_second_recompress_largeQP2_listsA[6]))\n",
    "second_largeQP2_csv8 = list(zip(csv_second_largeQP2_listsA[7], pkl_second_largeQP2_listsA[7], csv_second_recompress_largeQP2_listsA[7], pkl_second_recompress_largeQP2_listsA[7]))\n",
    "second_largeQP2_csv9 = list(zip(csv_second_largeQP2_listsA[8], pkl_second_largeQP2_listsA[8], csv_second_recompress_largeQP2_listsA[8], pkl_second_recompress_largeQP2_listsA[8]))\n",
    "second_largeQP2_csv10 = list(zip(csv_second_largeQP2_listsA[9], pkl_second_largeQP2_listsA[9], csv_second_recompress_largeQP2_listsA[9], pkl_second_recompress_largeQP2_listsA[9]))\n",
    "print(len(second_largeQP2_csv1))\n",
    "\n",
    "second_largeQP2_csv1 = random.sample(second_largeQP2_csv1, 100)\n",
    "second_largeQP2_csv2 = random.sample(second_largeQP2_csv2, 100)\n",
    "second_largeQP2_csv3 = random.sample(second_largeQP2_csv3, 100)\n",
    "second_largeQP2_csv4 = random.sample(second_largeQP2_csv4, 100)\n",
    "second_largeQP2_csv5 = random.sample(second_largeQP2_csv5, 100)\n",
    "second_largeQP2_csv6 = random.sample(second_largeQP2_csv6, 100)\n",
    "second_largeQP2_csv7 = random.sample(second_largeQP2_csv7, 100)\n",
    "second_largeQP2_csv8 = random.sample(second_largeQP2_csv8, 100)\n",
    "second_largeQP2_csv9 = random.sample(second_largeQP2_csv9, 100)\n",
    "# second_largeQP2_csv10 = selected_data[9]\n",
    "print('\\ndouble images train by QP1<QP2: ', len(second_largeQP2_csv1))\n",
    "\n",
    "second_largeQP2_csv10 = random.sample(second_largeQP2_csv10, 300)\n",
    "print('\\ndouble images test by QP1<QP2: ', len(second_largeQP2_csv10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_csv_list:  600\n",
      "\n",
      "test_csv_largeQP1 600\n",
      "test_csv_sameQP 600\n",
      "test_csv_largeQP2 600\n"
     ]
    }
   ],
   "source": [
    "train_csv_list1 = single_csv1 + second_largeQP1_csv1 + second_sameQP_csv1 + second_largeQP2_csv1\n",
    "train_csv_list2 = single_csv2 + second_largeQP1_csv2 + second_sameQP_csv2 + second_largeQP2_csv2\n",
    "train_csv_list3 = single_csv3 + second_largeQP1_csv3 + second_sameQP_csv3 + second_largeQP2_csv3\n",
    "train_csv_list4 = single_csv4 + second_largeQP1_csv4 + second_sameQP_csv4 + second_largeQP2_csv4\n",
    "train_csv_list5 = single_csv5 + second_largeQP1_csv5 + second_sameQP_csv5 + second_largeQP2_csv5\n",
    "train_csv_list6 = single_csv6 + second_largeQP1_csv6 + second_sameQP_csv6 + second_largeQP2_csv6\n",
    "train_csv_list7 = single_csv7 + second_largeQP1_csv7 + second_sameQP_csv7 + second_largeQP2_csv7\n",
    "train_csv_list8 = single_csv8 + second_largeQP1_csv8 + second_sameQP_csv8 + second_largeQP2_csv8\n",
    "train_csv_list9 = single_csv9 + second_largeQP1_csv9 + second_sameQP_csv9 + second_largeQP2_csv9\n",
    "print(\"train_csv_list: \", len(train_csv_list9))\n",
    "\n",
    "test_csv_largeQP1 = single_csv10 + second_largeQP1_csv10\n",
    "test_csv_sameQP = single_csv10 + second_sameQP_csv10\n",
    "test_csv_largeQP2 = single_csv10 + second_largeQP2_csv10\n",
    "\n",
    "print(\"\\ntest_csv_largeQP1\", len(test_csv_largeQP1))\n",
    "print(\"test_csv_sameQP\", len(test_csv_sameQP))\n",
    "print(\"test_csv_largeQP2\", len(test_csv_largeQP2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_smoothing(probabilities, alpha=1):\n",
    "    \"\"\"\n",
    "    ラプラス平滑化を行う関数\n",
    "    \n",
    "    Args:\n",
    "    probabilities (list): 平滑化する確率分布のリスト\n",
    "    alpha (float): 平滑化パラメータ\n",
    "    \n",
    "    Returns:\n",
    "    smoothed_probabilities (list): 平滑化された確率分布のリスト\n",
    "    \"\"\"\n",
    "    total_count = sum(probabilities)\n",
    "    num_elements = len(probabilities)\n",
    "    \n",
    "    smoothed_probabilities = [(count + alpha) / (total_count + alpha * num_elements) for count in probabilities]\n",
    "    \n",
    "    return smoothed_probabilities\n",
    "\n",
    "\n",
    "def process_train_csv_lists(train_csv_list):\n",
    "    pu_columns = [\"PU1_64\", \"PU1_32\", \"PU1_16\", \"PU1_8\", \"PU1_4\",  \n",
    "                  \"PU2_64\",\"PU2_32\", \"PU2_16\", \"PU2_8\", \"PU2_4\"]\n",
    "\n",
    "#     luminance_columns = [\"LU1_0\",\"LU1_1\",\"LU1_2\",\"LU1_3\",\n",
    "#                          \"LU1_4\",\"LU1_5\",\"LU1_6\",\"LU1_7\",\n",
    "#                          \"LU1_8\",\"LU1_9\",\"LU1_10\",\"LU1_11\",\n",
    "#                          \"LU1_12\",\"LU1_13\",\"LU1_14\",\"LU1_15\",\n",
    "#                          \"LU1_16\",\"LU1_17\",\"LU1_18\",\"LU1_19\",\n",
    "#                          \"LU1_20\",\"LU1_21\",\"LU1_22\",\"LU1_23\",\n",
    "#                          \"LU1_24\",\"LU1_25\",\"LU1_26\",\"LU1_27\",\n",
    "#                          \"LU1_28\",\"LU1_29\",\"LU1_30\",\"LU1_31\",\n",
    "#                          \"LU1_32\",\"LU1_33\",\"LU1_34\",\n",
    "                         \n",
    "#                          \"LU2_0\",\"LU2_1\",\"LU2_2\",\"LU2_3\",\n",
    "#                          \"LU2_4\",\"LU2_5\",\"LU2_6\",\"LU2_7\",\n",
    "#                          \"LU2_8\",\"LU2_9\",\"LU2_10\",\"LU2_11\",\n",
    "#                          \"LU2_12\",\"LU2_13\",\"LU2_14\",\"LU2_15\",\n",
    "#                          \"LU2_16\",\"LU2_17\",\"LU2_18\",\"LU2_19\",\n",
    "#                          \"LU2_20\",\"LU2_21\",\"LU2_22\",\"LU2_23\",\n",
    "#                          \"LU2_24\",\"LU2_25\",\"LU2_26\",\"LU2_27\",\n",
    "#                          \"LU2_28\",\"LU2_29\",\"LU2_30\",\"LU2_31\",\n",
    "#                          \"LU2_32\",\"LU2_33\",\"LU2_34\"]\n",
    "    \n",
    "    luminance_columns = [\"LU1_0\",\"LU1_1\",\"LU1_9\",\"LU1_10\",\"LU1_11\",\"LU1_25\",\"LU1_26\",\"LU1_27\",\n",
    "                         \"LU2_0\",\"LU2_1\",\"LU2_9\",\"LU2_10\",\"LU2_11\", \"LU2_25\",\"LU2_26\",\"LU2_27\"]\n",
    "\n",
    "    chrominance_columns = [\"CH1_0\", \"CH1_1\", \"CH1_10\", \"CH1_26\", \"CH1_34\", \"CH1_36\", \n",
    "                           \"CH2_0\", \"CH2_1\", \"CH2_10\", \"CH2_26\", \"CH2_34\", \"CH2_36\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    label_columns = [\"LABEL\"]\n",
    "    mae1_columns = [f\"MAE1_{i}\" for i in range(52)]\n",
    "    mae2_columns = [f\"MAE2_{i}\" for i in range(52)]\n",
    "    mae_columns = [\"MAE\"]\n",
    "    final_qp_columns = [\"FINAL_QP\"]\n",
    "    kl_divergence1 = [\"KLD_PU\"]\n",
    "    kl_divergence2 = [\"KLD_LUMA\"]\n",
    "    kl_divergence3 = [\"KLD_CHROMA\"]\n",
    "    ratio_columns1 = [\"RATIO1\"]\n",
    "    ratio_columns2 = [\"RATIO2\"]\n",
    "    \n",
    "    train_df1_1 = pd.DataFrame(columns=pu_columns)\n",
    "    train_df1_2 = pd.DataFrame(columns=luminance_columns)\n",
    "    train_df1_3 = pd.DataFrame(columns=chrominance_columns)\n",
    "    LABEL = pd.DataFrame(columns=label_columns)\n",
    "    RATIO1 = pd.DataFrame(columns=ratio_columns1)\n",
    "    RATIO2 = pd.DataFrame(columns=ratio_columns2)\n",
    "    train_df3 = pd.DataFrame(columns=mae1_columns)\n",
    "    train_df4 = pd.DataFrame(columns=mae2_columns)\n",
    "    MAE = pd.DataFrame(columns=mae_columns)\n",
    "    FINAL_QP = pd.DataFrame(columns=final_qp_columns)\n",
    "    kl_divergence_df1 = pd.DataFrame(columns=kl_divergence1)\n",
    "    kl_divergence_df2 = pd.DataFrame(columns=kl_divergence2)\n",
    "    kl_divergence_df3 = pd.DataFrame(columns=kl_divergence3)\n",
    "\n",
    "    for path1, path2, path3, path4 in train_csv_list:\n",
    "        label = 1 if (\"2ndQP\" in path1) and (\"3rdQP\" in path3) else 0\n",
    "        train_pkl_list = [path2, path4]\n",
    "        df1 = pd.read_csv(path1)\n",
    "        df2 = pd.read_csv(path3)\n",
    "        \n",
    "        # 平滑化を行う\n",
    "        probabilities_df1 = laplace_smoothing([df1.loc[i, \"pu_counts\"] for i in [0,1,2,3,4]])\n",
    "        probabilities_df2 = laplace_smoothing([df2.loc[i, \"pu_counts\"] for i in [0,1,2,3,4]])\n",
    "        kl_divergence1 = entropy(probabilities_df1, probabilities_df2)\n",
    "        \n",
    "        probabilities_df3 = laplace_smoothing([df1.loc[i, \"luminance_counts\"] for i in [0,1,9,10,11,25,26,27]])\n",
    "        probabilities_df4 = laplace_smoothing([df2.loc[i, \"luminance_counts\"] for i in [0,1,9,10,11,25,26,27]])\n",
    "        kl_divergence2 = entropy(probabilities_df3, probabilities_df4)\n",
    "        \n",
    "        probabilities_df5 = laplace_smoothing([df1.loc[i, \"chroma_counts\"] for i in [0,1,10,26,34,36]])\n",
    "        probabilities_df6 = laplace_smoothing([df2.loc[i, \"chroma_counts\"] for i in [0,1,10,26,34,36]])\n",
    "        kl_divergence3 = entropy(probabilities_df5, probabilities_df6)\n",
    "        \n",
    "        \n",
    "        pu_values = [df1.loc[i, \"pu_counts\"] for i in range(5)] + [df2.loc[i, \"pu_counts\"] for i in range(5)]\n",
    "        # lu_values = [df1.loc[i, \"luminance_counts\"] for i in range(35)] + [df2.loc[i, \"luminance_counts\"] for i in range(35)]\n",
    "        lu_values = [df1.loc[i, \"luminance_counts\"] for i in [0,1,9,10,11,25,26,27]] + [df2.loc[i, \"luminance_counts\"] for i in [0,1,9,10,11,25,26,27]]\n",
    "        ch_values = [df1.loc[i, \"chroma_counts\"] for i in [0,1,10,26,34,36]] + [df2.loc[i, \"chroma_counts\"] for i in [0,1,10,26,34,36]]\n",
    "        \n",
    "        train_df1_1 = pd.concat([train_df1_1, pd.DataFrame([pu_values], columns=pu_columns)], ignore_index=True)\n",
    "        train_df1_2= pd.concat([train_df1_2, pd.DataFrame([lu_values], columns=luminance_columns)], ignore_index=True)\n",
    "        train_df1_3 = pd.concat([train_df1_3, pd.DataFrame([ch_values], columns=chrominance_columns)], ignore_index=True)\n",
    "        \n",
    "        kl_divergence_df1 = pd.concat([kl_divergence_df1, pd.DataFrame({\"KLD_PU\": [kl_divergence1]})], ignore_index=True)\n",
    "        kl_divergence_df2 = pd.concat([kl_divergence_df2, pd.DataFrame({\"KLD_LUMA\": [kl_divergence2]})], ignore_index=True)\n",
    "        kl_divergence_df3 = pd.concat([kl_divergence_df3, pd.DataFrame({\"KLD_CHROMA\": [kl_divergence3]})], ignore_index=True)\n",
    "\n",
    "\n",
    "        LABEL = pd.concat([LABEL, pd.DataFrame({\"LABEL\": [label]})], ignore_index=True)\n",
    "\n",
    "        final_QP = extract_finalQP(train_pkl_list[0])\n",
    "\n",
    "        mae_d1 = calculate_mae(train_pkl_list[0])\n",
    "        mae_d2 = calculate_mae(train_pkl_list[1])\n",
    "        ratio1 = ratio_double_compressed(mae_d1, final_QP)\n",
    "        ratio2 = ratio_double_compressed(mae_d2, final_QP)\n",
    "\n",
    "        RATIO1 = pd.concat([RATIO1, pd.DataFrame({\"RATIO1\": [ratio1]})], ignore_index=True)\n",
    "        RATIO2 = pd.concat([RATIO2, pd.DataFrame({\"RATIO2\": [ratio2]})], ignore_index=True)\n",
    "\n",
    "        train_df3 = pd.concat([train_df3, pd.DataFrame({f\"MAE1_{i}\": [mae_d1[i]] for i in range(52)})], ignore_index=True)\n",
    "        train_df4 = pd.concat([train_df4, pd.DataFrame({f\"MAE2_{i}\": [mae_d2[i]] for i in range(52)})], ignore_index=True)\n",
    "        MAE = pd.concat([MAE, pd.DataFrame({\"MAE\": [mae_d1]})], ignore_index=True)\n",
    "        FINAL_QP = pd.concat([FINAL_QP, pd.DataFrame({\"FINAL_QP\": [final_QP]})], ignore_index=True)\n",
    "\n",
    "    train_df1_1.reset_index(drop=True, inplace=True)\n",
    "    train_df1_2.reset_index(drop=True, inplace=True)\n",
    "    train_df1_3.reset_index(drop=True, inplace=True)\n",
    "    LABEL.reset_index(drop=True, inplace=True)\n",
    "    RATIO1.reset_index(drop=True, inplace=True)\n",
    "    RATIO2.reset_index(drop=True, inplace=True)\n",
    "    kl_divergence_df1.reset_index(drop=True, inplace=True)\n",
    "    kl_divergence_df2.reset_index(drop=True, inplace=True)\n",
    "    kl_divergence_df3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # train_df = pd.concat([train_df1_1, train_df1_2, train_df1_3, train_df3, train_df4], axis=1)\n",
    "    train_df = pd.concat([FINAL_QP, train_df1_1, train_df1_2, train_df1_3, kl_divergence_df1, kl_divergence_df2, kl_divergence_df3, RATIO1, RATIO2], axis=1)\n",
    "    train_df_onlyGhost = pd.concat([FINAL_QP, kl_divergence_df1, kl_divergence_df2, kl_divergence_df3, RATIO1, RATIO2], axis=1)\n",
    "\n",
    "    return train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1, train_df_onlyGhost1, LABEL1, MAE1, FINAL_QP1 = process_train_csv_lists(train_csv_list1)\n",
    "train_df2, train_df_onlyGhost2, LABEL2, MAE2, FINAL_QP2 = process_train_csv_lists(train_csv_list2)\n",
    "train_df3, train_df_onlyGhost3, LABEL3, MAE3, FINAL_QP3 = process_train_csv_lists(train_csv_list3)\n",
    "train_df4, train_df_onlyGhost4, LABEL4, MAE4, FINAL_QP4 = process_train_csv_lists(train_csv_list4)\n",
    "train_df5, train_df_onlyGhost5, LABEL5, MAE5, FINAL_QP5 = process_train_csv_lists(train_csv_list5)\n",
    "train_df6, train_df_onlyGhost6, LABEL6, MAE6, FINAL_QP6 = process_train_csv_lists(train_csv_list6)\n",
    "train_df7, train_df_onlyGhost7, LABEL7, MAE7, FINAL_QP7 = process_train_csv_lists(train_csv_list7)\n",
    "train_df8, train_df_onlyGhost8, LABEL8, MAE8, FINAL_QP8 = process_train_csv_lists(train_csv_list8)\n",
    "train_df9, train_df_onlyGhost9, LABEL9, MAE9, FINAL_QP9 = process_train_csv_lists(train_csv_list9)\n",
    "\n",
    "test_df1, test_df_onlyGhost1, LABEL_t1, MAE_t1, FINAL_QP_t1 = process_train_csv_lists(test_csv_largeQP1)\n",
    "test_df2, test_df_onlyGhost2, LABEL_t2, MAE_t2, FINAL_QP_t2 = process_train_csv_lists(test_csv_sameQP)\n",
    "test_df3, test_df_onlyGhost3, LABEL_t3, MAE_t3, FINAL_QP_t3 = process_train_csv_lists(test_csv_largeQP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各データフレームを結合\n",
    "combined_train_df = pd.concat([train_df1, train_df2, train_df3, train_df4, train_df5, train_df6, train_df7, train_df8, train_df9], ignore_index=True)\n",
    "combined_train_df_onlyGhost = pd.concat([train_df_onlyGhost1, train_df_onlyGhost2, train_df_onlyGhost3, train_df_onlyGhost4, train_df_onlyGhost5, train_df_onlyGhost6, train_df_onlyGhost7, train_df_onlyGhost8, train_df_onlyGhost9], ignore_index=True)\n",
    "combined_LABEL = pd.concat([LABEL1, LABEL2, LABEL3, LABEL4, LABEL5, LABEL6, LABEL7, LABEL8, LABEL9], ignore_index=True)\n",
    "combined_MAE = pd.concat([MAE1, MAE2, MAE3, MAE4, MAE5, MAE6, MAE7, MAE8, MAE9], ignore_index=True)\n",
    "combined_FINAL_QP = pd.concat([FINAL_QP1, FINAL_QP2, FINAL_QP3, FINAL_QP4, FINAL_QP5, FINAL_QP6, FINAL_QP7, FINAL_QP8, FINAL_QP9], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5400, 44)\n",
      "(5400, 6)\n",
      "(5400, 1)\n",
      "(5400, 1)\n",
      "(5400, 1)\n",
      "(600, 44)\n",
      "(600, 6)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 44)\n",
      "(600, 6)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 44)\n",
      "(600, 6)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 1)\n"
     ]
    }
   ],
   "source": [
    "print(combined_train_df.shape)\n",
    "print(combined_train_df_onlyGhost.shape)\n",
    "print(combined_LABEL.shape)\n",
    "print(combined_MAE.shape)\n",
    "print(combined_FINAL_QP.shape)\n",
    "\n",
    "print(test_df1.shape)\n",
    "print(test_df_onlyGhost1.shape)\n",
    "print(LABEL_t1.shape)\n",
    "print(MAE_t1.shape)\n",
    "print(FINAL_QP_t1.shape)\n",
    "\n",
    "print(test_df2.shape)\n",
    "print(test_df_onlyGhost2.shape)\n",
    "print(LABEL_t2.shape)\n",
    "print(MAE_t2.shape)\n",
    "print(FINAL_QP_t2.shape)\n",
    "\n",
    "print(test_df3.shape)\n",
    "print(test_df_onlyGhost3.shape)\n",
    "print(LABEL_t3.shape)\n",
    "print(MAE_t3.shape)\n",
    "print(FINAL_QP_t3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling:\n",
      "Combined Train DF:\n",
      "  FINAL_QP PU1_64 PU1_32 PU1_16  PU1_8  PU1_4 PU2_64 PU2_32 PU2_16  PU2_8  PU2_4 LU1_0 LU1_1 LU1_9 LU1_10 LU1_11 LU1_25 LU1_26 LU1_27 LU2_0 LU2_1 LU2_9 LU2_10 LU2_11 LU2_25 LU2_26 LU2_27  CH1_0  CH1_1 CH1_10 CH1_26 CH1_34 CH1_36  CH2_0  CH2_1 CH2_10 CH2_26 CH2_34 CH2_36    KLD_PU  KLD_LUMA KLD_CHROMA    RATIO1    RATIO2\n",
      "0       10      0  11136   7328  11444  30092      0  11072   7328  11228  30372  7491  8539  2984   3615   2079   1860   2967   1688  7187  9115  3178   4467   1837   1886   2835   1666  11800  15996   8388   7240   1872  14704  11788  16300   8880   7508   1700  13824  0.000059  0.003921   0.000957  0.132963   0.07724\n",
      "1       16      0  13312   8832  14516  23340      0  12544   9488  14056  23912  7549  6398  2989   2266   1848   1684   3045   1517  7306  6812  3210   2833   2071   1666   3021   1622  11260   7064   8016   4340   1488  27832  10744   7224   8132   5068   1248  27584   0.00101  0.002715   0.001543  0.053895  0.027892\n",
      "2       20      0  12992  13136  14512  19360      0  12800  13216  14324  19660  8607  6806  2501   1786   1169   1817   3044   1635  8811  7376  2575   2054   1176   1812   3137   1529   8912   3808   6924   3744   1376  35236   8564   3688   7204   3760   1208  35576  0.000087   0.00101   0.000454  0.020671  0.013854\n",
      "3       24      0  19712   9648  14684  15956      0  19904   9408  14572  16116  9706  6686  1820   3043   1120   1553   3213   1666  9622  7575  1944   3216   1174   1504   3360   1604   8276   1792   5592   2084   1332  40924   7644   2032   5208   1952   1036  42128  0.000086  0.001595   0.001907  0.077032  0.071636\n",
      "4       27      0  21632  10624  14236  13508      0  21440  11104  14020  13436  9690  7583  1741   3260    990   1580   3522   1435  9989  8654  1640   3886    792   1616   3701   1413   5956   1452   3192   1844    716  46840   5348   1268   3260   1564    836  47724  0.000221   0.00337   0.001462  0.217541  0.193399\n",
      "Combined Train DF Only Ghost:\n",
      "  FINAL_QP    KLD_PU  KLD_LUMA KLD_CHROMA    RATIO1    RATIO2\n",
      "0       10  0.000059  0.003921   0.000957  0.132963   0.07724\n",
      "1       16   0.00101  0.002715   0.001543  0.053895  0.027892\n",
      "2       20  0.000087   0.00101   0.000454  0.020671  0.013854\n",
      "3       24  0.000086  0.001595   0.001907  0.077032  0.071636\n",
      "4       27  0.000221   0.00337   0.001462  0.217541  0.193399\n",
      "\n",
      "Before scaling:\n",
      "Combined Test DF:\n",
      "  FINAL_QP PU1_64 PU1_32 PU1_16  PU1_8  PU1_4 PU2_64 PU2_32 PU2_16  PU2_8  PU2_4  LU1_0  LU1_1 LU1_9 LU1_10 LU1_11 LU1_25 LU1_26 LU1_27  LU2_0  LU2_1 LU2_9 LU2_10 LU2_11 LU2_25 LU2_26 LU2_27  CH1_0  CH1_1 CH1_10 CH1_26 CH1_34 CH1_36  CH2_0  CH2_1 CH2_10 CH2_26 CH2_34 CH2_36    KLD_PU  KLD_LUMA KLD_CHROMA    RATIO1    RATIO2\n",
      "0       10      0   3840   7216  18980  29964      0   3712   7184  18836  30268  10712  10910  1581   2225   1327    867   1331    973  10148  11939  1591   2301   1283    964   1584   1259  14664  14108   8044   7636   2716  12832  14640  14836   8192   7908   2540  11884  0.000072  0.003457   0.001117  0.112225  0.064618\n",
      "1       16      0  16512  10400  17764  15324      0  16256  10352  17916  15476  11503  12038  1549   2024   1515   1277   1380   1167  12077  13098  1508   1828   1519   1185   1599   1390  11068   9968   5116   4388   2572  26888  10280   9800   4828   4408   2432  28252  0.000059  0.001885   0.001279  0.057656  0.019632\n",
      "2       20      0  28672  17760   7820   5748      0  28800  17696   7680   5824  13850  14109  1272   1471   1044    614   1170   1229  14010  15218  1531   1443    936    570   1268   1158  10440   4096   3480   3292   3024  35668   9956   4416   3664   3820   2712  35432  0.000036  0.001525   0.001409   0.05299   0.02786\n",
      "3       24      0  40832  14464   3048   1656      0  41088  14256   3120   1536  14689  14373   989   1224   1278    895    780   1181  15185  15407  1034   1461   1332    969    908   1088  10868   1096   3156   3200   3920  37760  10008   1408   3712   3220   3908  37744  0.000129  0.000826   0.001955  0.258297  0.233152\n",
      "4       27      0  45824  11584   1728    864      0  45440  11968   1744    848  14746  12321  1068   1448    992   1281   1324   1511  15297  12526  1144   1723    932   1053   1454   1887   8320    660   1948   1144   3572  44356   8392    644   1792   1600   3356  44216  0.000134   0.00242   0.001438  0.178115  0.184594\n",
      "Combined Test DF Only Ghost:\n",
      "  FINAL_QP    KLD_PU  KLD_LUMA KLD_CHROMA    RATIO1    RATIO2\n",
      "0       10  0.000072  0.003457   0.001117  0.112225  0.064618\n",
      "1       16  0.000059  0.001885   0.001279  0.057656  0.019632\n",
      "2       20  0.000036  0.001525   0.001409   0.05299   0.02786\n",
      "3       24  0.000129  0.000826   0.001955  0.258297  0.233152\n",
      "4       27  0.000134   0.00242   0.001438  0.178115  0.184594\n"
     ]
    }
   ],
   "source": [
    "print(\"Before scaling:\")\n",
    "print(\"Combined Train DF:\")\n",
    "print(combined_train_df.head())\n",
    "print(\"Combined Train DF Only Ghost:\")\n",
    "print(combined_train_df_onlyGhost.head())\n",
    "\n",
    "print(\"\\nBefore scaling:\")\n",
    "print(\"Combined Test DF:\")\n",
    "print(test_df1.head())\n",
    "print(\"Combined Test DF Only Ghost:\")\n",
    "print(test_df_onlyGhost1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After scaling:\n",
      "X_train:\n",
      "      0    1         2         3         4         5    6         7         8         9         10        11        12        13        14        15        16        17        18        19        20        21        22        23        24        25        26        27        28        29        30        31        32        33        34        35        36        37        38        39        40        41        42        43\n",
      "0  0.125  0.0  0.189130  0.239916  0.396700  0.528969  0.0  0.187839  0.239665  0.383261  0.529240  0.126528  0.193854  0.227751  0.169701  0.171326  0.132121  0.101560  0.178379  0.132159  0.203803  0.237005  0.209079  0.151462  0.127856  0.089262  0.182736  0.301945  0.614947  0.476483  0.442435  0.174823  0.203322  0.295527  0.621000  0.463079  0.423989  0.156250  0.190690  0.003311  0.022557  0.013819  0.131174  0.075880\n",
      "1  0.275  0.0  0.226087  0.289157  0.503189  0.410280  0.0  0.212812  0.310309  0.479792  0.416672  0.128481  0.130527  0.228133  0.105233  0.152105  0.119619  0.104536  0.160309  0.136464  0.135917  0.239391  0.131488  0.171011  0.112941  0.095909  0.177909  0.288127  0.271567  0.455351  0.265216  0.138962  0.434302  0.269354  0.275221  0.424072  0.286198  0.114706  0.431856  0.056625  0.015603  0.022282  0.051942  0.026457\n",
      "2  0.375  0.0  0.220652  0.430068  0.503050  0.340318  0.0  0.217155  0.432234  0.488940  0.342580  0.164102  0.142595  0.190887  0.082294  0.095607  0.129067  0.104498  0.172778  0.190912  0.152542  0.192035  0.094496  0.096241  0.122839  0.100054  0.167709  0.228045  0.146394  0.393320  0.228795  0.128502  0.564572  0.214701  0.140506  0.375678  0.212333  0.111029  0.571929  0.004863  0.005771  0.006556  0.018650  0.012398\n",
      "3  0.475  0.0  0.334783  0.315872  0.509013  0.280481  0.0  0.337676  0.307692  0.497406  0.280825  0.201104  0.139046  0.138910  0.142366  0.091529  0.110314  0.110946  0.176054  0.220253  0.158408  0.144977  0.149675  0.096074  0.101959  0.108022  0.175935  0.211771  0.068891  0.317655  0.127353  0.124393  0.664649  0.191637  0.077415  0.271589  0.110233  0.095221  0.686764  0.004850  0.009147  0.027539  0.075127  0.070267\n",
      "4  0.550  0.0  0.367391  0.347826  0.493483  0.237449  0.0  0.363735  0.363161  0.478564  0.234126  0.200566  0.165577  0.132880  0.152736  0.080712  0.112232  0.122735  0.151643  0.233530  0.190214  0.122306  0.181490  0.064160  0.109552  0.120207  0.154985  0.152405  0.055820  0.181322  0.112686  0.066866  0.768738  0.134075  0.048308  0.170004  0.088322  0.076838  0.784843  0.012363  0.019381  0.021107  0.215928  0.192214\n",
      "X_train_onlyGhost:\n",
      "       0         1         2         3         4         5\n",
      "0  0.125  0.003311  0.022557  0.013819  0.131174  0.075880\n",
      "1  0.275  0.056625  0.015603  0.022282  0.051942  0.026457\n",
      "2  0.375  0.004863  0.005771  0.006556  0.018650  0.012398\n",
      "3  0.475  0.004850  0.009147  0.027539  0.075127  0.070267\n",
      "4  0.550  0.012363  0.019381  0.021107  0.215928  0.192214\n",
      "\n",
      "Test data after scaling:\n",
      "X_test_list1:\n",
      "      0    1         2         3         4         5    6         7         8         9         10        11        12        13        14        15        16        17        18        19        20        21        22        23        24        25        26        27        28        29        30        31        32        33        34        35        36        37        38        39        40        41        42        43\n",
      "0  0.125  0.0  0.065217  0.236249  0.657931  0.526719  0.0  0.062975  0.234956  0.642955  0.527427  0.234975  0.263983  0.120669  0.103274  0.108754  0.061585  0.039144  0.102822  0.239282  0.287045  0.118652  0.106225  0.105180  0.065352  0.044560  0.138094  0.375230  0.542365  0.456942  0.466634  0.253642  0.170385  0.367028  0.565224  0.427201  0.446578  0.233456  0.156688  0.004049  0.019880  0.016134  0.110394  0.063239\n",
      "1  0.275  0.0  0.280435  0.340492  0.615779  0.269371  0.0  0.275787  0.338566  0.611551  0.269673  0.261607  0.297347  0.118226  0.093668  0.124397  0.090709  0.041013  0.123322  0.309070  0.321209  0.112462  0.083765  0.124896  0.080334  0.045096  0.152462  0.283214  0.383208  0.290616  0.268150  0.240194  0.417693  0.257722  0.373362  0.251773  0.248927  0.223529  0.443564  0.003281  0.010816  0.018472  0.055711  0.018184\n",
      "2  0.375  0.0  0.486957  0.581456  0.271076  0.101041  0.0  0.488599  0.578755  0.262152  0.101485  0.340628  0.358603  0.097084  0.067240  0.085206  0.043614  0.033001  0.129874  0.379002  0.383699  0.114177  0.065483  0.076190  0.038641  0.033268  0.127015  0.267144  0.157466  0.197682  0.201173  0.282406  0.572173  0.249599  0.168241  0.191072  0.215722  0.249265  0.569405  0.002024  0.008743  0.020335  0.051035  0.026425\n",
      "3  0.475  0.0  0.693478  0.473546  0.105657  0.029110  0.0  0.697068  0.466248  0.106499  0.026765  0.368876  0.366411  0.075485  0.055436  0.104676  0.063574  0.018122  0.124802  0.421512  0.389270  0.077112  0.066337  0.109273  0.065690  0.020404  0.119338  0.278096  0.042134  0.179277  0.195551  0.366081  0.608980  0.250903  0.053642  0.193575  0.181839  0.359191  0.609927  0.007207  0.004711  0.028225  0.256769  0.232027\n",
      "4  0.550  0.0  0.778261  0.379256  0.059900  0.015188  0.0  0.770901  0.391418  0.059530  0.014777  0.370796  0.305717  0.081514  0.066141  0.080879  0.090993  0.038877  0.159675  0.425563  0.304348  0.085316  0.078779  0.075856  0.071385  0.039914  0.206976  0.212897  0.025373  0.110657  0.069910  0.333582  0.725033  0.210389  0.024535  0.093450  0.090355  0.308456  0.723360  0.007539  0.013904  0.020763  0.176420  0.183396\n",
      "X_test_onlyGhost_list1:\n",
      "       0         1         2         3         4         5\n",
      "0  0.125  0.004049  0.019880  0.016134  0.110394  0.063239\n",
      "1  0.275  0.003281  0.010816  0.018472  0.055711  0.018184\n",
      "2  0.375  0.002024  0.008743  0.020335  0.051035  0.026425\n",
      "3  0.475  0.007207  0.004711  0.028225  0.256769  0.232027\n",
      "4  0.550  0.007539  0.013904  0.020763  0.176420  0.183396\n"
     ]
    }
   ],
   "source": [
    "def process_results_to_lists(train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP, scaler_main=None, scaler_ghost=None, fit_scaler=True):\n",
    "    if fit_scaler:\n",
    "        scaler_main = MinMaxScaler()\n",
    "        scaler_ghost = MinMaxScaler()\n",
    "        X_train = scaler_main.fit_transform(train_df)\n",
    "        X_train_onlyGhost = scaler_ghost.fit_transform(train_df_onlyGhost)\n",
    "    else:\n",
    "        X_train = scaler_main.transform(train_df)\n",
    "        X_train_onlyGhost = scaler_ghost.transform(train_df_onlyGhost)\n",
    "\n",
    "    MAE_array = MAE.values\n",
    "    FINAL_QP_array = FINAL_QP.values\n",
    "    Y_train = LABEL['LABEL'].astype(int).values\n",
    "\n",
    "    return X_train, X_train_onlyGhost, MAE_array, FINAL_QP_array, Y_train, scaler_main, scaler_ghost\n",
    "\n",
    "# 訓練データのスケーリング\n",
    "X_train, X_train_onlyGhost, MAE_array, FINAL_QP_array, Y_train, scaler_main, scaler_ghost = process_results_to_lists(\n",
    "    combined_train_df, combined_train_df_onlyGhost, combined_LABEL, combined_MAE, combined_FINAL_QP, fit_scaler=True\n",
    ")\n",
    "\n",
    "# スケーリング後のデータを表示（任意）\n",
    "print(\"After scaling:\")\n",
    "print(\"X_train:\")\n",
    "print(pd.DataFrame(X_train).head())\n",
    "print(\"X_train_onlyGhost:\")\n",
    "print(pd.DataFrame(X_train_onlyGhost).head())\n",
    "\n",
    "# データを元に戻すための関数\n",
    "def restore_data_to_original_order(data, original_lengths):\n",
    "    restored_data = []\n",
    "    start_index = 0\n",
    "    for length in original_lengths:\n",
    "        restored_data.append(data[start_index:start_index + length])\n",
    "        start_index += length\n",
    "    return restored_data\n",
    "\n",
    "# 元のデータフレームの長さ\n",
    "original_lengths = [len(train_df1), len(train_df2), len(train_df3), len(train_df4), len(train_df5), \n",
    "                    len(train_df6), len(train_df7), len(train_df8), len(train_df9)]\n",
    "\n",
    "# データを元の順序に戻す\n",
    "X_train_list = restore_data_to_original_order(X_train, original_lengths)\n",
    "X_train_onlyGhost_list = restore_data_to_original_order(X_train_onlyGhost, original_lengths)\n",
    "MAE_list = restore_data_to_original_order(MAE_array, original_lengths)\n",
    "FINAL_QP_list = restore_data_to_original_order(FINAL_QP_array, original_lengths)\n",
    "Y_train_list = restore_data_to_original_order(Y_train, original_lengths)\n",
    "\n",
    "# テストデータのスケーリング関数\n",
    "def append_results_to_lists(train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP, X_train_list, X_train_onlyGhost_list, MAE_list, FINAL_QP_list, Y_train_list, scaler_main=None, scaler_ghost=None, fit_scaler=True):\n",
    "    X_train, X_train_onlyGhost, MAE_array, FINAL_QP_array, Y_train, _, _ = process_results_to_lists(\n",
    "        train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP, scaler_main, scaler_ghost, fit_scaler)\n",
    "    X_train_list.append(X_train)\n",
    "    X_train_onlyGhost_list.append(X_train_onlyGhost)\n",
    "    MAE_list.append(MAE_array)\n",
    "    FINAL_QP_list.append(FINAL_QP_array)\n",
    "    Y_train_list.append(Y_train)\n",
    "    return X_train_list, X_train_onlyGhost_list, MAE_list, FINAL_QP_list, Y_train_list\n",
    "\n",
    "# テストデータ用のリストの初期化\n",
    "X_test_list1 = []\n",
    "X_test_onlyGhost_list1 = []\n",
    "MAE_list_t1 = []\n",
    "FINAL_QP_list_t1 = []\n",
    "Y_test_list1 = []\n",
    "\n",
    "X_test_list2 = []\n",
    "X_test_onlyGhost_list2 = []\n",
    "MAE_list_t2 = []\n",
    "FINAL_QP_list_t2 = []\n",
    "Y_test_list2 = []\n",
    "\n",
    "X_test_list3 = []\n",
    "X_test_onlyGhost_list3 = []\n",
    "MAE_list_t3 = []\n",
    "FINAL_QP_list_t3 = []\n",
    "Y_test_list3 = []\n",
    "\n",
    "# テストデータの処理とスケーリング\n",
    "X_test_list1, X_test_onlyGhost_list1, MAE_list_t1, FINAL_QP_list_t1, Y_test_list1 = append_results_to_lists(\n",
    "    test_df1, test_df_onlyGhost1, LABEL_t1, MAE_t1, FINAL_QP_t1, X_test_list1, X_test_onlyGhost_list1, MAE_list_t1, FINAL_QP_list_t1, Y_test_list1, scaler_main, scaler_ghost, fit_scaler=False\n",
    ")\n",
    "X_test_list2, X_test_onlyGhost_list2, MAE_list_t2, FINAL_QP_list_t2, Y_test_list2 = append_results_to_lists(\n",
    "    test_df2, test_df_onlyGhost2, LABEL_t2, MAE_t2, FINAL_QP_t2, X_test_list2, X_test_onlyGhost_list2, MAE_list_t2, FINAL_QP_list_t2, Y_test_list2, scaler_main, scaler_ghost, fit_scaler=False\n",
    ")\n",
    "X_test_list3, X_test_onlyGhost_list3, MAE_list_t3, FINAL_QP_list_t3, Y_test_list3 = append_results_to_lists(\n",
    "    test_df3, test_df_onlyGhost3, LABEL_t3, MAE_t3, FINAL_QP_t3, X_test_list3, X_test_onlyGhost_list3, MAE_list_t3, FINAL_QP_list_t3, Y_test_list3, scaler_main, scaler_ghost, fit_scaler=False\n",
    ")\n",
    "\n",
    "# 確認用の出力\n",
    "print(\"\\nTest data after scaling:\")\n",
    "print(\"X_test_list1:\")\n",
    "print(pd.DataFrame(X_test_list1[0]).head())\n",
    "print(\"X_test_onlyGhost_list1:\")\n",
    "print(pd.DataFrame(X_test_onlyGhost_list1[0]).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Fold-1>\n",
      "Train indices: [0 1 2 3 4 5 6 8]\n",
      "Test indices: [7]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8566666666666667\n",
      "0.5\n",
      "0.565\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9562    0.8733    0.9129       300\n",
      "           1     0.8834    0.9600    0.9201       300\n",
      "\n",
      "    accuracy                         0.9167       600\n",
      "   macro avg     0.9198    0.9167    0.9165       600\n",
      "weighted avg     0.9198    0.9167    0.9165       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9373    0.8467    0.8897       300\n",
      "           1     0.8602    0.9433    0.8998       300\n",
      "\n",
      "    accuracy                         0.8950       600\n",
      "   macro avg     0.8987    0.8950    0.8948       600\n",
      "weighted avg     0.8987    0.8950    0.8948       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9161    0.8733    0.8942       300\n",
      "           1     0.8790    0.9200    0.8990       300\n",
      "\n",
      "    accuracy                         0.8967       600\n",
      "   macro avg     0.8975    0.8967    0.8966       600\n",
      "weighted avg     0.8975    0.8967    0.8966       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9338    0.8467    0.8881       300\n",
      "           1     0.8598    0.9400    0.8981       300\n",
      "\n",
      "    accuracy                         0.8933       600\n",
      "   macro avg     0.8968    0.8933    0.8931       600\n",
      "weighted avg     0.8968    0.8933    0.8931       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6283    0.8733    0.7308       300\n",
      "           1     0.7923    0.4833    0.6004       300\n",
      "\n",
      "    accuracy                         0.6783       600\n",
      "   macro avg     0.7103    0.6783    0.6656       600\n",
      "weighted avg     0.7103    0.6783    0.6656       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6350    0.8467    0.7257       300\n",
      "           1     0.7700    0.5133    0.6160       300\n",
      "\n",
      "    accuracy                         0.6800       600\n",
      "   macro avg     0.7025    0.6800    0.6709       600\n",
      "weighted avg     0.7025    0.6800    0.6709       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9588    0.8533    0.9030       300\n",
      "           1     0.8679    0.9633    0.9131       300\n",
      "\n",
      "    accuracy                         0.9083       600\n",
      "   macro avg     0.9133    0.9083    0.9081       600\n",
      "weighted avg     0.9133    0.9083    0.9081       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8731    0.7567    0.8107       300\n",
      "           1     0.7853    0.8900    0.8344       300\n",
      "\n",
      "    accuracy                         0.8233       600\n",
      "   macro avg     0.8292    0.8233    0.8225       600\n",
      "weighted avg     0.8292    0.8233    0.8225       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8889    0.8533    0.8707       300\n",
      "           1     0.8590    0.8933    0.8758       300\n",
      "\n",
      "    accuracy                         0.8733       600\n",
      "   macro avg     0.8739    0.8733    0.8733       600\n",
      "weighted avg     0.8739    0.8733    0.8733       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5911    0.7567    0.6637       300\n",
      "           1     0.6620    0.4767    0.5543       300\n",
      "\n",
      "    accuracy                         0.6167       600\n",
      "   macro avg     0.6266    0.6167    0.6090       600\n",
      "weighted avg     0.6266    0.6167    0.6090       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5401    0.8533    0.6615       300\n",
      "           1     0.6508    0.2733    0.3850       300\n",
      "\n",
      "    accuracy                         0.5633       600\n",
      "   macro avg     0.5954    0.5633    0.5232       600\n",
      "weighted avg     0.5954    0.5633    0.5232       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5457    0.7567    0.6341       300\n",
      "           1     0.6033    0.3700    0.4587       300\n",
      "\n",
      "    accuracy                         0.5633       600\n",
      "   macro avg     0.5745    0.5633    0.5464       600\n",
      "weighted avg     0.5745    0.5633    0.5464       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8543    0.8600    0.8571       300\n",
      "           1     0.8591    0.8533    0.8562       300\n",
      "\n",
      "    accuracy                         0.8567       600\n",
      "   macro avg     0.8567    0.8567    0.8567       600\n",
      "weighted avg     0.8567    0.8567    0.8567       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       300\n",
      "           1     0.5000    1.0000    0.6667       300\n",
      "\n",
      "    accuracy                         0.5000       600\n",
      "   macro avg     0.2500    0.5000    0.3333       600\n",
      "weighted avg     0.2500    0.5000    0.3333       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6258    0.3233    0.4264       300\n",
      "           1     0.5438    0.8067    0.6497       300\n",
      "\n",
      "    accuracy                         0.5650       600\n",
      "   macro avg     0.5848    0.5650    0.5380       600\n",
      "weighted avg     0.5848    0.5650    0.5380       600\n",
      "\n",
      "<Fold-2>\n",
      "Train indices: [0 2 3 4 5 6 7 8]\n",
      "Test indices: [1]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8566666666666667\n",
      "0.5\n",
      "0.565\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9278    0.9000    0.9137       300\n",
      "           1     0.9029    0.9300    0.9163       300\n",
      "\n",
      "    accuracy                         0.9150       600\n",
      "   macro avg     0.9154    0.9150    0.9150       600\n",
      "weighted avg     0.9154    0.9150    0.9150       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9407    0.8467    0.8912       300\n",
      "           1     0.8606    0.9467    0.9016       300\n",
      "\n",
      "    accuracy                         0.8967       600\n",
      "   macro avg     0.9007    0.8967    0.8964       600\n",
      "weighted avg     0.9007    0.8967    0.8964       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9184    0.9000    0.9091       300\n",
      "           1     0.9020    0.9200    0.9109       300\n",
      "\n",
      "    accuracy                         0.9100       600\n",
      "   macro avg     0.9102    0.9100    0.9100       600\n",
      "weighted avg     0.9102    0.9100    0.9100       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9373    0.8467    0.8897       300\n",
      "           1     0.8602    0.9433    0.8998       300\n",
      "\n",
      "    accuracy                         0.8950       600\n",
      "   macro avg     0.8987    0.8950    0.8948       600\n",
      "weighted avg     0.8987    0.8950    0.8948       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6265    0.9000    0.7387       300\n",
      "           1     0.8225    0.4633    0.5928       300\n",
      "\n",
      "    accuracy                         0.6817       600\n",
      "   macro avg     0.7245    0.6817    0.6657       600\n",
      "weighted avg     0.7245    0.6817    0.6657       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6225    0.8467    0.7175       300\n",
      "           1     0.7604    0.4867    0.5935       300\n",
      "\n",
      "    accuracy                         0.6667       600\n",
      "   macro avg     0.6915    0.6667    0.6555       600\n",
      "weighted avg     0.6915    0.6667    0.6555       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9586    0.8500    0.9011       300\n",
      "           1     0.8653    0.9633    0.9117       300\n",
      "\n",
      "    accuracy                         0.9067       600\n",
      "   macro avg     0.9120    0.9067    0.9064       600\n",
      "weighted avg     0.9120    0.9067    0.9064       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8669    0.7167    0.7847       300\n",
      "           1     0.7585    0.8900    0.8190       300\n",
      "\n",
      "    accuracy                         0.8033       600\n",
      "   macro avg     0.8127    0.8033    0.8018       600\n",
      "weighted avg     0.8127    0.8033    0.8018       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8885    0.8500    0.8688       300\n",
      "           1     0.8562    0.8933    0.8744       300\n",
      "\n",
      "    accuracy                         0.8717       600\n",
      "   macro avg     0.8724    0.8717    0.8716       600\n",
      "weighted avg     0.8724    0.8717    0.8716       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5890    0.7167    0.6466       300\n",
      "           1     0.6383    0.5000    0.5607       300\n",
      "\n",
      "    accuracy                         0.6083       600\n",
      "   macro avg     0.6137    0.6083    0.6037       600\n",
      "weighted avg     0.6137    0.6083    0.6037       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5290    0.8500    0.6522       300\n",
      "           1     0.6186    0.2433    0.3493       300\n",
      "\n",
      "    accuracy                         0.5467       600\n",
      "   macro avg     0.5738    0.5467    0.5007       600\n",
      "weighted avg     0.5738    0.5467    0.5007       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5599    0.7167    0.6287       300\n",
      "           1     0.6065    0.4367    0.5078       300\n",
      "\n",
      "    accuracy                         0.5767       600\n",
      "   macro avg     0.5832    0.5767    0.5682       600\n",
      "weighted avg     0.5832    0.5767    0.5682       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8543    0.8600    0.8571       300\n",
      "           1     0.8591    0.8533    0.8562       300\n",
      "\n",
      "    accuracy                         0.8567       600\n",
      "   macro avg     0.8567    0.8567    0.8567       600\n",
      "weighted avg     0.8567    0.8567    0.8567       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       300\n",
      "           1     0.5000    1.0000    0.6667       300\n",
      "\n",
      "    accuracy                         0.5000       600\n",
      "   macro avg     0.2500    0.5000    0.3333       600\n",
      "weighted avg     0.2500    0.5000    0.3333       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6258    0.3233    0.4264       300\n",
      "           1     0.5438    0.8067    0.6497       300\n",
      "\n",
      "    accuracy                         0.5650       600\n",
      "   macro avg     0.5848    0.5650    0.5380       600\n",
      "weighted avg     0.5848    0.5650    0.5380       600\n",
      "\n",
      "<Fold-3>\n",
      "Train indices: [0 1 2 3 4 6 7 8]\n",
      "Test indices: [5]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8566666666666667\n",
      "0.5\n",
      "0.565\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9418    0.9167    0.9291       300\n",
      "           1     0.9188    0.9433    0.9309       300\n",
      "\n",
      "    accuracy                         0.9300       600\n",
      "   macro avg     0.9303    0.9300    0.9300       600\n",
      "weighted avg     0.9303    0.9300    0.9300       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9370    0.8433    0.8877       300\n",
      "           1     0.8576    0.9433    0.8984       300\n",
      "\n",
      "    accuracy                         0.8933       600\n",
      "   macro avg     0.8973    0.8933    0.8931       600\n",
      "weighted avg     0.8973    0.8933    0.8931       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8730    0.9167    0.8943       300\n",
      "           1     0.9123    0.8667    0.8889       300\n",
      "\n",
      "    accuracy                         0.8917       600\n",
      "   macro avg     0.8926    0.8917    0.8916       600\n",
      "weighted avg     0.8926    0.8917    0.8916       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9370    0.8433    0.8877       300\n",
      "           1     0.8576    0.9433    0.8984       300\n",
      "\n",
      "    accuracy                         0.8933       600\n",
      "   macro avg     0.8973    0.8933    0.8931       600\n",
      "weighted avg     0.8973    0.8933    0.8931       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6057    0.9167    0.7294       300\n",
      "           1     0.8288    0.4033    0.5426       300\n",
      "\n",
      "    accuracy                         0.6600       600\n",
      "   macro avg     0.7172    0.6600    0.6360       600\n",
      "weighted avg     0.7172    0.6600    0.6360       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6216    0.8433    0.7157       300\n",
      "           1     0.7565    0.4867    0.5923       300\n",
      "\n",
      "    accuracy                         0.6650       600\n",
      "   macro avg     0.6890    0.6650    0.6540       600\n",
      "weighted avg     0.6890    0.6650    0.6540       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9583    0.8433    0.8972       300\n",
      "           1     0.8601    0.9633    0.9088       300\n",
      "\n",
      "    accuracy                         0.9033       600\n",
      "   macro avg     0.9092    0.9033    0.9030       600\n",
      "weighted avg     0.9092    0.9033    0.9030       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8745    0.7433    0.8036       300\n",
      "           1     0.7768    0.8933    0.8310       300\n",
      "\n",
      "    accuracy                         0.8183       600\n",
      "   macro avg     0.8257    0.8183    0.8173       600\n",
      "weighted avg     0.8257    0.8183    0.8173       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8940    0.8433    0.8679       300\n",
      "           1     0.8517    0.9000    0.8752       300\n",
      "\n",
      "    accuracy                         0.8717       600\n",
      "   macro avg     0.8729    0.8717    0.8716       600\n",
      "weighted avg     0.8729    0.8717    0.8716       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5931    0.7433    0.6598       300\n",
      "           1     0.6562    0.4900    0.5611       300\n",
      "\n",
      "    accuracy                         0.6167       600\n",
      "   macro avg     0.6247    0.6167    0.6104       600\n",
      "weighted avg     0.6247    0.6167    0.6104       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5293    0.8433    0.6504       300\n",
      "           1     0.6148    0.2500    0.3555       300\n",
      "\n",
      "    accuracy                         0.5467       600\n",
      "   macro avg     0.5720    0.5467    0.5029       600\n",
      "weighted avg     0.5720    0.5467    0.5029       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5479    0.7433    0.6308       300\n",
      "           1     0.6010    0.3867    0.4706       300\n",
      "\n",
      "    accuracy                         0.5650       600\n",
      "   macro avg     0.5745    0.5650    0.5507       600\n",
      "weighted avg     0.5745    0.5650    0.5507       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8543    0.8600    0.8571       300\n",
      "           1     0.8591    0.8533    0.8562       300\n",
      "\n",
      "    accuracy                         0.8567       600\n",
      "   macro avg     0.8567    0.8567    0.8567       600\n",
      "weighted avg     0.8567    0.8567    0.8567       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       300\n",
      "           1     0.5000    1.0000    0.6667       300\n",
      "\n",
      "    accuracy                         0.5000       600\n",
      "   macro avg     0.2500    0.5000    0.3333       600\n",
      "weighted avg     0.2500    0.5000    0.3333       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6258    0.3233    0.4264       300\n",
      "           1     0.5438    0.8067    0.6497       300\n",
      "\n",
      "    accuracy                         0.5650       600\n",
      "   macro avg     0.5848    0.5650    0.5380       600\n",
      "weighted avg     0.5848    0.5650    0.5380       600\n",
      "\n",
      "<Fold-4>\n",
      "Train indices: [1 2 3 4 5 6 7 8]\n",
      "Test indices: [0]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8566666666666667\n",
      "0.5\n",
      "0.565\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9317    0.9100    0.9207       300\n",
      "           1     0.9121    0.9333    0.9226       300\n",
      "\n",
      "    accuracy                         0.9217       600\n",
      "   macro avg     0.9219    0.9217    0.9217       600\n",
      "weighted avg     0.9219    0.9217    0.9217       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9416    0.8600    0.8990       300\n",
      "           1     0.8712    0.9467    0.9073       300\n",
      "\n",
      "    accuracy                         0.9033       600\n",
      "   macro avg     0.9064    0.9033    0.9032       600\n",
      "weighted avg     0.9064    0.9033    0.9032       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9192    0.9100    0.9146       300\n",
      "           1     0.9109    0.9200    0.9154       300\n",
      "\n",
      "    accuracy                         0.9150       600\n",
      "   macro avg     0.9150    0.9150    0.9150       600\n",
      "weighted avg     0.9150    0.9150    0.9150       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9348    0.8600    0.8958       300\n",
      "           1     0.8704    0.9400    0.9038       300\n",
      "\n",
      "    accuracy                         0.9000       600\n",
      "   macro avg     0.9026    0.9000    0.8998       600\n",
      "weighted avg     0.9026    0.9000    0.8998       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6290    0.9100    0.7439       300\n",
      "           1     0.8373    0.4633    0.5966       300\n",
      "\n",
      "    accuracy                         0.6867       600\n",
      "   macro avg     0.7332    0.6867    0.6702       600\n",
      "weighted avg     0.7332    0.6867    0.6702       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6339    0.8600    0.7298       300\n",
      "           1     0.7824    0.5033    0.6126       300\n",
      "\n",
      "    accuracy                         0.6817       600\n",
      "   macro avg     0.7081    0.6817    0.6712       600\n",
      "weighted avg     0.7081    0.6817    0.6712       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9612    0.8267    0.8889       300\n",
      "           1     0.8480    0.9667    0.9034       300\n",
      "\n",
      "    accuracy                         0.8967       600\n",
      "   macro avg     0.9046    0.8967    0.8962       600\n",
      "weighted avg     0.9046    0.8967    0.8962       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8571    0.7200    0.7826       300\n",
      "           1     0.7586    0.8800    0.8148       300\n",
      "\n",
      "    accuracy                         0.8000       600\n",
      "   macro avg     0.8079    0.8000    0.7987       600\n",
      "weighted avg     0.8079    0.8000    0.7987       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8953    0.8267    0.8596       300\n",
      "           1     0.8390    0.9033    0.8700       300\n",
      "\n",
      "    accuracy                         0.8650       600\n",
      "   macro avg     0.8672    0.8650    0.8648       600\n",
      "weighted avg     0.8672    0.8650    0.8648       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5902    0.7200    0.6486       300\n",
      "           1     0.6410    0.5000    0.5618       300\n",
      "\n",
      "    accuracy                         0.6100       600\n",
      "   macro avg     0.6156    0.6100    0.6052       600\n",
      "weighted avg     0.6156    0.6100    0.6052       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5299    0.8267    0.6458       300\n",
      "           1     0.6061    0.2667    0.3704       300\n",
      "\n",
      "    accuracy                         0.5467       600\n",
      "   macro avg     0.5680    0.5467    0.5081       600\n",
      "weighted avg     0.5680    0.5467    0.5081       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5567    0.7200    0.6279       300\n",
      "           1     0.6038    0.4267    0.5000       300\n",
      "\n",
      "    accuracy                         0.5733       600\n",
      "   macro avg     0.5802    0.5733    0.5640       600\n",
      "weighted avg     0.5802    0.5733    0.5640       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8543    0.8600    0.8571       300\n",
      "           1     0.8591    0.8533    0.8562       300\n",
      "\n",
      "    accuracy                         0.8567       600\n",
      "   macro avg     0.8567    0.8567    0.8567       600\n",
      "weighted avg     0.8567    0.8567    0.8567       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       300\n",
      "           1     0.5000    1.0000    0.6667       300\n",
      "\n",
      "    accuracy                         0.5000       600\n",
      "   macro avg     0.2500    0.5000    0.3333       600\n",
      "weighted avg     0.2500    0.5000    0.3333       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6258    0.3233    0.4264       300\n",
      "           1     0.5438    0.8067    0.6497       300\n",
      "\n",
      "    accuracy                         0.5650       600\n",
      "   macro avg     0.5848    0.5650    0.5380       600\n",
      "weighted avg     0.5848    0.5650    0.5380       600\n",
      "\n",
      "<Fold-5>\n",
      "Train indices: [0 1 2 3 4 5 6 7]\n",
      "Test indices: [8]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8566666666666667\n",
      "0.5\n",
      "0.565\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9371    0.8933    0.9147       300\n",
      "           1     0.8981    0.9400    0.9186       300\n",
      "\n",
      "    accuracy                         0.9167       600\n",
      "   macro avg     0.9176    0.9167    0.9166       600\n",
      "weighted avg     0.9176    0.9167    0.9166       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9375    0.8500    0.8916       300\n",
      "           1     0.8628    0.9433    0.9013       300\n",
      "\n",
      "    accuracy                         0.8967       600\n",
      "   macro avg     0.9002    0.8967    0.8964       600\n",
      "weighted avg     0.9002    0.8967    0.8964       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9178    0.8933    0.9054       300\n",
      "           1     0.8961    0.9200    0.9079       300\n",
      "\n",
      "    accuracy                         0.9067       600\n",
      "   macro avg     0.9070    0.9067    0.9067       600\n",
      "weighted avg     0.9070    0.9067    0.9067       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9444    0.8500    0.8947       300\n",
      "           1     0.8636    0.9500    0.9048       300\n",
      "\n",
      "    accuracy                         0.9000       600\n",
      "   macro avg     0.9040    0.9000    0.8997       600\n",
      "weighted avg     0.9040    0.9000    0.8997       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6321    0.8933    0.7403       300\n",
      "           1     0.8182    0.4800    0.6050       300\n",
      "\n",
      "    accuracy                         0.6867       600\n",
      "   macro avg     0.7251    0.6867    0.6727       600\n",
      "weighted avg     0.7251    0.6867    0.6727       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6265    0.8500    0.7214       300\n",
      "           1     0.7668    0.4933    0.6004       300\n",
      "\n",
      "    accuracy                         0.6717       600\n",
      "   macro avg     0.6967    0.6717    0.6609       600\n",
      "weighted avg     0.6967    0.6717    0.6609       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9582    0.8400    0.8952       300\n",
      "           1     0.8576    0.9633    0.9074       300\n",
      "\n",
      "    accuracy                         0.9017       600\n",
      "   macro avg     0.9079    0.9017    0.9013       600\n",
      "weighted avg     0.9079    0.9017    0.9013       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8735    0.7367    0.7993       300\n",
      "           1     0.7723    0.8933    0.8284       300\n",
      "\n",
      "    accuracy                         0.8150       600\n",
      "   macro avg     0.8229    0.8150    0.8139       600\n",
      "weighted avg     0.8229    0.8150    0.8139       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8936    0.8400    0.8660       300\n",
      "           1     0.8491    0.9000    0.8738       300\n",
      "\n",
      "    accuracy                         0.8700       600\n",
      "   macro avg     0.8713    0.8700    0.8699       600\n",
      "weighted avg     0.8713    0.8700    0.8699       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5941    0.7367    0.6577       300\n",
      "           1     0.6535    0.4967    0.5644       300\n",
      "\n",
      "    accuracy                         0.6167       600\n",
      "   macro avg     0.6238    0.6167    0.6111       600\n",
      "weighted avg     0.6238    0.6167    0.6111       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5373    0.8400    0.6554       300\n",
      "           1     0.6336    0.2767    0.3852       300\n",
      "\n",
      "    accuracy                         0.5583       600\n",
      "   macro avg     0.5855    0.5583    0.5203       600\n",
      "weighted avg     0.5855    0.5583    0.5203       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5511    0.7367    0.6305       300\n",
      "           1     0.6030    0.4000    0.4810       300\n",
      "\n",
      "    accuracy                         0.5683       600\n",
      "   macro avg     0.5771    0.5683    0.5557       600\n",
      "weighted avg     0.5771    0.5683    0.5557       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8543    0.8600    0.8571       300\n",
      "           1     0.8591    0.8533    0.8562       300\n",
      "\n",
      "    accuracy                         0.8567       600\n",
      "   macro avg     0.8567    0.8567    0.8567       600\n",
      "weighted avg     0.8567    0.8567    0.8567       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       300\n",
      "           1     0.5000    1.0000    0.6667       300\n",
      "\n",
      "    accuracy                         0.5000       600\n",
      "   macro avg     0.2500    0.5000    0.3333       600\n",
      "weighted avg     0.2500    0.5000    0.3333       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6258    0.3233    0.4264       300\n",
      "           1     0.5438    0.8067    0.6497       300\n",
      "\n",
      "    accuracy                         0.5650       600\n",
      "   macro avg     0.5848    0.5650    0.5380       600\n",
      "weighted avg     0.5848    0.5650    0.5380       600\n",
      "\n",
      "<Fold-6>\n",
      "Train indices: [0 1 3 4 5 6 7 8]\n",
      "Test indices: [2]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8566666666666667\n",
      "0.5\n",
      "0.565\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9573    0.8967    0.9260       300\n",
      "           1     0.9028    0.9600    0.9305       300\n",
      "\n",
      "    accuracy                         0.9283       600\n",
      "   macro avg     0.9301    0.9283    0.9283       600\n",
      "weighted avg     0.9301    0.9283    0.9283       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9245    0.8567    0.8893       300\n",
      "           1     0.8665    0.9300    0.8971       300\n",
      "\n",
      "    accuracy                         0.8933       600\n",
      "   macro avg     0.8955    0.8933    0.8932       600\n",
      "weighted avg     0.8955    0.8933    0.8932       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9276    0.8967    0.9119       300\n",
      "           1     0.9000    0.9300    0.9148       300\n",
      "\n",
      "    accuracy                         0.9133       600\n",
      "   macro avg     0.9138    0.9133    0.9133       600\n",
      "weighted avg     0.9138    0.9133    0.9133       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8986    0.8567    0.8771       300\n",
      "           1     0.8631    0.9033    0.8827       300\n",
      "\n",
      "    accuracy                         0.8800       600\n",
      "   macro avg     0.8808    0.8800    0.8799       600\n",
      "weighted avg     0.8808    0.8800    0.8799       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6227    0.8967    0.7350       300\n",
      "           1     0.8155    0.4567    0.5855       300\n",
      "\n",
      "    accuracy                         0.6767       600\n",
      "   macro avg     0.7191    0.6767    0.6602       600\n",
      "weighted avg     0.7191    0.6767    0.6602       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6208    0.8567    0.7199       300\n",
      "           1     0.7688    0.4767    0.5885       300\n",
      "\n",
      "    accuracy                         0.6667       600\n",
      "   macro avg     0.6948    0.6667    0.6542       600\n",
      "weighted avg     0.6948    0.6667    0.6542       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9582    0.8400    0.8952       300\n",
      "           1     0.8576    0.9633    0.9074       300\n",
      "\n",
      "    accuracy                         0.9017       600\n",
      "   macro avg     0.9079    0.9017    0.9013       600\n",
      "weighted avg     0.9079    0.9017    0.9013       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8725    0.7300    0.7949       300\n",
      "           1     0.7679    0.8933    0.8259       300\n",
      "\n",
      "    accuracy                         0.8117       600\n",
      "   macro avg     0.8202    0.8117    0.8104       600\n",
      "weighted avg     0.8202    0.8117    0.8104       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8936    0.8400    0.8660       300\n",
      "           1     0.8491    0.9000    0.8738       300\n",
      "\n",
      "    accuracy                         0.8700       600\n",
      "   macro avg     0.8713    0.8700    0.8699       600\n",
      "weighted avg     0.8713    0.8700    0.8699       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5919    0.7300    0.6537       300\n",
      "           1     0.6478    0.4967    0.5623       300\n",
      "\n",
      "    accuracy                         0.6133       600\n",
      "   macro avg     0.6199    0.6133    0.6080       600\n",
      "weighted avg     0.6199    0.6133    0.6080       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5373    0.8400    0.6554       300\n",
      "           1     0.6336    0.2767    0.3852       300\n",
      "\n",
      "    accuracy                         0.5583       600\n",
      "   macro avg     0.5855    0.5583    0.5203       600\n",
      "weighted avg     0.5855    0.5583    0.5203       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5489    0.7300    0.6266       300\n",
      "           1     0.5970    0.4000    0.4790       300\n",
      "\n",
      "    accuracy                         0.5650       600\n",
      "   macro avg     0.5729    0.5650    0.5528       600\n",
      "weighted avg     0.5729    0.5650    0.5528       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8543    0.8600    0.8571       300\n",
      "           1     0.8591    0.8533    0.8562       300\n",
      "\n",
      "    accuracy                         0.8567       600\n",
      "   macro avg     0.8567    0.8567    0.8567       600\n",
      "weighted avg     0.8567    0.8567    0.8567       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       300\n",
      "           1     0.5000    1.0000    0.6667       300\n",
      "\n",
      "    accuracy                         0.5000       600\n",
      "   macro avg     0.2500    0.5000    0.3333       600\n",
      "weighted avg     0.2500    0.5000    0.3333       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6258    0.3233    0.4264       300\n",
      "           1     0.5438    0.8067    0.6497       300\n",
      "\n",
      "    accuracy                         0.5650       600\n",
      "   macro avg     0.5848    0.5650    0.5380       600\n",
      "weighted avg     0.5848    0.5650    0.5380       600\n",
      "\n",
      "<Fold-7>\n",
      "Train indices: [0 1 2 3 5 6 7 8]\n",
      "Test indices: [4]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8566666666666667\n",
      "0.5\n",
      "0.565\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9252    0.9067    0.9158       300\n",
      "           1     0.9085    0.9267    0.9175       300\n",
      "\n",
      "    accuracy                         0.9167       600\n",
      "   macro avg     0.9168    0.9167    0.9167       600\n",
      "weighted avg     0.9168    0.9167    0.9167       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9373    0.8467    0.8897       300\n",
      "           1     0.8602    0.9433    0.8998       300\n",
      "\n",
      "    accuracy                         0.8950       600\n",
      "   macro avg     0.8987    0.8950    0.8948       600\n",
      "weighted avg     0.8987    0.8950    0.8948       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9097    0.9067    0.9082       300\n",
      "           1     0.9070    0.9100    0.9085       300\n",
      "\n",
      "    accuracy                         0.9083       600\n",
      "   macro avg     0.9083    0.9083    0.9083       600\n",
      "weighted avg     0.9083    0.9083    0.9083       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9338    0.8467    0.8881       300\n",
      "           1     0.8598    0.9400    0.8981       300\n",
      "\n",
      "    accuracy                         0.8933       600\n",
      "   macro avg     0.8968    0.8933    0.8931       600\n",
      "weighted avg     0.8968    0.8933    0.8931       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6239    0.9067    0.7391       300\n",
      "           1     0.8293    0.4533    0.5862       300\n",
      "\n",
      "    accuracy                         0.6800       600\n",
      "   macro avg     0.7266    0.6800    0.6627       600\n",
      "weighted avg     0.7266    0.6800    0.6627       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6350    0.8467    0.7257       300\n",
      "           1     0.7700    0.5133    0.6160       300\n",
      "\n",
      "    accuracy                         0.6800       600\n",
      "   macro avg     0.7025    0.6800    0.6709       600\n",
      "weighted avg     0.7025    0.6800    0.6709       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9533    0.8167    0.8797       300\n",
      "           1     0.8397    0.9600    0.8958       300\n",
      "\n",
      "    accuracy                         0.8883       600\n",
      "   macro avg     0.8965    0.8883    0.8878       600\n",
      "weighted avg     0.8965    0.8883    0.8878       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8711    0.7433    0.8022       300\n",
      "           1     0.7762    0.8900    0.8292       300\n",
      "\n",
      "    accuracy                         0.8167       600\n",
      "   macro avg     0.8236    0.8167    0.8157       600\n",
      "weighted avg     0.8236    0.8167    0.8157       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8942    0.8167    0.8537       300\n",
      "           1     0.8313    0.9033    0.8658       300\n",
      "\n",
      "    accuracy                         0.8600       600\n",
      "   macro avg     0.8627    0.8600    0.8597       600\n",
      "weighted avg     0.8627    0.8600    0.8597       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5947    0.7433    0.6607       300\n",
      "           1     0.6578    0.4933    0.5638       300\n",
      "\n",
      "    accuracy                         0.6183       600\n",
      "   macro avg     0.6262    0.6183    0.6123       600\n",
      "weighted avg     0.6262    0.6183    0.6123       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5338    0.8167    0.6456       300\n",
      "           1     0.6099    0.2867    0.3900       300\n",
      "\n",
      "    accuracy                         0.5517       600\n",
      "   macro avg     0.5718    0.5517    0.5178       600\n",
      "weighted avg     0.5718    0.5517    0.5178       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5479    0.7433    0.6308       300\n",
      "           1     0.6010    0.3867    0.4706       300\n",
      "\n",
      "    accuracy                         0.5650       600\n",
      "   macro avg     0.5745    0.5650    0.5507       600\n",
      "weighted avg     0.5745    0.5650    0.5507       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8543    0.8600    0.8571       300\n",
      "           1     0.8591    0.8533    0.8562       300\n",
      "\n",
      "    accuracy                         0.8567       600\n",
      "   macro avg     0.8567    0.8567    0.8567       600\n",
      "weighted avg     0.8567    0.8567    0.8567       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       300\n",
      "           1     0.5000    1.0000    0.6667       300\n",
      "\n",
      "    accuracy                         0.5000       600\n",
      "   macro avg     0.2500    0.5000    0.3333       600\n",
      "weighted avg     0.2500    0.5000    0.3333       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6258    0.3233    0.4264       300\n",
      "           1     0.5438    0.8067    0.6497       300\n",
      "\n",
      "    accuracy                         0.5650       600\n",
      "   macro avg     0.5848    0.5650    0.5380       600\n",
      "weighted avg     0.5848    0.5650    0.5380       600\n",
      "\n",
      "<Fold-8>\n",
      "Train indices: [0 1 2 4 5 6 7 8]\n",
      "Test indices: [3]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8566666666666667\n",
      "0.5\n",
      "0.565\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9397    0.8833    0.9107       300\n",
      "           1     0.8899    0.9433    0.9159       300\n",
      "\n",
      "    accuracy                         0.9133       600\n",
      "   macro avg     0.9148    0.9133    0.9133       600\n",
      "weighted avg     0.9148    0.9133    0.9133       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9375    0.8500    0.8916       300\n",
      "           1     0.8628    0.9433    0.9013       300\n",
      "\n",
      "    accuracy                         0.8967       600\n",
      "   macro avg     0.9002    0.8967    0.8964       600\n",
      "weighted avg     0.9002    0.8967    0.8964       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9138    0.8833    0.8983       300\n",
      "           1     0.8871    0.9167    0.9016       300\n",
      "\n",
      "    accuracy                         0.9000       600\n",
      "   macro avg     0.9004    0.9000    0.9000       600\n",
      "weighted avg     0.9004    0.9000    0.9000       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9341    0.8500    0.8901       300\n",
      "           1     0.8624    0.9400    0.8995       300\n",
      "\n",
      "    accuracy                         0.8950       600\n",
      "   macro avg     0.8982    0.8950    0.8948       600\n",
      "weighted avg     0.8982    0.8950    0.8948       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6134    0.8833    0.7240       300\n",
      "           1     0.7917    0.4433    0.5684       300\n",
      "\n",
      "    accuracy                         0.6633       600\n",
      "   macro avg     0.7025    0.6633    0.6462       600\n",
      "weighted avg     0.7025    0.6633    0.6462       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6281    0.8500    0.7224       300\n",
      "           1     0.7680    0.4967    0.6032       300\n",
      "\n",
      "    accuracy                         0.6733       600\n",
      "   macro avg     0.6981    0.6733    0.6628       600\n",
      "weighted avg     0.6981    0.6733    0.6628       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9486    0.8000    0.8680       300\n",
      "           1     0.8271    0.9567    0.8872       300\n",
      "\n",
      "    accuracy                         0.8783       600\n",
      "   macro avg     0.8879    0.8783    0.8776       600\n",
      "weighted avg     0.8879    0.8783    0.8776       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8629    0.7133    0.7810       300\n",
      "           1     0.7557    0.8867    0.8160       300\n",
      "\n",
      "    accuracy                         0.8000       600\n",
      "   macro avg     0.8093    0.8000    0.7985       600\n",
      "weighted avg     0.8093    0.8000    0.7985       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8922    0.8000    0.8436       300\n",
      "           1     0.8187    0.9033    0.8590       300\n",
      "\n",
      "    accuracy                         0.8517       600\n",
      "   macro avg     0.8555    0.8517    0.8513       600\n",
      "weighted avg     0.8555    0.8517    0.8513       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5912    0.7133    0.6465       300\n",
      "           1     0.6387    0.5067    0.5651       300\n",
      "\n",
      "    accuracy                         0.6100       600\n",
      "   macro avg     0.6149    0.6100    0.6058       600\n",
      "weighted avg     0.6149    0.6100    0.6058       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5369    0.8000    0.6426       300\n",
      "           1     0.6078    0.3100    0.4106       300\n",
      "\n",
      "    accuracy                         0.5550       600\n",
      "   macro avg     0.5724    0.5550    0.5266       600\n",
      "weighted avg     0.5724    0.5550    0.5266       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5602    0.7133    0.6276       300\n",
      "           1     0.6055    0.4400    0.5097       300\n",
      "\n",
      "    accuracy                         0.5767       600\n",
      "   macro avg     0.5829    0.5767    0.5686       600\n",
      "weighted avg     0.5829    0.5767    0.5686       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8543    0.8600    0.8571       300\n",
      "           1     0.8591    0.8533    0.8562       300\n",
      "\n",
      "    accuracy                         0.8567       600\n",
      "   macro avg     0.8567    0.8567    0.8567       600\n",
      "weighted avg     0.8567    0.8567    0.8567       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       300\n",
      "           1     0.5000    1.0000    0.6667       300\n",
      "\n",
      "    accuracy                         0.5000       600\n",
      "   macro avg     0.2500    0.5000    0.3333       600\n",
      "weighted avg     0.2500    0.5000    0.3333       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6258    0.3233    0.4264       300\n",
      "           1     0.5438    0.8067    0.6497       300\n",
      "\n",
      "    accuracy                         0.5650       600\n",
      "   macro avg     0.5848    0.5650    0.5380       600\n",
      "weighted avg     0.5848    0.5650    0.5380       600\n",
      "\n",
      "<Fold-9>\n",
      "Train indices: [0 1 2 3 4 5 7 8]\n",
      "Test indices: [6]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8566666666666667\n",
      "0.5\n",
      "0.565\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9315    0.9067    0.9189       300\n",
      "           1     0.9091    0.9333    0.9211       300\n",
      "\n",
      "    accuracy                         0.9200       600\n",
      "   macro avg     0.9203    0.9200    0.9200       600\n",
      "weighted avg     0.9203    0.9200    0.9200       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9410    0.8500    0.8932       300\n",
      "           1     0.8632    0.9467    0.9030       300\n",
      "\n",
      "    accuracy                         0.8983       600\n",
      "   macro avg     0.9021    0.8983    0.8981       600\n",
      "weighted avg     0.9021    0.8983    0.8981       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9097    0.9067    0.9082       300\n",
      "           1     0.9070    0.9100    0.9085       300\n",
      "\n",
      "    accuracy                         0.9083       600\n",
      "   macro avg     0.9083    0.9083    0.9083       600\n",
      "weighted avg     0.9083    0.9083    0.9083       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9375    0.8500    0.8916       300\n",
      "           1     0.8628    0.9433    0.9013       300\n",
      "\n",
      "    accuracy                         0.8967       600\n",
      "   macro avg     0.9002    0.8967    0.8964       600\n",
      "weighted avg     0.9002    0.8967    0.8964       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6296    0.9067    0.7432       300\n",
      "           1     0.8333    0.4667    0.5983       300\n",
      "\n",
      "    accuracy                         0.6867       600\n",
      "   macro avg     0.7315    0.6867    0.6707       600\n",
      "weighted avg     0.7315    0.6867    0.6707       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6250    0.8500    0.7203       300\n",
      "           1     0.7656    0.4900    0.5976       300\n",
      "\n",
      "    accuracy                         0.6700       600\n",
      "   macro avg     0.6953    0.6700    0.6589       600\n",
      "weighted avg     0.6953    0.6700    0.6589       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9579    0.8333    0.8913       300\n",
      "           1     0.8525    0.9633    0.9045       300\n",
      "\n",
      "    accuracy                         0.8983       600\n",
      "   macro avg     0.9052    0.8983    0.8979       600\n",
      "weighted avg     0.9052    0.8983    0.8979       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8735    0.7367    0.7993       300\n",
      "           1     0.7723    0.8933    0.8284       300\n",
      "\n",
      "    accuracy                         0.8150       600\n",
      "   macro avg     0.8229    0.8150    0.8139       600\n",
      "weighted avg     0.8229    0.8150    0.8139       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8865    0.8333    0.8591       300\n",
      "           1     0.8428    0.8933    0.8673       300\n",
      "\n",
      "    accuracy                         0.8633       600\n",
      "   macro avg     0.8646    0.8633    0.8632       600\n",
      "weighted avg     0.8646    0.8633    0.8632       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5957    0.7367    0.6587       300\n",
      "           1     0.6550    0.5000    0.5671       300\n",
      "\n",
      "    accuracy                         0.6183       600\n",
      "   macro avg     0.6254    0.6183    0.6129       600\n",
      "weighted avg     0.6254    0.6183    0.6129       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5297    0.8333    0.6477       300\n",
      "           1     0.6094    0.2600    0.3645       300\n",
      "\n",
      "    accuracy                         0.5467       600\n",
      "   macro avg     0.5695    0.5467    0.5061       600\n",
      "weighted avg     0.5695    0.5467    0.5061       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5525    0.7367    0.6314       300\n",
      "           1     0.6050    0.4033    0.4840       300\n",
      "\n",
      "    accuracy                         0.5700       600\n",
      "   macro avg     0.5787    0.5700    0.5577       600\n",
      "weighted avg     0.5787    0.5700    0.5577       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8543    0.8600    0.8571       300\n",
      "           1     0.8591    0.8533    0.8562       300\n",
      "\n",
      "    accuracy                         0.8567       600\n",
      "   macro avg     0.8567    0.8567    0.8567       600\n",
      "weighted avg     0.8567    0.8567    0.8567       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       300\n",
      "           1     0.5000    1.0000    0.6667       300\n",
      "\n",
      "    accuracy                         0.5000       600\n",
      "   macro avg     0.2500    0.5000    0.3333       600\n",
      "weighted avg     0.2500    0.5000    0.3333       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6258    0.3233    0.4264       300\n",
      "           1     0.5438    0.8067    0.6497       300\n",
      "\n",
      "    accuracy                         0.5650       600\n",
      "   macro avg     0.5848    0.5650    0.5380       600\n",
      "weighted avg     0.5848    0.5650    0.5380       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cの範囲を指定\n",
    "C_values = {'C': [0.01, 0.1, 1, 10, 100, 1000, 2000, 3000, 4000, 5000]}\n",
    "# C_values = {'C': [100]}\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "kfold = KFold(n_splits=9, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "results = pd.DataFrame(columns=['C_RBF_LQP1','Score_RBF_LQP1', 'tnr_rbf_lqp1', 'tpr_rbf_lqp1',\n",
    "                                'C_RBF_SQP','Score_RBF_SQP', 'tnr_rbf_sqp', 'tpr_rbf_sqp',\n",
    "                                'C_RBF_LQP2','Score_RBF_LQP2', 'tnr_rbf_lqp2', 'tpr_rbf_lqp2',\n",
    "                                'C_LINEAR_LQP1','Score_LINEAR_LQP1', 'tnr_linear_lqp1', 'tpr_linear_lqp1',\n",
    "                                'C_LINEAR_SQP','Score_LINEAR_SQP', 'tnr_linear_sqp', 'tpr_linear_sqp',\n",
    "                                'C_LINEAR_LQP2','Score_LINEAR_LQP2', 'tnr_linear_lqp2', 'tpr_linear_lqp2',\n",
    "                                \n",
    "                                'C_RBF2_LQP1','Score_RBF2_LQP1', 'tnr_rbf2_lqp1', 'tpr_rbf2_lqp1',\n",
    "                                'C_RBF2_SQP','Score_RBF2_SQP', 'tnr_rbf2_sqp', 'tpr_rbf2_sqp',\n",
    "                                'C_RBF2_LQP2','Score_RBF2_LQP2', 'tnr_rbf2_lqp2', 'tpr_rbf2_lqp2',\n",
    "                                'C_LINEAR2_LQP1','Score_LINEAR2_LQP1', 'tnr_linear2_lqp1', 'tpr_linear2_lqp1',\n",
    "                                'C_LINEAR2_SQP','Score_LINEAR2_SQP', 'tnr_linear2_sqp2', 'tpr_linear2_sqp',\n",
    "                                'C_LINEAR2_LQP2','Score_LINEAR2_LQP2', 'tnr_linear2_lqp2', 'tpr_linear2_lqp2',\n",
    "                                \n",
    "                                'Threshold_LQP1', 'LQP1_old', 'tnr_old_lqp1', 'tpr_old_lqp1',\n",
    "                                'Threshold_SQP', 'SQP_old', 'tnr_old_sqp', 'tpr_old_sqp',\n",
    "                                'Threshold_LQP2', 'LQP2_old', 'tnr_old_lqp2', 'tpr_old_lqp2'])\n",
    "\n",
    "\n",
    "# results = pd.DataFrame(columns=['C_RBF_LQP1','Score_RBF_LQP1', 'tnr_rbf_lqp1', 'tpr_rbf_lqp1',\n",
    "#                                 'C_RBF_SQP','Score_RBF_SQP', 'tnr_rbf_sqp', 'tpr_rbf_sqp',\n",
    "#                                 'C_RBF_LQP2','Score_RBF_LQP2', 'tnr_rbf_lqp2', 'tpr_rbf_lqp2',\n",
    "#                                 'C_LINEAR_LQP1','Score_LINEAR_LQP1', 'tnr_linear_lqp1', 'tpr_linear_lqp1',\n",
    "#                                 'C_LINEAR_SQP','Score_LINEAR_SQP', 'tnr_linear_sqp', 'tpr_linear_sqp',\n",
    "#                                 'C_LINEAR_LQP2','Score_LINEAR_LQP2', 'tnr_linear_lqp2', 'tpr_linear_lqp2',\n",
    "                                                        \n",
    "#                                 'Threshold_LQP1', 'LQP1_old', 'tnr_old_lqp1', 'tpr_old_lqp1',\n",
    "#                                 'Threshold_SQP', 'SQP_old', 'tnr_old_sqp', 'tpr_old_sqp',\n",
    "#                                 'Threshold_LQP2', 'LQP2_old', 'tnr_old_lqp2', 'tpr_old_lqp2'])\n",
    "\n",
    "    \n",
    "X_index = np.arange(9)  # インデックスとして0から8までの数字を用意\n",
    "\n",
    "# ループで各分割のtrain_idsとtest_idsを取得\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(X_index)):\n",
    "    print(f\"<Fold-{fold+1}>\")\n",
    "    print(\"Train indices:\", train_ids)\n",
    "    print(\"Test indices:\", test_ids)\n",
    "    \n",
    "    train_data = [X_train_list[i] for i in train_ids]\n",
    "    train_data_OG = [X_train_onlyGhost_list[i] for i in train_ids]\n",
    "    train_label = [Y_train_list[i] for i in train_ids]\n",
    "    \n",
    "    val_data = [X_train_list[i] for i in test_ids]\n",
    "    val_data_OG = [X_train_onlyGhost_list[i] for i in test_ids]\n",
    "    val_label = [Y_train_list[i] for i in test_ids]\n",
    "    \n",
    "    X_train = [item for data in train_data for item in data]\n",
    "    X_train_OG = [item for data in train_data_OG for item in data]\n",
    "    Y_train = [item for data in train_label for item in data]\n",
    "    \n",
    "    X_val = [item for data in val_data for item in data]\n",
    "    X_val_OG = [item for data in val_data_OG for item in data]\n",
    "    Y_val = [item for data in val_label for item in data]\n",
    "    \n",
    "    # print(len(Y_train))\n",
    "    # print(len(Y_val))\n",
    "    \n",
    "    test_data1 = [item for data in X_test_list1 for item in data]\n",
    "    test_data_OG1 = [item for data in X_test_onlyGhost_list1 for item in data]\n",
    "    test_label1 = [item for data in Y_test_list1 for item in data]\n",
    "    MAE_data1 = [item for data in MAE_list_t1 for item in data]\n",
    "    FINAL_QP_data1 = [item for data in FINAL_QP_list_t1 for item in data]\n",
    "    \n",
    "    test_data2 = [item for data in X_test_list2 for item in data]\n",
    "    test_data_OG2 = [item for data in X_test_onlyGhost_list2 for item in data]\n",
    "    test_label2 = [item for data in Y_test_list2 for item in data]\n",
    "    MAE_data2 = [item for data in MAE_list_t2 for item in data]\n",
    "    FINAL_QP_data2 = [item for data in FINAL_QP_list_t2 for item in data]\n",
    "    \n",
    "    test_data3 = [item for data in X_test_list3 for item in data]\n",
    "    test_data_OG3 = [item for data in X_test_onlyGhost_list3 for item in data]\n",
    "    test_label3 = [item for data in Y_test_list3 for item in data]\n",
    "    MAE_data3 = [item for data in MAE_list_t3 for item in data]\n",
    "    FINAL_QP_data3 = [item for data in FINAL_QP_list_t3 for item in data]\n",
    "    \n",
    "    print(len(MAE_data1))\n",
    "    print(len(MAE_data2))\n",
    "    print(len(MAE_data3))\n",
    "    \n",
    "                                                                                   \n",
    "    best_threshold = 0\n",
    "    best_accuracy = 0\n",
    "    best_predicted_labels = []\n",
    "    best_ground_truth_labels = []\n",
    "    \n",
    "    sameQP_best_threshold = 0\n",
    "    sameQP_best_accuracy = 0\n",
    "    sameQP_best_predicted_labels = []\n",
    "    sameQP_best_ground_truth_labels = []\n",
    "    \n",
    "    largeQP_best_threshold = 0\n",
    "    largeQP_best_accuracy = 0\n",
    "    largeQP_best_predicted_labels = []\n",
    "    largeQP_best_ground_truth_labels = []\n",
    "            \n",
    "    for threshold in np.arange(0.00, 1.01, 0.01):\n",
    "        test_old = np.array([is_double_compressed(MAE_data1[i], FINAL_QP_data1[i], threshold) for i in range(600)])\n",
    "        predicted_labels = test_old.astype(int)\n",
    "        ground_truth_labels = np.array(test_label1)\n",
    "        accuracy = np.sum(ground_truth_labels == predicted_labels) / len(ground_truth_labels)\n",
    "    \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_threshold = threshold\n",
    "            best_predicted_labels = predicted_labels\n",
    "            best_ground_truth_labels = ground_truth_labels\n",
    "            \n",
    "    for threshold in np.arange(0.00, 1.01, 0.01):\n",
    "        test_sameQP_old = np.array([is_double_compressed(MAE_data2[i], FINAL_QP_data2[i], threshold) for i in range(600)])\n",
    "        same_predicted_labels = test_sameQP_old.astype(int)\n",
    "        same_ground_truth_labels = np.array(test_label2)\n",
    "        same_accuracy = np.sum(same_ground_truth_labels == same_predicted_labels) / len(same_ground_truth_labels)\n",
    "    \n",
    "        if same_accuracy > sameQP_best_accuracy:\n",
    "            sameQP_best_accuracy = same_accuracy\n",
    "            sameQP_best_threshold = threshold\n",
    "            sameQP_best_predicted_labels = same_predicted_labels\n",
    "            sameQP_best_ground_truth_labels = same_ground_truth_labels\n",
    "                        \n",
    "    for threshold in np.arange(0.00, 1.01, 0.01):\n",
    "        test_largeQP_old = np.array([is_double_compressed(MAE_data3[i], FINAL_QP_data3[i], threshold) for i in range(600)])\n",
    "        large_predicted_labels = test_largeQP_old.astype(int)\n",
    "        large_ground_truth_labels = np.array(test_label3)\n",
    "        large_accuracy = np.sum(large_ground_truth_labels == large_predicted_labels) / len(large_ground_truth_labels)\n",
    "    \n",
    "        if large_accuracy > largeQP_best_accuracy:\n",
    "            largeQP_best_accuracy = large_accuracy\n",
    "            largeQP_best_threshold = threshold\n",
    "            largeQP_best_predicted_labels = large_predicted_labels\n",
    "            largeQP_best_ground_truth_labels = large_ground_truth_labels       \n",
    "            \n",
    "            \n",
    "    print(best_accuracy)\n",
    "    print(sameQP_best_accuracy)\n",
    "    print(largeQP_best_accuracy)\n",
    "            \n",
    "            \n",
    "    best_val_score_RBF, best_svm_model_RBF, best_c_value_RBF = 0, None, None\n",
    "    best_val_score_onlyGhost_RBF, best_svm_model_onlyGhost_RBF, best_c_value_onlyGhost_RBF = 0, None, None\n",
    "    \n",
    "    best_val_score_LINEAR, best_svm_model_LINEAR, best_c_value_LINEAR = 0, None, None\n",
    "    best_val_score_onlyGhost_LINEAR, best_svm_model_onlyGhost_LINEAR, best_c_value_onlyGhost_LINEAR = 0, None, None\n",
    "        \n",
    "    for C_value in C_values['C']:    \n",
    "        # SVMモデルのインスタンスを作成\n",
    "        svm_model_RBF = SVC(kernel='rbf', C=C_value)\n",
    "        svm_model_onlyGhost_RBF = SVC(kernel='rbf', C=C_value)\n",
    "        \n",
    "        svm_model_LINEAR = SVC(kernel='linear', C=C_value)\n",
    "        svm_model_onlyGhost_LINEAR = SVC(kernel='linear', C=C_value)\n",
    "\n",
    "        # 訓練データで訓練\n",
    "        svm_model_RBF.fit(X_train, Y_train)\n",
    "        svm_model_onlyGhost_RBF.fit(X_train_OG, Y_train)\n",
    "        \n",
    "        svm_model_LINEAR.fit(X_train, Y_train)\n",
    "        svm_model_onlyGhost_LINEAR.fit(X_train_OG, Y_train)\n",
    "\n",
    "        \n",
    "        val_accuracy_RBF = accuracy_score(Y_val, svm_model_RBF.predict(X_val))\n",
    "        val_accuracy_onlyGhost_RBF = accuracy_score(Y_val, svm_model_onlyGhost_RBF.predict(X_val_OG))\n",
    "        \n",
    "        val_accuracy_LINEAR = accuracy_score(Y_val, svm_model_LINEAR.predict(X_val))\n",
    "        val_accuracy_onlyGhost_LINEAR = accuracy_score(Y_val, svm_model_onlyGhost_LINEAR.predict(X_val_OG))\n",
    "        \n",
    "\n",
    "        # 検証データでの精度が最も高かった場合、そのモデルを保存\n",
    "        if val_accuracy_RBF > best_val_score_RBF:\n",
    "            best_val_score_RBF, best_svm_model_RBF, best_c_value_RBF = val_accuracy_RBF, svm_model_RBF, C_value\n",
    "\n",
    "        if val_accuracy_onlyGhost_RBF > best_val_score_onlyGhost_RBF:\n",
    "            best_val_score_onlyGhost_RBF, best_svm_model_onlyGhost_RBF, best_c_value_onlyGhost_RBF = val_accuracy_onlyGhost_RBF, svm_model_onlyGhost_RBF, C_value\n",
    "            \n",
    "        if val_accuracy_LINEAR > best_val_score_LINEAR:\n",
    "            best_val_score_LINEAR, best_svm_model_LINEAR, best_c_value_LINEAR = val_accuracy_LINEAR, svm_model_LINEAR, C_value\n",
    "\n",
    "        if val_accuracy_onlyGhost_LINEAR > best_val_score_onlyGhost_LINEAR:\n",
    "            best_val_score_onlyGhost_LINEAR, best_svm_model_onlyGhost_LINEAR, best_c_value_onlyGhost_LINEAR = val_accuracy_onlyGhost_LINEAR, svm_model_onlyGhost_LINEAR, C_value\n",
    "\n",
    "\n",
    "    # テストデータで評価    \n",
    "    predictions_RBF = best_svm_model_RBF.predict(test_data1)\n",
    "    # predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test)\n",
    "    accuracy_RBF = accuracy_score(test_label1, predictions_RBF)\n",
    "    report_RBF = classification_report(test_label1, predictions_RBF, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label1, predictions_RBF)\n",
    "    tnr_rbf_lqp1 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_rbf_lqp1 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'report_RBF:\\n{report_RBF}')\n",
    "    \n",
    "    predictions_LINEAR = best_svm_model_LINEAR.predict(test_data1)\n",
    "    # predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test)\n",
    "    accuracy_LINEAR = accuracy_score(test_label1, predictions_LINEAR)\n",
    "    report_LINEAR = classification_report(test_label1, predictions_LINEAR, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label1, predictions_LINEAR)\n",
    "    tnr_linear_lqp1 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_linear_lqp1 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'report_LINEAR:\\n{report_LINEAR}')\n",
    "    \n",
    "    same_predictions_RBF = best_svm_model_RBF.predict(test_data2)\n",
    "    # same_predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test_sameQP)\n",
    "    same_accuracy_RBF = accuracy_score(test_label2, same_predictions_RBF)\n",
    "    same_report_RBF = classification_report(test_label2, same_predictions_RBF, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label2, same_predictions_RBF)\n",
    "    tnr_rbf_sqp = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_rbf_sqp = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'same_report_RBF:\\n{same_report_RBF}')\n",
    "    \n",
    "    same_predictions_LINEAR = best_svm_model_LINEAR.predict(test_data2)\n",
    "    # same_predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test_sameQP)\n",
    "    same_accuracy_LINEAR = accuracy_score(test_label2, same_predictions_LINEAR)\n",
    "    same_report_LINEAR = classification_report(test_label2, same_predictions_LINEAR, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label2, same_predictions_LINEAR)\n",
    "    tnr_linear_sqp = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_linear_sqp = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'same_report_LINEAR:\\n{same_report_LINEAR}')\n",
    "    \n",
    "    large_predictions_RBF = best_svm_model_RBF.predict(test_data3)\n",
    "    # large_predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test_largeQP)\n",
    "    large_accuracy_RBF = accuracy_score(test_label3, large_predictions_RBF)\n",
    "    large_report_RBF = classification_report(test_label3, large_predictions_RBF, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label3, large_predictions_RBF)\n",
    "    tnr_rbf_lqp2 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_rbf_lqp2 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'large_report_RBF:\\n{large_report_RBF}')\n",
    "    \n",
    "    large_predictions_LINEAR = best_svm_model_LINEAR.predict(test_data3)\n",
    "    # large_predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test_largeQP)\n",
    "    large_accuracy_LINEAR = accuracy_score(test_label3, large_predictions_LINEAR)\n",
    "    large_report_LINEAR = classification_report(test_label3, large_predictions_LINEAR, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label3, large_predictions_LINEAR)\n",
    "    tnr_linear_lqp2 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_linear_lqp2 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'large_report_LINEAR:\\n{large_report_LINEAR}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # テストデータで評価    \n",
    "    predictions_RBF2 = best_svm_model_onlyGhost_RBF.predict(test_data_OG1)\n",
    "    # predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test)\n",
    "    accuracy_RBF2 = accuracy_score(test_label1, predictions_RBF2)\n",
    "    report_RBF2 = classification_report(test_label1, predictions_RBF2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label1, predictions_RBF2)\n",
    "    tnr_rbf2_lqp1 = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_rbf2_lqp1 = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'report_RBF2:\\n{report_RBF2}')\n",
    "    \n",
    "    predictions_LINEAR2 = best_svm_model_onlyGhost_LINEAR.predict(test_data_OG1)\n",
    "    # predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test)\n",
    "    accuracy_LINEAR2 = accuracy_score(test_label1, predictions_LINEAR2)\n",
    "    report_LINEAR2 = classification_report(test_label1, predictions_LINEAR2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label1, predictions_LINEAR2)\n",
    "    tnr_linear2_lqp1 = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_linear2_lqp1 = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'report_LINEAR2:\\n{report_LINEAR2}')\n",
    "    \n",
    "    same_predictions_RBF2 = best_svm_model_onlyGhost_RBF.predict(test_data_OG2)\n",
    "    # same_predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test_sameQP)\n",
    "    same_accuracy_RBF2 = accuracy_score(test_label2, same_predictions_RBF2)\n",
    "    same_report_RBF2 = classification_report(test_label2, same_predictions_RBF2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label2, same_predictions_RBF2)\n",
    "    tnr_rbf2_sqp = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_rbf2_sqp = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'same_report_RBF2:\\n{same_report_RBF2}')\n",
    "    \n",
    "    same_predictions_LINEAR2 = best_svm_model_onlyGhost_LINEAR.predict(test_data_OG2)\n",
    "    # same_predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test_sameQP)\n",
    "    same_accuracy_LINEAR2 = accuracy_score(test_label2, same_predictions_LINEAR2)\n",
    "    same_report_LINEAR2 = classification_report(test_label2, same_predictions_LINEAR2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label2, same_predictions_LINEAR2)\n",
    "    tnr_linear2_sqp = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_linear2_sqp = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'same_report_LINEAR2:\\n{same_report_LINEAR2}')\n",
    "    \n",
    "    large_predictions_RBF2 = best_svm_model_onlyGhost_RBF.predict(test_data_OG3)\n",
    "    # large_predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test_largeQP)\n",
    "    large_accuracy_RBF2 = accuracy_score(test_label3, large_predictions_RBF2)\n",
    "    large_report_RBF2 = classification_report(test_label3, large_predictions_RBF2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label3, large_predictions_RBF2)\n",
    "    tnr_rbf2_lqp2 = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_rbf2_lqp2 = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'large_report_RBF2:\\n{large_report_RBF2}')\n",
    "    \n",
    "    large_predictions_LINEAR2 = best_svm_model_onlyGhost_LINEAR.predict(test_data_OG3)\n",
    "    # large_predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test_largeQP)\n",
    "    large_accuracy_LINEAR2 = accuracy_score(test_label3, large_predictions_LINEAR2)\n",
    "    large_report_LINEAR2 = classification_report(test_label3, large_predictions_LINEAR2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label3, large_predictions_LINEAR2)\n",
    "    tnr_linear2_lqp2 = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_linear2_lqp2 = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'large_report_LINEAR2:\\n{large_report_LINEAR2}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # テストデータで評価\n",
    "    test_old = classification_report(best_ground_truth_labels, best_predicted_labels, labels=[0,1], target_names=['0', '1'], zero_division=0, digits=4)\n",
    "    conf_matrix = confusion_matrix(best_ground_truth_labels, best_predicted_labels)\n",
    "    tnr_old_lqp1 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_old_lqp1 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'Summary old_model:\\n{test_old}')\n",
    "    \n",
    "    test_sameQP_old = classification_report(sameQP_best_ground_truth_labels, sameQP_best_predicted_labels, labels=[0,1], target_names=['0', '1'], zero_division=0, digits=4)\n",
    "    conf_matrix = confusion_matrix(sameQP_best_ground_truth_labels, sameQP_best_predicted_labels)\n",
    "    tnr_old_sqp = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_old_sqp = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'Summary old_model:\\n{test_sameQP_old}')\n",
    "    \n",
    "    test_largeQP_old = classification_report(largeQP_best_ground_truth_labels, largeQP_best_predicted_labels, labels=[0,1], target_names=['0', '1'], zero_division=0, digits=4)\n",
    "    conf_matrix = confusion_matrix(largeQP_best_ground_truth_labels, largeQP_best_predicted_labels)\n",
    "    tnr_old_lqp2 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_old_lqp2 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'Summary old_model:\\n{test_largeQP_old}')\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Test結果を保存\n",
    "    \n",
    "    result_row ={'C_RBF_LQP1':best_c_value_RBF,'Score_RBF_LQP1': accuracy_RBF, 'tnr_rbf_lqp1':tnr_rbf_lqp1, 'tpr_rbf_lqp1':tpr_rbf_lqp1,\n",
    "                'C_RBF_SQP': best_c_value_RBF, 'Score_RBF_SQP': same_accuracy_RBF, 'tnr_rbf_sqp':tnr_rbf_sqp, 'tpr_rbf_sqp':tpr_rbf_sqp,\n",
    "                'C_RBF_LQP2': best_c_value_RBF,'Score_RBF_LQP2': large_accuracy_RBF, 'tnr_rbf_lqp2':tnr_rbf_lqp2, 'tpr_rbf_lqp2':tpr_rbf_lqp2,\n",
    "                                    \n",
    "                'C_LINEAR_LQP1': best_c_value_LINEAR,'Score_LINEAR_LQP1':accuracy_LINEAR, 'tnr_linear_lqp1':tnr_linear_lqp1, 'tpr_linear_lqp1':tpr_linear_lqp1,\n",
    "                'C_LINEAR_SQP': best_c_value_LINEAR,'Score_LINEAR_SQP':same_accuracy_LINEAR, 'tnr_linear_sqp':tnr_linear_sqp, 'tpr_linear_sqp':tpr_linear_sqp,\n",
    "                'C_LINEAR_LQP2': best_c_value_LINEAR,'Score_LINEAR_LQP2':large_accuracy_LINEAR, 'tnr_linear_lqp2':tnr_linear_lqp2, 'tpr_linear_lqp2':tpr_linear_lqp2,\n",
    "                 \n",
    "                'C_RBF2_LQP1':best_c_value_onlyGhost_RBF,'Score_RBF2_LQP1': accuracy_RBF2, 'tnr_rbf2_lqp1':tnr_rbf2_lqp1, 'tpr_rbf2_lqp1':tpr_rbf2_lqp1,\n",
    "                'C_RBF2_SQP': best_c_value_onlyGhost_RBF, 'Score_RBF2_SQP': same_accuracy_RBF2, 'tnr_rbf2_sqp':tnr_rbf2_sqp, 'tpr_rbf2_sqp':tpr_rbf2_sqp,\n",
    "                'C_RBF2_LQP2': best_c_value_onlyGhost_RBF,'Score_RBF2_LQP2': large_accuracy_RBF2, 'tnr_rbf2_lqp2':tnr_rbf2_lqp2, 'tpr_rbf2_lqp2':tpr_rbf2_lqp2,\n",
    "                                    \n",
    "                'C_LINEAR2_LQP1': best_c_value_onlyGhost_LINEAR,'Score_LINEAR2_LQP1':accuracy_LINEAR2, 'tnr_linear2_lqp1':tnr_linear2_lqp1, 'tpr_linear2_lqp1':tpr_linear2_lqp1,\n",
    "                'C_LINEAR2_SQP': best_c_value_onlyGhost_LINEAR,'Score_LINEAR2_SQP':same_accuracy_LINEAR2, 'tnr_linear2_sqp':tnr_linear2_sqp, 'tpr_linear2_sqp':tpr_linear2_sqp,\n",
    "                'C_LINEAR2_LQP2': best_c_value_onlyGhost_LINEAR,'Score_LINEAR2_LQP2':large_accuracy_LINEAR2, 'tnr_linear2_lqp2':tnr_linear2_lqp2, 'tpr_linear2_lqp2':tpr_linear2_lqp2,\n",
    "                                                        \n",
    "                'Threshold_LQP1':best_threshold, 'LQP1_old':best_accuracy, 'tnr_old_lqp1':tnr_old_lqp1, 'tpr_old_lqp1':tpr_old_lqp1,\n",
    "                'Threshold_SQP':sameQP_best_threshold, 'SQP_old':sameQP_best_accuracy, 'tnr_old_sqp':tnr_old_sqp, 'tpr_old_sqp':tpr_old_sqp,\n",
    "                'Threshold_LQP2':largeQP_best_threshold, 'LQP2_old':largeQP_best_accuracy, 'tnr_old_lqp2':tnr_old_lqp2, 'tpr_old_lqp2':tpr_old_lqp2}\n",
    "\n",
    "\n",
    "    results = pd.concat([results, pd.DataFrame([result_row])], ignore_index=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Average TNR  Average TPR  Average Test Score  Standard Deviation  Max Test Score  Min Test Score\n",
      "0     RBF_LQP1        89.85        94.11               91.98                0.59           93.00           91.33\n",
      "1      RBF_SQP        89.85        91.26               90.56                0.78           91.50           89.17\n",
      "2     RBF_LQP2        89.85        45.70               67.78                0.99           68.67           66.00\n",
      "3  LINEAR_LQP1        85.00        94.30               89.65                0.31           90.33           89.33\n",
      "4   LINEAR_SQP        85.00        93.81               89.41                0.59           90.00           88.00\n",
      "5  LINEAR_LQP2        85.00        49.56               67.28                0.64           68.17           66.50\n",
      "6     OLD_LQP1        86.00        85.33               85.67                0.00           85.67           85.67\n",
      "7      OLD_SQP         0.00       100.00               50.00                0.00           50.00           50.00\n",
      "8     OLD_LQP2        32.33        80.67               56.50                0.00           56.50           56.50\n"
     ]
    }
   ],
   "source": [
    "# 各統計情報を100倍して小数点第4位までの表記に変更\n",
    "statistics_data = {\n",
    "    'Model': ['RBF_LQP1', 'RBF_SQP', 'RBF_LQP2', 'LINEAR_LQP1', 'LINEAR_SQP', 'LINEAR_LQP2', 'OLD_LQP1', 'OLD_SQP', 'OLD_LQP2'],\n",
    "    'Average TNR': [round(results['tnr_rbf_lqp1'].mean() * 100, 2), round(results['tnr_rbf_sqp'].mean() * 100, 2), round(results['tnr_rbf_lqp2'].mean() * 100, 2), round(results['tnr_linear_lqp1'].mean() * 100, 2), round(results['tnr_linear_sqp'].mean() * 100, 2), round(results['tnr_linear_lqp2'].mean() * 100, 2),round(results['tnr_old_lqp1'].mean() * 100, 2), round(results['tnr_old_sqp'].mean() * 100, 2), round(results['tnr_old_lqp2'].mean() * 100, 2)],\n",
    "    'Average TPR': [round(results['tpr_rbf_lqp1'].mean() * 100, 2), round(results['tpr_rbf_sqp'].mean() * 100, 2), round(results['tpr_rbf_lqp2'].mean() * 100, 2), round(results['tpr_linear_lqp1'].mean() * 100, 2), round(results['tpr_linear_sqp'].mean() * 100, 2), round(results['tpr_linear_lqp2'].mean() * 100, 2),round(results['tpr_old_lqp1'].mean() * 100, 2), round(results['tpr_old_sqp'].mean() * 100, 2), round(results['tpr_old_lqp2'].mean() * 100, 2)],\n",
    "    'Average Test Score': [round(results['Score_RBF_LQP1'].mean() * 100, 2), round(results['Score_RBF_SQP'].mean() * 100, 2), round(results['Score_RBF_LQP2'].mean() * 100, 2), round(results['Score_LINEAR_LQP1'].mean() * 100, 2), round(results['Score_LINEAR_SQP'].mean() * 100, 2), round(results['Score_LINEAR_LQP2'].mean() * 100, 2),round(results['LQP1_old'].mean() * 100, 2), round(results['SQP_old'].mean() * 100, 2), round(results['LQP2_old'].mean() * 100, 2)],\n",
    "    'Standard Deviation': [round(results['Score_RBF_LQP1'].std() * 100, 2), round(results['Score_RBF_SQP'].std() * 100, 2), round(results['Score_RBF_LQP2'].std() * 100, 2), round(results['Score_LINEAR_LQP1'].std() * 100, 2), round(results['Score_LINEAR_SQP'].std() * 100, 2), round(results['Score_LINEAR_LQP2'].std() * 100, 2),round(results['LQP1_old'].std() * 100, 2), round(results['SQP_old'].std() * 100, 2), round(results['LQP2_old'].std() * 100, 2)],\n",
    "    'Max Test Score': [round(results['Score_RBF_LQP1'].max() * 100, 2), round(results['Score_RBF_SQP'].max() * 100, 2), round(results['Score_RBF_LQP2'].max() * 100, 2), round(results['Score_LINEAR_LQP1'].max() * 100, 2), round(results['Score_LINEAR_SQP'].max() * 100, 2), round(results['Score_LINEAR_LQP2'].max() * 100, 2),round(results['LQP1_old'].max() * 100, 2), round(results['SQP_old'].max() * 100, 2), round(results['LQP2_old'].max() * 100, 2)],\n",
    "    'Min Test Score': [round(results['Score_RBF_LQP1'].min() * 100, 2), round(results['Score_RBF_SQP'].min() * 100, 2), round(results['Score_RBF_LQP2'].min() * 100, 2), round(results['Score_LINEAR_LQP1'].min() * 100, 2), round(results['Score_LINEAR_SQP'].min() * 100, 2), round(results['Score_LINEAR_LQP2'].min() * 100, 2),round(results['LQP1_old'].min() * 100, 2), round(results['SQP_old'].min() * 100, 2), round(results['LQP2_old'].min() * 100, 2)],\n",
    "}\n",
    "\n",
    "# DataFrameを作成\n",
    "statistics_df = pd.DataFrame(statistics_data)\n",
    "\n",
    "# 表示\n",
    "print(statistics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Average TNR  Average TPR  Average Test Score  Standard Deviation  Max Test Score  Min Test Score\n",
      "0     RBF_LQP1        83.37        96.26               89.81                0.95           90.83           87.83\n",
      "1      RBF_SQP        83.37        89.89               86.63                0.71           87.33           85.17\n",
      "2     RBF_LQP2        83.37        27.15               55.26                0.64           56.33           54.67\n",
      "3  LINEAR_LQP1        73.30        89.00               81.15                0.84           82.33           80.00\n",
      "4   LINEAR_SQP        73.30        49.56               61.43                0.39           61.83           60.83\n",
      "5  LINEAR_LQP2        73.30        40.56               56.93                0.52           57.67           56.33\n",
      "6     OLD_LQP1        86.00        85.33               85.67                0.00           85.67           85.67\n",
      "7      OLD_SQP         0.00       100.00               50.00                0.00           50.00           50.00\n",
      "8     OLD_LQP2        32.33        80.67               56.50                0.00           56.50           56.50\n"
     ]
    }
   ],
   "source": [
    "# 各統計情報を100倍して小数点第4位までの表記に変更\n",
    "statistics_data2 = {\n",
    "    'Model': ['RBF_LQP1', 'RBF_SQP', 'RBF_LQP2', 'LINEAR_LQP1', 'LINEAR_SQP', 'LINEAR_LQP2', 'OLD_LQP1', 'OLD_SQP', 'OLD_LQP2'],\n",
    "    'Average TNR': [round(results['tnr_rbf2_lqp1'].mean() * 100, 2), round(results['tnr_rbf2_sqp'].mean() * 100, 2), round(results['tnr_rbf2_lqp2'].mean() * 100, 2), round(results['tnr_linear2_lqp1'].mean() * 100, 2), round(results['tnr_linear2_sqp'].mean() * 100, 2), round(results['tnr_linear2_lqp2'].mean() * 100, 2),round(results['tnr_old_lqp1'].mean() * 100, 2), round(results['tnr_old_sqp'].mean() * 100, 2), round(results['tnr_old_lqp2'].mean() * 100, 2)],\n",
    "    'Average TPR': [round(results['tpr_rbf2_lqp1'].mean() * 100, 2), round(results['tpr_rbf2_sqp'].mean() * 100, 2), round(results['tpr_rbf2_lqp2'].mean() * 100, 2), round(results['tpr_linear2_lqp1'].mean() * 100, 2), round(results['tpr_linear2_sqp'].mean() * 100, 2), round(results['tpr_linear2_lqp2'].mean() * 100, 2),round(results['tpr_old_lqp1'].mean() * 100, 2), round(results['tpr_old_sqp'].mean() * 100, 2), round(results['tpr_old_lqp2'].mean() * 100, 2)],\n",
    "    'Average Test Score': [round(results['Score_RBF2_LQP1'].mean() * 100, 2), round(results['Score_RBF2_SQP'].mean() * 100, 2), round(results['Score_RBF2_LQP2'].mean() * 100, 2), round(results['Score_LINEAR2_LQP1'].mean() * 100, 2), round(results['Score_LINEAR2_SQP'].mean() * 100, 2), round(results['Score_LINEAR2_LQP2'].mean() * 100, 2),round(results['LQP1_old'].mean() * 100, 2), round(results['SQP_old'].mean() * 100, 2), round(results['LQP2_old'].mean() * 100, 2)],\n",
    "    'Standard Deviation': [round(results['Score_RBF2_LQP1'].std() * 100, 2), round(results['Score_RBF2_SQP'].std() * 100, 2), round(results['Score_RBF2_LQP2'].std() * 100, 2), round(results['Score_LINEAR2_LQP1'].std() * 100, 2), round(results['Score_LINEAR2_SQP'].std() * 100, 2), round(results['Score_LINEAR2_LQP2'].std() * 100, 2),round(results['LQP1_old'].std() * 100, 2), round(results['SQP_old'].std() * 100, 2), round(results['LQP2_old'].std() * 100, 2)],\n",
    "    'Max Test Score': [round(results['Score_RBF2_LQP1'].max() * 100, 2), round(results['Score_RBF2_SQP'].max() * 100, 2), round(results['Score_RBF2_LQP2'].max() * 100, 2), round(results['Score_LINEAR2_LQP1'].max() * 100, 2), round(results['Score_LINEAR2_SQP'].max() * 100, 2), round(results['Score_LINEAR2_LQP2'].max() * 100, 2),round(results['LQP1_old'].max() * 100, 2), round(results['SQP_old'].max() * 100, 2), round(results['LQP2_old'].max() * 100, 2)],\n",
    "    'Min Test Score': [round(results['Score_RBF2_LQP1'].min() * 100, 2), round(results['Score_RBF2_SQP'].min() * 100, 2), round(results['Score_RBF2_LQP2'].min() * 100, 2), round(results['Score_LINEAR2_LQP1'].min() * 100, 2), round(results['Score_LINEAR2_SQP'].min() * 100, 2), round(results['Score_LINEAR2_LQP2'].min() * 100, 2),round(results['LQP1_old'].min() * 100, 2), round(results['SQP_old'].min() * 100, 2), round(results['LQP2_old'].min() * 100, 2)],\n",
    "}\n",
    "\n",
    "# DataFrameを作成\n",
    "statistics_df2 = pd.DataFrame(statistics_data2)\n",
    "\n",
    "# 表示\n",
    "print(statistics_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    100\n",
      "1    100\n",
      "2     10\n",
      "3    100\n",
      "4    100\n",
      "5    100\n",
      "6    100\n",
      "7    100\n",
      "8    100\n",
      "Name: C_RBF_LQP1, dtype: object\n",
      "0     100\n",
      "1    3000\n",
      "2     100\n",
      "3     100\n",
      "4    1000\n",
      "5      10\n",
      "6     100\n",
      "7     100\n",
      "8    2000\n",
      "Name: C_LINEAR_LQP1, dtype: object\n",
      "\n",
      "0    3000\n",
      "1    2000\n",
      "2    4000\n",
      "3    1000\n",
      "4    1000\n",
      "5    2000\n",
      "6     100\n",
      "7     100\n",
      "8    4000\n",
      "Name: C_RBF2_LQP1, dtype: object\n",
      "0      1\n",
      "1    100\n",
      "2      1\n",
      "3     10\n",
      "4      1\n",
      "5      1\n",
      "6      1\n",
      "7     10\n",
      "8      1\n",
      "Name: C_LINEAR2_LQP1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(results['C_RBF_LQP1'])\n",
    "print(results['C_LINEAR_LQP1'])\n",
    "print()\n",
    "print(results['C_RBF2_LQP1'])\n",
    "print(results['C_LINEAR2_LQP1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df.to_csv('statistics_data4.csv', index=False)\n",
    "statistics_df2.to_csv('statistics2_data4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
