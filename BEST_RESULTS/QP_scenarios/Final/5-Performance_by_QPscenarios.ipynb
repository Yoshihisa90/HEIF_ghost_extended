{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import os.path as osp\n",
    "import re\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.signal import find_peaks\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import torch\n",
    "import glob\n",
    "from scipy.stats import entropy\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)  # DataFrameを改行せずに表示\n",
    "pd.set_option('display.max_columns', None)  # すべての列を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_finalQP(filename):\n",
    "    match = re.search(r'2ndQP(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    match = re.search(r'1stQP(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_1stQP(filename):\n",
    "    match = re.search(r'1stQP(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def ratio_double_compressed(mean_difference, final_QP):\n",
    "    # mean_difference = mean_difference[0]\n",
    "    # final_QP = final_QP[0]\n",
    "    clamped_mean_difference = np.maximum(mean_difference, -0.01)\n",
    "    \n",
    "    #全体のエネルギーを計算\n",
    "    energy = np.sum(np.square(clamped_mean_difference))\n",
    "    # energy = np.sum(np.square(mean_difference))\n",
    "    \n",
    "    #QP2より右側のエネルギーを計算\n",
    "    right_energy = np.sum(np.square(clamped_mean_difference[final_QP+1:52]))\n",
    "\n",
    "        \n",
    "    # エネルギー比を計算して閾値と比較\n",
    "    if energy > 0:\n",
    "        return right_energy / energy\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def is_double_compressed(mean_difference, final_QP, threshold):\n",
    "    mean_difference = mean_difference[0]\n",
    "    final_QP = final_QP[0]\n",
    "    clamped_mean_difference = np.maximum(mean_difference, -0.01)\n",
    "    \n",
    "    #全体のエネルギーを計算\n",
    "    energy = np.sum(np.square(clamped_mean_difference))\n",
    "    # energy = np.sum(np.square(mean_difference))\n",
    "    \n",
    "    #QP2より右側のエネルギーを計算\n",
    "    right_energy = np.sum(np.square(clamped_mean_difference[final_QP+1:52]))\n",
    "    # right_energy = np.sum(np.square(mean_difference[final_QP+1:52]))\n",
    "    \n",
    "    # print('energy: ', energy)\n",
    "    # print('R-energy: ', right_energy)\n",
    "    # print('Ratio: ', right_energy / energy)\n",
    "    \n",
    "    \n",
    "    # エネルギー比を計算して閾値と比較\n",
    "    if energy <= 0:\n",
    "        return -1\n",
    "    \n",
    "    elif (right_energy / energy) != 0 and (right_energy / energy) > threshold:\n",
    "        return True\n",
    "    \n",
    "    elif (right_energy / energy) != 0 and (right_energy / energy) <= threshold:\n",
    "        return False\n",
    "    \n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def calculate_mae(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            loaded_data, loaded_data_shifted = pickle.load(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # タプル内のリストを抽出\n",
    "    original_mae = np.array(loaded_data)\n",
    "    shifted_mae = np.array(loaded_data_shifted)\n",
    "\n",
    "    # Coding ghostを計算してリストに格納する\n",
    "    mae_difference = shifted_mae - original_mae\n",
    "    \n",
    "    # mae_differenceの各要素においてマイナスの値を0に変換\n",
    "    # mae_difference_positive = np.maximum(mae_difference, 0)\n",
    "    \n",
    "    return mae_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['123', '157', '203', '266', '2', '289', '121', '195', '60', '22', '48', '190', '243', '95', '248', '140', '143', '296', '144', '83', '101', '136', '220', '176', '255', '58', '52', '81', '37', '215'], ['181', '59', '17', '161', '25', '14', '180', '149', '281', '124', '169', '286', '10', '199', '223', '197', '193', '32', '236', '154', '209', '116', '115', '171', '177', '29', '183', '285', '135', '212'], ['70', '62', '191', '219', '85', '132', '217', '120', '15', '110', '156', '54', '249', '93', '127', '145', '227', '150', '74', '13', '240', '66', '201', '214', '221', '78', '291', '31', '80', '126'], ['298', '69', '7', '89', '111', '251', '284', '250', '99', '18', '295', '128', '280', '173', '229', '87', '186', '100', '165', '56', '272', '244', '267', '21', '68', '113', '222', '34', '258', '50'], ['141', '108', '134', '233', '208', '179', '292', '65', '142', '77', '254', '175', '139', '184', '246', '138', '64', '1', '97', '294', '90', '44', '275', '43', '24', '192', '158', '287', '242', '234'], ['79', '8', '261', '262', '105', '91', '196', '205', '30', '299', '119', '94', '269', '125', '117', '107', '103', '288', '300', '46', '114', '216', '270', '28', '265', '260', '226', '200', '168', '213'], ['137', '88', '63', '72', '45', '278', '146', '241', '170', '155', '61', '239', '274', '92', '172', '159', '218', '106', '259', '49', '104', '198', '264', '189', '47', '71', '20', '133', '276', '55'], ['178', '232', '263', '210', '129', '27', '130', '231', '245', '4', '167', '225', '160', '162', '230', '206', '283', '185', '75', '38', '6', '282', '35', '82', '268', '228', '96', '12', '237', '41'], ['163', '109', '84', '252', '26', '57', '151', '148', '188', '174', '164', '277', '257', '33', '187', '16', '67', '207', '271', '51', '131', '293', '118', '297', '36', '166', '273', '253', '153', '39'], ['235', '204', '112', '42', '19', '73', '53', '182', '194', '256', '9', '238', '5', '247', '224', '23', '40', '290', '102', '152', '76', '11', '86', '202', '3', '98', '147', '122', '211', '279']]\n",
      "\n",
      "CSV Single ListsA:\n",
      "CSV List 1A: 300\n",
      "CSV List 2A: 300\n",
      "CSV List 3A: 300\n",
      "CSV List 4A: 300\n",
      "CSV List 5A: 300\n",
      "CSV List 6A: 300\n",
      "CSV List 7A: 300\n",
      "CSV List 8A: 300\n",
      "CSV List 9A: 300\n",
      "CSV List 10A: 300\n",
      "\n",
      "CSV Single Recompress ListsA:\n",
      "CSV List 1A: 300\n",
      "CSV List 2A: 300\n",
      "CSV List 3A: 300\n",
      "CSV List 4A: 300\n",
      "CSV List 5A: 300\n",
      "CSV List 6A: 300\n",
      "CSV List 7A: 300\n",
      "CSV List 8A: 300\n",
      "CSV List 9A: 300\n",
      "CSV List 10A: 300\n",
      "\n",
      "CSV Second Large QP1 ListsA:\n",
      "CSV List 1A: 1710\n",
      "CSV List 2A: 1710\n",
      "CSV List 3A: 1710\n",
      "CSV List 4A: 1710\n",
      "CSV List 5A: 1710\n",
      "CSV List 6A: 1710\n",
      "CSV List 7A: 1710\n",
      "CSV List 8A: 1710\n",
      "CSV List 9A: 1710\n",
      "CSV List 10A: 1710\n",
      "\n",
      "CSV Second Recompress Large QP1 ListsA:\n",
      "CSV List 1A: 1710\n",
      "CSV List 2A: 1710\n",
      "CSV List 3A: 1710\n",
      "CSV List 4A: 1710\n",
      "CSV List 5A: 1710\n",
      "CSV List 6A: 1710\n",
      "CSV List 7A: 1710\n",
      "CSV List 8A: 1710\n",
      "CSV List 9A: 1710\n",
      "CSV List 10A: 1710\n",
      "\n",
      "CSV Second Same QP ListsA:\n",
      "CSV List 1A: 300\n",
      "CSV List 2A: 300\n",
      "CSV List 3A: 300\n",
      "CSV List 4A: 300\n",
      "CSV List 5A: 300\n",
      "CSV List 6A: 300\n",
      "CSV List 7A: 300\n",
      "CSV List 8A: 300\n",
      "CSV List 9A: 300\n",
      "CSV List 10A: 300\n",
      "\n",
      "CSV Second Recompress Same QP ListsA:\n",
      "CSV List 1A: 300\n",
      "CSV List 2A: 300\n",
      "CSV List 3A: 300\n",
      "CSV List 4A: 300\n",
      "CSV List 5A: 300\n",
      "CSV List 6A: 300\n",
      "CSV List 7A: 300\n",
      "CSV List 8A: 300\n",
      "CSV List 9A: 300\n",
      "CSV List 10A: 300\n",
      "\n",
      "CSV Second Large QP2 ListsA:\n",
      "CSV List 1A: 1170\n",
      "CSV List 2A: 1170\n",
      "CSV List 3A: 1170\n",
      "CSV List 4A: 1170\n",
      "CSV List 5A: 1170\n",
      "CSV List 6A: 1170\n",
      "CSV List 7A: 1170\n",
      "CSV List 8A: 1170\n",
      "CSV List 9A: 1170\n",
      "CSV List 10A: 1170\n",
      "\n",
      "CSV Second Recompress Large QP2 ListsA:\n",
      "CSV List 1A: 1170\n",
      "CSV List 2A: 1170\n",
      "CSV List 3A: 1170\n",
      "CSV List 4A: 1170\n",
      "CSV List 5A: 1170\n",
      "CSV List 6A: 1170\n",
      "CSV List 7A: 1170\n",
      "CSV List 8A: 1170\n",
      "CSV List 9A: 1170\n",
      "CSV List 10A: 1170\n",
      "\n",
      "PKL Single ListsA:\n",
      "PKL List 1A: 300\n",
      "PKL List 2A: 300\n",
      "PKL List 3A: 300\n",
      "PKL List 4A: 300\n",
      "PKL List 5A: 300\n",
      "PKL List 6A: 300\n",
      "PKL List 7A: 300\n",
      "PKL List 8A: 300\n",
      "PKL List 9A: 300\n",
      "PKL List 10A: 300\n",
      "\n",
      "PKL Single Recompress ListsA:\n",
      "PKL List 1A: 300\n",
      "PKL List 2A: 300\n",
      "PKL List 3A: 300\n",
      "PKL List 4A: 300\n",
      "PKL List 5A: 300\n",
      "PKL List 6A: 300\n",
      "PKL List 7A: 300\n",
      "PKL List 8A: 300\n",
      "PKL List 9A: 300\n",
      "PKL List 10A: 300\n",
      "\n",
      "PKL Second Large QP1 ListsA:\n",
      "PKL List 1A: 1710\n",
      "PKL List 2A: 1710\n",
      "PKL List 3A: 1710\n",
      "PKL List 4A: 1710\n",
      "PKL List 5A: 1710\n",
      "PKL List 6A: 1710\n",
      "PKL List 7A: 1710\n",
      "PKL List 8A: 1710\n",
      "PKL List 9A: 1710\n",
      "PKL List 10A: 1710\n",
      "\n",
      "PKL Second Recompress Large QP1 ListsA:\n",
      "PKL List 1A: 1710\n",
      "PKL List 2A: 1710\n",
      "PKL List 3A: 1710\n",
      "PKL List 4A: 1710\n",
      "PKL List 5A: 1710\n",
      "PKL List 6A: 1710\n",
      "PKL List 7A: 1710\n",
      "PKL List 8A: 1710\n",
      "PKL List 9A: 1710\n",
      "PKL List 10A: 1710\n",
      "\n",
      "PKL Second Same QP ListsA:\n",
      "PKL List 1A: 300\n",
      "PKL List 2A: 300\n",
      "PKL List 3A: 300\n",
      "PKL List 4A: 300\n",
      "PKL List 5A: 300\n",
      "PKL List 6A: 300\n",
      "PKL List 7A: 300\n",
      "PKL List 8A: 300\n",
      "PKL List 9A: 300\n",
      "PKL List 10A: 300\n",
      "\n",
      "PKL Second Recompress Same QP ListsA:\n",
      "PKL List 1A: 300\n",
      "PKL List 2A: 300\n",
      "PKL List 3A: 300\n",
      "PKL List 4A: 300\n",
      "PKL List 5A: 300\n",
      "PKL List 6A: 300\n",
      "PKL List 7A: 300\n",
      "PKL List 8A: 300\n",
      "PKL List 9A: 300\n",
      "PKL List 10A: 300\n",
      "\n",
      "PKL Second Large QP2 ListsA:\n",
      "PKL List 1A: 1170\n",
      "PKL List 2A: 1170\n",
      "PKL List 3A: 1170\n",
      "PKL List 4A: 1170\n",
      "PKL List 5A: 1170\n",
      "PKL List 6A: 1170\n",
      "PKL List 7A: 1170\n",
      "PKL List 8A: 1170\n",
      "PKL List 9A: 1170\n",
      "PKL List 10A: 1170\n",
      "\n",
      "PKL Second Recompress Large QP2 ListsA:\n",
      "PKL List 1A: 1170\n",
      "PKL List 2A: 1170\n",
      "PKL List 3A: 1170\n",
      "PKL List 4A: 1170\n",
      "PKL List 5A: 1170\n",
      "PKL List 6A: 1170\n",
      "PKL List 7A: 1170\n",
      "PKL List 8A: 1170\n",
      "PKL List 9A: 1170\n",
      "PKL List 10A: 1170\n"
     ]
    }
   ],
   "source": [
    "rootpath_csv = \"/Prove/Yoshihisa/HEIF_ghost/HEIF_IMAGES_CSV/\"\n",
    "rootpath_pkl = \"/Prove/Yoshihisa/HEIF_ghost/PKL/\"\n",
    "\n",
    "train_list1 = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\"]\n",
    "train_list2 = [\"31\", \"32\", \"33\", \"34\", \"35\", \"36\", \"37\", \"38\", \"39\", \"40\", \"41\", \"42\", \"43\", \"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"50\", \"51\", \"52\", \"53\", \"54\", \"55\", \"56\", \"57\", \"58\", \"59\", \"60\"]\n",
    "train_list3 = [\"61\", \"62\", \"63\", \"64\", \"65\", \"66\", \"67\", \"68\", \"69\", \"70\", \"71\", \"72\", \"73\", \"74\", \"75\", \"76\", \"77\", \"78\", \"79\", \"80\", \"81\", \"82\", \"83\", \"84\", \"85\", \"86\", \"87\", \"88\", \"89\", \"90\"]\n",
    "train_list4 = [\"91\", \"92\", \"93\", \"94\", \"95\", \"96\", \"97\", \"98\", \"99\", \"100\", \"101\", \"102\", \"103\", \"104\", \"105\", \"106\", \"107\", \"108\", \"109\", \"110\", \"111\", \"112\", \"113\", \"114\", \"115\", \"116\", \"117\", \"118\", \"119\", \"120\"]\n",
    "train_list5 = [\"121\", \"122\", \"123\", \"124\", \"125\", \"126\", \"127\", \"128\", \"129\", \"130\", \"131\", \"132\", \"133\", \"134\", \"135\", \"136\", \"137\", \"138\", \"139\", \"140\", \"141\", \"142\", \"143\", \"144\", \"145\", \"146\", \"147\", \"148\", \"149\", \"150\"]\n",
    "train_list6 = [\"151\", \"152\", \"153\", \"154\", \"155\", \"156\", \"157\", \"158\", \"159\", \"160\", \"161\", \"162\", \"163\", \"164\", \"165\", \"166\", \"167\", \"168\", \"169\", \"170\", \"171\", \"172\", \"173\", \"174\", \"175\", \"176\", \"177\", \"178\", \"179\", \"180\"]\n",
    "train_list7 = [\"181\", \"182\", \"183\", \"184\", \"185\", \"186\", \"187\", \"188\", \"189\", \"190\", \"191\", \"192\", \"193\", \"194\", \"195\", \"196\", \"197\", \"198\", \"199\", \"200\", \"201\", \"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\"]\n",
    "train_list8 = [\"211\", \"212\", \"213\", \"214\", \"215\", \"216\", \"217\", \"218\", \"219\", \"220\", \"221\", \"222\", \"223\", \"224\", \"225\", \"226\", \"227\", \"228\", \"229\", \"230\", \"231\", \"232\", \"233\", \"234\", \"235\", \"236\", \"237\", \"238\", \"239\", \"240\"]\n",
    "train_list9 = [\"241\", \"242\", \"243\", \"244\", \"245\", \"246\", \"247\", \"248\", \"249\", \"250\", \"251\", \"252\", \"253\", \"254\", \"255\", \"256\", \"257\", \"258\", \"259\", \"260\", \"261\", \"262\", \"263\", \"264\", \"265\", \"266\", \"267\", \"268\", \"269\", \"270\"]\n",
    "train_list10 = [\"271\", \"272\", \"273\", \"274\", \"275\", \"276\", \"277\", \"278\", \"279\", \"280\", \"281\", \"282\", \"283\", \"284\", \"285\", \"286\", \"287\", \"288\", \"289\", \"290\", \"291\", \"292\", \"293\", \"294\", \"295\", \"296\", \"297\", \"298\", \"299\", \"300\"]\n",
    "\n",
    "all_train_lists = [train_list1, train_list2, train_list3, train_list4, train_list5,\n",
    "                   train_list6, train_list7, train_list8, train_list9, train_list10]\n",
    "\n",
    "# すべてのリストを1つのリストに結合する\n",
    "combined_train_list = sum(all_train_lists, [])\n",
    "\n",
    "# リストの順序をランダムにシャッフルする\n",
    "random.shuffle(combined_train_list)\n",
    "\n",
    "# シャッフルされたリストを10個のグループに分割する\n",
    "train_lists = [combined_train_list[i:i+30] for i in range(0, len(combined_train_list), 30)]\n",
    "print(train_lists)\n",
    "\n",
    "\n",
    "\n",
    "# CSV関連のリストを生成\n",
    "csv_single_listsA = [[] for _ in range(10)]\n",
    "csv_single_recompress_listsA = [[] for _ in range(10)]\n",
    "csv_second_largeQP1_listsA = [[] for _ in range(10)]\n",
    "csv_second_recompress_largeQP1_listsA = [[] for _ in range(10)]\n",
    "csv_second_sameQP_listsA = [[] for _ in range(10)]\n",
    "csv_second_recompress_sameQP_listsA = [[] for _ in range(10)]\n",
    "csv_second_largeQP2_listsA = [[] for _ in range(10)]\n",
    "csv_second_recompress_largeQP2_listsA = [[] for _ in range(10)]\n",
    "\n",
    "def process_csv_lists(rootpath, train_list, single_list, single_recompress_list, \n",
    "                      second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                      second_sameQP_list, second_recompress_sameQP_list,\n",
    "                      second_largeQP2_list, second_recompress_largeQP2_list):\n",
    "    \n",
    "    for image in train_list:\n",
    "        single_path = osp.join(rootpath, f'HEIF_images_single_csv/{image}_*')\n",
    "        single_recompress_path = osp.join(rootpath, f'HEIF_images_second_sameQP_csv/{image}_*')\n",
    "        \n",
    "        second_largeQP1_path = osp.join(rootpath, f'HEIF_images_second_csv/{image}_*')\n",
    "        second_recompress_largeQP1_path = osp.join(rootpath, f'HEIF_images_triple_csv/{image}_*')\n",
    "        \n",
    "        second_sameQP_path = osp.join(rootpath, f'HEIF_images_second_sameQP_csv/{image}_*')\n",
    "        second_recompress_sameQP_path = osp.join(rootpath, f'HEIF_images_triple_sameQP_csv/{image}_*')\n",
    "        \n",
    "        second_largeQP2_path = osp.join(rootpath, f'HEIF_images_second_largeQP_csv/{image}_*')\n",
    "        second_recompress_largeQP2_path = osp.join(rootpath, f'HEIF_images_triple_largeQP_csv/{image}_*')\n",
    "        \n",
    "        for path in sorted(glob.glob(single_path)):\n",
    "            single_list.append(path)\n",
    "        for path in sorted(glob.glob(single_recompress_path)):\n",
    "            single_recompress_list.append(path)\n",
    "        for path in sorted(glob.glob(second_largeQP1_path)):\n",
    "            second_largeQP1_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP1_path)):\n",
    "            second_recompress_largeQP1_list.append(path)\n",
    "        for path in sorted(glob.glob(second_sameQP_path)):\n",
    "            second_sameQP_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_sameQP_path)):\n",
    "            second_recompress_sameQP_list.append(path)\n",
    "        for path in sorted(glob.glob(second_largeQP2_path)):\n",
    "            second_largeQP2_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP2_path)):\n",
    "            second_recompress_largeQP2_list.append(path)\n",
    "\n",
    "# 各カテゴリのCSVリストを生成\n",
    "for train_list, single_list, single_recompress_list in zip(train_lists, \n",
    "                                                           csv_single_listsA,\n",
    "                                                           csv_single_recompress_listsA):\n",
    "    process_csv_lists(rootpath_csv, train_list, single_list, single_recompress_list, \n",
    "                      [], [], [], [], [], [])\n",
    "\n",
    "\n",
    "for train_list, second_largeQP1_list, second_recompress_largeQP1_list, second_sameQP_list, second_recompress_sameQP_list, second_largeQP2_list, second_recompress_largeQP2_list in zip(train_lists, \n",
    "                                                                                                                                                                                                                   csv_second_largeQP1_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_recompress_largeQP1_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_sameQP_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_recompress_sameQP_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_largeQP2_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_recompress_largeQP2_listsA):\n",
    "    process_csv_lists(rootpath_csv, train_list, [], [], \n",
    "                      second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                      second_sameQP_list, second_recompress_sameQP_list,\n",
    "                      second_largeQP2_list, second_recompress_largeQP2_list)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "# 出力リストを初期化\n",
    "pkl_single_listsA = [[] for _ in range(10)]\n",
    "pkl_single_recompress_listsA = [[] for _ in range(10)]\n",
    "pkl_second_largeQP1_listsA = [[] for _ in range(10)]\n",
    "pkl_second_recompress_largeQP1_listsA = [[] for _ in range(10)]\n",
    "pkl_second_sameQP_listsA = [[] for _ in range(10)]\n",
    "pkl_second_recompress_sameQP_listsA = [[] for _ in range(10)]\n",
    "pkl_second_largeQP2_listsA = [[] for _ in range(10)]\n",
    "pkl_second_recompress_largeQP2_listsA = [[] for _ in range(10)]    \n",
    "\n",
    "def process_train_lists_pkl(rootpath, train_list, single_list, single_recompress_list, \n",
    "                            second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                            second_sameQP_list, second_recompress_sameQP_list,\n",
    "                            second_largeQP2_list, second_recompress_largeQP2_list):\n",
    "    \n",
    "    for image in train_list:\n",
    "        single_path = osp.join(rootpath, f'pkl_single/{image}_*')\n",
    "        single_recompress_path = osp.join(rootpath, f'pkl_second_sameQP/{image}_*')\n",
    "        \n",
    "        second_largeQP1_path = osp.join(rootpath, f'pkl_second/{image}_*')\n",
    "        second_recompress_largeQP1_path = osp.join(rootpath, f'pkl_triple/{image}_*')\n",
    "        \n",
    "        second_sameQP_path = osp.join(rootpath, f'pkl_second_sameQP/{image}_*')\n",
    "        second_recompress_sameQP_path = osp.join(rootpath, f'pkl_triple_sameQP/{image}_*')\n",
    "        \n",
    "        second_largeQP2_path = osp.join(rootpath, f'pkl_second_largeQP/{image}_*')\n",
    "        second_recompress_largeQP2_path = osp.join(rootpath, f'pkl_triple_largeQP/{image}_*')\n",
    "        \n",
    "\n",
    "        for path in sorted(glob.glob(single_path)):\n",
    "            single_list.append(path)\n",
    "        for path in sorted(glob.glob(single_recompress_path)):\n",
    "            single_recompress_list.append(path)\n",
    "            \n",
    "        for path in sorted(glob.glob(second_largeQP1_path)):\n",
    "            second_largeQP1_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP1_path)):\n",
    "            second_recompress_largeQP1_list.append(path)\n",
    "                \n",
    "        for path in sorted(glob.glob(second_sameQP_path)):\n",
    "            second_sameQP_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_sameQP_path)):\n",
    "            second_recompress_sameQP_list.append(path)\n",
    "            \n",
    "        for path in sorted(glob.glob(second_largeQP2_path)):\n",
    "            second_largeQP2_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP2_path)):\n",
    "            second_recompress_largeQP2_list.append(path)\n",
    "\n",
    "# 各カテゴリのリストを生成\n",
    "for train_list, single_list, single_recompress_list in zip(train_lists, \n",
    "                                                           pkl_single_listsA,\n",
    "                                                           pkl_single_recompress_listsA):\n",
    "    process_train_lists_pkl(rootpath_pkl, train_list, single_list, single_recompress_list, \n",
    "                            [], [], [], [], [], [])\n",
    "\n",
    "\n",
    "for train_list, second_largeQP1_list, second_recompress_largeQP1_list, second_sameQP_list, second_recompress_sameQP_list, second_largeQP2_list, second_recompress_largeQP2_list in zip(train_lists, \n",
    "                                                                                                                                                                                                                   pkl_second_largeQP1_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_recompress_largeQP1_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_sameQP_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_recompress_sameQP_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_largeQP2_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_recompress_largeQP2_listsA):\n",
    "    process_train_lists_pkl(rootpath_pkl, train_list, [], [], \n",
    "                            second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                            second_sameQP_list, second_recompress_sameQP_list,\n",
    "                            second_largeQP2_list, second_recompress_largeQP2_list)\n",
    "\n",
    "\n",
    "print(\"\\nCSV Single ListsA:\")\n",
    "for i, lst in enumerate(csv_single_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Single Recompress ListsA:\")\n",
    "for i, lst in enumerate(csv_single_recompress_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Large QP1 ListsA:\")\n",
    "for i, lst in enumerate(csv_second_largeQP1_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Recompress Large QP1 ListsA:\")\n",
    "for i, lst in enumerate(csv_second_recompress_largeQP1_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Same QP ListsA:\")\n",
    "for i, lst in enumerate(csv_second_sameQP_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Recompress Same QP ListsA:\")\n",
    "for i, lst in enumerate(csv_second_recompress_sameQP_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Large QP2 ListsA:\")\n",
    "for i, lst in enumerate(csv_second_largeQP2_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Recompress Large QP2 ListsA:\")\n",
    "for i, lst in enumerate(csv_second_recompress_largeQP2_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "# 出力リストを表示\n",
    "print(\"\\nPKL Single ListsA:\")\n",
    "for i, lst in enumerate(pkl_single_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Single Recompress ListsA:\")\n",
    "for i, lst in enumerate(pkl_single_recompress_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Large QP1 ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_largeQP1_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Recompress Large QP1 ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_recompress_largeQP1_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Same QP ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_sameQP_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Recompress Same QP ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_recompress_sameQP_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Large QP2 ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_largeQP2_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Recompress Large QP2 ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_recompress_largeQP2_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "# single_listsおよびsingle_recompress_listsは初期化されている前提\n",
    "single_csv1 = list(zip(csv_single_listsA[0], pkl_single_listsA[0], csv_single_recompress_listsA[0], pkl_single_recompress_listsA[0]))\n",
    "single_csv2 = list(zip(csv_single_listsA[1], pkl_single_listsA[1], csv_single_recompress_listsA[1], pkl_single_recompress_listsA[1]))\n",
    "single_csv3 = list(zip(csv_single_listsA[2], pkl_single_listsA[2], csv_single_recompress_listsA[2], pkl_single_recompress_listsA[2]))\n",
    "single_csv4 = list(zip(csv_single_listsA[3], pkl_single_listsA[3], csv_single_recompress_listsA[3], pkl_single_recompress_listsA[3]))\n",
    "single_csv5 = list(zip(csv_single_listsA[4], pkl_single_listsA[4], csv_single_recompress_listsA[4], pkl_single_recompress_listsA[4]))\n",
    "single_csv6 = list(zip(csv_single_listsA[5], pkl_single_listsA[5], csv_single_recompress_listsA[5], pkl_single_recompress_listsA[5]))\n",
    "single_csv7 = list(zip(csv_single_listsA[6], pkl_single_listsA[6], csv_single_recompress_listsA[6], pkl_single_recompress_listsA[6]))\n",
    "single_csv8 = list(zip(csv_single_listsA[7], pkl_single_listsA[7], csv_single_recompress_listsA[7], pkl_single_recompress_listsA[7]))\n",
    "single_csv9 = list(zip(csv_single_listsA[8], pkl_single_listsA[8], csv_single_recompress_listsA[8], pkl_single_recompress_listsA[8]))\n",
    "single_csv10 = list(zip(csv_single_listsA[9], pkl_single_listsA[9], csv_single_recompress_listsA[9], pkl_single_recompress_listsA[9]))\n",
    "print(len(single_csv10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1710\n",
      "\n",
      "double images train by QP1>QP2:  100\n",
      "\n",
      "double images test by QP1>QP2:  300\n"
     ]
    }
   ],
   "source": [
    "# Large_QP1\n",
    "second_largeQP1_csv1 = list(zip(csv_second_largeQP1_listsA[0], pkl_second_largeQP1_listsA[0], csv_second_recompress_largeQP1_listsA[0], pkl_second_recompress_largeQP1_listsA[0]))\n",
    "second_largeQP1_csv2 = list(zip(csv_second_largeQP1_listsA[1], pkl_second_largeQP1_listsA[1], csv_second_recompress_largeQP1_listsA[1], pkl_second_recompress_largeQP1_listsA[1]))\n",
    "second_largeQP1_csv3 = list(zip(csv_second_largeQP1_listsA[2], pkl_second_largeQP1_listsA[2], csv_second_recompress_largeQP1_listsA[2], pkl_second_recompress_largeQP1_listsA[2]))\n",
    "second_largeQP1_csv4 = list(zip(csv_second_largeQP1_listsA[3], pkl_second_largeQP1_listsA[3], csv_second_recompress_largeQP1_listsA[3], pkl_second_recompress_largeQP1_listsA[3]))\n",
    "second_largeQP1_csv5 = list(zip(csv_second_largeQP1_listsA[4], pkl_second_largeQP1_listsA[4], csv_second_recompress_largeQP1_listsA[4], pkl_second_recompress_largeQP1_listsA[4]))\n",
    "second_largeQP1_csv6 = list(zip(csv_second_largeQP1_listsA[5], pkl_second_largeQP1_listsA[5], csv_second_recompress_largeQP1_listsA[5], pkl_second_recompress_largeQP1_listsA[5]))\n",
    "second_largeQP1_csv7 = list(zip(csv_second_largeQP1_listsA[6], pkl_second_largeQP1_listsA[6], csv_second_recompress_largeQP1_listsA[6], pkl_second_recompress_largeQP1_listsA[6]))\n",
    "second_largeQP1_csv8 = list(zip(csv_second_largeQP1_listsA[7], pkl_second_largeQP1_listsA[7], csv_second_recompress_largeQP1_listsA[7], pkl_second_recompress_largeQP1_listsA[7]))\n",
    "second_largeQP1_csv9 = list(zip(csv_second_largeQP1_listsA[8], pkl_second_largeQP1_listsA[8], csv_second_recompress_largeQP1_listsA[8], pkl_second_recompress_largeQP1_listsA[8]))\n",
    "second_largeQP1_csv10 = list(zip(csv_second_largeQP1_listsA[9], pkl_second_largeQP1_listsA[9], csv_second_recompress_largeQP1_listsA[9], pkl_second_recompress_largeQP1_listsA[9]))\n",
    "print(len(second_largeQP1_csv1))\n",
    "\n",
    "\n",
    "second_largeQP1_csv1 = random.sample(second_largeQP1_csv1, 100)\n",
    "second_largeQP1_csv2 = random.sample(second_largeQP1_csv2, 100)\n",
    "second_largeQP1_csv3 = random.sample(second_largeQP1_csv3, 100)\n",
    "second_largeQP1_csv4 = random.sample(second_largeQP1_csv4, 100)\n",
    "second_largeQP1_csv5 = random.sample(second_largeQP1_csv5, 100)\n",
    "second_largeQP1_csv6 = random.sample(second_largeQP1_csv6, 100)\n",
    "second_largeQP1_csv7 = random.sample(second_largeQP1_csv7, 100)\n",
    "second_largeQP1_csv8 = random.sample(second_largeQP1_csv8, 100)\n",
    "second_largeQP1_csv9 = random.sample(second_largeQP1_csv9, 100)\n",
    "# second_largeQP1_csv10 = selected_data[9]\n",
    "print('\\ndouble images train by QP1>QP2: ', len(second_largeQP1_csv1))\n",
    "\n",
    "\n",
    "second_largeQP1_csv10 = random.sample(second_largeQP1_csv10, 300)\n",
    "print('\\ndouble images test by QP1>QP2: ', len(second_largeQP1_csv10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "\n",
      "double images train by QP1=QP2:  100\n",
      "\n",
      "double images test by QP1=QP2:  300\n"
     ]
    }
   ],
   "source": [
    "# sameQP\n",
    "second_sameQP_csv1 = list(zip(csv_second_sameQP_listsA[0], pkl_second_sameQP_listsA[0], csv_second_recompress_sameQP_listsA[0], pkl_second_recompress_sameQP_listsA[0]))\n",
    "second_sameQP_csv2 = list(zip(csv_second_sameQP_listsA[1], pkl_second_sameQP_listsA[1], csv_second_recompress_sameQP_listsA[1], pkl_second_recompress_sameQP_listsA[1]))\n",
    "second_sameQP_csv3 = list(zip(csv_second_sameQP_listsA[2], pkl_second_sameQP_listsA[2], csv_second_recompress_sameQP_listsA[2], pkl_second_recompress_sameQP_listsA[2]))\n",
    "second_sameQP_csv4 = list(zip(csv_second_sameQP_listsA[3], pkl_second_sameQP_listsA[3], csv_second_recompress_sameQP_listsA[3], pkl_second_recompress_sameQP_listsA[3]))\n",
    "second_sameQP_csv5 = list(zip(csv_second_sameQP_listsA[4], pkl_second_sameQP_listsA[4], csv_second_recompress_sameQP_listsA[4], pkl_second_recompress_sameQP_listsA[4]))\n",
    "second_sameQP_csv6 = list(zip(csv_second_sameQP_listsA[5], pkl_second_sameQP_listsA[5], csv_second_recompress_sameQP_listsA[5], pkl_second_recompress_sameQP_listsA[5]))\n",
    "second_sameQP_csv7 = list(zip(csv_second_sameQP_listsA[6], pkl_second_sameQP_listsA[6], csv_second_recompress_sameQP_listsA[6], pkl_second_recompress_sameQP_listsA[6]))\n",
    "second_sameQP_csv8 = list(zip(csv_second_sameQP_listsA[7], pkl_second_sameQP_listsA[7], csv_second_recompress_sameQP_listsA[7], pkl_second_recompress_sameQP_listsA[7]))\n",
    "second_sameQP_csv9 = list(zip(csv_second_sameQP_listsA[8], pkl_second_sameQP_listsA[8], csv_second_recompress_sameQP_listsA[8], pkl_second_recompress_sameQP_listsA[8]))\n",
    "second_sameQP_csv10 = list(zip(csv_second_sameQP_listsA[9], pkl_second_sameQP_listsA[9], csv_second_recompress_sameQP_listsA[9], pkl_second_recompress_sameQP_listsA[9]))\n",
    "print(len(second_sameQP_csv10))\n",
    "\n",
    "second_sameQP_csv1 = random.sample(second_sameQP_csv1, 100)\n",
    "second_sameQP_csv2 = random.sample(second_sameQP_csv2, 100)\n",
    "second_sameQP_csv3 = random.sample(second_sameQP_csv3, 100)\n",
    "second_sameQP_csv4 = random.sample(second_sameQP_csv4, 100)\n",
    "second_sameQP_csv5 = random.sample(second_sameQP_csv5, 100)\n",
    "second_sameQP_csv6 = random.sample(second_sameQP_csv6, 100)\n",
    "second_sameQP_csv7 = random.sample(second_sameQP_csv7, 100)\n",
    "second_sameQP_csv8 = random.sample(second_sameQP_csv8, 100)\n",
    "second_sameQP_csv9 = random.sample(second_sameQP_csv9, 100)\n",
    "print('\\ndouble images train by QP1=QP2: ',len(second_sameQP_csv9))\n",
    "\n",
    "second_sameQP_csv10 = random.sample(second_sameQP_csv10, 300)\n",
    "print('\\ndouble images test by QP1=QP2: ',len(second_sameQP_csv10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1170\n",
      "\n",
      "double images train by QP1<QP2:  100\n",
      "\n",
      "double images test by QP1<QP2:  300\n"
     ]
    }
   ],
   "source": [
    "# Large_QP2\n",
    "second_largeQP2_csv1 = list(zip(csv_second_largeQP2_listsA[0], pkl_second_largeQP2_listsA[0], csv_second_recompress_largeQP2_listsA[0], pkl_second_recompress_largeQP2_listsA[0]))\n",
    "second_largeQP2_csv2 = list(zip(csv_second_largeQP2_listsA[1], pkl_second_largeQP2_listsA[1], csv_second_recompress_largeQP2_listsA[1], pkl_second_recompress_largeQP2_listsA[1]))\n",
    "second_largeQP2_csv3 = list(zip(csv_second_largeQP2_listsA[2], pkl_second_largeQP2_listsA[2], csv_second_recompress_largeQP2_listsA[2], pkl_second_recompress_largeQP2_listsA[2]))\n",
    "second_largeQP2_csv4 = list(zip(csv_second_largeQP2_listsA[3], pkl_second_largeQP2_listsA[3], csv_second_recompress_largeQP2_listsA[3], pkl_second_recompress_largeQP2_listsA[3]))\n",
    "second_largeQP2_csv5 = list(zip(csv_second_largeQP2_listsA[4], pkl_second_largeQP2_listsA[4], csv_second_recompress_largeQP2_listsA[4], pkl_second_recompress_largeQP2_listsA[4]))\n",
    "second_largeQP2_csv6 = list(zip(csv_second_largeQP2_listsA[5], pkl_second_largeQP2_listsA[5], csv_second_recompress_largeQP2_listsA[5], pkl_second_recompress_largeQP2_listsA[5]))\n",
    "second_largeQP2_csv7 = list(zip(csv_second_largeQP2_listsA[6], pkl_second_largeQP2_listsA[6], csv_second_recompress_largeQP2_listsA[6], pkl_second_recompress_largeQP2_listsA[6]))\n",
    "second_largeQP2_csv8 = list(zip(csv_second_largeQP2_listsA[7], pkl_second_largeQP2_listsA[7], csv_second_recompress_largeQP2_listsA[7], pkl_second_recompress_largeQP2_listsA[7]))\n",
    "second_largeQP2_csv9 = list(zip(csv_second_largeQP2_listsA[8], pkl_second_largeQP2_listsA[8], csv_second_recompress_largeQP2_listsA[8], pkl_second_recompress_largeQP2_listsA[8]))\n",
    "second_largeQP2_csv10 = list(zip(csv_second_largeQP2_listsA[9], pkl_second_largeQP2_listsA[9], csv_second_recompress_largeQP2_listsA[9], pkl_second_recompress_largeQP2_listsA[9]))\n",
    "print(len(second_largeQP2_csv1))\n",
    "\n",
    "second_largeQP2_csv1 = random.sample(second_largeQP2_csv1, 100)\n",
    "second_largeQP2_csv2 = random.sample(second_largeQP2_csv2, 100)\n",
    "second_largeQP2_csv3 = random.sample(second_largeQP2_csv3, 100)\n",
    "second_largeQP2_csv4 = random.sample(second_largeQP2_csv4, 100)\n",
    "second_largeQP2_csv5 = random.sample(second_largeQP2_csv5, 100)\n",
    "second_largeQP2_csv6 = random.sample(second_largeQP2_csv6, 100)\n",
    "second_largeQP2_csv7 = random.sample(second_largeQP2_csv7, 100)\n",
    "second_largeQP2_csv8 = random.sample(second_largeQP2_csv8, 100)\n",
    "second_largeQP2_csv9 = random.sample(second_largeQP2_csv9, 100)\n",
    "# second_largeQP2_csv10 = selected_data[9]\n",
    "print('\\ndouble images train by QP1<QP2: ', len(second_largeQP2_csv1))\n",
    "\n",
    "second_largeQP2_csv10 = random.sample(second_largeQP2_csv10, 300)\n",
    "print('\\ndouble images test by QP1<QP2: ', len(second_largeQP2_csv10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_csv_list:  600\n",
      "\n",
      "test_csv_largeQP1 600\n",
      "test_csv_sameQP 600\n",
      "test_csv_largeQP2 600\n"
     ]
    }
   ],
   "source": [
    "train_csv_list1 = single_csv1 + second_largeQP1_csv1 + second_sameQP_csv1 + second_largeQP2_csv1\n",
    "train_csv_list2 = single_csv2 + second_largeQP1_csv2 + second_sameQP_csv2 + second_largeQP2_csv2\n",
    "train_csv_list3 = single_csv3 + second_largeQP1_csv3 + second_sameQP_csv3 + second_largeQP2_csv3\n",
    "train_csv_list4 = single_csv4 + second_largeQP1_csv4 + second_sameQP_csv4 + second_largeQP2_csv4\n",
    "train_csv_list5 = single_csv5 + second_largeQP1_csv5 + second_sameQP_csv5 + second_largeQP2_csv5\n",
    "train_csv_list6 = single_csv6 + second_largeQP1_csv6 + second_sameQP_csv6 + second_largeQP2_csv6\n",
    "train_csv_list7 = single_csv7 + second_largeQP1_csv7 + second_sameQP_csv7 + second_largeQP2_csv7\n",
    "train_csv_list8 = single_csv8 + second_largeQP1_csv8 + second_sameQP_csv8 + second_largeQP2_csv8\n",
    "train_csv_list9 = single_csv9 + second_largeQP1_csv9 + second_sameQP_csv9 + second_largeQP2_csv9\n",
    "print(\"train_csv_list: \", len(train_csv_list9))\n",
    "\n",
    "test_csv_largeQP1 = single_csv10 + second_largeQP1_csv10\n",
    "test_csv_sameQP = single_csv10 + second_sameQP_csv10\n",
    "test_csv_largeQP2 = single_csv10 + second_largeQP2_csv10\n",
    "\n",
    "print(\"\\ntest_csv_largeQP1\", len(test_csv_largeQP1))\n",
    "print(\"test_csv_sameQP\", len(test_csv_sameQP))\n",
    "print(\"test_csv_largeQP2\", len(test_csv_largeQP2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_smoothing(probabilities, alpha=1):\n",
    "    \"\"\"\n",
    "    ラプラス平滑化を行う関数\n",
    "    \n",
    "    Args:\n",
    "    probabilities (list): 平滑化する確率分布のリスト\n",
    "    alpha (float): 平滑化パラメータ\n",
    "    \n",
    "    Returns:\n",
    "    smoothed_probabilities (list): 平滑化された確率分布のリスト\n",
    "    \"\"\"\n",
    "    total_count = sum(probabilities)\n",
    "    num_elements = len(probabilities)\n",
    "    \n",
    "    smoothed_probabilities = [(count + alpha) / (total_count + alpha * num_elements) for count in probabilities]\n",
    "    \n",
    "    return smoothed_probabilities\n",
    "\n",
    "\n",
    "def process_train_csv_lists(train_csv_list):\n",
    "    pu_columns = [\"PU1_64\", \"PU1_32\", \"PU1_16\", \"PU1_8\", \"PU1_4\",  \n",
    "                  \"PU2_64\",\"PU2_32\", \"PU2_16\", \"PU2_8\", \"PU2_4\"]\n",
    "\n",
    "#     luminance_columns = [\"LU1_0\",\"LU1_1\",\"LU1_2\",\"LU1_3\",\n",
    "#                          \"LU1_4\",\"LU1_5\",\"LU1_6\",\"LU1_7\",\n",
    "#                          \"LU1_8\",\"LU1_9\",\"LU1_10\",\"LU1_11\",\n",
    "#                          \"LU1_12\",\"LU1_13\",\"LU1_14\",\"LU1_15\",\n",
    "#                          \"LU1_16\",\"LU1_17\",\"LU1_18\",\"LU1_19\",\n",
    "#                          \"LU1_20\",\"LU1_21\",\"LU1_22\",\"LU1_23\",\n",
    "#                          \"LU1_24\",\"LU1_25\",\"LU1_26\",\"LU1_27\",\n",
    "#                          \"LU1_28\",\"LU1_29\",\"LU1_30\",\"LU1_31\",\n",
    "#                          \"LU1_32\",\"LU1_33\",\"LU1_34\",\n",
    "                         \n",
    "#                          \"LU2_0\",\"LU2_1\",\"LU2_2\",\"LU2_3\",\n",
    "#                          \"LU2_4\",\"LU2_5\",\"LU2_6\",\"LU2_7\",\n",
    "#                          \"LU2_8\",\"LU2_9\",\"LU2_10\",\"LU2_11\",\n",
    "#                          \"LU2_12\",\"LU2_13\",\"LU2_14\",\"LU2_15\",\n",
    "#                          \"LU2_16\",\"LU2_17\",\"LU2_18\",\"LU2_19\",\n",
    "#                          \"LU2_20\",\"LU2_21\",\"LU2_22\",\"LU2_23\",\n",
    "#                          \"LU2_24\",\"LU2_25\",\"LU2_26\",\"LU2_27\",\n",
    "#                          \"LU2_28\",\"LU2_29\",\"LU2_30\",\"LU2_31\",\n",
    "#                          \"LU2_32\",\"LU2_33\",\"LU2_34\"]\n",
    "    \n",
    "    luminance_columns = [\"LU1_0\",\"LU1_1\",\"LU1_9\",\"LU1_10\",\"LU1_11\",\"LU1_25\",\"LU1_26\",\"LU1_27\",\n",
    "                         \"LU2_0\",\"LU2_1\",\"LU2_9\",\"LU2_10\",\"LU2_11\", \"LU2_25\",\"LU2_26\",\"LU2_27\"]\n",
    "\n",
    "    chrominance_columns = [\"CH1_0\", \"CH1_1\", \"CH1_10\", \"CH1_26\", \"CH1_34\", \"CH1_36\", \n",
    "                           \"CH2_0\", \"CH2_1\", \"CH2_10\", \"CH2_26\", \"CH2_34\", \"CH2_36\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    label_columns = [\"LABEL\"]\n",
    "    mae1_columns = [f\"MAE1_{i}\" for i in range(52)]\n",
    "    mae2_columns = [f\"MAE2_{i}\" for i in range(52)]\n",
    "    mae_columns = [\"MAE\"]\n",
    "    final_qp_columns = [\"FINAL_QP\"]\n",
    "    kl_divergence1 = [\"KLD_PU\"]\n",
    "    kl_divergence2 = [\"KLD_LUMA\"]\n",
    "    kl_divergence3 = [\"KLD_CHROMA\"]\n",
    "    ratio_columns1 = [\"RATIO1\"]\n",
    "    ratio_columns2 = [\"RATIO2\"]\n",
    "    \n",
    "    train_df1_1 = pd.DataFrame(columns=pu_columns)\n",
    "    train_df1_2 = pd.DataFrame(columns=luminance_columns)\n",
    "    train_df1_3 = pd.DataFrame(columns=chrominance_columns)\n",
    "    LABEL = pd.DataFrame(columns=label_columns)\n",
    "    RATIO1 = pd.DataFrame(columns=ratio_columns1)\n",
    "    RATIO2 = pd.DataFrame(columns=ratio_columns2)\n",
    "    train_df3 = pd.DataFrame(columns=mae1_columns)\n",
    "    train_df4 = pd.DataFrame(columns=mae2_columns)\n",
    "    MAE = pd.DataFrame(columns=mae_columns)\n",
    "    FINAL_QP = pd.DataFrame(columns=final_qp_columns)\n",
    "    kl_divergence_df1 = pd.DataFrame(columns=kl_divergence1)\n",
    "    kl_divergence_df2 = pd.DataFrame(columns=kl_divergence2)\n",
    "    kl_divergence_df3 = pd.DataFrame(columns=kl_divergence3)\n",
    "\n",
    "    for path1, path2, path3, path4 in train_csv_list:\n",
    "        label = 1 if (\"2ndQP\" in path1) and (\"3rdQP\" in path3) else 0\n",
    "        train_pkl_list = [path2, path4]\n",
    "        df1 = pd.read_csv(path1)\n",
    "        df2 = pd.read_csv(path3)\n",
    "        \n",
    "        # 平滑化を行う\n",
    "        probabilities_df1 = laplace_smoothing([df1.loc[i, \"pu_counts\"] for i in [0,1,2,3,4]])\n",
    "        probabilities_df2 = laplace_smoothing([df2.loc[i, \"pu_counts\"] for i in [0,1,2,3,4]])\n",
    "        kl_divergence1 = entropy(probabilities_df1, probabilities_df2)\n",
    "        \n",
    "        probabilities_df3 = laplace_smoothing([df1.loc[i, \"luminance_counts\"] for i in [0,1,9,10,11,25,26,27]])\n",
    "        probabilities_df4 = laplace_smoothing([df2.loc[i, \"luminance_counts\"] for i in [0,1,9,10,11,25,26,27]])\n",
    "        kl_divergence2 = entropy(probabilities_df3, probabilities_df4)\n",
    "        \n",
    "        probabilities_df5 = laplace_smoothing([df1.loc[i, \"chroma_counts\"] for i in [0,1,10,26,34,36]])\n",
    "        probabilities_df6 = laplace_smoothing([df2.loc[i, \"chroma_counts\"] for i in [0,1,10,26,34,36]])\n",
    "        kl_divergence3 = entropy(probabilities_df5, probabilities_df6)\n",
    "        \n",
    "        \n",
    "        pu_values = [df1.loc[i, \"pu_counts\"] for i in range(5)] + [df2.loc[i, \"pu_counts\"] for i in range(5)]\n",
    "        # lu_values = [df1.loc[i, \"luminance_counts\"] for i in range(35)] + [df2.loc[i, \"luminance_counts\"] for i in range(35)]\n",
    "        lu_values = [df1.loc[i, \"luminance_counts\"] for i in [0,1,9,10,11,25,26,27]] + [df2.loc[i, \"luminance_counts\"] for i in [0,1,9,10,11,25,26,27]]\n",
    "        ch_values = [df1.loc[i, \"chroma_counts\"] for i in [0,1,10,26,34,36]] + [df2.loc[i, \"chroma_counts\"] for i in [0,1,10,26,34,36]]\n",
    "        \n",
    "        train_df1_1 = pd.concat([train_df1_1, pd.DataFrame([pu_values], columns=pu_columns)], ignore_index=True)\n",
    "        train_df1_2= pd.concat([train_df1_2, pd.DataFrame([lu_values], columns=luminance_columns)], ignore_index=True)\n",
    "        train_df1_3 = pd.concat([train_df1_3, pd.DataFrame([ch_values], columns=chrominance_columns)], ignore_index=True)\n",
    "        \n",
    "        kl_divergence_df1 = pd.concat([kl_divergence_df1, pd.DataFrame({\"KLD_PU\": [kl_divergence1]})], ignore_index=True)\n",
    "        kl_divergence_df2 = pd.concat([kl_divergence_df2, pd.DataFrame({\"KLD_LUMA\": [kl_divergence2]})], ignore_index=True)\n",
    "        kl_divergence_df3 = pd.concat([kl_divergence_df3, pd.DataFrame({\"KLD_CHROMA\": [kl_divergence3]})], ignore_index=True)\n",
    "\n",
    "\n",
    "        LABEL = pd.concat([LABEL, pd.DataFrame({\"LABEL\": [label]})], ignore_index=True)\n",
    "\n",
    "        final_QP = extract_finalQP(train_pkl_list[0])\n",
    "\n",
    "        mae_d1 = calculate_mae(train_pkl_list[0])\n",
    "        mae_d2 = calculate_mae(train_pkl_list[1])\n",
    "        ratio1 = ratio_double_compressed(mae_d1, final_QP)\n",
    "        ratio2 = ratio_double_compressed(mae_d2, final_QP)\n",
    "\n",
    "        RATIO1 = pd.concat([RATIO1, pd.DataFrame({\"RATIO1\": [ratio1]})], ignore_index=True)\n",
    "        RATIO2 = pd.concat([RATIO2, pd.DataFrame({\"RATIO2\": [ratio2]})], ignore_index=True)\n",
    "\n",
    "        train_df3 = pd.concat([train_df3, pd.DataFrame({f\"MAE1_{i}\": [mae_d1[i]] for i in range(52)})], ignore_index=True)\n",
    "        train_df4 = pd.concat([train_df4, pd.DataFrame({f\"MAE2_{i}\": [mae_d2[i]] for i in range(52)})], ignore_index=True)\n",
    "        MAE = pd.concat([MAE, pd.DataFrame({\"MAE\": [mae_d1]})], ignore_index=True)\n",
    "        FINAL_QP = pd.concat([FINAL_QP, pd.DataFrame({\"FINAL_QP\": [final_QP]})], ignore_index=True)\n",
    "\n",
    "    train_df1_1.reset_index(drop=True, inplace=True)\n",
    "    train_df1_2.reset_index(drop=True, inplace=True)\n",
    "    train_df1_3.reset_index(drop=True, inplace=True)\n",
    "    LABEL.reset_index(drop=True, inplace=True)\n",
    "    RATIO1.reset_index(drop=True, inplace=True)\n",
    "    RATIO2.reset_index(drop=True, inplace=True)\n",
    "    kl_divergence_df1.reset_index(drop=True, inplace=True)\n",
    "    kl_divergence_df2.reset_index(drop=True, inplace=True)\n",
    "    kl_divergence_df3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # train_df = pd.concat([train_df1_1, train_df1_2, train_df1_3, train_df3, train_df4], axis=1)\n",
    "    train_df = pd.concat([FINAL_QP, train_df1_1, train_df1_2, train_df1_3, kl_divergence_df1, kl_divergence_df2, kl_divergence_df3, RATIO1, RATIO2], axis=1)\n",
    "    train_df_onlyGhost = pd.concat([FINAL_QP, kl_divergence_df1, kl_divergence_df2, kl_divergence_df3, RATIO1, RATIO2], axis=1)\n",
    "\n",
    "    return train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1, train_df_onlyGhost1, LABEL1, MAE1, FINAL_QP1 = process_train_csv_lists(train_csv_list1)\n",
    "train_df2, train_df_onlyGhost2, LABEL2, MAE2, FINAL_QP2 = process_train_csv_lists(train_csv_list2)\n",
    "train_df3, train_df_onlyGhost3, LABEL3, MAE3, FINAL_QP3 = process_train_csv_lists(train_csv_list3)\n",
    "train_df4, train_df_onlyGhost4, LABEL4, MAE4, FINAL_QP4 = process_train_csv_lists(train_csv_list4)\n",
    "train_df5, train_df_onlyGhost5, LABEL5, MAE5, FINAL_QP5 = process_train_csv_lists(train_csv_list5)\n",
    "train_df6, train_df_onlyGhost6, LABEL6, MAE6, FINAL_QP6 = process_train_csv_lists(train_csv_list6)\n",
    "train_df7, train_df_onlyGhost7, LABEL7, MAE7, FINAL_QP7 = process_train_csv_lists(train_csv_list7)\n",
    "train_df8, train_df_onlyGhost8, LABEL8, MAE8, FINAL_QP8 = process_train_csv_lists(train_csv_list8)\n",
    "train_df9, train_df_onlyGhost9, LABEL9, MAE9, FINAL_QP9 = process_train_csv_lists(train_csv_list9)\n",
    "\n",
    "test_df1, test_df_onlyGhost1, LABEL_t1, MAE_t1, FINAL_QP_t1 = process_train_csv_lists(test_csv_largeQP1)\n",
    "test_df2, test_df_onlyGhost2, LABEL_t2, MAE_t2, FINAL_QP_t2 = process_train_csv_lists(test_csv_sameQP)\n",
    "test_df3, test_df_onlyGhost3, LABEL_t3, MAE_t3, FINAL_QP_t3 = process_train_csv_lists(test_csv_largeQP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各データフレームを結合\n",
    "combined_train_df = pd.concat([train_df1, train_df2, train_df3, train_df4, train_df5, train_df6, train_df7, train_df8, train_df9], ignore_index=True)\n",
    "combined_train_df_onlyGhost = pd.concat([train_df_onlyGhost1, train_df_onlyGhost2, train_df_onlyGhost3, train_df_onlyGhost4, train_df_onlyGhost5, train_df_onlyGhost6, train_df_onlyGhost7, train_df_onlyGhost8, train_df_onlyGhost9], ignore_index=True)\n",
    "combined_LABEL = pd.concat([LABEL1, LABEL2, LABEL3, LABEL4, LABEL5, LABEL6, LABEL7, LABEL8, LABEL9], ignore_index=True)\n",
    "combined_MAE = pd.concat([MAE1, MAE2, MAE3, MAE4, MAE5, MAE6, MAE7, MAE8, MAE9], ignore_index=True)\n",
    "combined_FINAL_QP = pd.concat([FINAL_QP1, FINAL_QP2, FINAL_QP3, FINAL_QP4, FINAL_QP5, FINAL_QP6, FINAL_QP7, FINAL_QP8, FINAL_QP9], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5400, 44)\n",
      "(5400, 6)\n",
      "(5400, 1)\n",
      "(5400, 1)\n",
      "(5400, 1)\n",
      "(600, 44)\n",
      "(600, 6)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 44)\n",
      "(600, 6)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 44)\n",
      "(600, 6)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 1)\n"
     ]
    }
   ],
   "source": [
    "print(combined_train_df.shape)\n",
    "print(combined_train_df_onlyGhost.shape)\n",
    "print(combined_LABEL.shape)\n",
    "print(combined_MAE.shape)\n",
    "print(combined_FINAL_QP.shape)\n",
    "\n",
    "print(test_df1.shape)\n",
    "print(test_df_onlyGhost1.shape)\n",
    "print(LABEL_t1.shape)\n",
    "print(MAE_t1.shape)\n",
    "print(FINAL_QP_t1.shape)\n",
    "\n",
    "print(test_df2.shape)\n",
    "print(test_df_onlyGhost2.shape)\n",
    "print(LABEL_t2.shape)\n",
    "print(MAE_t2.shape)\n",
    "print(FINAL_QP_t2.shape)\n",
    "\n",
    "print(test_df3.shape)\n",
    "print(test_df_onlyGhost3.shape)\n",
    "print(LABEL_t3.shape)\n",
    "print(MAE_t3.shape)\n",
    "print(FINAL_QP_t3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling:\n",
      "Combined Train DF:\n",
      "  FINAL_QP PU1_64 PU1_32 PU1_16  PU1_8  PU1_4 PU2_64 PU2_32 PU2_16  PU2_8  PU2_4 LU1_0 LU1_1 LU1_9 LU1_10 LU1_11 LU1_25 LU1_26 LU1_27 LU2_0 LU2_1 LU2_9 LU2_10 LU2_11 LU2_25 LU2_26 LU2_27  CH1_0  CH1_1 CH1_10 CH1_26 CH1_34 CH1_36  CH2_0  CH2_1 CH2_10 CH2_26 CH2_34 CH2_36    KLD_PU  KLD_LUMA KLD_CHROMA    RATIO1    RATIO2\n",
      "0       10      0   5568   2160   9360  42912      0   5504   2208   7932  44356  5276  4868  2968   5987   2742   1914   2371   1903  5345  5180  2997   6033   2648   1922   2360   1875  13772  12360   7880   7212   1220  17556  13888  12424   8080   7312   1144  17152  0.002435  0.000368   0.000184  0.036319  0.026933\n",
      "1       16      0   6016   3040  12116  38828      0   5824   3120  10692  40364  6100  5149  3255   4479   2985   1699   2407   1790  5904  5441  3241   5160   2775   1669   2415   1781  13316   8376   7520   5292   1024  24472  12984   8868   7696   5444    980  24028  0.002077  0.002206   0.000456  0.015317   0.00948\n",
      "2       20      0   6208   4448  13340  36004      0   6208   4512  12260  37020  6055  6062  3202   4455   3042   1834   2416   1708  6207  6204  3206   4450   2998   1841   2381   1703  12444   6552   6580   4292   1060  29072  12160   6996   6744   4632    948  28520  0.001012  0.000115   0.000736  0.007772  0.004674\n",
      "3       24      0   8064   4784  13996  33156      0   8064   4704  13276  33956  7128  6685  2795   4910   2263   1608   2530   1809  7288  6753  2901   4755   2299   1695   2523   1856  10780   4664   5732   3444   1064  34316  10144   5136   5868   3388    852  34612  0.000489  0.000262    0.00116  0.005024  0.003024\n",
      "4       27      0   8512   6176  14920  30392      0   8512   6176  14340  30972  7100  6777  2966   5054   2462   1673   2379   1691  7510  7252  3023   5311   2337   1608   2402   1612   9200   3932   4784   2892   1296  37896   8268   4016   4620   2744   1060  39292  0.000284  0.000863   0.001799  0.195502   0.16559\n",
      "Combined Train DF Only Ghost:\n",
      "  FINAL_QP    KLD_PU  KLD_LUMA KLD_CHROMA    RATIO1    RATIO2\n",
      "0       10  0.002435  0.000368   0.000184  0.036319  0.026933\n",
      "1       16  0.002077  0.002206   0.000456  0.015317   0.00948\n",
      "2       20  0.001012  0.000115   0.000736  0.007772  0.004674\n",
      "3       24  0.000489  0.000262    0.00116  0.005024  0.003024\n",
      "4       27  0.000284  0.000863   0.001799  0.195502   0.16559\n",
      "\n",
      "Before scaling:\n",
      "Combined Test DF:\n",
      "  FINAL_QP PU1_64 PU1_32 PU1_16  PU1_8  PU1_4 PU2_64 PU2_32 PU2_16  PU2_8  PU2_4 LU1_0 LU1_1 LU1_9 LU1_10 LU1_11 LU1_25 LU1_26 LU1_27 LU2_0 LU2_1 LU2_9 LU2_10 LU2_11 LU2_25 LU2_26 LU2_27  CH1_0  CH1_1 CH1_10 CH1_26 CH1_34 CH1_36  CH2_0  CH2_1 CH2_10 CH2_26 CH2_34 CH2_36    KLD_PU  KLD_LUMA KLD_CHROMA    RATIO1    RATIO2\n",
      "0       10      0  10880   7568   7908  33644      0  10816   7616   7552  34016  8297  9519  2708   2173   2806    915   1971   1589  8256  9888  2681   2213   2925    911   2069   1550  14276  16996   8108   6056   1524  13040  14180  17168   8444   6216   1424  12568  0.000177  0.000284    0.00037  0.082337  0.056326\n",
      "1       16      0  21696   3792   8640  25872      0  21440   3968   8180  26412  7199  5463  2877   2612   2530    791   1976   1548  7134  5835  3519   3113   3042    765   2012   1526  14872  15424   8076   4552   1236  15840  14572  15420   8344   4960   1032  15672  0.000396  0.003674   0.000742  0.035606  0.019595\n",
      "2       20      0  19776   6880  10176  23168      0  19648   6976   9708  23668  7743  4236  2169   2820   1934    795   1923   1509  7856  4380  2225   2899   1989    770   1884   1568  15284   6560   9916   4512   1000  22728  14936   6944   9900   4568    944  22708  0.000292  0.000153   0.000281  0.026824  0.020166\n",
      "3       24      0  24448   3488  11200  20864      0  24384   3520  10716  21380  7086  4504  2159   2999   1932    605   2061   1523  7103  4805  2188   3047   1998    648   2107   1488  15160   3220   9720   3352   1104  27444  15092   3360   9448   3232    948  27920  0.000288  0.000349   0.000424  0.006947  0.004443\n",
      "4       27      0  24704   4480  11740  19076      0  24576   4624  11352  19448  9199  5159  1513   2483   1683    678   2042   1436  9448  5468  1466   2494   1730    667   1998   1503  11632   2248   4656   2064    984  38416  11296   2124   4288   1820    880  39592  0.000212  0.000365   0.001051  0.228172  0.194586\n",
      "Combined Test DF Only Ghost:\n",
      "  FINAL_QP    KLD_PU  KLD_LUMA KLD_CHROMA    RATIO1    RATIO2\n",
      "0       10  0.000177  0.000284    0.00037  0.082337  0.056326\n",
      "1       16  0.000396  0.003674   0.000742  0.035606  0.019595\n",
      "2       20  0.000292  0.000153   0.000281  0.026824  0.020166\n",
      "3       24  0.000288  0.000349   0.000424  0.006947  0.004443\n",
      "4       27  0.000212  0.000365   0.001051  0.228172  0.194586\n"
     ]
    }
   ],
   "source": [
    "print(\"Before scaling:\")\n",
    "print(\"Combined Train DF:\")\n",
    "print(combined_train_df.head())\n",
    "print(\"Combined Train DF Only Ghost:\")\n",
    "print(combined_train_df_onlyGhost.head())\n",
    "\n",
    "print(\"\\nBefore scaling:\")\n",
    "print(\"Combined Test DF:\")\n",
    "print(test_df1.head())\n",
    "print(\"Combined Test DF Only Ghost:\")\n",
    "print(test_df_onlyGhost1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After scaling:\n",
      "X_train:\n",
      "      0    1         2         3         4         5    6         7         8         9         10        11        12        13        14        15        16        17        18        19        20        21        22        23        24        25        26        27        28        29        30        31        32        33        34        35        36        37        38        39        40        41        42        43\n",
      "0  0.125  0.0  0.094565  0.070231  0.324459  0.766669  0.0  0.093377  0.072517  0.278121  0.772914  0.066565  0.097782  0.228252  0.279645  0.225462  0.129754  0.072956  0.208731  0.072644  0.101237  0.230037  0.290597  0.220582  0.130296  0.069321  0.205660  0.445927  0.499919  0.466714  0.407274  0.119655  0.221104  0.455523  0.491067  0.458050  0.402466  0.126381  0.216444  0.105847  0.002110  0.001880  0.034256  0.025452\n",
      "1  0.275  0.0  0.102174  0.099057  0.419994  0.693704  0.0  0.098806  0.102470  0.374895  0.703353  0.093881  0.107312  0.250405  0.209161  0.245709  0.115179  0.074223  0.196337  0.092550  0.110107  0.248771  0.248089  0.231173  0.113145  0.071169  0.195349  0.431162  0.338780  0.445392  0.298848  0.100432  0.348069  0.425872  0.350514  0.436281  0.299648  0.108263  0.342184  0.090297  0.012711  0.004665  0.013208  0.007972\n",
      "2  0.375  0.0  0.105435  0.145178  0.462424  0.643250  0.0  0.105320  0.148187  0.429874  0.645083  0.092389  0.138278  0.246314  0.208039  0.250458  0.124331  0.074539  0.187342  0.103340  0.136036  0.246084  0.213517  0.249771  0.124805  0.070027  0.186794  0.402927  0.265006  0.389718  0.242376  0.103962  0.432516  0.398845  0.276522  0.382313  0.254954  0.104728  0.424329  0.044016  0.000652  0.007539  0.005648  0.003157\n",
      "3  0.475  0.0  0.136957  0.156184  0.485164  0.592368  0.0  0.136808  0.154493  0.465498  0.591692  0.127959  0.159408  0.214898  0.229306  0.185552  0.109010  0.078549  0.198421  0.141835  0.154693  0.222666  0.228368  0.191477  0.114907  0.074798  0.203576  0.349048  0.188643  0.339493  0.194488  0.104355  0.528785  0.332721  0.203004  0.332653  0.186482  0.094123  0.535733  0.021266  0.001498  0.011888  0.002894  0.001505\n",
      "4  0.550  0.0  0.144565  0.201782  0.517194  0.542986  0.0  0.144408  0.202838  0.502805  0.539695  0.127030  0.162529  0.228097  0.236036  0.202133  0.113416  0.073238  0.185478  0.149740  0.171651  0.232033  0.255441  0.194646  0.109010  0.070733  0.176813  0.297889  0.159036  0.283345  0.163316  0.127109  0.594507  0.271189  0.158735  0.261905  0.151035  0.117101  0.621315  0.012344  0.004965  0.018428  0.193784  0.164330\n",
      "X_train_onlyGhost:\n",
      "       0         1         2         3         4         5\n",
      "0  0.125  0.105847  0.002110  0.001880  0.034256  0.025452\n",
      "1  0.275  0.090297  0.012711  0.004665  0.013208  0.007972\n",
      "2  0.375  0.044016  0.000652  0.007539  0.005648  0.003157\n",
      "3  0.475  0.021266  0.001498  0.011888  0.002894  0.001505\n",
      "4  0.550  0.012344  0.004965  0.018428  0.193784  0.164330\n",
      "\n",
      "Test data after scaling:\n",
      "X_test_list1:\n",
      "      0    1         2         3         4         5    6         7         8         9         10        11        12        13        14        15        16        17        18        19        20        21        22        23        24        25        26        27        28        29        30        31        32        33        34        35        36        37        38        39        40        41        42        43\n",
      "0  0.125  0.0  0.184783  0.247379  0.274126  0.601086  0.0  0.183496  0.250131  0.264797  0.592737  0.166711  0.255528  0.208182  0.101379  0.230795  0.062030  0.058886  0.174290  0.176305  0.261232  0.205774  0.104592  0.243683  0.061759  0.059543  0.170012  0.462246  0.687429  0.480218  0.341992  0.149470  0.138199  0.465101  0.678577  0.478685  0.342140  0.157313  0.132616  0.007711  0.001624  0.003793  0.080374  0.054892\n",
      "1  0.275  0.0  0.368478  0.123690  0.299501  0.462231  0.0  0.363735  0.130321  0.286816  0.460236  0.130312  0.117962  0.221227  0.121898  0.207799  0.053623  0.059061  0.169793  0.136351  0.123496  0.270117  0.148415  0.253440  0.051861  0.057628  0.167380  0.481544  0.623847  0.478323  0.257059  0.121224  0.189602  0.477959  0.609486  0.473016  0.273007  0.114008  0.189379  0.017198  0.021174  0.007598  0.033542  0.018103\n",
      "2  0.375  0.0  0.335870  0.224843  0.352745  0.413921  0.0  0.333333  0.229112  0.340393  0.412421  0.148346  0.076346  0.166577  0.131620  0.158140  0.053895  0.057197  0.165515  0.162061  0.074050  0.170762  0.137995  0.165624  0.052200  0.053327  0.171986  0.494884  0.265329  0.587302  0.254800  0.098078  0.316052  0.489898  0.274466  0.561224  0.251431  0.104286  0.318045  0.012679  0.000868  0.002872  0.024741  0.018675\n",
      "3  0.475  0.0  0.415217  0.113732  0.388242  0.372758  0.0  0.413681  0.115607  0.375736  0.372552  0.126566  0.085436  0.165805  0.139986  0.157974  0.041014  0.062051  0.167051  0.135247  0.088493  0.167921  0.145201  0.166375  0.043929  0.060820  0.163212  0.490869  0.130238  0.575693  0.189293  0.108278  0.402629  0.495014  0.132806  0.535601  0.177895  0.104728  0.413357  0.012516  0.002001  0.004342  0.004821  0.002926\n",
      "4  0.550  0.0  0.419565  0.146226  0.406961  0.340813  0.0  0.416938  0.151865  0.398036  0.338886  0.196612  0.107652  0.115940  0.115868  0.137227  0.045963  0.061383  0.157508  0.218752  0.111024  0.112485  0.118274  0.144025  0.045217  0.057157  0.164857  0.376635  0.090924  0.275764  0.116557  0.096508  0.604053  0.370506  0.083953  0.243084  0.100176  0.097216  0.626801  0.009226  0.002096  0.010767  0.226526  0.193373\n",
      "X_test_onlyGhost_list1:\n",
      "       0         1         2         3         4         5\n",
      "0  0.125  0.007711  0.001624  0.003793  0.080374  0.054892\n",
      "1  0.275  0.017198  0.021174  0.007598  0.033542  0.018103\n",
      "2  0.375  0.012679  0.000868  0.002872  0.024741  0.018675\n",
      "3  0.475  0.012516  0.002001  0.004342  0.004821  0.002926\n",
      "4  0.550  0.009226  0.002096  0.010767  0.226526  0.193373\n"
     ]
    }
   ],
   "source": [
    "def process_results_to_lists(train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP, scaler_main=None, scaler_ghost=None, fit_scaler=True):\n",
    "    if fit_scaler:\n",
    "        scaler_main = MinMaxScaler()\n",
    "        scaler_ghost = MinMaxScaler()\n",
    "        X_train = scaler_main.fit_transform(train_df)\n",
    "        X_train_onlyGhost = scaler_ghost.fit_transform(train_df_onlyGhost)\n",
    "    else:\n",
    "        X_train = scaler_main.transform(train_df)\n",
    "        X_train_onlyGhost = scaler_ghost.transform(train_df_onlyGhost)\n",
    "\n",
    "    MAE_array = MAE.values\n",
    "    FINAL_QP_array = FINAL_QP.values\n",
    "    Y_train = LABEL['LABEL'].astype(int).values\n",
    "\n",
    "    return X_train, X_train_onlyGhost, MAE_array, FINAL_QP_array, Y_train, scaler_main, scaler_ghost\n",
    "\n",
    "# 訓練データのスケーリング\n",
    "X_train, X_train_onlyGhost, MAE_array, FINAL_QP_array, Y_train, scaler_main, scaler_ghost = process_results_to_lists(\n",
    "    combined_train_df, combined_train_df_onlyGhost, combined_LABEL, combined_MAE, combined_FINAL_QP, fit_scaler=True\n",
    ")\n",
    "\n",
    "# スケーリング後のデータを表示（任意）\n",
    "print(\"After scaling:\")\n",
    "print(\"X_train:\")\n",
    "print(pd.DataFrame(X_train).head())\n",
    "print(\"X_train_onlyGhost:\")\n",
    "print(pd.DataFrame(X_train_onlyGhost).head())\n",
    "\n",
    "# データを元に戻すための関数\n",
    "def restore_data_to_original_order(data, original_lengths):\n",
    "    restored_data = []\n",
    "    start_index = 0\n",
    "    for length in original_lengths:\n",
    "        restored_data.append(data[start_index:start_index + length])\n",
    "        start_index += length\n",
    "    return restored_data\n",
    "\n",
    "# 元のデータフレームの長さ\n",
    "original_lengths = [len(train_df1), len(train_df2), len(train_df3), len(train_df4), len(train_df5), \n",
    "                    len(train_df6), len(train_df7), len(train_df8), len(train_df9)]\n",
    "\n",
    "# データを元の順序に戻す\n",
    "X_train_list = restore_data_to_original_order(X_train, original_lengths)\n",
    "X_train_onlyGhost_list = restore_data_to_original_order(X_train_onlyGhost, original_lengths)\n",
    "MAE_list = restore_data_to_original_order(MAE_array, original_lengths)\n",
    "FINAL_QP_list = restore_data_to_original_order(FINAL_QP_array, original_lengths)\n",
    "Y_train_list = restore_data_to_original_order(Y_train, original_lengths)\n",
    "\n",
    "# テストデータのスケーリング関数\n",
    "def append_results_to_lists(train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP, X_train_list, X_train_onlyGhost_list, MAE_list, FINAL_QP_list, Y_train_list, scaler_main=None, scaler_ghost=None, fit_scaler=True):\n",
    "    X_train, X_train_onlyGhost, MAE_array, FINAL_QP_array, Y_train, _, _ = process_results_to_lists(\n",
    "        train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP, scaler_main, scaler_ghost, fit_scaler)\n",
    "    X_train_list.append(X_train)\n",
    "    X_train_onlyGhost_list.append(X_train_onlyGhost)\n",
    "    MAE_list.append(MAE_array)\n",
    "    FINAL_QP_list.append(FINAL_QP_array)\n",
    "    Y_train_list.append(Y_train)\n",
    "    return X_train_list, X_train_onlyGhost_list, MAE_list, FINAL_QP_list, Y_train_list\n",
    "\n",
    "# テストデータ用のリストの初期化\n",
    "X_test_list1 = []\n",
    "X_test_onlyGhost_list1 = []\n",
    "MAE_list_t1 = []\n",
    "FINAL_QP_list_t1 = []\n",
    "Y_test_list1 = []\n",
    "\n",
    "X_test_list2 = []\n",
    "X_test_onlyGhost_list2 = []\n",
    "MAE_list_t2 = []\n",
    "FINAL_QP_list_t2 = []\n",
    "Y_test_list2 = []\n",
    "\n",
    "X_test_list3 = []\n",
    "X_test_onlyGhost_list3 = []\n",
    "MAE_list_t3 = []\n",
    "FINAL_QP_list_t3 = []\n",
    "Y_test_list3 = []\n",
    "\n",
    "# テストデータの処理とスケーリング\n",
    "X_test_list1, X_test_onlyGhost_list1, MAE_list_t1, FINAL_QP_list_t1, Y_test_list1 = append_results_to_lists(\n",
    "    test_df1, test_df_onlyGhost1, LABEL_t1, MAE_t1, FINAL_QP_t1, X_test_list1, X_test_onlyGhost_list1, MAE_list_t1, FINAL_QP_list_t1, Y_test_list1, scaler_main, scaler_ghost, fit_scaler=False\n",
    ")\n",
    "X_test_list2, X_test_onlyGhost_list2, MAE_list_t2, FINAL_QP_list_t2, Y_test_list2 = append_results_to_lists(\n",
    "    test_df2, test_df_onlyGhost2, LABEL_t2, MAE_t2, FINAL_QP_t2, X_test_list2, X_test_onlyGhost_list2, MAE_list_t2, FINAL_QP_list_t2, Y_test_list2, scaler_main, scaler_ghost, fit_scaler=False\n",
    ")\n",
    "X_test_list3, X_test_onlyGhost_list3, MAE_list_t3, FINAL_QP_list_t3, Y_test_list3 = append_results_to_lists(\n",
    "    test_df3, test_df_onlyGhost3, LABEL_t3, MAE_t3, FINAL_QP_t3, X_test_list3, X_test_onlyGhost_list3, MAE_list_t3, FINAL_QP_list_t3, Y_test_list3, scaler_main, scaler_ghost, fit_scaler=False\n",
    ")\n",
    "\n",
    "# 確認用の出力\n",
    "print(\"\\nTest data after scaling:\")\n",
    "print(\"X_test_list1:\")\n",
    "print(pd.DataFrame(X_test_list1[0]).head())\n",
    "print(\"X_test_onlyGhost_list1:\")\n",
    "print(pd.DataFrame(X_test_onlyGhost_list1[0]).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Fold-1>\n",
      "Train indices: [0 1 2 3 4 5 6 8]\n",
      "Test indices: [7]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8733333333333333\n",
      "0.52\n",
      "0.595\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9559    0.8667    0.9091       300\n",
      "           1     0.8780    0.9600    0.9172       300\n",
      "\n",
      "    accuracy                         0.9133       600\n",
      "   macro avg     0.9170    0.9133    0.9131       600\n",
      "weighted avg     0.9170    0.9133    0.9131       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9600    0.8800    0.9183       300\n",
      "           1     0.8892    0.9633    0.9248       300\n",
      "\n",
      "    accuracy                         0.9217       600\n",
      "   macro avg     0.9246    0.9217    0.9215       600\n",
      "weighted avg     0.9246    0.9217    0.9215       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9253    0.8667    0.8950       300\n",
      "           1     0.8746    0.9300    0.9015       300\n",
      "\n",
      "    accuracy                         0.8983       600\n",
      "   macro avg     0.8999    0.8983    0.8982       600\n",
      "weighted avg     0.8999    0.8983    0.8982       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9429    0.8800    0.9103       300\n",
      "           1     0.8875    0.9467    0.9161       300\n",
      "\n",
      "    accuracy                         0.9133       600\n",
      "   macro avg     0.9152    0.9133    0.9132       600\n",
      "weighted avg     0.9152    0.9133    0.9132       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6357    0.8667    0.7334       300\n",
      "           1     0.7906    0.5033    0.6151       300\n",
      "\n",
      "    accuracy                         0.6850       600\n",
      "   macro avg     0.7131    0.6850    0.6742       600\n",
      "weighted avg     0.7131    0.6850    0.6742       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6140    0.8800    0.7233       300\n",
      "           1     0.7882    0.4467    0.5702       300\n",
      "\n",
      "    accuracy                         0.6633       600\n",
      "   macro avg     0.7011    0.6633    0.6468       600\n",
      "weighted avg     0.7011    0.6633    0.6468       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9329    0.8800    0.9057       300\n",
      "           1     0.8864    0.9367    0.9109       300\n",
      "\n",
      "    accuracy                         0.9083       600\n",
      "   macro avg     0.9096    0.9083    0.9083       600\n",
      "weighted avg     0.9096    0.9083    0.9083       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8381    0.7767    0.8062       300\n",
      "           1     0.7919    0.8500    0.8199       300\n",
      "\n",
      "    accuracy                         0.8133       600\n",
      "   macro avg     0.8150    0.8133    0.8131       600\n",
      "weighted avg     0.8150    0.8133    0.8131       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9199    0.8800    0.8995       300\n",
      "           1     0.8850    0.9233    0.9038       300\n",
      "\n",
      "    accuracy                         0.9017       600\n",
      "   macro avg     0.9024    0.9017    0.9016       600\n",
      "weighted avg     0.9024    0.9017    0.9016       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6197    0.7767    0.6893       300\n",
      "           1     0.7009    0.5233    0.5992       300\n",
      "\n",
      "    accuracy                         0.6500       600\n",
      "   macro avg     0.6603    0.6500    0.6443       600\n",
      "weighted avg     0.6603    0.6500    0.6443       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5377    0.8800    0.6675       300\n",
      "           1     0.6697    0.2433    0.3570       300\n",
      "\n",
      "    accuracy                         0.5617       600\n",
      "   macro avg     0.6037    0.5617    0.5122       600\n",
      "weighted avg     0.6037    0.5617    0.5122       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5588    0.7767    0.6499       300\n",
      "           1     0.6339    0.3867    0.4803       300\n",
      "\n",
      "    accuracy                         0.5817       600\n",
      "   macro avg     0.5963    0.5817    0.5651       600\n",
      "weighted avg     0.5963    0.5817    0.5651       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8862    0.8567    0.8712       300\n",
      "           1     0.8613    0.8900    0.8754       300\n",
      "\n",
      "    accuracy                         0.8733       600\n",
      "   macro avg     0.8737    0.8733    0.8733       600\n",
      "weighted avg     0.8737    0.8733    0.8733       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5226    0.4633    0.4912       300\n",
      "           1     0.5180    0.5767    0.5457       300\n",
      "\n",
      "    accuracy                         0.5200       600\n",
      "   macro avg     0.5203    0.5200    0.5185       600\n",
      "weighted avg     0.5203    0.5200    0.5185       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6913    0.3433    0.4588       300\n",
      "           1     0.5632    0.8467    0.6764       300\n",
      "\n",
      "    accuracy                         0.5950       600\n",
      "   macro avg     0.6272    0.5950    0.5676       600\n",
      "weighted avg     0.6272    0.5950    0.5676       600\n",
      "\n",
      "<Fold-2>\n",
      "Train indices: [0 2 3 4 5 6 7 8]\n",
      "Test indices: [1]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8733333333333333\n",
      "0.52\n",
      "0.595\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9470    0.8933    0.9194       300\n",
      "           1     0.8991    0.9500    0.9238       300\n",
      "\n",
      "    accuracy                         0.9217       600\n",
      "   macro avg     0.9230    0.9217    0.9216       600\n",
      "weighted avg     0.9230    0.9217    0.9216       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9596    0.8700    0.9126       300\n",
      "           1     0.8811    0.9633    0.9204       300\n",
      "\n",
      "    accuracy                         0.9167       600\n",
      "   macro avg     0.9203    0.9167    0.9165       600\n",
      "weighted avg     0.9203    0.9167    0.9165       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9116    0.8933    0.9024       300\n",
      "           1     0.8954    0.9133    0.9043       300\n",
      "\n",
      "    accuracy                         0.9033       600\n",
      "   macro avg     0.9035    0.9033    0.9033       600\n",
      "weighted avg     0.9035    0.9033    0.9033       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9457    0.8700    0.9062       300\n",
      "           1     0.8796    0.9500    0.9135       300\n",
      "\n",
      "    accuracy                         0.9100       600\n",
      "   macro avg     0.9126    0.9100    0.9099       600\n",
      "weighted avg     0.9126    0.9100    0.9099       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6442    0.8933    0.7486       300\n",
      "           1     0.8261    0.5067    0.6281       300\n",
      "\n",
      "    accuracy                         0.7000       600\n",
      "   macro avg     0.7352    0.7000    0.6884       600\n",
      "weighted avg     0.7352    0.7000    0.6884       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6156    0.8700    0.7210       300\n",
      "           1     0.7784    0.4567    0.5756       300\n",
      "\n",
      "    accuracy                         0.6633       600\n",
      "   macro avg     0.6970    0.6633    0.6483       600\n",
      "weighted avg     0.6970    0.6633    0.6483       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9158    0.8700    0.8923       300\n",
      "           1     0.8762    0.9200    0.8976       300\n",
      "\n",
      "    accuracy                         0.8950       600\n",
      "   macro avg     0.8960    0.8950    0.8949       600\n",
      "weighted avg     0.8960    0.8950    0.8949       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8403    0.8067    0.8231       300\n",
      "           1     0.8141    0.8467    0.8301       300\n",
      "\n",
      "    accuracy                         0.8267       600\n",
      "   macro avg     0.8272    0.8267    0.8266       600\n",
      "weighted avg     0.8272    0.8267    0.8266       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9126    0.8700    0.8908       300\n",
      "           1     0.8758    0.9167    0.8958       300\n",
      "\n",
      "    accuracy                         0.8933       600\n",
      "   macro avg     0.8942    0.8933    0.8933       600\n",
      "weighted avg     0.8942    0.8933    0.8933       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6221    0.8067    0.7025       300\n",
      "           1     0.7251    0.5100    0.5988       300\n",
      "\n",
      "    accuracy                         0.6583       600\n",
      "   macro avg     0.6736    0.6583    0.6506       600\n",
      "weighted avg     0.6736    0.6583    0.6506       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5613    0.8700    0.6824       300\n",
      "           1     0.7111    0.3200    0.4414       300\n",
      "\n",
      "    accuracy                         0.5950       600\n",
      "   macro avg     0.6362    0.5950    0.5619       600\n",
      "weighted avg     0.6362    0.5950    0.5619       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5615    0.8067    0.6621       300\n",
      "           1     0.6568    0.3700    0.4733       300\n",
      "\n",
      "    accuracy                         0.5883       600\n",
      "   macro avg     0.6091    0.5883    0.5677       600\n",
      "weighted avg     0.6091    0.5883    0.5677       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8862    0.8567    0.8712       300\n",
      "           1     0.8613    0.8900    0.8754       300\n",
      "\n",
      "    accuracy                         0.8733       600\n",
      "   macro avg     0.8737    0.8733    0.8733       600\n",
      "weighted avg     0.8737    0.8733    0.8733       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5226    0.4633    0.4912       300\n",
      "           1     0.5180    0.5767    0.5457       300\n",
      "\n",
      "    accuracy                         0.5200       600\n",
      "   macro avg     0.5203    0.5200    0.5185       600\n",
      "weighted avg     0.5203    0.5200    0.5185       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6913    0.3433    0.4588       300\n",
      "           1     0.5632    0.8467    0.6764       300\n",
      "\n",
      "    accuracy                         0.5950       600\n",
      "   macro avg     0.6272    0.5950    0.5676       600\n",
      "weighted avg     0.6272    0.5950    0.5676       600\n",
      "\n",
      "<Fold-3>\n",
      "Train indices: [0 1 2 3 4 6 7 8]\n",
      "Test indices: [5]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8733333333333333\n",
      "0.52\n",
      "0.595\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9460    0.8767    0.9100       300\n",
      "           1     0.8851    0.9500    0.9164       300\n",
      "\n",
      "    accuracy                         0.9133       600\n",
      "   macro avg     0.9156    0.9133    0.9132       600\n",
      "weighted avg     0.9156    0.9133    0.9132       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9593    0.8633    0.9088       300\n",
      "           1     0.8758    0.9633    0.9175       300\n",
      "\n",
      "    accuracy                         0.9133       600\n",
      "   macro avg     0.9175    0.9133    0.9131       600\n",
      "weighted avg     0.9175    0.9133    0.9131       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9228    0.8767    0.8991       300\n",
      "           1     0.8825    0.9267    0.9041       300\n",
      "\n",
      "    accuracy                         0.9017       600\n",
      "   macro avg     0.9027    0.9017    0.9016       600\n",
      "weighted avg     0.9027    0.9017    0.9016       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9487    0.8633    0.9040       300\n",
      "           1     0.8746    0.9533    0.9123       300\n",
      "\n",
      "    accuracy                         0.9083       600\n",
      "   macro avg     0.9117    0.9083    0.9081       600\n",
      "weighted avg     0.9117    0.9083    0.9081       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6478    0.8767    0.7450       300\n",
      "           1     0.8093    0.5233    0.6356       300\n",
      "\n",
      "    accuracy                         0.7000       600\n",
      "   macro avg     0.7285    0.7000    0.6903       600\n",
      "weighted avg     0.7285    0.7000    0.6903       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6395    0.8633    0.7348       300\n",
      "           1     0.7897    0.5133    0.6222       300\n",
      "\n",
      "    accuracy                         0.6883       600\n",
      "   macro avg     0.7146    0.6883    0.6785       600\n",
      "weighted avg     0.7146    0.6883    0.6785       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9094    0.8700    0.8893       300\n",
      "           1     0.8754    0.9133    0.8940       300\n",
      "\n",
      "    accuracy                         0.8917       600\n",
      "   macro avg     0.8924    0.8917    0.8916       600\n",
      "weighted avg     0.8924    0.8917    0.8916       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8403    0.8067    0.8231       300\n",
      "           1     0.8141    0.8467    0.8301       300\n",
      "\n",
      "    accuracy                         0.8267       600\n",
      "   macro avg     0.8272    0.8267    0.8266       600\n",
      "weighted avg     0.8272    0.8267    0.8266       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9190    0.8700    0.8938       300\n",
      "           1     0.8766    0.9233    0.8994       300\n",
      "\n",
      "    accuracy                         0.8967       600\n",
      "   macro avg     0.8978    0.8967    0.8966       600\n",
      "weighted avg     0.8978    0.8967    0.8966       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6253    0.8067    0.7045       300\n",
      "           1     0.7277    0.5167    0.6043       300\n",
      "\n",
      "    accuracy                         0.6617       600\n",
      "   macro avg     0.6765    0.6617    0.6544       600\n",
      "weighted avg     0.6765    0.6617    0.6544       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5711    0.8700    0.6896       300\n",
      "           1     0.7273    0.3467    0.4695       300\n",
      "\n",
      "    accuracy                         0.6083       600\n",
      "   macro avg     0.6492    0.6083    0.5795       600\n",
      "weighted avg     0.6492    0.6083    0.5795       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5628    0.8067    0.6630       300\n",
      "           1     0.6588    0.3733    0.4766       300\n",
      "\n",
      "    accuracy                         0.5900       600\n",
      "   macro avg     0.6108    0.5900    0.5698       600\n",
      "weighted avg     0.6108    0.5900    0.5698       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8862    0.8567    0.8712       300\n",
      "           1     0.8613    0.8900    0.8754       300\n",
      "\n",
      "    accuracy                         0.8733       600\n",
      "   macro avg     0.8737    0.8733    0.8733       600\n",
      "weighted avg     0.8737    0.8733    0.8733       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5226    0.4633    0.4912       300\n",
      "           1     0.5180    0.5767    0.5457       300\n",
      "\n",
      "    accuracy                         0.5200       600\n",
      "   macro avg     0.5203    0.5200    0.5185       600\n",
      "weighted avg     0.5203    0.5200    0.5185       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6913    0.3433    0.4588       300\n",
      "           1     0.5632    0.8467    0.6764       300\n",
      "\n",
      "    accuracy                         0.5950       600\n",
      "   macro avg     0.6272    0.5950    0.5676       600\n",
      "weighted avg     0.6272    0.5950    0.5676       600\n",
      "\n",
      "<Fold-4>\n",
      "Train indices: [1 2 3 4 5 6 7 8]\n",
      "Test indices: [0]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8733333333333333\n",
      "0.52\n",
      "0.595\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9435    0.8900    0.9160       300\n",
      "           1     0.8959    0.9467    0.9206       300\n",
      "\n",
      "    accuracy                         0.9183       600\n",
      "   macro avg     0.9197    0.9183    0.9183       600\n",
      "weighted avg     0.9197    0.9183    0.9183       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9627    0.8600    0.9085       300\n",
      "           1     0.8735    0.9667    0.9177       300\n",
      "\n",
      "    accuracy                         0.9133       600\n",
      "   macro avg     0.9181    0.9133    0.9131       600\n",
      "weighted avg     0.9181    0.9133    0.9131       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9082    0.8900    0.8990       300\n",
      "           1     0.8922    0.9100    0.9010       300\n",
      "\n",
      "    accuracy                         0.9000       600\n",
      "   macro avg     0.9002    0.9000    0.9000       600\n",
      "weighted avg     0.9002    0.9000    0.9000       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9627    0.8600    0.9085       300\n",
      "           1     0.8735    0.9667    0.9177       300\n",
      "\n",
      "    accuracy                         0.9133       600\n",
      "   macro avg     0.9181    0.9133    0.9131       600\n",
      "weighted avg     0.9181    0.9133    0.9131       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6465    0.8900    0.7489       300\n",
      "           1     0.8235    0.5133    0.6324       300\n",
      "\n",
      "    accuracy                         0.7017       600\n",
      "   macro avg     0.7350    0.7017    0.6907       600\n",
      "weighted avg     0.7350    0.7017    0.6907       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6450    0.8600    0.7371       300\n",
      "           1     0.7900    0.5267    0.6320       300\n",
      "\n",
      "    accuracy                         0.6933       600\n",
      "   macro avg     0.7175    0.6933    0.6846       600\n",
      "weighted avg     0.7175    0.6933    0.6846       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9021    0.8600    0.8805       300\n",
      "           1     0.8662    0.9067    0.8860       300\n",
      "\n",
      "    accuracy                         0.8833       600\n",
      "   macro avg     0.8842    0.8833    0.8833       600\n",
      "weighted avg     0.8842    0.8833    0.8833       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8304    0.7833    0.8062       300\n",
      "           1     0.7950    0.8400    0.8169       300\n",
      "\n",
      "    accuracy                         0.8117       600\n",
      "   macro avg     0.8127    0.8117    0.8115       600\n",
      "weighted avg     0.8127    0.8117    0.8115       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9117    0.8600    0.8851       300\n",
      "           1     0.8675    0.9167    0.8914       300\n",
      "\n",
      "    accuracy                         0.8883       600\n",
      "   macro avg     0.8896    0.8883    0.8882       600\n",
      "weighted avg     0.8896    0.8883    0.8882       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6168    0.7833    0.6902       300\n",
      "           1     0.7032    0.5133    0.5934       300\n",
      "\n",
      "    accuracy                         0.6483       600\n",
      "   macro avg     0.6600    0.6483    0.6418       600\n",
      "weighted avg     0.6600    0.6483    0.6418       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5670    0.8600    0.6834       300\n",
      "           1     0.7103    0.3433    0.4629       300\n",
      "\n",
      "    accuracy                         0.6017       600\n",
      "   macro avg     0.6387    0.6017    0.5732       600\n",
      "weighted avg     0.6387    0.6017    0.5732       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5718    0.7833    0.6610       300\n",
      "           1     0.6561    0.4133    0.5072       300\n",
      "\n",
      "    accuracy                         0.5983       600\n",
      "   macro avg     0.6139    0.5983    0.5841       600\n",
      "weighted avg     0.6139    0.5983    0.5841       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8862    0.8567    0.8712       300\n",
      "           1     0.8613    0.8900    0.8754       300\n",
      "\n",
      "    accuracy                         0.8733       600\n",
      "   macro avg     0.8737    0.8733    0.8733       600\n",
      "weighted avg     0.8737    0.8733    0.8733       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5226    0.4633    0.4912       300\n",
      "           1     0.5180    0.5767    0.5457       300\n",
      "\n",
      "    accuracy                         0.5200       600\n",
      "   macro avg     0.5203    0.5200    0.5185       600\n",
      "weighted avg     0.5203    0.5200    0.5185       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6913    0.3433    0.4588       300\n",
      "           1     0.5632    0.8467    0.6764       300\n",
      "\n",
      "    accuracy                         0.5950       600\n",
      "   macro avg     0.6272    0.5950    0.5676       600\n",
      "weighted avg     0.6272    0.5950    0.5676       600\n",
      "\n",
      "<Fold-5>\n",
      "Train indices: [0 1 2 3 4 5 6 7]\n",
      "Test indices: [8]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8733333333333333\n",
      "0.52\n",
      "0.595\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9531    0.8800    0.9151       300\n",
      "           1     0.8885    0.9567    0.9213       300\n",
      "\n",
      "    accuracy                         0.9183       600\n",
      "   macro avg     0.9208    0.9183    0.9182       600\n",
      "weighted avg     0.9208    0.9183    0.9182       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9590    0.8567    0.9049       300\n",
      "           1     0.8705    0.9633    0.9146       300\n",
      "\n",
      "    accuracy                         0.9100       600\n",
      "   macro avg     0.9147    0.9100    0.9097       600\n",
      "weighted avg     0.9147    0.9100    0.9097       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9263    0.8800    0.9026       300\n",
      "           1     0.8857    0.9300    0.9073       300\n",
      "\n",
      "    accuracy                         0.9050       600\n",
      "   macro avg     0.9060    0.9050    0.9049       600\n",
      "weighted avg     0.9060    0.9050    0.9049       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9625    0.8567    0.9065       300\n",
      "           1     0.8709    0.9667    0.9163       300\n",
      "\n",
      "    accuracy                         0.9117       600\n",
      "   macro avg     0.9167    0.9117    0.9114       600\n",
      "weighted avg     0.9167    0.9117    0.9114       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6600    0.8800    0.7543       300\n",
      "           1     0.8200    0.5467    0.6560       300\n",
      "\n",
      "    accuracy                         0.7133       600\n",
      "   macro avg     0.7400    0.7133    0.7051       600\n",
      "weighted avg     0.7400    0.7133    0.7051       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6457    0.8567    0.7364       300\n",
      "           1     0.7871    0.5300    0.6335       300\n",
      "\n",
      "    accuracy                         0.6933       600\n",
      "   macro avg     0.7164    0.6933    0.6849       600\n",
      "weighted avg     0.7164    0.6933    0.6849       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9324    0.8733    0.9019       300\n",
      "           1     0.8809    0.9367    0.9079       300\n",
      "\n",
      "    accuracy                         0.9050       600\n",
      "   macro avg     0.9066    0.9050    0.9049       600\n",
      "weighted avg     0.9066    0.9050    0.9049       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8375    0.7900    0.8130       300\n",
      "           1     0.8013    0.8467    0.8233       300\n",
      "\n",
      "    accuracy                         0.8183       600\n",
      "   macro avg     0.8194    0.8183    0.8182       600\n",
      "weighted avg     0.8194    0.8183    0.8182       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9193    0.8733    0.8957       300\n",
      "           1     0.8794    0.9233    0.9008       300\n",
      "\n",
      "    accuracy                         0.8983       600\n",
      "   macro avg     0.8993    0.8983    0.8983       600\n",
      "weighted avg     0.8993    0.8983    0.8983       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6188    0.7900    0.6940       300\n",
      "           1     0.7097    0.5133    0.5957       300\n",
      "\n",
      "    accuracy                         0.6517       600\n",
      "   macro avg     0.6642    0.6517    0.6449       600\n",
      "weighted avg     0.6642    0.6517    0.6449       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5447    0.8733    0.6709       300\n",
      "           1     0.6807    0.2700    0.3866       300\n",
      "\n",
      "    accuracy                         0.5717       600\n",
      "   macro avg     0.6127    0.5717    0.5288       600\n",
      "weighted avg     0.6127    0.5717    0.5288       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5670    0.7900    0.6602       300\n",
      "           1     0.6538    0.3967    0.4938       300\n",
      "\n",
      "    accuracy                         0.5933       600\n",
      "   macro avg     0.6104    0.5933    0.5770       600\n",
      "weighted avg     0.6104    0.5933    0.5770       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8862    0.8567    0.8712       300\n",
      "           1     0.8613    0.8900    0.8754       300\n",
      "\n",
      "    accuracy                         0.8733       600\n",
      "   macro avg     0.8737    0.8733    0.8733       600\n",
      "weighted avg     0.8737    0.8733    0.8733       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5226    0.4633    0.4912       300\n",
      "           1     0.5180    0.5767    0.5457       300\n",
      "\n",
      "    accuracy                         0.5200       600\n",
      "   macro avg     0.5203    0.5200    0.5185       600\n",
      "weighted avg     0.5203    0.5200    0.5185       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6913    0.3433    0.4588       300\n",
      "           1     0.5632    0.8467    0.6764       300\n",
      "\n",
      "    accuracy                         0.5950       600\n",
      "   macro avg     0.6272    0.5950    0.5676       600\n",
      "weighted avg     0.6272    0.5950    0.5676       600\n",
      "\n",
      "<Fold-6>\n",
      "Train indices: [0 1 3 4 5 6 7 8]\n",
      "Test indices: [2]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8733333333333333\n",
      "0.52\n",
      "0.595\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9583    0.9200    0.9388       300\n",
      "           1     0.9231    0.9600    0.9412       300\n",
      "\n",
      "    accuracy                         0.9400       600\n",
      "   macro avg     0.9407    0.9400    0.9400       600\n",
      "weighted avg     0.9407    0.9400    0.9400       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9586    0.8500    0.9011       300\n",
      "           1     0.8653    0.9633    0.9117       300\n",
      "\n",
      "    accuracy                         0.9067       600\n",
      "   macro avg     0.9120    0.9067    0.9064       600\n",
      "weighted avg     0.9120    0.9067    0.9064       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9231    0.9200    0.9215       300\n",
      "           1     0.9203    0.9233    0.9218       300\n",
      "\n",
      "    accuracy                         0.9217       600\n",
      "   macro avg     0.9217    0.9217    0.9217       600\n",
      "weighted avg     0.9217    0.9217    0.9217       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9623    0.8500    0.9027       300\n",
      "           1     0.8657    0.9667    0.9134       300\n",
      "\n",
      "    accuracy                         0.9083       600\n",
      "   macro avg     0.9140    0.9083    0.9080       600\n",
      "weighted avg     0.9140    0.9083    0.9080       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6301    0.9200    0.7480       300\n",
      "           1     0.8519    0.4600    0.5974       300\n",
      "\n",
      "    accuracy                         0.6900       600\n",
      "   macro avg     0.7410    0.6900    0.6727       600\n",
      "weighted avg     0.7410    0.6900    0.6727       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6489    0.8500    0.7359       300\n",
      "           1     0.7826    0.5400    0.6391       300\n",
      "\n",
      "    accuracy                         0.6950       600\n",
      "   macro avg     0.7157    0.6950    0.6875       600\n",
      "weighted avg     0.7157    0.6950    0.6875       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9263    0.8800    0.9026       300\n",
      "           1     0.8857    0.9300    0.9073       300\n",
      "\n",
      "    accuracy                         0.9050       600\n",
      "   macro avg     0.9060    0.9050    0.9049       600\n",
      "weighted avg     0.9060    0.9050    0.9049       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8363    0.7833    0.8090       300\n",
      "           1     0.7962    0.8467    0.8207       300\n",
      "\n",
      "    accuracy                         0.8150       600\n",
      "   macro avg     0.8163    0.8150    0.8148       600\n",
      "weighted avg     0.8163    0.8150    0.8148       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9231    0.8800    0.9010       300\n",
      "           1     0.8854    0.9267    0.9055       300\n",
      "\n",
      "    accuracy                         0.9033       600\n",
      "   macro avg     0.9042    0.9033    0.9033       600\n",
      "weighted avg     0.9042    0.9033    0.9033       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6201    0.7833    0.6922       300\n",
      "           1     0.7059    0.5200    0.5988       300\n",
      "\n",
      "    accuracy                         0.6517       600\n",
      "   macro avg     0.6630    0.6517    0.6455       600\n",
      "weighted avg     0.6630    0.6517    0.6455       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5477    0.8800    0.6752       300\n",
      "           1     0.6949    0.2733    0.3923       300\n",
      "\n",
      "    accuracy                         0.5767       600\n",
      "   macro avg     0.6213    0.5767    0.5338       600\n",
      "weighted avg     0.6213    0.5767    0.5338       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5732    0.7833    0.6620       300\n",
      "           1     0.6579    0.4167    0.5102       300\n",
      "\n",
      "    accuracy                         0.6000       600\n",
      "   macro avg     0.6155    0.6000    0.5861       600\n",
      "weighted avg     0.6155    0.6000    0.5861       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8862    0.8567    0.8712       300\n",
      "           1     0.8613    0.8900    0.8754       300\n",
      "\n",
      "    accuracy                         0.8733       600\n",
      "   macro avg     0.8737    0.8733    0.8733       600\n",
      "weighted avg     0.8737    0.8733    0.8733       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5226    0.4633    0.4912       300\n",
      "           1     0.5180    0.5767    0.5457       300\n",
      "\n",
      "    accuracy                         0.5200       600\n",
      "   macro avg     0.5203    0.5200    0.5185       600\n",
      "weighted avg     0.5203    0.5200    0.5185       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6913    0.3433    0.4588       300\n",
      "           1     0.5632    0.8467    0.6764       300\n",
      "\n",
      "    accuracy                         0.5950       600\n",
      "   macro avg     0.6272    0.5950    0.5676       600\n",
      "weighted avg     0.6272    0.5950    0.5676       600\n",
      "\n",
      "<Fold-7>\n",
      "Train indices: [0 1 2 3 5 6 7 8]\n",
      "Test indices: [4]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8733333333333333\n",
      "0.52\n",
      "0.595\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9500    0.8867    0.9172       300\n",
      "           1     0.8938    0.9533    0.9226       300\n",
      "\n",
      "    accuracy                         0.9200       600\n",
      "   macro avg     0.9219    0.9200    0.9199       600\n",
      "weighted avg     0.9219    0.9200    0.9199       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9562    0.8733    0.9129       300\n",
      "           1     0.8834    0.9600    0.9201       300\n",
      "\n",
      "    accuracy                         0.9167       600\n",
      "   macro avg     0.9198    0.9167    0.9165       600\n",
      "weighted avg     0.9198    0.9167    0.9165       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9301    0.8867    0.9078       300\n",
      "           1     0.8917    0.9333    0.9121       300\n",
      "\n",
      "    accuracy                         0.9100       600\n",
      "   macro avg     0.9109    0.9100    0.9100       600\n",
      "weighted avg     0.9109    0.9100    0.9100       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9391    0.8733    0.9050       300\n",
      "           1     0.8816    0.9433    0.9114       300\n",
      "\n",
      "    accuracy                         0.9083       600\n",
      "   macro avg     0.9103    0.9083    0.9082       600\n",
      "weighted avg     0.9103    0.9083    0.9082       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6584    0.8867    0.7557       300\n",
      "           1     0.8265    0.5400    0.6532       300\n",
      "\n",
      "    accuracy                         0.7133       600\n",
      "   macro avg     0.7425    0.7133    0.7045       600\n",
      "weighted avg     0.7425    0.7133    0.7045       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6150    0.8733    0.7218       300\n",
      "           1     0.7816    0.4533    0.5738       300\n",
      "\n",
      "    accuracy                         0.6633       600\n",
      "   macro avg     0.6983    0.6633    0.6478       600\n",
      "weighted avg     0.6983    0.6633    0.6478       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9018    0.8567    0.8786       300\n",
      "           1     0.8635    0.9067    0.8846       300\n",
      "\n",
      "    accuracy                         0.8817       600\n",
      "   macro avg     0.8826    0.8817    0.8816       600\n",
      "weighted avg     0.8826    0.8817    0.8816       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8434    0.7900    0.8158       300\n",
      "           1     0.8025    0.8533    0.8271       300\n",
      "\n",
      "    accuracy                         0.8217       600\n",
      "   macro avg     0.8230    0.8217    0.8215       600\n",
      "weighted avg     0.8230    0.8217    0.8215       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9081    0.8567    0.8816       300\n",
      "           1     0.8644    0.9133    0.8882       300\n",
      "\n",
      "    accuracy                         0.8850       600\n",
      "   macro avg     0.8862    0.8850    0.8849       600\n",
      "weighted avg     0.8862    0.8850    0.8849       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6188    0.7900    0.6940       300\n",
      "           1     0.7097    0.5133    0.5957       300\n",
      "\n",
      "    accuracy                         0.6517       600\n",
      "   macro avg     0.6642    0.6517    0.6449       600\n",
      "weighted avg     0.6642    0.6517    0.6449       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5749    0.8567    0.6881       300\n",
      "           1     0.7190    0.3667    0.4857       300\n",
      "\n",
      "    accuracy                         0.6117       600\n",
      "   macro avg     0.6469    0.6117    0.5869       600\n",
      "weighted avg     0.6469    0.6117    0.5869       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5697    0.7900    0.6620       300\n",
      "           1     0.6576    0.4033    0.5000       300\n",
      "\n",
      "    accuracy                         0.5967       600\n",
      "   macro avg     0.6137    0.5967    0.5810       600\n",
      "weighted avg     0.6137    0.5967    0.5810       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8862    0.8567    0.8712       300\n",
      "           1     0.8613    0.8900    0.8754       300\n",
      "\n",
      "    accuracy                         0.8733       600\n",
      "   macro avg     0.8737    0.8733    0.8733       600\n",
      "weighted avg     0.8737    0.8733    0.8733       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5226    0.4633    0.4912       300\n",
      "           1     0.5180    0.5767    0.5457       300\n",
      "\n",
      "    accuracy                         0.5200       600\n",
      "   macro avg     0.5203    0.5200    0.5185       600\n",
      "weighted avg     0.5203    0.5200    0.5185       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6913    0.3433    0.4588       300\n",
      "           1     0.5632    0.8467    0.6764       300\n",
      "\n",
      "    accuracy                         0.5950       600\n",
      "   macro avg     0.6272    0.5950    0.5676       600\n",
      "weighted avg     0.6272    0.5950    0.5676       600\n",
      "\n",
      "<Fold-8>\n",
      "Train indices: [0 1 2 4 5 6 7 8]\n",
      "Test indices: [3]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8733333333333333\n",
      "0.52\n",
      "0.595\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9527    0.8733    0.9113       300\n",
      "           1     0.8831    0.9567    0.9184       300\n",
      "\n",
      "    accuracy                         0.9150       600\n",
      "   macro avg     0.9179    0.9150    0.9149       600\n",
      "weighted avg     0.9179    0.9150    0.9149       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9620    0.8433    0.8988       300\n",
      "           1     0.8605    0.9667    0.9105       300\n",
      "\n",
      "    accuracy                         0.9050       600\n",
      "   macro avg     0.9113    0.9050    0.9046       600\n",
      "weighted avg     0.9113    0.9050    0.9046       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9193    0.8733    0.8957       300\n",
      "           1     0.8794    0.9233    0.9008       300\n",
      "\n",
      "    accuracy                         0.8983       600\n",
      "   macro avg     0.8993    0.8983    0.8983       600\n",
      "weighted avg     0.8993    0.8983    0.8983       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9656    0.8433    0.9004       300\n",
      "           1     0.8609    0.9700    0.9122       300\n",
      "\n",
      "    accuracy                         0.9067       600\n",
      "   macro avg     0.9133    0.9067    0.9063       600\n",
      "weighted avg     0.9133    0.9067    0.9063       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6550    0.8733    0.7486       300\n",
      "           1     0.8100    0.5400    0.6480       300\n",
      "\n",
      "    accuracy                         0.7067       600\n",
      "   macro avg     0.7325    0.7067    0.6983       600\n",
      "weighted avg     0.7325    0.7067    0.6983       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6454    0.8433    0.7312       300\n",
      "           1     0.7740    0.5367    0.6339       300\n",
      "\n",
      "    accuracy                         0.6900       600\n",
      "   macro avg     0.7097    0.6900    0.6825       600\n",
      "weighted avg     0.7097    0.6900    0.6825       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9301    0.8867    0.9078       300\n",
      "           1     0.8917    0.9333    0.9121       300\n",
      "\n",
      "    accuracy                         0.9100       600\n",
      "   macro avg     0.9109    0.9100    0.9100       600\n",
      "weighted avg     0.9109    0.9100    0.9100       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8345    0.7900    0.8116       300\n",
      "           1     0.8006    0.8433    0.8214       300\n",
      "\n",
      "    accuracy                         0.8167       600\n",
      "   macro avg     0.8176    0.8167    0.8165       600\n",
      "weighted avg     0.8176    0.8167    0.8165       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9268    0.8867    0.9063       300\n",
      "           1     0.8914    0.9300    0.9103       300\n",
      "\n",
      "    accuracy                         0.9083       600\n",
      "   macro avg     0.9091    0.9083    0.9083       600\n",
      "weighted avg     0.9091    0.9083    0.9083       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6188    0.7900    0.6940       300\n",
      "           1     0.7097    0.5133    0.5957       300\n",
      "\n",
      "    accuracy                         0.6517       600\n",
      "   macro avg     0.6642    0.6517    0.6449       600\n",
      "weighted avg     0.6642    0.6517    0.6449       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5519    0.8867    0.6803       300\n",
      "           1     0.7119    0.2800    0.4019       300\n",
      "\n",
      "    accuracy                         0.5833       600\n",
      "   macro avg     0.6319    0.5833    0.5411       600\n",
      "weighted avg     0.6319    0.5833    0.5411       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5752    0.7900    0.6657       300\n",
      "           1     0.6649    0.4167    0.5123       300\n",
      "\n",
      "    accuracy                         0.6033       600\n",
      "   macro avg     0.6201    0.6033    0.5890       600\n",
      "weighted avg     0.6201    0.6033    0.5890       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8862    0.8567    0.8712       300\n",
      "           1     0.8613    0.8900    0.8754       300\n",
      "\n",
      "    accuracy                         0.8733       600\n",
      "   macro avg     0.8737    0.8733    0.8733       600\n",
      "weighted avg     0.8737    0.8733    0.8733       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5226    0.4633    0.4912       300\n",
      "           1     0.5180    0.5767    0.5457       300\n",
      "\n",
      "    accuracy                         0.5200       600\n",
      "   macro avg     0.5203    0.5200    0.5185       600\n",
      "weighted avg     0.5203    0.5200    0.5185       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6913    0.3433    0.4588       300\n",
      "           1     0.5632    0.8467    0.6764       300\n",
      "\n",
      "    accuracy                         0.5950       600\n",
      "   macro avg     0.6272    0.5950    0.5676       600\n",
      "weighted avg     0.6272    0.5950    0.5676       600\n",
      "\n",
      "<Fold-9>\n",
      "Train indices: [0 1 2 3 4 5 7 8]\n",
      "Test indices: [6]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8733333333333333\n",
      "0.52\n",
      "0.595\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9527    0.8733    0.9113       300\n",
      "           1     0.8831    0.9567    0.9184       300\n",
      "\n",
      "    accuracy                         0.9150       600\n",
      "   macro avg     0.9179    0.9150    0.9149       600\n",
      "weighted avg     0.9179    0.9150    0.9149       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9586    0.8500    0.9011       300\n",
      "           1     0.8653    0.9633    0.9117       300\n",
      "\n",
      "    accuracy                         0.9067       600\n",
      "   macro avg     0.9120    0.9067    0.9064       600\n",
      "weighted avg     0.9120    0.9067    0.9064       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9129    0.8733    0.8927       300\n",
      "           1     0.8786    0.9167    0.8972       300\n",
      "\n",
      "    accuracy                         0.8950       600\n",
      "   macro avg     0.8957    0.8950    0.8950       600\n",
      "weighted avg     0.8957    0.8950    0.8950       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9586    0.8500    0.9011       300\n",
      "           1     0.8653    0.9633    0.9117       300\n",
      "\n",
      "    accuracy                         0.9067       600\n",
      "   macro avg     0.9120    0.9067    0.9064       600\n",
      "weighted avg     0.9120    0.9067    0.9064       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6422    0.8733    0.7401       300\n",
      "           1     0.8021    0.5133    0.6260       300\n",
      "\n",
      "    accuracy                         0.6933       600\n",
      "   macro avg     0.7221    0.6933    0.6831       600\n",
      "weighted avg     0.7221    0.6933    0.6831       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6423    0.8500    0.7317       300\n",
      "           1     0.7783    0.5267    0.6282       300\n",
      "\n",
      "    accuracy                         0.6883       600\n",
      "   macro avg     0.7103    0.6883    0.6800       600\n",
      "weighted avg     0.7103    0.6883    0.6800       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9291    0.8733    0.9003       300\n",
      "           1     0.8805    0.9333    0.9061       300\n",
      "\n",
      "    accuracy                         0.9033       600\n",
      "   macro avg     0.9048    0.9033    0.9032       600\n",
      "weighted avg     0.9048    0.9033    0.9032       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8410    0.7933    0.8165       300\n",
      "           1     0.8044    0.8500    0.8266       300\n",
      "\n",
      "    accuracy                         0.8217       600\n",
      "   macro avg     0.8227    0.8217    0.8215       600\n",
      "weighted avg     0.8227    0.8217    0.8215       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9161    0.8733    0.8942       300\n",
      "           1     0.8790    0.9200    0.8990       300\n",
      "\n",
      "    accuracy                         0.8967       600\n",
      "   macro avg     0.8975    0.8967    0.8966       600\n",
      "weighted avg     0.8975    0.8967    0.8966       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6214    0.7933    0.6969       300\n",
      "           1     0.7143    0.5167    0.5996       300\n",
      "\n",
      "    accuracy                         0.6550       600\n",
      "   macro avg     0.6678    0.6550    0.6483       600\n",
      "weighted avg     0.6678    0.6550    0.6483       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5358    0.8733    0.6641       300\n",
      "           1     0.6577    0.2433    0.3552       300\n",
      "\n",
      "    accuracy                         0.5583       600\n",
      "   macro avg     0.5967    0.5583    0.5097       600\n",
      "weighted avg     0.5967    0.5583    0.5097       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5626    0.7933    0.6584       300\n",
      "           1     0.6497    0.3833    0.4822       300\n",
      "\n",
      "    accuracy                         0.5883       600\n",
      "   macro avg     0.6062    0.5883    0.5703       600\n",
      "weighted avg     0.6062    0.5883    0.5703       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8862    0.8567    0.8712       300\n",
      "           1     0.8613    0.8900    0.8754       300\n",
      "\n",
      "    accuracy                         0.8733       600\n",
      "   macro avg     0.8737    0.8733    0.8733       600\n",
      "weighted avg     0.8737    0.8733    0.8733       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5226    0.4633    0.4912       300\n",
      "           1     0.5180    0.5767    0.5457       300\n",
      "\n",
      "    accuracy                         0.5200       600\n",
      "   macro avg     0.5203    0.5200    0.5185       600\n",
      "weighted avg     0.5203    0.5200    0.5185       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6913    0.3433    0.4588       300\n",
      "           1     0.5632    0.8467    0.6764       300\n",
      "\n",
      "    accuracy                         0.5950       600\n",
      "   macro avg     0.6272    0.5950    0.5676       600\n",
      "weighted avg     0.6272    0.5950    0.5676       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cの範囲を指定\n",
    "C_values = {'C': [0.01, 0.1, 1, 10, 100, 1000, 2000, 3000, 4000, 5000]}\n",
    "# C_values = {'C': [100]}\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "kfold = KFold(n_splits=9, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "results = pd.DataFrame(columns=['C_RBF_LQP1','Score_RBF_LQP1', 'tnr_rbf_lqp1', 'tpr_rbf_lqp1',\n",
    "                                'C_RBF_SQP','Score_RBF_SQP', 'tnr_rbf_sqp', 'tpr_rbf_sqp',\n",
    "                                'C_RBF_LQP2','Score_RBF_LQP2', 'tnr_rbf_lqp2', 'tpr_rbf_lqp2',\n",
    "                                'C_LINEAR_LQP1','Score_LINEAR_LQP1', 'tnr_linear_lqp1', 'tpr_linear_lqp1',\n",
    "                                'C_LINEAR_SQP','Score_LINEAR_SQP', 'tnr_linear_sqp', 'tpr_linear_sqp',\n",
    "                                'C_LINEAR_LQP2','Score_LINEAR_LQP2', 'tnr_linear_lqp2', 'tpr_linear_lqp2',\n",
    "                                \n",
    "                                'C_RBF2_LQP1','Score_RBF2_LQP1', 'tnr_rbf2_lqp1', 'tpr_rbf2_lqp1',\n",
    "                                'C_RBF2_SQP','Score_RBF2_SQP', 'tnr_rbf2_sqp', 'tpr_rbf2_sqp',\n",
    "                                'C_RBF2_LQP2','Score_RBF2_LQP2', 'tnr_rbf2_lqp2', 'tpr_rbf2_lqp2',\n",
    "                                'C_LINEAR2_LQP1','Score_LINEAR2_LQP1', 'tnr_linear2_lqp1', 'tpr_linear2_lqp1',\n",
    "                                'C_LINEAR2_SQP','Score_LINEAR2_SQP', 'tnr_linear2_sqp2', 'tpr_linear2_sqp',\n",
    "                                'C_LINEAR2_LQP2','Score_LINEAR2_LQP2', 'tnr_linear2_lqp2', 'tpr_linear2_lqp2',\n",
    "                                \n",
    "                                'Threshold_LQP1', 'LQP1_old', 'tnr_old_lqp1', 'tpr_old_lqp1',\n",
    "                                'Threshold_SQP', 'SQP_old', 'tnr_old_sqp', 'tpr_old_sqp',\n",
    "                                'Threshold_LQP2', 'LQP2_old', 'tnr_old_lqp2', 'tpr_old_lqp2'])\n",
    "\n",
    "\n",
    "# results = pd.DataFrame(columns=['C_RBF_LQP1','Score_RBF_LQP1', 'tnr_rbf_lqp1', 'tpr_rbf_lqp1',\n",
    "#                                 'C_RBF_SQP','Score_RBF_SQP', 'tnr_rbf_sqp', 'tpr_rbf_sqp',\n",
    "#                                 'C_RBF_LQP2','Score_RBF_LQP2', 'tnr_rbf_lqp2', 'tpr_rbf_lqp2',\n",
    "#                                 'C_LINEAR_LQP1','Score_LINEAR_LQP1', 'tnr_linear_lqp1', 'tpr_linear_lqp1',\n",
    "#                                 'C_LINEAR_SQP','Score_LINEAR_SQP', 'tnr_linear_sqp', 'tpr_linear_sqp',\n",
    "#                                 'C_LINEAR_LQP2','Score_LINEAR_LQP2', 'tnr_linear_lqp2', 'tpr_linear_lqp2',\n",
    "                                                        \n",
    "#                                 'Threshold_LQP1', 'LQP1_old', 'tnr_old_lqp1', 'tpr_old_lqp1',\n",
    "#                                 'Threshold_SQP', 'SQP_old', 'tnr_old_sqp', 'tpr_old_sqp',\n",
    "#                                 'Threshold_LQP2', 'LQP2_old', 'tnr_old_lqp2', 'tpr_old_lqp2'])\n",
    "\n",
    "    \n",
    "X_index = np.arange(9)  # インデックスとして0から8までの数字を用意\n",
    "\n",
    "# ループで各分割のtrain_idsとtest_idsを取得\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(X_index)):\n",
    "    print(f\"<Fold-{fold+1}>\")\n",
    "    print(\"Train indices:\", train_ids)\n",
    "    print(\"Test indices:\", test_ids)\n",
    "    \n",
    "    train_data = [X_train_list[i] for i in train_ids]\n",
    "    train_data_OG = [X_train_onlyGhost_list[i] for i in train_ids]\n",
    "    train_label = [Y_train_list[i] for i in train_ids]\n",
    "    \n",
    "    val_data = [X_train_list[i] for i in test_ids]\n",
    "    val_data_OG = [X_train_onlyGhost_list[i] for i in test_ids]\n",
    "    val_label = [Y_train_list[i] for i in test_ids]\n",
    "    \n",
    "    X_train = [item for data in train_data for item in data]\n",
    "    X_train_OG = [item for data in train_data_OG for item in data]\n",
    "    Y_train = [item for data in train_label for item in data]\n",
    "    \n",
    "    X_val = [item for data in val_data for item in data]\n",
    "    X_val_OG = [item for data in val_data_OG for item in data]\n",
    "    Y_val = [item for data in val_label for item in data]\n",
    "    \n",
    "    # print(len(Y_train))\n",
    "    # print(len(Y_val))\n",
    "    \n",
    "    test_data1 = [item for data in X_test_list1 for item in data]\n",
    "    test_data_OG1 = [item for data in X_test_onlyGhost_list1 for item in data]\n",
    "    test_label1 = [item for data in Y_test_list1 for item in data]\n",
    "    MAE_data1 = [item for data in MAE_list_t1 for item in data]\n",
    "    FINAL_QP_data1 = [item for data in FINAL_QP_list_t1 for item in data]\n",
    "    \n",
    "    test_data2 = [item for data in X_test_list2 for item in data]\n",
    "    test_data_OG2 = [item for data in X_test_onlyGhost_list2 for item in data]\n",
    "    test_label2 = [item for data in Y_test_list2 for item in data]\n",
    "    MAE_data2 = [item for data in MAE_list_t2 for item in data]\n",
    "    FINAL_QP_data2 = [item for data in FINAL_QP_list_t2 for item in data]\n",
    "    \n",
    "    test_data3 = [item for data in X_test_list3 for item in data]\n",
    "    test_data_OG3 = [item for data in X_test_onlyGhost_list3 for item in data]\n",
    "    test_label3 = [item for data in Y_test_list3 for item in data]\n",
    "    MAE_data3 = [item for data in MAE_list_t3 for item in data]\n",
    "    FINAL_QP_data3 = [item for data in FINAL_QP_list_t3 for item in data]\n",
    "    \n",
    "    print(len(MAE_data1))\n",
    "    print(len(MAE_data2))\n",
    "    print(len(MAE_data3))\n",
    "    \n",
    "                                                                                   \n",
    "    best_threshold = 0\n",
    "    best_accuracy = 0\n",
    "    best_predicted_labels = []\n",
    "    best_ground_truth_labels = []\n",
    "    \n",
    "    sameQP_best_threshold = 0\n",
    "    sameQP_best_accuracy = 0\n",
    "    sameQP_best_predicted_labels = []\n",
    "    sameQP_best_ground_truth_labels = []\n",
    "    \n",
    "    largeQP_best_threshold = 0\n",
    "    largeQP_best_accuracy = 0\n",
    "    largeQP_best_predicted_labels = []\n",
    "    largeQP_best_ground_truth_labels = []\n",
    "            \n",
    "    for threshold in np.arange(0.00, 1.01, 0.01):\n",
    "        test_old = np.array([is_double_compressed(MAE_data1[i], FINAL_QP_data1[i], threshold) for i in range(600)])\n",
    "        predicted_labels = test_old.astype(int)\n",
    "        ground_truth_labels = np.array(test_label1)\n",
    "        accuracy = np.sum(ground_truth_labels == predicted_labels) / len(ground_truth_labels)\n",
    "    \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_threshold = threshold\n",
    "            best_predicted_labels = predicted_labels\n",
    "            best_ground_truth_labels = ground_truth_labels\n",
    "            \n",
    "    for threshold in np.arange(0.00, 1.01, 0.01):\n",
    "        test_sameQP_old = np.array([is_double_compressed(MAE_data2[i], FINAL_QP_data2[i], threshold) for i in range(600)])\n",
    "        same_predicted_labels = test_sameQP_old.astype(int)\n",
    "        same_ground_truth_labels = np.array(test_label2)\n",
    "        same_accuracy = np.sum(same_ground_truth_labels == same_predicted_labels) / len(same_ground_truth_labels)\n",
    "    \n",
    "        if same_accuracy > sameQP_best_accuracy:\n",
    "            sameQP_best_accuracy = same_accuracy\n",
    "            sameQP_best_threshold = threshold\n",
    "            sameQP_best_predicted_labels = same_predicted_labels\n",
    "            sameQP_best_ground_truth_labels = same_ground_truth_labels\n",
    "                        \n",
    "    for threshold in np.arange(0.00, 1.01, 0.01):\n",
    "        test_largeQP_old = np.array([is_double_compressed(MAE_data3[i], FINAL_QP_data3[i], threshold) for i in range(600)])\n",
    "        large_predicted_labels = test_largeQP_old.astype(int)\n",
    "        large_ground_truth_labels = np.array(test_label3)\n",
    "        large_accuracy = np.sum(large_ground_truth_labels == large_predicted_labels) / len(large_ground_truth_labels)\n",
    "    \n",
    "        if large_accuracy > largeQP_best_accuracy:\n",
    "            largeQP_best_accuracy = large_accuracy\n",
    "            largeQP_best_threshold = threshold\n",
    "            largeQP_best_predicted_labels = large_predicted_labels\n",
    "            largeQP_best_ground_truth_labels = large_ground_truth_labels       \n",
    "            \n",
    "            \n",
    "    print(best_accuracy)\n",
    "    print(sameQP_best_accuracy)\n",
    "    print(largeQP_best_accuracy)\n",
    "            \n",
    "            \n",
    "    best_val_score_RBF, best_svm_model_RBF, best_c_value_RBF = 0, None, None\n",
    "    best_val_score_onlyGhost_RBF, best_svm_model_onlyGhost_RBF, best_c_value_onlyGhost_RBF = 0, None, None\n",
    "    \n",
    "    best_val_score_LINEAR, best_svm_model_LINEAR, best_c_value_LINEAR = 0, None, None\n",
    "    best_val_score_onlyGhost_LINEAR, best_svm_model_onlyGhost_LINEAR, best_c_value_onlyGhost_LINEAR = 0, None, None\n",
    "        \n",
    "    for C_value in C_values['C']:    \n",
    "        # SVMモデルのインスタンスを作成\n",
    "        svm_model_RBF = SVC(kernel='rbf', C=C_value)\n",
    "        svm_model_onlyGhost_RBF = SVC(kernel='rbf', C=C_value)\n",
    "        \n",
    "        svm_model_LINEAR = SVC(kernel='linear', C=C_value)\n",
    "        svm_model_onlyGhost_LINEAR = SVC(kernel='linear', C=C_value)\n",
    "\n",
    "        # 訓練データで訓練\n",
    "        svm_model_RBF.fit(X_train, Y_train)\n",
    "        svm_model_onlyGhost_RBF.fit(X_train_OG, Y_train)\n",
    "        \n",
    "        svm_model_LINEAR.fit(X_train, Y_train)\n",
    "        svm_model_onlyGhost_LINEAR.fit(X_train_OG, Y_train)\n",
    "\n",
    "        \n",
    "        val_accuracy_RBF = accuracy_score(Y_val, svm_model_RBF.predict(X_val))\n",
    "        val_accuracy_onlyGhost_RBF = accuracy_score(Y_val, svm_model_onlyGhost_RBF.predict(X_val_OG))\n",
    "        \n",
    "        val_accuracy_LINEAR = accuracy_score(Y_val, svm_model_LINEAR.predict(X_val))\n",
    "        val_accuracy_onlyGhost_LINEAR = accuracy_score(Y_val, svm_model_onlyGhost_LINEAR.predict(X_val_OG))\n",
    "        \n",
    "\n",
    "        # 検証データでの精度が最も高かった場合、そのモデルを保存\n",
    "        if val_accuracy_RBF > best_val_score_RBF:\n",
    "            best_val_score_RBF, best_svm_model_RBF, best_c_value_RBF = val_accuracy_RBF, svm_model_RBF, C_value\n",
    "\n",
    "        if val_accuracy_onlyGhost_RBF > best_val_score_onlyGhost_RBF:\n",
    "            best_val_score_onlyGhost_RBF, best_svm_model_onlyGhost_RBF, best_c_value_onlyGhost_RBF = val_accuracy_onlyGhost_RBF, svm_model_onlyGhost_RBF, C_value\n",
    "            \n",
    "        if val_accuracy_LINEAR > best_val_score_LINEAR:\n",
    "            best_val_score_LINEAR, best_svm_model_LINEAR, best_c_value_LINEAR = val_accuracy_LINEAR, svm_model_LINEAR, C_value\n",
    "\n",
    "        if val_accuracy_onlyGhost_LINEAR > best_val_score_onlyGhost_LINEAR:\n",
    "            best_val_score_onlyGhost_LINEAR, best_svm_model_onlyGhost_LINEAR, best_c_value_onlyGhost_LINEAR = val_accuracy_onlyGhost_LINEAR, svm_model_onlyGhost_LINEAR, C_value\n",
    "\n",
    "\n",
    "    # テストデータで評価    \n",
    "    predictions_RBF = best_svm_model_RBF.predict(test_data1)\n",
    "    # predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test)\n",
    "    accuracy_RBF = accuracy_score(test_label1, predictions_RBF)\n",
    "    report_RBF = classification_report(test_label1, predictions_RBF, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label1, predictions_RBF)\n",
    "    tnr_rbf_lqp1 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_rbf_lqp1 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'report_RBF:\\n{report_RBF}')\n",
    "    \n",
    "    predictions_LINEAR = best_svm_model_LINEAR.predict(test_data1)\n",
    "    # predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test)\n",
    "    accuracy_LINEAR = accuracy_score(test_label1, predictions_LINEAR)\n",
    "    report_LINEAR = classification_report(test_label1, predictions_LINEAR, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label1, predictions_LINEAR)\n",
    "    tnr_linear_lqp1 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_linear_lqp1 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'report_LINEAR:\\n{report_LINEAR}')\n",
    "    \n",
    "    same_predictions_RBF = best_svm_model_RBF.predict(test_data2)\n",
    "    # same_predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test_sameQP)\n",
    "    same_accuracy_RBF = accuracy_score(test_label2, same_predictions_RBF)\n",
    "    same_report_RBF = classification_report(test_label2, same_predictions_RBF, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label2, same_predictions_RBF)\n",
    "    tnr_rbf_sqp = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_rbf_sqp = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'same_report_RBF:\\n{same_report_RBF}')\n",
    "    \n",
    "    same_predictions_LINEAR = best_svm_model_LINEAR.predict(test_data2)\n",
    "    # same_predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test_sameQP)\n",
    "    same_accuracy_LINEAR = accuracy_score(test_label2, same_predictions_LINEAR)\n",
    "    same_report_LINEAR = classification_report(test_label2, same_predictions_LINEAR, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label2, same_predictions_LINEAR)\n",
    "    tnr_linear_sqp = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_linear_sqp = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'same_report_LINEAR:\\n{same_report_LINEAR}')\n",
    "    \n",
    "    large_predictions_RBF = best_svm_model_RBF.predict(test_data3)\n",
    "    # large_predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test_largeQP)\n",
    "    large_accuracy_RBF = accuracy_score(test_label3, large_predictions_RBF)\n",
    "    large_report_RBF = classification_report(test_label3, large_predictions_RBF, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label3, large_predictions_RBF)\n",
    "    tnr_rbf_lqp2 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_rbf_lqp2 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'large_report_RBF:\\n{large_report_RBF}')\n",
    "    \n",
    "    large_predictions_LINEAR = best_svm_model_LINEAR.predict(test_data3)\n",
    "    # large_predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test_largeQP)\n",
    "    large_accuracy_LINEAR = accuracy_score(test_label3, large_predictions_LINEAR)\n",
    "    large_report_LINEAR = classification_report(test_label3, large_predictions_LINEAR, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label3, large_predictions_LINEAR)\n",
    "    tnr_linear_lqp2 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_linear_lqp2 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'large_report_LINEAR:\\n{large_report_LINEAR}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # テストデータで評価    \n",
    "    predictions_RBF2 = best_svm_model_onlyGhost_RBF.predict(test_data_OG1)\n",
    "    # predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test)\n",
    "    accuracy_RBF2 = accuracy_score(test_label1, predictions_RBF2)\n",
    "    report_RBF2 = classification_report(test_label1, predictions_RBF2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label1, predictions_RBF2)\n",
    "    tnr_rbf2_lqp1 = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_rbf2_lqp1 = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'report_RBF2:\\n{report_RBF2}')\n",
    "    \n",
    "    predictions_LINEAR2 = best_svm_model_onlyGhost_LINEAR.predict(test_data_OG1)\n",
    "    # predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test)\n",
    "    accuracy_LINEAR2 = accuracy_score(test_label1, predictions_LINEAR2)\n",
    "    report_LINEAR2 = classification_report(test_label1, predictions_LINEAR2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label1, predictions_LINEAR2)\n",
    "    tnr_linear2_lqp1 = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_linear2_lqp1 = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'report_LINEAR2:\\n{report_LINEAR2}')\n",
    "    \n",
    "    same_predictions_RBF2 = best_svm_model_onlyGhost_RBF.predict(test_data_OG2)\n",
    "    # same_predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test_sameQP)\n",
    "    same_accuracy_RBF2 = accuracy_score(test_label2, same_predictions_RBF2)\n",
    "    same_report_RBF2 = classification_report(test_label2, same_predictions_RBF2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label2, same_predictions_RBF2)\n",
    "    tnr_rbf2_sqp = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_rbf2_sqp = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'same_report_RBF2:\\n{same_report_RBF2}')\n",
    "    \n",
    "    same_predictions_LINEAR2 = best_svm_model_onlyGhost_LINEAR.predict(test_data_OG2)\n",
    "    # same_predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test_sameQP)\n",
    "    same_accuracy_LINEAR2 = accuracy_score(test_label2, same_predictions_LINEAR2)\n",
    "    same_report_LINEAR2 = classification_report(test_label2, same_predictions_LINEAR2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label2, same_predictions_LINEAR2)\n",
    "    tnr_linear2_sqp = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_linear2_sqp = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'same_report_LINEAR2:\\n{same_report_LINEAR2}')\n",
    "    \n",
    "    large_predictions_RBF2 = best_svm_model_onlyGhost_RBF.predict(test_data_OG3)\n",
    "    # large_predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test_largeQP)\n",
    "    large_accuracy_RBF2 = accuracy_score(test_label3, large_predictions_RBF2)\n",
    "    large_report_RBF2 = classification_report(test_label3, large_predictions_RBF2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label3, large_predictions_RBF2)\n",
    "    tnr_rbf2_lqp2 = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_rbf2_lqp2 = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'large_report_RBF2:\\n{large_report_RBF2}')\n",
    "    \n",
    "    large_predictions_LINEAR2 = best_svm_model_onlyGhost_LINEAR.predict(test_data_OG3)\n",
    "    # large_predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test_largeQP)\n",
    "    large_accuracy_LINEAR2 = accuracy_score(test_label3, large_predictions_LINEAR2)\n",
    "    large_report_LINEAR2 = classification_report(test_label3, large_predictions_LINEAR2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label3, large_predictions_LINEAR2)\n",
    "    tnr_linear2_lqp2 = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_linear2_lqp2 = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'large_report_LINEAR2:\\n{large_report_LINEAR2}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # テストデータで評価\n",
    "    test_old = classification_report(best_ground_truth_labels, best_predicted_labels, labels=[0,1], target_names=['0', '1'], zero_division=0, digits=4)\n",
    "    conf_matrix = confusion_matrix(best_ground_truth_labels, best_predicted_labels)\n",
    "    tnr_old_lqp1 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_old_lqp1 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'Summary old_model:\\n{test_old}')\n",
    "    \n",
    "    test_sameQP_old = classification_report(sameQP_best_ground_truth_labels, sameQP_best_predicted_labels, labels=[0,1], target_names=['0', '1'], zero_division=0, digits=4)\n",
    "    conf_matrix = confusion_matrix(sameQP_best_ground_truth_labels, sameQP_best_predicted_labels)\n",
    "    tnr_old_sqp = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_old_sqp = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'Summary old_model:\\n{test_sameQP_old}')\n",
    "    \n",
    "    test_largeQP_old = classification_report(largeQP_best_ground_truth_labels, largeQP_best_predicted_labels, labels=[0,1], target_names=['0', '1'], zero_division=0, digits=4)\n",
    "    conf_matrix = confusion_matrix(largeQP_best_ground_truth_labels, largeQP_best_predicted_labels)\n",
    "    tnr_old_lqp2 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_old_lqp2 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'Summary old_model:\\n{test_largeQP_old}')\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Test結果を保存\n",
    "    \n",
    "    result_row ={'C_RBF_LQP1':best_c_value_RBF,'Score_RBF_LQP1': accuracy_RBF, 'tnr_rbf_lqp1':tnr_rbf_lqp1, 'tpr_rbf_lqp1':tpr_rbf_lqp1,\n",
    "                'C_RBF_SQP': best_c_value_RBF, 'Score_RBF_SQP': same_accuracy_RBF, 'tnr_rbf_sqp':tnr_rbf_sqp, 'tpr_rbf_sqp':tpr_rbf_sqp,\n",
    "                'C_RBF_LQP2': best_c_value_RBF,'Score_RBF_LQP2': large_accuracy_RBF, 'tnr_rbf_lqp2':tnr_rbf_lqp2, 'tpr_rbf_lqp2':tpr_rbf_lqp2,\n",
    "                                    \n",
    "                'C_LINEAR_LQP1': best_c_value_LINEAR,'Score_LINEAR_LQP1':accuracy_LINEAR, 'tnr_linear_lqp1':tnr_linear_lqp1, 'tpr_linear_lqp1':tpr_linear_lqp1,\n",
    "                'C_LINEAR_SQP': best_c_value_LINEAR,'Score_LINEAR_SQP':same_accuracy_LINEAR, 'tnr_linear_sqp':tnr_linear_sqp, 'tpr_linear_sqp':tpr_linear_sqp,\n",
    "                'C_LINEAR_LQP2': best_c_value_LINEAR,'Score_LINEAR_LQP2':large_accuracy_LINEAR, 'tnr_linear_lqp2':tnr_linear_lqp2, 'tpr_linear_lqp2':tpr_linear_lqp2,\n",
    "                 \n",
    "                'C_RBF2_LQP1':best_c_value_onlyGhost_RBF,'Score_RBF2_LQP1': accuracy_RBF2, 'tnr_rbf2_lqp1':tnr_rbf2_lqp1, 'tpr_rbf2_lqp1':tpr_rbf2_lqp1,\n",
    "                'C_RBF2_SQP': best_c_value_onlyGhost_RBF, 'Score_RBF2_SQP': same_accuracy_RBF2, 'tnr_rbf2_sqp':tnr_rbf2_sqp, 'tpr_rbf2_sqp':tpr_rbf2_sqp,\n",
    "                'C_RBF2_LQP2': best_c_value_onlyGhost_RBF,'Score_RBF2_LQP2': large_accuracy_RBF2, 'tnr_rbf2_lqp2':tnr_rbf2_lqp2, 'tpr_rbf2_lqp2':tpr_rbf2_lqp2,\n",
    "                                    \n",
    "                'C_LINEAR2_LQP1': best_c_value_onlyGhost_LINEAR,'Score_LINEAR2_LQP1':accuracy_LINEAR2, 'tnr_linear2_lqp1':tnr_linear2_lqp1, 'tpr_linear2_lqp1':tpr_linear2_lqp1,\n",
    "                'C_LINEAR2_SQP': best_c_value_onlyGhost_LINEAR,'Score_LINEAR2_SQP':same_accuracy_LINEAR2, 'tnr_linear2_sqp':tnr_linear2_sqp, 'tpr_linear2_sqp':tpr_linear2_sqp,\n",
    "                'C_LINEAR2_LQP2': best_c_value_onlyGhost_LINEAR,'Score_LINEAR2_LQP2':large_accuracy_LINEAR2, 'tnr_linear2_lqp2':tnr_linear2_lqp2, 'tpr_linear2_lqp2':tpr_linear2_lqp2,\n",
    "                                                        \n",
    "                'Threshold_LQP1':best_threshold, 'LQP1_old':best_accuracy, 'tnr_old_lqp1':tnr_old_lqp1, 'tpr_old_lqp1':tpr_old_lqp1,\n",
    "                'Threshold_SQP':sameQP_best_threshold, 'SQP_old':sameQP_best_accuracy, 'tnr_old_sqp':tnr_old_sqp, 'tpr_old_sqp':tpr_old_sqp,\n",
    "                'Threshold_LQP2':largeQP_best_threshold, 'LQP2_old':largeQP_best_accuracy, 'tnr_old_lqp2':tnr_old_lqp2, 'tpr_old_lqp2':tpr_old_lqp2}\n",
    "\n",
    "\n",
    "    results = pd.concat([results, pd.DataFrame([result_row])], ignore_index=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Average TNR  Average TPR  Average Test Score  Standard Deviation  Max Test Score  Min Test Score\n",
      "0     RBF_LQP1        88.44        95.44               91.94                0.82           94.00           91.33\n",
      "1      RBF_SQP        88.44        92.30               90.37                0.80           92.17           89.50\n",
      "2     RBF_LQP2        88.44        51.63               70.04                0.98           71.33           68.50\n",
      "3  LINEAR_LQP1        86.07        96.37               91.22                0.56           92.17           90.50\n",
      "4   LINEAR_SQP        86.07        95.85               90.96                0.26           91.33           90.67\n",
      "5  LINEAR_LQP2        86.07        50.33               68.20                1.42           69.50           66.33\n",
      "6     OLD_LQP1        85.67        89.00               87.33                0.00           87.33           87.33\n",
      "7      OLD_SQP        46.33        57.67               52.00                0.00           52.00           52.00\n",
      "8     OLD_LQP2        34.33        84.67               59.50                0.00           59.50           59.50\n"
     ]
    }
   ],
   "source": [
    "# 各統計情報を100倍して小数点第4位までの表記に変更\n",
    "statistics_data = {\n",
    "    'Model': ['RBF_LQP1', 'RBF_SQP', 'RBF_LQP2', 'LINEAR_LQP1', 'LINEAR_SQP', 'LINEAR_LQP2', 'OLD_LQP1', 'OLD_SQP', 'OLD_LQP2'],\n",
    "    'Average TNR': [round(results['tnr_rbf_lqp1'].mean() * 100, 2), round(results['tnr_rbf_sqp'].mean() * 100, 2), round(results['tnr_rbf_lqp2'].mean() * 100, 2), round(results['tnr_linear_lqp1'].mean() * 100, 2), round(results['tnr_linear_sqp'].mean() * 100, 2), round(results['tnr_linear_lqp2'].mean() * 100, 2),round(results['tnr_old_lqp1'].mean() * 100, 2), round(results['tnr_old_sqp'].mean() * 100, 2), round(results['tnr_old_lqp2'].mean() * 100, 2)],\n",
    "    'Average TPR': [round(results['tpr_rbf_lqp1'].mean() * 100, 2), round(results['tpr_rbf_sqp'].mean() * 100, 2), round(results['tpr_rbf_lqp2'].mean() * 100, 2), round(results['tpr_linear_lqp1'].mean() * 100, 2), round(results['tpr_linear_sqp'].mean() * 100, 2), round(results['tpr_linear_lqp2'].mean() * 100, 2),round(results['tpr_old_lqp1'].mean() * 100, 2), round(results['tpr_old_sqp'].mean() * 100, 2), round(results['tpr_old_lqp2'].mean() * 100, 2)],\n",
    "    'Average Test Score': [round(results['Score_RBF_LQP1'].mean() * 100, 2), round(results['Score_RBF_SQP'].mean() * 100, 2), round(results['Score_RBF_LQP2'].mean() * 100, 2), round(results['Score_LINEAR_LQP1'].mean() * 100, 2), round(results['Score_LINEAR_SQP'].mean() * 100, 2), round(results['Score_LINEAR_LQP2'].mean() * 100, 2),round(results['LQP1_old'].mean() * 100, 2), round(results['SQP_old'].mean() * 100, 2), round(results['LQP2_old'].mean() * 100, 2)],\n",
    "    'Standard Deviation': [round(results['Score_RBF_LQP1'].std() * 100, 2), round(results['Score_RBF_SQP'].std() * 100, 2), round(results['Score_RBF_LQP2'].std() * 100, 2), round(results['Score_LINEAR_LQP1'].std() * 100, 2), round(results['Score_LINEAR_SQP'].std() * 100, 2), round(results['Score_LINEAR_LQP2'].std() * 100, 2),round(results['LQP1_old'].std() * 100, 2), round(results['SQP_old'].std() * 100, 2), round(results['LQP2_old'].std() * 100, 2)],\n",
    "    'Max Test Score': [round(results['Score_RBF_LQP1'].max() * 100, 2), round(results['Score_RBF_SQP'].max() * 100, 2), round(results['Score_RBF_LQP2'].max() * 100, 2), round(results['Score_LINEAR_LQP1'].max() * 100, 2), round(results['Score_LINEAR_SQP'].max() * 100, 2), round(results['Score_LINEAR_LQP2'].max() * 100, 2),round(results['LQP1_old'].max() * 100, 2), round(results['SQP_old'].max() * 100, 2), round(results['LQP2_old'].max() * 100, 2)],\n",
    "    'Min Test Score': [round(results['Score_RBF_LQP1'].min() * 100, 2), round(results['Score_RBF_SQP'].min() * 100, 2), round(results['Score_RBF_LQP2'].min() * 100, 2), round(results['Score_LINEAR_LQP1'].min() * 100, 2), round(results['Score_LINEAR_SQP'].min() * 100, 2), round(results['Score_LINEAR_LQP2'].min() * 100, 2),round(results['LQP1_old'].min() * 100, 2), round(results['SQP_old'].min() * 100, 2), round(results['LQP2_old'].min() * 100, 2)],\n",
    "}\n",
    "\n",
    "# DataFrameを作成\n",
    "statistics_df = pd.DataFrame(statistics_data)\n",
    "\n",
    "# 表示\n",
    "print(statistics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Average TNR  Average TPR  Average Test Score  Standard Deviation  Max Test Score  Min Test Score\n",
      "0     RBF_LQP1        87.22        92.41               89.81                1.07           91.00           88.17\n",
      "1      RBF_SQP        87.22        92.15               89.69                0.73           90.83           88.50\n",
      "2     RBF_LQP2        87.22        29.85               58.54                1.98           61.17           55.83\n",
      "3  LINEAR_LQP1        79.11        84.70               81.91                0.55           82.67           81.17\n",
      "4   LINEAR_SQP        79.11        51.56               65.33                0.42           66.17           64.83\n",
      "5  LINEAR_LQP2        79.11        39.56               59.33                0.69           60.33           58.17\n",
      "6     OLD_LQP1        85.67        89.00               87.33                0.00           87.33           87.33\n",
      "7      OLD_SQP        46.33        57.67               52.00                0.00           52.00           52.00\n",
      "8     OLD_LQP2        34.33        84.67               59.50                0.00           59.50           59.50\n"
     ]
    }
   ],
   "source": [
    "# 各統計情報を100倍して小数点第4位までの表記に変更\n",
    "statistics_data2 = {\n",
    "    'Model': ['RBF_LQP1', 'RBF_SQP', 'RBF_LQP2', 'LINEAR_LQP1', 'LINEAR_SQP', 'LINEAR_LQP2', 'OLD_LQP1', 'OLD_SQP', 'OLD_LQP2'],\n",
    "    'Average TNR': [round(results['tnr_rbf2_lqp1'].mean() * 100, 2), round(results['tnr_rbf2_sqp'].mean() * 100, 2), round(results['tnr_rbf2_lqp2'].mean() * 100, 2), round(results['tnr_linear2_lqp1'].mean() * 100, 2), round(results['tnr_linear2_sqp'].mean() * 100, 2), round(results['tnr_linear2_lqp2'].mean() * 100, 2),round(results['tnr_old_lqp1'].mean() * 100, 2), round(results['tnr_old_sqp'].mean() * 100, 2), round(results['tnr_old_lqp2'].mean() * 100, 2)],\n",
    "    'Average TPR': [round(results['tpr_rbf2_lqp1'].mean() * 100, 2), round(results['tpr_rbf2_sqp'].mean() * 100, 2), round(results['tpr_rbf2_lqp2'].mean() * 100, 2), round(results['tpr_linear2_lqp1'].mean() * 100, 2), round(results['tpr_linear2_sqp'].mean() * 100, 2), round(results['tpr_linear2_lqp2'].mean() * 100, 2),round(results['tpr_old_lqp1'].mean() * 100, 2), round(results['tpr_old_sqp'].mean() * 100, 2), round(results['tpr_old_lqp2'].mean() * 100, 2)],\n",
    "    'Average Test Score': [round(results['Score_RBF2_LQP1'].mean() * 100, 2), round(results['Score_RBF2_SQP'].mean() * 100, 2), round(results['Score_RBF2_LQP2'].mean() * 100, 2), round(results['Score_LINEAR2_LQP1'].mean() * 100, 2), round(results['Score_LINEAR2_SQP'].mean() * 100, 2), round(results['Score_LINEAR2_LQP2'].mean() * 100, 2),round(results['LQP1_old'].mean() * 100, 2), round(results['SQP_old'].mean() * 100, 2), round(results['LQP2_old'].mean() * 100, 2)],\n",
    "    'Standard Deviation': [round(results['Score_RBF2_LQP1'].std() * 100, 2), round(results['Score_RBF2_SQP'].std() * 100, 2), round(results['Score_RBF2_LQP2'].std() * 100, 2), round(results['Score_LINEAR2_LQP1'].std() * 100, 2), round(results['Score_LINEAR2_SQP'].std() * 100, 2), round(results['Score_LINEAR2_LQP2'].std() * 100, 2),round(results['LQP1_old'].std() * 100, 2), round(results['SQP_old'].std() * 100, 2), round(results['LQP2_old'].std() * 100, 2)],\n",
    "    'Max Test Score': [round(results['Score_RBF2_LQP1'].max() * 100, 2), round(results['Score_RBF2_SQP'].max() * 100, 2), round(results['Score_RBF2_LQP2'].max() * 100, 2), round(results['Score_LINEAR2_LQP1'].max() * 100, 2), round(results['Score_LINEAR2_SQP'].max() * 100, 2), round(results['Score_LINEAR2_LQP2'].max() * 100, 2),round(results['LQP1_old'].max() * 100, 2), round(results['SQP_old'].max() * 100, 2), round(results['LQP2_old'].max() * 100, 2)],\n",
    "    'Min Test Score': [round(results['Score_RBF2_LQP1'].min() * 100, 2), round(results['Score_RBF2_SQP'].min() * 100, 2), round(results['Score_RBF2_LQP2'].min() * 100, 2), round(results['Score_LINEAR2_LQP1'].min() * 100, 2), round(results['Score_LINEAR2_SQP'].min() * 100, 2), round(results['Score_LINEAR2_LQP2'].min() * 100, 2),round(results['LQP1_old'].min() * 100, 2), round(results['SQP_old'].min() * 100, 2), round(results['LQP2_old'].min() * 100, 2)],\n",
    "}\n",
    "\n",
    "# DataFrameを作成\n",
    "statistics_df2 = pd.DataFrame(statistics_data2)\n",
    "\n",
    "# 表示\n",
    "print(statistics_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    100\n",
      "1    100\n",
      "2    100\n",
      "3    100\n",
      "4    100\n",
      "5     10\n",
      "6    100\n",
      "7    100\n",
      "8    100\n",
      "Name: C_RBF_LQP1, dtype: object\n",
      "0      10\n",
      "1      10\n",
      "2     100\n",
      "3     100\n",
      "4     100\n",
      "5    2000\n",
      "6      10\n",
      "7     100\n",
      "8     100\n",
      "Name: C_LINEAR_LQP1, dtype: object\n",
      "\n",
      "0    2000\n",
      "1     100\n",
      "2      10\n",
      "3      10\n",
      "4    2000\n",
      "5    1000\n",
      "6      10\n",
      "7    1000\n",
      "8    5000\n",
      "Name: C_RBF2_LQP1, dtype: object\n",
      "0    10\n",
      "1     1\n",
      "2     1\n",
      "3     1\n",
      "4     1\n",
      "5     1\n",
      "6     1\n",
      "7     1\n",
      "8     1\n",
      "Name: C_LINEAR2_LQP1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(results['C_RBF_LQP1'])\n",
    "print(results['C_LINEAR_LQP1'])\n",
    "print()\n",
    "print(results['C_RBF2_LQP1'])\n",
    "print(results['C_LINEAR2_LQP1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df.to_csv('statistics_data5.csv', index=False)\n",
    "statistics_df2.to_csv('statistics2_data5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
