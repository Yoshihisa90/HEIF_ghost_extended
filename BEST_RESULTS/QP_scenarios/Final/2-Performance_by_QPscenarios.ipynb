{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import os.path as osp\n",
    "import re\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.signal import find_peaks\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import torch\n",
    "import glob\n",
    "from scipy.stats import entropy\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)  # DataFrameを改行せずに表示\n",
    "pd.set_option('display.max_columns', None)  # すべての列を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_finalQP(filename):\n",
    "    match = re.search(r'2ndQP(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    match = re.search(r'1stQP(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_1stQP(filename):\n",
    "    match = re.search(r'1stQP(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def ratio_double_compressed(mean_difference, final_QP):\n",
    "    # mean_difference = mean_difference[0]\n",
    "    # final_QP = final_QP[0]\n",
    "    clamped_mean_difference = np.maximum(mean_difference, -0.01)\n",
    "    \n",
    "    #全体のエネルギーを計算\n",
    "    energy = np.sum(np.square(clamped_mean_difference))\n",
    "    # energy = np.sum(np.square(mean_difference))\n",
    "    \n",
    "    #QP2より右側のエネルギーを計算\n",
    "    right_energy = np.sum(np.square(clamped_mean_difference[final_QP+1:52]))\n",
    "\n",
    "        \n",
    "    # エネルギー比を計算して閾値と比較\n",
    "    if energy > 0:\n",
    "        return right_energy / energy\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def is_double_compressed(mean_difference, final_QP, threshold):\n",
    "    mean_difference = mean_difference[0]\n",
    "    final_QP = final_QP[0]\n",
    "    clamped_mean_difference = np.maximum(mean_difference, -0.01)\n",
    "    \n",
    "    #全体のエネルギーを計算\n",
    "    energy = np.sum(np.square(clamped_mean_difference))\n",
    "    # energy = np.sum(np.square(mean_difference))\n",
    "    \n",
    "    #QP2より右側のエネルギーを計算\n",
    "    right_energy = np.sum(np.square(clamped_mean_difference[final_QP+1:52]))\n",
    "    # right_energy = np.sum(np.square(mean_difference[final_QP+1:52]))\n",
    "    \n",
    "    # print('energy: ', energy)\n",
    "    # print('R-energy: ', right_energy)\n",
    "    # print('Ratio: ', right_energy / energy)\n",
    "    \n",
    "    \n",
    "    # エネルギー比を計算して閾値と比較\n",
    "    if energy <= 0:\n",
    "        return -1\n",
    "    \n",
    "    elif (right_energy / energy) != 0 and (right_energy / energy) > threshold:\n",
    "        return True\n",
    "    \n",
    "    elif (right_energy / energy) != 0 and (right_energy / energy) <= threshold:\n",
    "        return False\n",
    "    \n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def calculate_mae(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            loaded_data, loaded_data_shifted = pickle.load(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # タプル内のリストを抽出\n",
    "    original_mae = np.array(loaded_data)\n",
    "    shifted_mae = np.array(loaded_data_shifted)\n",
    "\n",
    "    # Coding ghostを計算してリストに格納する\n",
    "    mae_difference = shifted_mae - original_mae\n",
    "    \n",
    "    # mae_differenceの各要素においてマイナスの値を0に変換\n",
    "    # mae_difference_positive = np.maximum(mae_difference, 0)\n",
    "    \n",
    "    return mae_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['134', '115', '17', '52', '237', '37', '127', '122', '111', '277', '192', '60', '179', '10', '281', '203', '186', '230', '88', '129', '48', '244', '151', '119', '49', '63', '194', '214', '144', '278'], ['255', '204', '247', '234', '296', '232', '20', '187', '253', '31', '183', '251', '178', '273', '34', '291', '196', '1', '113', '44', '185', '276', '190', '279', '25', '200', '154', '259', '180', '143'], ['243', '123', '283', '242', '222', '120', '61', '30', '235', '280', '121', '295', '114', '79', '2', '208', '76', '83', '57', '45', '141', '166', '198', '145', '62', '167', '233', '157', '147', '211'], ['275', '22', '206', '161', '292', '59', '55', '207', '47', '51', '64', '11', '39', '193', '71', '135', '56', '7', '116', '14', '223', '107', '177', '66', '13', '298', '272', '124', '293', '264'], ['109', '125', '6', '209', '68', '32', '240', '28', '168', '262', '218', '94', '117', '3', '229', '188', '189', '9', '96', '245', '104', '221', '16', '93', '138', '215', '153', '140', '162', '85'], ['165', '130', '254', '261', '72', '132', '36', '131', '77', '112', '41', '92', '160', '78', '5', '217', '91', '225', '174', '4', '231', '282', '260', '195', '290', '89', '69', '98', '258', '142'], ['26', '15', '21', '181', '216', '226', '74', '210', '173', '106', '146', '103', '299', '191', '24', '43', '159', '228', '267', '238', '23', '224', '219', '172', '82', '126', '33', '58', '46', '152'], ['287', '252', '136', '8', '286', '102', '268', '271', '184', '256', '148', '87', '266', '158', '42', '84', '99', '156', '288', '80', '155', '53', '274', '35', '182', '54', '139', '75', '86', '171'], ['270', '164', '197', '297', '70', '220', '133', '128', '236', '176', '18', '248', '149', '263', '169', '257', '201', '170', '294', '205', '81', '269', '241', '73', '38', '202', '213', '101', '110', '265'], ['65', '40', '285', '227', '249', '175', '97', '105', '289', '90', '50', '137', '108', '67', '284', '199', '246', '12', '95', '239', '163', '19', '100', '212', '300', '29', '118', '27', '150', '250']]\n",
      "\n",
      "CSV Single ListsA:\n",
      "CSV List 1A: 300\n",
      "CSV List 2A: 300\n",
      "CSV List 3A: 300\n",
      "CSV List 4A: 300\n",
      "CSV List 5A: 300\n",
      "CSV List 6A: 300\n",
      "CSV List 7A: 300\n",
      "CSV List 8A: 300\n",
      "CSV List 9A: 300\n",
      "CSV List 10A: 300\n",
      "\n",
      "CSV Single Recompress ListsA:\n",
      "CSV List 1A: 300\n",
      "CSV List 2A: 300\n",
      "CSV List 3A: 300\n",
      "CSV List 4A: 300\n",
      "CSV List 5A: 300\n",
      "CSV List 6A: 300\n",
      "CSV List 7A: 300\n",
      "CSV List 8A: 300\n",
      "CSV List 9A: 300\n",
      "CSV List 10A: 300\n",
      "\n",
      "CSV Second Large QP1 ListsA:\n",
      "CSV List 1A: 1710\n",
      "CSV List 2A: 1710\n",
      "CSV List 3A: 1710\n",
      "CSV List 4A: 1710\n",
      "CSV List 5A: 1710\n",
      "CSV List 6A: 1710\n",
      "CSV List 7A: 1710\n",
      "CSV List 8A: 1710\n",
      "CSV List 9A: 1710\n",
      "CSV List 10A: 1710\n",
      "\n",
      "CSV Second Recompress Large QP1 ListsA:\n",
      "CSV List 1A: 1710\n",
      "CSV List 2A: 1710\n",
      "CSV List 3A: 1710\n",
      "CSV List 4A: 1710\n",
      "CSV List 5A: 1710\n",
      "CSV List 6A: 1710\n",
      "CSV List 7A: 1710\n",
      "CSV List 8A: 1710\n",
      "CSV List 9A: 1710\n",
      "CSV List 10A: 1710\n",
      "\n",
      "CSV Second Same QP ListsA:\n",
      "CSV List 1A: 300\n",
      "CSV List 2A: 300\n",
      "CSV List 3A: 300\n",
      "CSV List 4A: 300\n",
      "CSV List 5A: 300\n",
      "CSV List 6A: 300\n",
      "CSV List 7A: 300\n",
      "CSV List 8A: 300\n",
      "CSV List 9A: 300\n",
      "CSV List 10A: 300\n",
      "\n",
      "CSV Second Recompress Same QP ListsA:\n",
      "CSV List 1A: 300\n",
      "CSV List 2A: 300\n",
      "CSV List 3A: 300\n",
      "CSV List 4A: 300\n",
      "CSV List 5A: 300\n",
      "CSV List 6A: 300\n",
      "CSV List 7A: 300\n",
      "CSV List 8A: 300\n",
      "CSV List 9A: 300\n",
      "CSV List 10A: 300\n",
      "\n",
      "CSV Second Large QP2 ListsA:\n",
      "CSV List 1A: 1170\n",
      "CSV List 2A: 1170\n",
      "CSV List 3A: 1170\n",
      "CSV List 4A: 1170\n",
      "CSV List 5A: 1170\n",
      "CSV List 6A: 1170\n",
      "CSV List 7A: 1170\n",
      "CSV List 8A: 1170\n",
      "CSV List 9A: 1170\n",
      "CSV List 10A: 1170\n",
      "\n",
      "CSV Second Recompress Large QP2 ListsA:\n",
      "CSV List 1A: 1170\n",
      "CSV List 2A: 1170\n",
      "CSV List 3A: 1170\n",
      "CSV List 4A: 1170\n",
      "CSV List 5A: 1170\n",
      "CSV List 6A: 1170\n",
      "CSV List 7A: 1170\n",
      "CSV List 8A: 1170\n",
      "CSV List 9A: 1170\n",
      "CSV List 10A: 1170\n",
      "\n",
      "PKL Single ListsA:\n",
      "PKL List 1A: 300\n",
      "PKL List 2A: 300\n",
      "PKL List 3A: 300\n",
      "PKL List 4A: 300\n",
      "PKL List 5A: 300\n",
      "PKL List 6A: 300\n",
      "PKL List 7A: 300\n",
      "PKL List 8A: 300\n",
      "PKL List 9A: 300\n",
      "PKL List 10A: 300\n",
      "\n",
      "PKL Single Recompress ListsA:\n",
      "PKL List 1A: 300\n",
      "PKL List 2A: 300\n",
      "PKL List 3A: 300\n",
      "PKL List 4A: 300\n",
      "PKL List 5A: 300\n",
      "PKL List 6A: 300\n",
      "PKL List 7A: 300\n",
      "PKL List 8A: 300\n",
      "PKL List 9A: 300\n",
      "PKL List 10A: 300\n",
      "\n",
      "PKL Second Large QP1 ListsA:\n",
      "PKL List 1A: 1710\n",
      "PKL List 2A: 1710\n",
      "PKL List 3A: 1710\n",
      "PKL List 4A: 1710\n",
      "PKL List 5A: 1710\n",
      "PKL List 6A: 1710\n",
      "PKL List 7A: 1710\n",
      "PKL List 8A: 1710\n",
      "PKL List 9A: 1710\n",
      "PKL List 10A: 1710\n",
      "\n",
      "PKL Second Recompress Large QP1 ListsA:\n",
      "PKL List 1A: 1710\n",
      "PKL List 2A: 1710\n",
      "PKL List 3A: 1710\n",
      "PKL List 4A: 1710\n",
      "PKL List 5A: 1710\n",
      "PKL List 6A: 1710\n",
      "PKL List 7A: 1710\n",
      "PKL List 8A: 1710\n",
      "PKL List 9A: 1710\n",
      "PKL List 10A: 1710\n",
      "\n",
      "PKL Second Same QP ListsA:\n",
      "PKL List 1A: 300\n",
      "PKL List 2A: 300\n",
      "PKL List 3A: 300\n",
      "PKL List 4A: 300\n",
      "PKL List 5A: 300\n",
      "PKL List 6A: 300\n",
      "PKL List 7A: 300\n",
      "PKL List 8A: 300\n",
      "PKL List 9A: 300\n",
      "PKL List 10A: 300\n",
      "\n",
      "PKL Second Recompress Same QP ListsA:\n",
      "PKL List 1A: 300\n",
      "PKL List 2A: 300\n",
      "PKL List 3A: 300\n",
      "PKL List 4A: 300\n",
      "PKL List 5A: 300\n",
      "PKL List 6A: 300\n",
      "PKL List 7A: 300\n",
      "PKL List 8A: 300\n",
      "PKL List 9A: 300\n",
      "PKL List 10A: 300\n",
      "\n",
      "PKL Second Large QP2 ListsA:\n",
      "PKL List 1A: 1170\n",
      "PKL List 2A: 1170\n",
      "PKL List 3A: 1170\n",
      "PKL List 4A: 1170\n",
      "PKL List 5A: 1170\n",
      "PKL List 6A: 1170\n",
      "PKL List 7A: 1170\n",
      "PKL List 8A: 1170\n",
      "PKL List 9A: 1170\n",
      "PKL List 10A: 1170\n",
      "\n",
      "PKL Second Recompress Large QP2 ListsA:\n",
      "PKL List 1A: 1170\n",
      "PKL List 2A: 1170\n",
      "PKL List 3A: 1170\n",
      "PKL List 4A: 1170\n",
      "PKL List 5A: 1170\n",
      "PKL List 6A: 1170\n",
      "PKL List 7A: 1170\n",
      "PKL List 8A: 1170\n",
      "PKL List 9A: 1170\n",
      "PKL List 10A: 1170\n"
     ]
    }
   ],
   "source": [
    "rootpath_csv = \"/Prove/Yoshihisa/HEIF_ghost/HEIF_IMAGES_CSV/\"\n",
    "rootpath_pkl = \"/Prove/Yoshihisa/HEIF_ghost/PKL/\"\n",
    "\n",
    "train_list1 = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\"]\n",
    "train_list2 = [\"31\", \"32\", \"33\", \"34\", \"35\", \"36\", \"37\", \"38\", \"39\", \"40\", \"41\", \"42\", \"43\", \"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"50\", \"51\", \"52\", \"53\", \"54\", \"55\", \"56\", \"57\", \"58\", \"59\", \"60\"]\n",
    "train_list3 = [\"61\", \"62\", \"63\", \"64\", \"65\", \"66\", \"67\", \"68\", \"69\", \"70\", \"71\", \"72\", \"73\", \"74\", \"75\", \"76\", \"77\", \"78\", \"79\", \"80\", \"81\", \"82\", \"83\", \"84\", \"85\", \"86\", \"87\", \"88\", \"89\", \"90\"]\n",
    "train_list4 = [\"91\", \"92\", \"93\", \"94\", \"95\", \"96\", \"97\", \"98\", \"99\", \"100\", \"101\", \"102\", \"103\", \"104\", \"105\", \"106\", \"107\", \"108\", \"109\", \"110\", \"111\", \"112\", \"113\", \"114\", \"115\", \"116\", \"117\", \"118\", \"119\", \"120\"]\n",
    "train_list5 = [\"121\", \"122\", \"123\", \"124\", \"125\", \"126\", \"127\", \"128\", \"129\", \"130\", \"131\", \"132\", \"133\", \"134\", \"135\", \"136\", \"137\", \"138\", \"139\", \"140\", \"141\", \"142\", \"143\", \"144\", \"145\", \"146\", \"147\", \"148\", \"149\", \"150\"]\n",
    "train_list6 = [\"151\", \"152\", \"153\", \"154\", \"155\", \"156\", \"157\", \"158\", \"159\", \"160\", \"161\", \"162\", \"163\", \"164\", \"165\", \"166\", \"167\", \"168\", \"169\", \"170\", \"171\", \"172\", \"173\", \"174\", \"175\", \"176\", \"177\", \"178\", \"179\", \"180\"]\n",
    "train_list7 = [\"181\", \"182\", \"183\", \"184\", \"185\", \"186\", \"187\", \"188\", \"189\", \"190\", \"191\", \"192\", \"193\", \"194\", \"195\", \"196\", \"197\", \"198\", \"199\", \"200\", \"201\", \"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\"]\n",
    "train_list8 = [\"211\", \"212\", \"213\", \"214\", \"215\", \"216\", \"217\", \"218\", \"219\", \"220\", \"221\", \"222\", \"223\", \"224\", \"225\", \"226\", \"227\", \"228\", \"229\", \"230\", \"231\", \"232\", \"233\", \"234\", \"235\", \"236\", \"237\", \"238\", \"239\", \"240\"]\n",
    "train_list9 = [\"241\", \"242\", \"243\", \"244\", \"245\", \"246\", \"247\", \"248\", \"249\", \"250\", \"251\", \"252\", \"253\", \"254\", \"255\", \"256\", \"257\", \"258\", \"259\", \"260\", \"261\", \"262\", \"263\", \"264\", \"265\", \"266\", \"267\", \"268\", \"269\", \"270\"]\n",
    "train_list10 = [\"271\", \"272\", \"273\", \"274\", \"275\", \"276\", \"277\", \"278\", \"279\", \"280\", \"281\", \"282\", \"283\", \"284\", \"285\", \"286\", \"287\", \"288\", \"289\", \"290\", \"291\", \"292\", \"293\", \"294\", \"295\", \"296\", \"297\", \"298\", \"299\", \"300\"]\n",
    "\n",
    "all_train_lists = [train_list1, train_list2, train_list3, train_list4, train_list5,\n",
    "                   train_list6, train_list7, train_list8, train_list9, train_list10]\n",
    "\n",
    "# すべてのリストを1つのリストに結合する\n",
    "combined_train_list = sum(all_train_lists, [])\n",
    "\n",
    "# リストの順序をランダムにシャッフルする\n",
    "random.shuffle(combined_train_list)\n",
    "\n",
    "# シャッフルされたリストを10個のグループに分割する\n",
    "train_lists = [combined_train_list[i:i+30] for i in range(0, len(combined_train_list), 30)]\n",
    "print(train_lists)\n",
    "\n",
    "\n",
    "\n",
    "# CSV関連のリストを生成\n",
    "csv_single_listsA = [[] for _ in range(10)]\n",
    "csv_single_recompress_listsA = [[] for _ in range(10)]\n",
    "csv_second_largeQP1_listsA = [[] for _ in range(10)]\n",
    "csv_second_recompress_largeQP1_listsA = [[] for _ in range(10)]\n",
    "csv_second_sameQP_listsA = [[] for _ in range(10)]\n",
    "csv_second_recompress_sameQP_listsA = [[] for _ in range(10)]\n",
    "csv_second_largeQP2_listsA = [[] for _ in range(10)]\n",
    "csv_second_recompress_largeQP2_listsA = [[] for _ in range(10)]\n",
    "\n",
    "def process_csv_lists(rootpath, train_list, single_list, single_recompress_list, \n",
    "                      second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                      second_sameQP_list, second_recompress_sameQP_list,\n",
    "                      second_largeQP2_list, second_recompress_largeQP2_list):\n",
    "    \n",
    "    for image in train_list:\n",
    "        single_path = osp.join(rootpath, f'HEIF_images_single_csv/{image}_*')\n",
    "        single_recompress_path = osp.join(rootpath, f'HEIF_images_second_sameQP_csv/{image}_*')\n",
    "        \n",
    "        second_largeQP1_path = osp.join(rootpath, f'HEIF_images_second_csv/{image}_*')\n",
    "        second_recompress_largeQP1_path = osp.join(rootpath, f'HEIF_images_triple_csv/{image}_*')\n",
    "        \n",
    "        second_sameQP_path = osp.join(rootpath, f'HEIF_images_second_sameQP_csv/{image}_*')\n",
    "        second_recompress_sameQP_path = osp.join(rootpath, f'HEIF_images_triple_sameQP_csv/{image}_*')\n",
    "        \n",
    "        second_largeQP2_path = osp.join(rootpath, f'HEIF_images_second_largeQP_csv/{image}_*')\n",
    "        second_recompress_largeQP2_path = osp.join(rootpath, f'HEIF_images_triple_largeQP_csv/{image}_*')\n",
    "        \n",
    "        for path in sorted(glob.glob(single_path)):\n",
    "            single_list.append(path)\n",
    "        for path in sorted(glob.glob(single_recompress_path)):\n",
    "            single_recompress_list.append(path)\n",
    "        for path in sorted(glob.glob(second_largeQP1_path)):\n",
    "            second_largeQP1_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP1_path)):\n",
    "            second_recompress_largeQP1_list.append(path)\n",
    "        for path in sorted(glob.glob(second_sameQP_path)):\n",
    "            second_sameQP_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_sameQP_path)):\n",
    "            second_recompress_sameQP_list.append(path)\n",
    "        for path in sorted(glob.glob(second_largeQP2_path)):\n",
    "            second_largeQP2_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP2_path)):\n",
    "            second_recompress_largeQP2_list.append(path)\n",
    "\n",
    "# 各カテゴリのCSVリストを生成\n",
    "for train_list, single_list, single_recompress_list in zip(train_lists, \n",
    "                                                           csv_single_listsA,\n",
    "                                                           csv_single_recompress_listsA):\n",
    "    process_csv_lists(rootpath_csv, train_list, single_list, single_recompress_list, \n",
    "                      [], [], [], [], [], [])\n",
    "\n",
    "\n",
    "for train_list, second_largeQP1_list, second_recompress_largeQP1_list, second_sameQP_list, second_recompress_sameQP_list, second_largeQP2_list, second_recompress_largeQP2_list in zip(train_lists, \n",
    "                                                                                                                                                                                                                   csv_second_largeQP1_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_recompress_largeQP1_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_sameQP_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_recompress_sameQP_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_largeQP2_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_recompress_largeQP2_listsA):\n",
    "    process_csv_lists(rootpath_csv, train_list, [], [], \n",
    "                      second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                      second_sameQP_list, second_recompress_sameQP_list,\n",
    "                      second_largeQP2_list, second_recompress_largeQP2_list)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "# 出力リストを初期化\n",
    "pkl_single_listsA = [[] for _ in range(10)]\n",
    "pkl_single_recompress_listsA = [[] for _ in range(10)]\n",
    "pkl_second_largeQP1_listsA = [[] for _ in range(10)]\n",
    "pkl_second_recompress_largeQP1_listsA = [[] for _ in range(10)]\n",
    "pkl_second_sameQP_listsA = [[] for _ in range(10)]\n",
    "pkl_second_recompress_sameQP_listsA = [[] for _ in range(10)]\n",
    "pkl_second_largeQP2_listsA = [[] for _ in range(10)]\n",
    "pkl_second_recompress_largeQP2_listsA = [[] for _ in range(10)]    \n",
    "\n",
    "def process_train_lists_pkl(rootpath, train_list, single_list, single_recompress_list, \n",
    "                            second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                            second_sameQP_list, second_recompress_sameQP_list,\n",
    "                            second_largeQP2_list, second_recompress_largeQP2_list):\n",
    "    \n",
    "    for image in train_list:\n",
    "        single_path = osp.join(rootpath, f'pkl_single/{image}_*')\n",
    "        single_recompress_path = osp.join(rootpath, f'pkl_second_sameQP/{image}_*')\n",
    "        \n",
    "        second_largeQP1_path = osp.join(rootpath, f'pkl_second/{image}_*')\n",
    "        second_recompress_largeQP1_path = osp.join(rootpath, f'pkl_triple/{image}_*')\n",
    "        \n",
    "        second_sameQP_path = osp.join(rootpath, f'pkl_second_sameQP/{image}_*')\n",
    "        second_recompress_sameQP_path = osp.join(rootpath, f'pkl_triple_sameQP/{image}_*')\n",
    "        \n",
    "        second_largeQP2_path = osp.join(rootpath, f'pkl_second_largeQP/{image}_*')\n",
    "        second_recompress_largeQP2_path = osp.join(rootpath, f'pkl_triple_largeQP/{image}_*')\n",
    "        \n",
    "\n",
    "        for path in sorted(glob.glob(single_path)):\n",
    "            single_list.append(path)\n",
    "        for path in sorted(glob.glob(single_recompress_path)):\n",
    "            single_recompress_list.append(path)\n",
    "            \n",
    "        for path in sorted(glob.glob(second_largeQP1_path)):\n",
    "            second_largeQP1_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP1_path)):\n",
    "            second_recompress_largeQP1_list.append(path)\n",
    "                \n",
    "        for path in sorted(glob.glob(second_sameQP_path)):\n",
    "            second_sameQP_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_sameQP_path)):\n",
    "            second_recompress_sameQP_list.append(path)\n",
    "            \n",
    "        for path in sorted(glob.glob(second_largeQP2_path)):\n",
    "            second_largeQP2_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP2_path)):\n",
    "            second_recompress_largeQP2_list.append(path)\n",
    "\n",
    "# 各カテゴリのリストを生成\n",
    "for train_list, single_list, single_recompress_list in zip(train_lists, \n",
    "                                                           pkl_single_listsA,\n",
    "                                                           pkl_single_recompress_listsA):\n",
    "    process_train_lists_pkl(rootpath_pkl, train_list, single_list, single_recompress_list, \n",
    "                            [], [], [], [], [], [])\n",
    "\n",
    "\n",
    "for train_list, second_largeQP1_list, second_recompress_largeQP1_list, second_sameQP_list, second_recompress_sameQP_list, second_largeQP2_list, second_recompress_largeQP2_list in zip(train_lists, \n",
    "                                                                                                                                                                                                                   pkl_second_largeQP1_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_recompress_largeQP1_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_sameQP_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_recompress_sameQP_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_largeQP2_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_recompress_largeQP2_listsA):\n",
    "    process_train_lists_pkl(rootpath_pkl, train_list, [], [], \n",
    "                            second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                            second_sameQP_list, second_recompress_sameQP_list,\n",
    "                            second_largeQP2_list, second_recompress_largeQP2_list)\n",
    "\n",
    "\n",
    "print(\"\\nCSV Single ListsA:\")\n",
    "for i, lst in enumerate(csv_single_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Single Recompress ListsA:\")\n",
    "for i, lst in enumerate(csv_single_recompress_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Large QP1 ListsA:\")\n",
    "for i, lst in enumerate(csv_second_largeQP1_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Recompress Large QP1 ListsA:\")\n",
    "for i, lst in enumerate(csv_second_recompress_largeQP1_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Same QP ListsA:\")\n",
    "for i, lst in enumerate(csv_second_sameQP_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Recompress Same QP ListsA:\")\n",
    "for i, lst in enumerate(csv_second_recompress_sameQP_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Large QP2 ListsA:\")\n",
    "for i, lst in enumerate(csv_second_largeQP2_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Recompress Large QP2 ListsA:\")\n",
    "for i, lst in enumerate(csv_second_recompress_largeQP2_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "# 出力リストを表示\n",
    "print(\"\\nPKL Single ListsA:\")\n",
    "for i, lst in enumerate(pkl_single_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Single Recompress ListsA:\")\n",
    "for i, lst in enumerate(pkl_single_recompress_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Large QP1 ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_largeQP1_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Recompress Large QP1 ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_recompress_largeQP1_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Same QP ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_sameQP_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Recompress Same QP ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_recompress_sameQP_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Large QP2 ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_largeQP2_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Recompress Large QP2 ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_recompress_largeQP2_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "# single_listsおよびsingle_recompress_listsは初期化されている前提\n",
    "single_csv1 = list(zip(csv_single_listsA[0], pkl_single_listsA[0], csv_single_recompress_listsA[0], pkl_single_recompress_listsA[0]))\n",
    "single_csv2 = list(zip(csv_single_listsA[1], pkl_single_listsA[1], csv_single_recompress_listsA[1], pkl_single_recompress_listsA[1]))\n",
    "single_csv3 = list(zip(csv_single_listsA[2], pkl_single_listsA[2], csv_single_recompress_listsA[2], pkl_single_recompress_listsA[2]))\n",
    "single_csv4 = list(zip(csv_single_listsA[3], pkl_single_listsA[3], csv_single_recompress_listsA[3], pkl_single_recompress_listsA[3]))\n",
    "single_csv5 = list(zip(csv_single_listsA[4], pkl_single_listsA[4], csv_single_recompress_listsA[4], pkl_single_recompress_listsA[4]))\n",
    "single_csv6 = list(zip(csv_single_listsA[5], pkl_single_listsA[5], csv_single_recompress_listsA[5], pkl_single_recompress_listsA[5]))\n",
    "single_csv7 = list(zip(csv_single_listsA[6], pkl_single_listsA[6], csv_single_recompress_listsA[6], pkl_single_recompress_listsA[6]))\n",
    "single_csv8 = list(zip(csv_single_listsA[7], pkl_single_listsA[7], csv_single_recompress_listsA[7], pkl_single_recompress_listsA[7]))\n",
    "single_csv9 = list(zip(csv_single_listsA[8], pkl_single_listsA[8], csv_single_recompress_listsA[8], pkl_single_recompress_listsA[8]))\n",
    "single_csv10 = list(zip(csv_single_listsA[9], pkl_single_listsA[9], csv_single_recompress_listsA[9], pkl_single_recompress_listsA[9]))\n",
    "print(len(single_csv10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1710\n",
      "\n",
      "double images train by QP1>QP2:  100\n",
      "\n",
      "double images test by QP1>QP2:  300\n"
     ]
    }
   ],
   "source": [
    "# Large_QP1\n",
    "second_largeQP1_csv1 = list(zip(csv_second_largeQP1_listsA[0], pkl_second_largeQP1_listsA[0], csv_second_recompress_largeQP1_listsA[0], pkl_second_recompress_largeQP1_listsA[0]))\n",
    "second_largeQP1_csv2 = list(zip(csv_second_largeQP1_listsA[1], pkl_second_largeQP1_listsA[1], csv_second_recompress_largeQP1_listsA[1], pkl_second_recompress_largeQP1_listsA[1]))\n",
    "second_largeQP1_csv3 = list(zip(csv_second_largeQP1_listsA[2], pkl_second_largeQP1_listsA[2], csv_second_recompress_largeQP1_listsA[2], pkl_second_recompress_largeQP1_listsA[2]))\n",
    "second_largeQP1_csv4 = list(zip(csv_second_largeQP1_listsA[3], pkl_second_largeQP1_listsA[3], csv_second_recompress_largeQP1_listsA[3], pkl_second_recompress_largeQP1_listsA[3]))\n",
    "second_largeQP1_csv5 = list(zip(csv_second_largeQP1_listsA[4], pkl_second_largeQP1_listsA[4], csv_second_recompress_largeQP1_listsA[4], pkl_second_recompress_largeQP1_listsA[4]))\n",
    "second_largeQP1_csv6 = list(zip(csv_second_largeQP1_listsA[5], pkl_second_largeQP1_listsA[5], csv_second_recompress_largeQP1_listsA[5], pkl_second_recompress_largeQP1_listsA[5]))\n",
    "second_largeQP1_csv7 = list(zip(csv_second_largeQP1_listsA[6], pkl_second_largeQP1_listsA[6], csv_second_recompress_largeQP1_listsA[6], pkl_second_recompress_largeQP1_listsA[6]))\n",
    "second_largeQP1_csv8 = list(zip(csv_second_largeQP1_listsA[7], pkl_second_largeQP1_listsA[7], csv_second_recompress_largeQP1_listsA[7], pkl_second_recompress_largeQP1_listsA[7]))\n",
    "second_largeQP1_csv9 = list(zip(csv_second_largeQP1_listsA[8], pkl_second_largeQP1_listsA[8], csv_second_recompress_largeQP1_listsA[8], pkl_second_recompress_largeQP1_listsA[8]))\n",
    "second_largeQP1_csv10 = list(zip(csv_second_largeQP1_listsA[9], pkl_second_largeQP1_listsA[9], csv_second_recompress_largeQP1_listsA[9], pkl_second_recompress_largeQP1_listsA[9]))\n",
    "print(len(second_largeQP1_csv1))\n",
    "\n",
    "\n",
    "second_largeQP1_csv1 = random.sample(second_largeQP1_csv1, 100)\n",
    "second_largeQP1_csv2 = random.sample(second_largeQP1_csv2, 100)\n",
    "second_largeQP1_csv3 = random.sample(second_largeQP1_csv3, 100)\n",
    "second_largeQP1_csv4 = random.sample(second_largeQP1_csv4, 100)\n",
    "second_largeQP1_csv5 = random.sample(second_largeQP1_csv5, 100)\n",
    "second_largeQP1_csv6 = random.sample(second_largeQP1_csv6, 100)\n",
    "second_largeQP1_csv7 = random.sample(second_largeQP1_csv7, 100)\n",
    "second_largeQP1_csv8 = random.sample(second_largeQP1_csv8, 100)\n",
    "second_largeQP1_csv9 = random.sample(second_largeQP1_csv9, 100)\n",
    "# second_largeQP1_csv10 = selected_data[9]\n",
    "print('\\ndouble images train by QP1>QP2: ', len(second_largeQP1_csv1))\n",
    "\n",
    "\n",
    "second_largeQP1_csv10 = random.sample(second_largeQP1_csv10, 300)\n",
    "print('\\ndouble images test by QP1>QP2: ', len(second_largeQP1_csv10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "\n",
      "double images train by QP1=QP2:  100\n",
      "\n",
      "double images test by QP1=QP2:  300\n"
     ]
    }
   ],
   "source": [
    "# sameQP\n",
    "second_sameQP_csv1 = list(zip(csv_second_sameQP_listsA[0], pkl_second_sameQP_listsA[0], csv_second_recompress_sameQP_listsA[0], pkl_second_recompress_sameQP_listsA[0]))\n",
    "second_sameQP_csv2 = list(zip(csv_second_sameQP_listsA[1], pkl_second_sameQP_listsA[1], csv_second_recompress_sameQP_listsA[1], pkl_second_recompress_sameQP_listsA[1]))\n",
    "second_sameQP_csv3 = list(zip(csv_second_sameQP_listsA[2], pkl_second_sameQP_listsA[2], csv_second_recompress_sameQP_listsA[2], pkl_second_recompress_sameQP_listsA[2]))\n",
    "second_sameQP_csv4 = list(zip(csv_second_sameQP_listsA[3], pkl_second_sameQP_listsA[3], csv_second_recompress_sameQP_listsA[3], pkl_second_recompress_sameQP_listsA[3]))\n",
    "second_sameQP_csv5 = list(zip(csv_second_sameQP_listsA[4], pkl_second_sameQP_listsA[4], csv_second_recompress_sameQP_listsA[4], pkl_second_recompress_sameQP_listsA[4]))\n",
    "second_sameQP_csv6 = list(zip(csv_second_sameQP_listsA[5], pkl_second_sameQP_listsA[5], csv_second_recompress_sameQP_listsA[5], pkl_second_recompress_sameQP_listsA[5]))\n",
    "second_sameQP_csv7 = list(zip(csv_second_sameQP_listsA[6], pkl_second_sameQP_listsA[6], csv_second_recompress_sameQP_listsA[6], pkl_second_recompress_sameQP_listsA[6]))\n",
    "second_sameQP_csv8 = list(zip(csv_second_sameQP_listsA[7], pkl_second_sameQP_listsA[7], csv_second_recompress_sameQP_listsA[7], pkl_second_recompress_sameQP_listsA[7]))\n",
    "second_sameQP_csv9 = list(zip(csv_second_sameQP_listsA[8], pkl_second_sameQP_listsA[8], csv_second_recompress_sameQP_listsA[8], pkl_second_recompress_sameQP_listsA[8]))\n",
    "second_sameQP_csv10 = list(zip(csv_second_sameQP_listsA[9], pkl_second_sameQP_listsA[9], csv_second_recompress_sameQP_listsA[9], pkl_second_recompress_sameQP_listsA[9]))\n",
    "print(len(second_sameQP_csv10))\n",
    "\n",
    "second_sameQP_csv1 = random.sample(second_sameQP_csv1, 100)\n",
    "second_sameQP_csv2 = random.sample(second_sameQP_csv2, 100)\n",
    "second_sameQP_csv3 = random.sample(second_sameQP_csv3, 100)\n",
    "second_sameQP_csv4 = random.sample(second_sameQP_csv4, 100)\n",
    "second_sameQP_csv5 = random.sample(second_sameQP_csv5, 100)\n",
    "second_sameQP_csv6 = random.sample(second_sameQP_csv6, 100)\n",
    "second_sameQP_csv7 = random.sample(second_sameQP_csv7, 100)\n",
    "second_sameQP_csv8 = random.sample(second_sameQP_csv8, 100)\n",
    "second_sameQP_csv9 = random.sample(second_sameQP_csv9, 100)\n",
    "print('\\ndouble images train by QP1=QP2: ',len(second_sameQP_csv9))\n",
    "\n",
    "second_sameQP_csv10 = random.sample(second_sameQP_csv10, 300)\n",
    "print('\\ndouble images test by QP1=QP2: ',len(second_sameQP_csv10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1170\n",
      "\n",
      "double images train by QP1<QP2:  100\n",
      "\n",
      "double images test by QP1<QP2:  300\n"
     ]
    }
   ],
   "source": [
    "# Large_QP2\n",
    "second_largeQP2_csv1 = list(zip(csv_second_largeQP2_listsA[0], pkl_second_largeQP2_listsA[0], csv_second_recompress_largeQP2_listsA[0], pkl_second_recompress_largeQP2_listsA[0]))\n",
    "second_largeQP2_csv2 = list(zip(csv_second_largeQP2_listsA[1], pkl_second_largeQP2_listsA[1], csv_second_recompress_largeQP2_listsA[1], pkl_second_recompress_largeQP2_listsA[1]))\n",
    "second_largeQP2_csv3 = list(zip(csv_second_largeQP2_listsA[2], pkl_second_largeQP2_listsA[2], csv_second_recompress_largeQP2_listsA[2], pkl_second_recompress_largeQP2_listsA[2]))\n",
    "second_largeQP2_csv4 = list(zip(csv_second_largeQP2_listsA[3], pkl_second_largeQP2_listsA[3], csv_second_recompress_largeQP2_listsA[3], pkl_second_recompress_largeQP2_listsA[3]))\n",
    "second_largeQP2_csv5 = list(zip(csv_second_largeQP2_listsA[4], pkl_second_largeQP2_listsA[4], csv_second_recompress_largeQP2_listsA[4], pkl_second_recompress_largeQP2_listsA[4]))\n",
    "second_largeQP2_csv6 = list(zip(csv_second_largeQP2_listsA[5], pkl_second_largeQP2_listsA[5], csv_second_recompress_largeQP2_listsA[5], pkl_second_recompress_largeQP2_listsA[5]))\n",
    "second_largeQP2_csv7 = list(zip(csv_second_largeQP2_listsA[6], pkl_second_largeQP2_listsA[6], csv_second_recompress_largeQP2_listsA[6], pkl_second_recompress_largeQP2_listsA[6]))\n",
    "second_largeQP2_csv8 = list(zip(csv_second_largeQP2_listsA[7], pkl_second_largeQP2_listsA[7], csv_second_recompress_largeQP2_listsA[7], pkl_second_recompress_largeQP2_listsA[7]))\n",
    "second_largeQP2_csv9 = list(zip(csv_second_largeQP2_listsA[8], pkl_second_largeQP2_listsA[8], csv_second_recompress_largeQP2_listsA[8], pkl_second_recompress_largeQP2_listsA[8]))\n",
    "second_largeQP2_csv10 = list(zip(csv_second_largeQP2_listsA[9], pkl_second_largeQP2_listsA[9], csv_second_recompress_largeQP2_listsA[9], pkl_second_recompress_largeQP2_listsA[9]))\n",
    "print(len(second_largeQP2_csv1))\n",
    "\n",
    "second_largeQP2_csv1 = random.sample(second_largeQP2_csv1, 100)\n",
    "second_largeQP2_csv2 = random.sample(second_largeQP2_csv2, 100)\n",
    "second_largeQP2_csv3 = random.sample(second_largeQP2_csv3, 100)\n",
    "second_largeQP2_csv4 = random.sample(second_largeQP2_csv4, 100)\n",
    "second_largeQP2_csv5 = random.sample(second_largeQP2_csv5, 100)\n",
    "second_largeQP2_csv6 = random.sample(second_largeQP2_csv6, 100)\n",
    "second_largeQP2_csv7 = random.sample(second_largeQP2_csv7, 100)\n",
    "second_largeQP2_csv8 = random.sample(second_largeQP2_csv8, 100)\n",
    "second_largeQP2_csv9 = random.sample(second_largeQP2_csv9, 100)\n",
    "# second_largeQP2_csv10 = selected_data[9]\n",
    "print('\\ndouble images train by QP1<QP2: ', len(second_largeQP2_csv1))\n",
    "\n",
    "second_largeQP2_csv10 = random.sample(second_largeQP2_csv10, 300)\n",
    "print('\\ndouble images test by QP1<QP2: ', len(second_largeQP2_csv10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_csv_list:  600\n",
      "\n",
      "test_csv_largeQP1 600\n",
      "test_csv_sameQP 600\n",
      "test_csv_largeQP2 600\n"
     ]
    }
   ],
   "source": [
    "train_csv_list1 = single_csv1 + second_largeQP1_csv1 + second_sameQP_csv1 + second_largeQP2_csv1\n",
    "train_csv_list2 = single_csv2 + second_largeQP1_csv2 + second_sameQP_csv2 + second_largeQP2_csv2\n",
    "train_csv_list3 = single_csv3 + second_largeQP1_csv3 + second_sameQP_csv3 + second_largeQP2_csv3\n",
    "train_csv_list4 = single_csv4 + second_largeQP1_csv4 + second_sameQP_csv4 + second_largeQP2_csv4\n",
    "train_csv_list5 = single_csv5 + second_largeQP1_csv5 + second_sameQP_csv5 + second_largeQP2_csv5\n",
    "train_csv_list6 = single_csv6 + second_largeQP1_csv6 + second_sameQP_csv6 + second_largeQP2_csv6\n",
    "train_csv_list7 = single_csv7 + second_largeQP1_csv7 + second_sameQP_csv7 + second_largeQP2_csv7\n",
    "train_csv_list8 = single_csv8 + second_largeQP1_csv8 + second_sameQP_csv8 + second_largeQP2_csv8\n",
    "train_csv_list9 = single_csv9 + second_largeQP1_csv9 + second_sameQP_csv9 + second_largeQP2_csv9\n",
    "print(\"train_csv_list: \", len(train_csv_list9))\n",
    "\n",
    "test_csv_largeQP1 = single_csv10 + second_largeQP1_csv10\n",
    "test_csv_sameQP = single_csv10 + second_sameQP_csv10\n",
    "test_csv_largeQP2 = single_csv10 + second_largeQP2_csv10\n",
    "\n",
    "print(\"\\ntest_csv_largeQP1\", len(test_csv_largeQP1))\n",
    "print(\"test_csv_sameQP\", len(test_csv_sameQP))\n",
    "print(\"test_csv_largeQP2\", len(test_csv_largeQP2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_smoothing(probabilities, alpha=1):\n",
    "    \"\"\"\n",
    "    ラプラス平滑化を行う関数\n",
    "    \n",
    "    Args:\n",
    "    probabilities (list): 平滑化する確率分布のリスト\n",
    "    alpha (float): 平滑化パラメータ\n",
    "    \n",
    "    Returns:\n",
    "    smoothed_probabilities (list): 平滑化された確率分布のリスト\n",
    "    \"\"\"\n",
    "    total_count = sum(probabilities)\n",
    "    num_elements = len(probabilities)\n",
    "    \n",
    "    smoothed_probabilities = [(count + alpha) / (total_count + alpha * num_elements) for count in probabilities]\n",
    "    \n",
    "    return smoothed_probabilities\n",
    "\n",
    "\n",
    "def process_train_csv_lists(train_csv_list):\n",
    "    pu_columns = [\"PU1_64\", \"PU1_32\", \"PU1_16\", \"PU1_8\", \"PU1_4\",  \n",
    "                  \"PU2_64\",\"PU2_32\", \"PU2_16\", \"PU2_8\", \"PU2_4\"]\n",
    "\n",
    "#     luminance_columns = [\"LU1_0\",\"LU1_1\",\"LU1_2\",\"LU1_3\",\n",
    "#                          \"LU1_4\",\"LU1_5\",\"LU1_6\",\"LU1_7\",\n",
    "#                          \"LU1_8\",\"LU1_9\",\"LU1_10\",\"LU1_11\",\n",
    "#                          \"LU1_12\",\"LU1_13\",\"LU1_14\",\"LU1_15\",\n",
    "#                          \"LU1_16\",\"LU1_17\",\"LU1_18\",\"LU1_19\",\n",
    "#                          \"LU1_20\",\"LU1_21\",\"LU1_22\",\"LU1_23\",\n",
    "#                          \"LU1_24\",\"LU1_25\",\"LU1_26\",\"LU1_27\",\n",
    "#                          \"LU1_28\",\"LU1_29\",\"LU1_30\",\"LU1_31\",\n",
    "#                          \"LU1_32\",\"LU1_33\",\"LU1_34\",\n",
    "                         \n",
    "#                          \"LU2_0\",\"LU2_1\",\"LU2_2\",\"LU2_3\",\n",
    "#                          \"LU2_4\",\"LU2_5\",\"LU2_6\",\"LU2_7\",\n",
    "#                          \"LU2_8\",\"LU2_9\",\"LU2_10\",\"LU2_11\",\n",
    "#                          \"LU2_12\",\"LU2_13\",\"LU2_14\",\"LU2_15\",\n",
    "#                          \"LU2_16\",\"LU2_17\",\"LU2_18\",\"LU2_19\",\n",
    "#                          \"LU2_20\",\"LU2_21\",\"LU2_22\",\"LU2_23\",\n",
    "#                          \"LU2_24\",\"LU2_25\",\"LU2_26\",\"LU2_27\",\n",
    "#                          \"LU2_28\",\"LU2_29\",\"LU2_30\",\"LU2_31\",\n",
    "#                          \"LU2_32\",\"LU2_33\",\"LU2_34\"]\n",
    "    \n",
    "    luminance_columns = [\"LU1_0\",\"LU1_1\",\"LU1_9\",\"LU1_10\",\"LU1_11\",\"LU1_25\",\"LU1_26\",\"LU1_27\",\n",
    "                         \"LU2_0\",\"LU2_1\",\"LU2_9\",\"LU2_10\",\"LU2_11\", \"LU2_25\",\"LU2_26\",\"LU2_27\"]\n",
    "\n",
    "    chrominance_columns = [\"CH1_0\", \"CH1_1\", \"CH1_10\", \"CH1_26\", \"CH1_34\", \"CH1_36\", \n",
    "                           \"CH2_0\", \"CH2_1\", \"CH2_10\", \"CH2_26\", \"CH2_34\", \"CH2_36\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    label_columns = [\"LABEL\"]\n",
    "    mae1_columns = [f\"MAE1_{i}\" for i in range(52)]\n",
    "    mae2_columns = [f\"MAE2_{i}\" for i in range(52)]\n",
    "    mae_columns = [\"MAE\"]\n",
    "    final_qp_columns = [\"FINAL_QP\"]\n",
    "    kl_divergence1 = [\"KLD_PU\"]\n",
    "    kl_divergence2 = [\"KLD_LUMA\"]\n",
    "    kl_divergence3 = [\"KLD_CHROMA\"]\n",
    "    ratio_columns1 = [\"RATIO1\"]\n",
    "    ratio_columns2 = [\"RATIO2\"]\n",
    "    \n",
    "    train_df1_1 = pd.DataFrame(columns=pu_columns)\n",
    "    train_df1_2 = pd.DataFrame(columns=luminance_columns)\n",
    "    train_df1_3 = pd.DataFrame(columns=chrominance_columns)\n",
    "    LABEL = pd.DataFrame(columns=label_columns)\n",
    "    RATIO1 = pd.DataFrame(columns=ratio_columns1)\n",
    "    RATIO2 = pd.DataFrame(columns=ratio_columns2)\n",
    "    train_df3 = pd.DataFrame(columns=mae1_columns)\n",
    "    train_df4 = pd.DataFrame(columns=mae2_columns)\n",
    "    MAE = pd.DataFrame(columns=mae_columns)\n",
    "    FINAL_QP = pd.DataFrame(columns=final_qp_columns)\n",
    "    kl_divergence_df1 = pd.DataFrame(columns=kl_divergence1)\n",
    "    kl_divergence_df2 = pd.DataFrame(columns=kl_divergence2)\n",
    "    kl_divergence_df3 = pd.DataFrame(columns=kl_divergence3)\n",
    "\n",
    "    for path1, path2, path3, path4 in train_csv_list:\n",
    "        label = 1 if (\"2ndQP\" in path1) and (\"3rdQP\" in path3) else 0\n",
    "        train_pkl_list = [path2, path4]\n",
    "        df1 = pd.read_csv(path1)\n",
    "        df2 = pd.read_csv(path3)\n",
    "        \n",
    "        # 平滑化を行う\n",
    "        probabilities_df1 = laplace_smoothing([df1.loc[i, \"pu_counts\"] for i in [0,1,2,3,4]])\n",
    "        probabilities_df2 = laplace_smoothing([df2.loc[i, \"pu_counts\"] for i in [0,1,2,3,4]])\n",
    "        kl_divergence1 = entropy(probabilities_df1, probabilities_df2)\n",
    "        \n",
    "        probabilities_df3 = laplace_smoothing([df1.loc[i, \"luminance_counts\"] for i in [0,1,9,10,11,25,26,27]])\n",
    "        probabilities_df4 = laplace_smoothing([df2.loc[i, \"luminance_counts\"] for i in [0,1,9,10,11,25,26,27]])\n",
    "        kl_divergence2 = entropy(probabilities_df3, probabilities_df4)\n",
    "        \n",
    "        probabilities_df5 = laplace_smoothing([df1.loc[i, \"chroma_counts\"] for i in [0,1,10,26,34,36]])\n",
    "        probabilities_df6 = laplace_smoothing([df2.loc[i, \"chroma_counts\"] for i in [0,1,10,26,34,36]])\n",
    "        kl_divergence3 = entropy(probabilities_df5, probabilities_df6)\n",
    "        \n",
    "        \n",
    "        pu_values = [df1.loc[i, \"pu_counts\"] for i in range(5)] + [df2.loc[i, \"pu_counts\"] for i in range(5)]\n",
    "        # lu_values = [df1.loc[i, \"luminance_counts\"] for i in range(35)] + [df2.loc[i, \"luminance_counts\"] for i in range(35)]\n",
    "        lu_values = [df1.loc[i, \"luminance_counts\"] for i in [0,1,9,10,11,25,26,27]] + [df2.loc[i, \"luminance_counts\"] for i in [0,1,9,10,11,25,26,27]]\n",
    "        ch_values = [df1.loc[i, \"chroma_counts\"] for i in [0,1,10,26,34,36]] + [df2.loc[i, \"chroma_counts\"] for i in [0,1,10,26,34,36]]\n",
    "        \n",
    "        train_df1_1 = pd.concat([train_df1_1, pd.DataFrame([pu_values], columns=pu_columns)], ignore_index=True)\n",
    "        train_df1_2= pd.concat([train_df1_2, pd.DataFrame([lu_values], columns=luminance_columns)], ignore_index=True)\n",
    "        train_df1_3 = pd.concat([train_df1_3, pd.DataFrame([ch_values], columns=chrominance_columns)], ignore_index=True)\n",
    "        \n",
    "        kl_divergence_df1 = pd.concat([kl_divergence_df1, pd.DataFrame({\"KLD_PU\": [kl_divergence1]})], ignore_index=True)\n",
    "        kl_divergence_df2 = pd.concat([kl_divergence_df2, pd.DataFrame({\"KLD_LUMA\": [kl_divergence2]})], ignore_index=True)\n",
    "        kl_divergence_df3 = pd.concat([kl_divergence_df3, pd.DataFrame({\"KLD_CHROMA\": [kl_divergence3]})], ignore_index=True)\n",
    "\n",
    "\n",
    "        LABEL = pd.concat([LABEL, pd.DataFrame({\"LABEL\": [label]})], ignore_index=True)\n",
    "\n",
    "        final_QP = extract_finalQP(train_pkl_list[0])\n",
    "\n",
    "        mae_d1 = calculate_mae(train_pkl_list[0])\n",
    "        mae_d2 = calculate_mae(train_pkl_list[1])\n",
    "        ratio1 = ratio_double_compressed(mae_d1, final_QP)\n",
    "        ratio2 = ratio_double_compressed(mae_d2, final_QP)\n",
    "\n",
    "        RATIO1 = pd.concat([RATIO1, pd.DataFrame({\"RATIO1\": [ratio1]})], ignore_index=True)\n",
    "        RATIO2 = pd.concat([RATIO2, pd.DataFrame({\"RATIO2\": [ratio2]})], ignore_index=True)\n",
    "\n",
    "        train_df3 = pd.concat([train_df3, pd.DataFrame({f\"MAE1_{i}\": [mae_d1[i]] for i in range(52)})], ignore_index=True)\n",
    "        train_df4 = pd.concat([train_df4, pd.DataFrame({f\"MAE2_{i}\": [mae_d2[i]] for i in range(52)})], ignore_index=True)\n",
    "        MAE = pd.concat([MAE, pd.DataFrame({\"MAE\": [mae_d1]})], ignore_index=True)\n",
    "        FINAL_QP = pd.concat([FINAL_QP, pd.DataFrame({\"FINAL_QP\": [final_QP]})], ignore_index=True)\n",
    "\n",
    "    train_df1_1.reset_index(drop=True, inplace=True)\n",
    "    train_df1_2.reset_index(drop=True, inplace=True)\n",
    "    train_df1_3.reset_index(drop=True, inplace=True)\n",
    "    LABEL.reset_index(drop=True, inplace=True)\n",
    "    RATIO1.reset_index(drop=True, inplace=True)\n",
    "    RATIO2.reset_index(drop=True, inplace=True)\n",
    "    kl_divergence_df1.reset_index(drop=True, inplace=True)\n",
    "    kl_divergence_df2.reset_index(drop=True, inplace=True)\n",
    "    kl_divergence_df3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # train_df = pd.concat([train_df1_1, train_df1_2, train_df1_3, train_df3, train_df4], axis=1)\n",
    "    train_df = pd.concat([FINAL_QP, train_df1_1, train_df1_2, train_df1_3, kl_divergence_df1, kl_divergence_df2, kl_divergence_df3, RATIO1, RATIO2], axis=1)\n",
    "    train_df_onlyGhost = pd.concat([FINAL_QP, kl_divergence_df1, kl_divergence_df2, kl_divergence_df3, RATIO1, RATIO2], axis=1)\n",
    "\n",
    "    return train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1, train_df_onlyGhost1, LABEL1, MAE1, FINAL_QP1 = process_train_csv_lists(train_csv_list1)\n",
    "train_df2, train_df_onlyGhost2, LABEL2, MAE2, FINAL_QP2 = process_train_csv_lists(train_csv_list2)\n",
    "train_df3, train_df_onlyGhost3, LABEL3, MAE3, FINAL_QP3 = process_train_csv_lists(train_csv_list3)\n",
    "train_df4, train_df_onlyGhost4, LABEL4, MAE4, FINAL_QP4 = process_train_csv_lists(train_csv_list4)\n",
    "train_df5, train_df_onlyGhost5, LABEL5, MAE5, FINAL_QP5 = process_train_csv_lists(train_csv_list5)\n",
    "train_df6, train_df_onlyGhost6, LABEL6, MAE6, FINAL_QP6 = process_train_csv_lists(train_csv_list6)\n",
    "train_df7, train_df_onlyGhost7, LABEL7, MAE7, FINAL_QP7 = process_train_csv_lists(train_csv_list7)\n",
    "train_df8, train_df_onlyGhost8, LABEL8, MAE8, FINAL_QP8 = process_train_csv_lists(train_csv_list8)\n",
    "train_df9, train_df_onlyGhost9, LABEL9, MAE9, FINAL_QP9 = process_train_csv_lists(train_csv_list9)\n",
    "\n",
    "test_df1, test_df_onlyGhost1, LABEL_t1, MAE_t1, FINAL_QP_t1 = process_train_csv_lists(test_csv_largeQP1)\n",
    "test_df2, test_df_onlyGhost2, LABEL_t2, MAE_t2, FINAL_QP_t2 = process_train_csv_lists(test_csv_sameQP)\n",
    "test_df3, test_df_onlyGhost3, LABEL_t3, MAE_t3, FINAL_QP_t3 = process_train_csv_lists(test_csv_largeQP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各データフレームを結合\n",
    "combined_train_df = pd.concat([train_df1, train_df2, train_df3, train_df4, train_df5, train_df6, train_df7, train_df8, train_df9], ignore_index=True)\n",
    "combined_train_df_onlyGhost = pd.concat([train_df_onlyGhost1, train_df_onlyGhost2, train_df_onlyGhost3, train_df_onlyGhost4, train_df_onlyGhost5, train_df_onlyGhost6, train_df_onlyGhost7, train_df_onlyGhost8, train_df_onlyGhost9], ignore_index=True)\n",
    "combined_LABEL = pd.concat([LABEL1, LABEL2, LABEL3, LABEL4, LABEL5, LABEL6, LABEL7, LABEL8, LABEL9], ignore_index=True)\n",
    "combined_MAE = pd.concat([MAE1, MAE2, MAE3, MAE4, MAE5, MAE6, MAE7, MAE8, MAE9], ignore_index=True)\n",
    "combined_FINAL_QP = pd.concat([FINAL_QP1, FINAL_QP2, FINAL_QP3, FINAL_QP4, FINAL_QP5, FINAL_QP6, FINAL_QP7, FINAL_QP8, FINAL_QP9], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5400, 44)\n",
      "(5400, 6)\n",
      "(5400, 1)\n",
      "(5400, 1)\n",
      "(5400, 1)\n",
      "(600, 44)\n",
      "(600, 6)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 44)\n",
      "(600, 6)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 44)\n",
      "(600, 6)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 1)\n"
     ]
    }
   ],
   "source": [
    "print(combined_train_df.shape)\n",
    "print(combined_train_df_onlyGhost.shape)\n",
    "print(combined_LABEL.shape)\n",
    "print(combined_MAE.shape)\n",
    "print(combined_FINAL_QP.shape)\n",
    "\n",
    "print(test_df1.shape)\n",
    "print(test_df_onlyGhost1.shape)\n",
    "print(LABEL_t1.shape)\n",
    "print(MAE_t1.shape)\n",
    "print(FINAL_QP_t1.shape)\n",
    "\n",
    "print(test_df2.shape)\n",
    "print(test_df_onlyGhost2.shape)\n",
    "print(LABEL_t2.shape)\n",
    "print(MAE_t2.shape)\n",
    "print(FINAL_QP_t2.shape)\n",
    "\n",
    "print(test_df3.shape)\n",
    "print(test_df_onlyGhost3.shape)\n",
    "print(LABEL_t3.shape)\n",
    "print(MAE_t3.shape)\n",
    "print(FINAL_QP_t3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling:\n",
      "Combined Train DF:\n",
      "  FINAL_QP PU1_64 PU1_32 PU1_16  PU1_8  PU1_4 PU2_64 PU2_32 PU2_16  PU2_8  PU2_4 LU1_0 LU1_1 LU1_9 LU1_10 LU1_11 LU1_25 LU1_26 LU1_27 LU2_0 LU2_1 LU2_9 LU2_10 LU2_11 LU2_25 LU2_26 LU2_27  CH1_0 CH1_1 CH1_10 CH1_26 CH1_34 CH1_36  CH2_0 CH2_1 CH2_10 CH2_26 CH2_34 CH2_36    KLD_PU  KLD_LUMA KLD_CHROMA    RATIO1    RATIO2\n",
      "0       10      0      0    144  10408  49448      0      0    144   8592  51264  5335  3623  1858   2518   2074   2129   2429   2312  5384  3820  1850   2480   2039   2092   2469   2274  15244  8844   7524   8348   1176  18864  15268  9352   7688   8604   1128  17960  0.003536  0.000296   0.000718  0.029901  0.022884\n",
      "1       16      0    256    480  13600  45664      0    256    496  12032  47216  5555  4102  1632   2591   1903   2014   2532   2044  5617  4208  1654   2592   1896   1987   2535   2095  14540  6792   5844   5968   1196  25660  14100  7616   5904   6256   1048  25076  0.002067  0.000075    0.00128   0.01277  0.008011\n",
      "2       20      0    384   1392  15304  42920      0    384   1360  14004  44252  5782  4156  1609   2514   1958   1833   2508   2233  5940  4278  1597   2511   1998   1872   2489   2165  12984  6060   5240   5292   1012  29412  12564  6400   5156   5380    916  29584  0.001319  0.000195   0.000382  0.007265  0.004286\n",
      "3       24      0   1024   2080  16812  40084      0   1024   2048  15816  41112  6754  5187  1647   2487   1747   1797   2500   1928  7020  5442  1617   2370   1772   1790   2534   1863  10864  4436   4760   4188   1228  34524  10180  4548   4504   3996   1088  35684  0.000732  0.000547   0.001054  0.004988  0.002699\n",
      "4       27      0   1472   3728  18572  36228      0   1472   3712  18356  36460  7021  5831  1469   2505   1647   1711   2500   1889  7488  6427  1394   2385   1690   1688   2535   1924   9248  3792   4104   3392   1204  38260   8964  3820   3916   3284    988  39028  0.000034  0.001278   0.000673   0.19256  0.152602\n",
      "Combined Train DF Only Ghost:\n",
      "  FINAL_QP    KLD_PU  KLD_LUMA KLD_CHROMA    RATIO1    RATIO2\n",
      "0       10  0.003536  0.000296   0.000718  0.029901  0.022884\n",
      "1       16  0.002067  0.000075    0.00128   0.01277  0.008011\n",
      "2       20  0.001319  0.000195   0.000382  0.007265  0.004286\n",
      "3       24  0.000732  0.000547   0.001054  0.004988  0.002699\n",
      "4       27  0.000034  0.001278   0.000673   0.19256  0.152602\n",
      "\n",
      "Before scaling:\n",
      "Combined Test DF:\n",
      "  FINAL_QP PU1_64 PU1_32 PU1_16  PU1_8  PU1_4 PU2_64 PU2_32 PU2_16  PU2_8  PU2_4  LU1_0  LU1_1 LU1_9 LU1_10 LU1_11 LU1_25 LU1_26 LU1_27 LU2_0  LU2_1 LU2_9 LU2_10 LU2_11 LU2_25 LU2_26 LU2_27  CH1_0  CH1_1 CH1_10 CH1_26 CH1_34 CH1_36  CH2_0  CH2_1 CH2_10 CH2_26 CH2_34 CH2_36    KLD_PU  KLD_LUMA KLD_CHROMA    RATIO1    RATIO2\n",
      "0       10      0   9536  10544  15640  24280      0   9536  10368  15592  24504  10004  10633  2962   2977   2647    529    687    529  9798  11920  3023   3002   2689    530    681    499  11856  18532   9064   6180   2632  11736  11712  18940   9264   6056   2512  11516  0.000043   0.00176   0.000227  0.247965  0.142726\n",
      "1       16      0  33472   6448   7508  12572      0  33152   6736   7348  12764   5651   5980  4069   2257   3659    335    506    421  5356   6263  4000   2840   3978    244    498    390  11216   5720   8412   4764   1052  28836  10196   6312   8768   5276    740  28708  0.000183  0.004315   0.002823  0.114133  0.056324\n",
      "2       20      0  33728   9472   7012   9788      0  33088  10080   6720  10112   6192   4812  3896   2602   1783    278    518    251  6216   5109  4120   3030   2016    194    522    235   8512   1852   6544   2620    560  39912   8244   2052   6892   2976    632  39204  0.000606  0.002363   0.000935  0.047329  0.029513\n",
      "3       24      0  38720   7056   6596   7628      0  38720   7056   6368   7856   6468   5160  2821   2467   1799    162    548    177  6489   6090  2747   2418   1786    173    609    157   7692   1160   4412   1164    396  45176   7468   1056   4404   1176    296  45600  0.000123  0.003192   0.000426  0.132974  0.142164\n",
      "4       27      0  39616   8128   5836   6420      0  39680   8032   5856   6432   6553   4397  3186   3204   1732    237    689    274  6572   5203  3433   3130   1769    240    757    266   3868    836   2924    584    340  51448   4044    876   3032    724    316  51008  0.000011   0.00251     0.0004  0.199586  0.175292\n",
      "Combined Test DF Only Ghost:\n",
      "  FINAL_QP    KLD_PU  KLD_LUMA KLD_CHROMA    RATIO1    RATIO2\n",
      "0       10  0.000043   0.00176   0.000227  0.247965  0.142726\n",
      "1       16  0.000183  0.004315   0.002823  0.114133  0.056324\n",
      "2       20  0.000606  0.002363   0.000935  0.047329  0.029513\n",
      "3       24  0.000123  0.003192   0.000426  0.132974  0.142164\n",
      "4       27  0.000011   0.00251     0.0004  0.199586  0.175292\n"
     ]
    }
   ],
   "source": [
    "print(\"Before scaling:\")\n",
    "print(\"Combined Train DF:\")\n",
    "print(combined_train_df.head())\n",
    "print(\"Combined Train DF Only Ghost:\")\n",
    "print(combined_train_df_onlyGhost.head())\n",
    "\n",
    "print(\"\\nBefore scaling:\")\n",
    "print(\"Combined Test DF:\")\n",
    "print(test_df1.head())\n",
    "print(\"Combined Test DF Only Ghost:\")\n",
    "print(test_df_onlyGhost1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After scaling:\n",
      "X_train:\n",
      "      0    1         2         3         4         5    6         7         8         9         10        11        12        13        14        15        16        17        18        19        20        21        22        23        24        25        26        27        28        29        30        31        32        33        34        35        36        37        38        39        40        41        42        43\n",
      "0  0.125  0.0  0.000000  0.004193  0.360788  0.883442  0.0  0.000000  0.004717  0.293282  0.893288  0.071055  0.048449  0.142528  0.091166  0.172013  0.144329  0.078652  0.258237  0.073998  0.047723  0.142681  0.090885  0.169725  0.141821  0.077345  0.249424  0.375172  0.355295  0.392365  0.510144  0.072200  0.276793  0.374069  0.365884  0.389226  0.485882  0.065996  0.262145  0.135273  0.001678  0.007354  0.027715  0.021441\n",
      "1  0.275  0.0  0.004348  0.015199  0.471436  0.815836  0.0  0.004343  0.016247  0.410705  0.822750  0.078618  0.062616  0.125192  0.093813  0.157803  0.136533  0.082466  0.228303  0.082364  0.059160  0.127564  0.095098  0.157798  0.134703  0.079695  0.229791  0.357846  0.272859  0.304756  0.364703  0.073428  0.396273  0.345453  0.297966  0.298906  0.353287  0.061315  0.387040  0.079077  0.000404  0.013121  0.010544  0.006545\n",
      "2  0.375  0.0  0.006522  0.045073  0.530505  0.766812  0.0  0.006515  0.044549  0.478017  0.771102  0.086421  0.064214  0.123427  0.091021  0.162373  0.124263  0.081577  0.249414  0.093961  0.061223  0.123168  0.092051  0.166305  0.126907  0.078057  0.237468  0.319551  0.243452  0.273258  0.323393  0.062132  0.462236  0.307820  0.250391  0.261037  0.303817  0.053592  0.466161  0.050474  0.001099  0.003911  0.005027  0.002813\n",
      "3  0.475  0.0  0.017391  0.067610  0.582779  0.716144  0.0  0.017372  0.067086  0.539869  0.716387  0.119835  0.094709  0.126342  0.090042  0.144840  0.121822  0.081281  0.215347  0.132737  0.095534  0.124711  0.086747  0.147456  0.121348  0.079660  0.204344  0.267375  0.178210  0.248227  0.255928  0.075393  0.552110  0.249412  0.177934  0.228028  0.225661  0.063656  0.573224  0.028005  0.003125  0.010801  0.002745  0.001224\n",
      "4  0.550  0.0  0.025000  0.121593  0.643788  0.647252  0.0  0.024973  0.121593  0.626570  0.635324  0.129013  0.113757  0.112688  0.090695  0.136530  0.115992  0.081281  0.210991  0.149540  0.124569  0.107512  0.087311  0.140617  0.114433  0.079695  0.211034  0.227604  0.152338  0.214018  0.207284  0.073919  0.617792  0.219620  0.149452  0.198258  0.185453  0.057805  0.631915  0.001300  0.007344  0.006898  0.190745  0.151365\n",
      "X_train_onlyGhost:\n",
      "       0         1         2         3         4         5\n",
      "0  0.125  0.135273  0.001678  0.007354  0.027715  0.021441\n",
      "1  0.275  0.079077  0.000404  0.013121  0.010544  0.006545\n",
      "2  0.375  0.050474  0.001099  0.003911  0.005027  0.002813\n",
      "3  0.475  0.028005  0.003125  0.010801  0.002745  0.001224\n",
      "4  0.550  0.001300  0.007344  0.006898  0.190745  0.151365\n",
      "\n",
      "Test data after scaling:\n",
      "X_test_list1:\n",
      "      0    1         2         3         4         5    6         7         8         9         10        11        12        13        14        15        16        17        18        19        20        21        22        23        24        25        26        27        28        29        30        31        32        33        34        35        36        37        38        39        40        41        42        43\n",
      "0  0.125  0.0  0.161957  0.344864  0.542152  0.433788  0.0  0.161781  0.339623  0.532223  0.426988  0.231557  0.255790  0.227217  0.107811  0.219628  0.035862  0.014146  0.059086  0.232479  0.286485  0.233148  0.110522  0.223937  0.035930  0.013674  0.054733  0.291790  0.744496  0.472674  0.377658  0.161591  0.151477  0.286946  0.741002  0.469016  0.341992  0.146969  0.149045  0.001649  0.010124  0.002331  0.246277  0.141473\n",
      "1  0.275  0.0  0.568478  0.210692  0.260261  0.224612  0.0  0.562432  0.220650  0.250819  0.222416  0.081918  0.118164  0.312136  0.081701  0.303723  0.022710  0.007443  0.047023  0.072993  0.119735  0.308499  0.104428  0.331443  0.016541  0.007158  0.042777  0.276039  0.229793  0.438673  0.291127  0.064587  0.452110  0.249804  0.246948  0.443904  0.297944  0.043295  0.450786  0.006990  0.024855  0.028925  0.112138  0.054934\n",
      "2  0.375  0.0  0.572826  0.309748  0.243067  0.174873  0.0  0.561346  0.330189  0.229383  0.176204  0.100516  0.083617  0.298865  0.094212  0.147831  0.018846  0.007887  0.028035  0.103870  0.085718  0.317754  0.111575  0.167807  0.013152  0.008012  0.025776  0.209490  0.074401  0.341260  0.160108  0.034381  0.646835  0.201980  0.080282  0.348927  0.168060  0.036976  0.635004  0.023182  0.013600  0.009584  0.045182  0.028080\n",
      "3  0.475  0.0  0.657609  0.230608  0.228647  0.136282  0.0  0.656895  0.231132  0.217368  0.136893  0.110003  0.093910  0.216401  0.089317  0.149161  0.010982  0.008998  0.019770  0.113672  0.114635  0.211862  0.088553  0.148624  0.011728  0.011110  0.017221  0.189309  0.046601  0.230079  0.071132  0.024312  0.739381  0.182967  0.041315  0.222965  0.066411  0.017318  0.747262  0.004701  0.018376  0.004361  0.131023  0.140910\n",
      "4  0.550  0.0  0.672826  0.265723  0.202302  0.114700  0.0  0.673181  0.263103  0.199891  0.112079  0.112925  0.071342  0.244400  0.116043  0.143593  0.016067  0.014220  0.030604  0.116652  0.088489  0.264769  0.115337  0.147206  0.016270  0.016381  0.029176  0.095196  0.033585  0.152482  0.035688  0.020874  0.849648  0.099079  0.034272  0.153503  0.040885  0.018488  0.842179  0.000426  0.014444  0.004102  0.197787  0.174090\n",
      "X_test_onlyGhost_list1:\n",
      "       0         1         2         3         4         5\n",
      "0  0.125  0.001649  0.010124  0.002331  0.246277  0.141473\n",
      "1  0.275  0.006990  0.024855  0.028925  0.112138  0.054934\n",
      "2  0.375  0.023182  0.013600  0.009584  0.045182  0.028080\n",
      "3  0.475  0.004701  0.018376  0.004361  0.131023  0.140910\n",
      "4  0.550  0.000426  0.014444  0.004102  0.197787  0.174090\n"
     ]
    }
   ],
   "source": [
    "def process_results_to_lists(train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP, scaler_main=None, scaler_ghost=None, fit_scaler=True):\n",
    "    if fit_scaler:\n",
    "        scaler_main = MinMaxScaler()\n",
    "        scaler_ghost = MinMaxScaler()\n",
    "        X_train = scaler_main.fit_transform(train_df)\n",
    "        X_train_onlyGhost = scaler_ghost.fit_transform(train_df_onlyGhost)\n",
    "    else:\n",
    "        X_train = scaler_main.transform(train_df)\n",
    "        X_train_onlyGhost = scaler_ghost.transform(train_df_onlyGhost)\n",
    "\n",
    "    MAE_array = MAE.values\n",
    "    FINAL_QP_array = FINAL_QP.values\n",
    "    Y_train = LABEL['LABEL'].astype(int).values\n",
    "\n",
    "    return X_train, X_train_onlyGhost, MAE_array, FINAL_QP_array, Y_train, scaler_main, scaler_ghost\n",
    "\n",
    "# 訓練データのスケーリング\n",
    "X_train, X_train_onlyGhost, MAE_array, FINAL_QP_array, Y_train, scaler_main, scaler_ghost = process_results_to_lists(\n",
    "    combined_train_df, combined_train_df_onlyGhost, combined_LABEL, combined_MAE, combined_FINAL_QP, fit_scaler=True\n",
    ")\n",
    "\n",
    "# スケーリング後のデータを表示（任意）\n",
    "print(\"After scaling:\")\n",
    "print(\"X_train:\")\n",
    "print(pd.DataFrame(X_train).head())\n",
    "print(\"X_train_onlyGhost:\")\n",
    "print(pd.DataFrame(X_train_onlyGhost).head())\n",
    "\n",
    "# データを元に戻すための関数\n",
    "def restore_data_to_original_order(data, original_lengths):\n",
    "    restored_data = []\n",
    "    start_index = 0\n",
    "    for length in original_lengths:\n",
    "        restored_data.append(data[start_index:start_index + length])\n",
    "        start_index += length\n",
    "    return restored_data\n",
    "\n",
    "# 元のデータフレームの長さ\n",
    "original_lengths = [len(train_df1), len(train_df2), len(train_df3), len(train_df4), len(train_df5), \n",
    "                    len(train_df6), len(train_df7), len(train_df8), len(train_df9)]\n",
    "\n",
    "# データを元の順序に戻す\n",
    "X_train_list = restore_data_to_original_order(X_train, original_lengths)\n",
    "X_train_onlyGhost_list = restore_data_to_original_order(X_train_onlyGhost, original_lengths)\n",
    "MAE_list = restore_data_to_original_order(MAE_array, original_lengths)\n",
    "FINAL_QP_list = restore_data_to_original_order(FINAL_QP_array, original_lengths)\n",
    "Y_train_list = restore_data_to_original_order(Y_train, original_lengths)\n",
    "\n",
    "# テストデータのスケーリング関数\n",
    "def append_results_to_lists(train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP, X_train_list, X_train_onlyGhost_list, MAE_list, FINAL_QP_list, Y_train_list, scaler_main=None, scaler_ghost=None, fit_scaler=True):\n",
    "    X_train, X_train_onlyGhost, MAE_array, FINAL_QP_array, Y_train, _, _ = process_results_to_lists(\n",
    "        train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP, scaler_main, scaler_ghost, fit_scaler)\n",
    "    X_train_list.append(X_train)\n",
    "    X_train_onlyGhost_list.append(X_train_onlyGhost)\n",
    "    MAE_list.append(MAE_array)\n",
    "    FINAL_QP_list.append(FINAL_QP_array)\n",
    "    Y_train_list.append(Y_train)\n",
    "    return X_train_list, X_train_onlyGhost_list, MAE_list, FINAL_QP_list, Y_train_list\n",
    "\n",
    "# テストデータ用のリストの初期化\n",
    "X_test_list1 = []\n",
    "X_test_onlyGhost_list1 = []\n",
    "MAE_list_t1 = []\n",
    "FINAL_QP_list_t1 = []\n",
    "Y_test_list1 = []\n",
    "\n",
    "X_test_list2 = []\n",
    "X_test_onlyGhost_list2 = []\n",
    "MAE_list_t2 = []\n",
    "FINAL_QP_list_t2 = []\n",
    "Y_test_list2 = []\n",
    "\n",
    "X_test_list3 = []\n",
    "X_test_onlyGhost_list3 = []\n",
    "MAE_list_t3 = []\n",
    "FINAL_QP_list_t3 = []\n",
    "Y_test_list3 = []\n",
    "\n",
    "# テストデータの処理とスケーリング\n",
    "X_test_list1, X_test_onlyGhost_list1, MAE_list_t1, FINAL_QP_list_t1, Y_test_list1 = append_results_to_lists(\n",
    "    test_df1, test_df_onlyGhost1, LABEL_t1, MAE_t1, FINAL_QP_t1, X_test_list1, X_test_onlyGhost_list1, MAE_list_t1, FINAL_QP_list_t1, Y_test_list1, scaler_main, scaler_ghost, fit_scaler=False\n",
    ")\n",
    "X_test_list2, X_test_onlyGhost_list2, MAE_list_t2, FINAL_QP_list_t2, Y_test_list2 = append_results_to_lists(\n",
    "    test_df2, test_df_onlyGhost2, LABEL_t2, MAE_t2, FINAL_QP_t2, X_test_list2, X_test_onlyGhost_list2, MAE_list_t2, FINAL_QP_list_t2, Y_test_list2, scaler_main, scaler_ghost, fit_scaler=False\n",
    ")\n",
    "X_test_list3, X_test_onlyGhost_list3, MAE_list_t3, FINAL_QP_list_t3, Y_test_list3 = append_results_to_lists(\n",
    "    test_df3, test_df_onlyGhost3, LABEL_t3, MAE_t3, FINAL_QP_t3, X_test_list3, X_test_onlyGhost_list3, MAE_list_t3, FINAL_QP_list_t3, Y_test_list3, scaler_main, scaler_ghost, fit_scaler=False\n",
    ")\n",
    "\n",
    "# 確認用の出力\n",
    "print(\"\\nTest data after scaling:\")\n",
    "print(\"X_test_list1:\")\n",
    "print(pd.DataFrame(X_test_list1[0]).head())\n",
    "print(\"X_test_onlyGhost_list1:\")\n",
    "print(pd.DataFrame(X_test_onlyGhost_list1[0]).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Fold-1>\n",
      "Train indices: [0 1 2 3 4 5 6 8]\n",
      "Test indices: [7]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.87\n",
      "0.5116666666666667\n",
      "0.5866666666666667\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9414    0.8567    0.8970       300\n",
      "           1     0.8685    0.9467    0.9059       300\n",
      "\n",
      "    accuracy                         0.9017       600\n",
      "   macro avg     0.9049    0.9017    0.9015       600\n",
      "weighted avg     0.9049    0.9017    0.9015       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9735    0.8567    0.9113       300\n",
      "           1     0.8720    0.9767    0.9214       300\n",
      "\n",
      "    accuracy                         0.9167       600\n",
      "   macro avg     0.9228    0.9167    0.9164       600\n",
      "weighted avg     0.9228    0.9167    0.9164       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9018    0.8567    0.8786       300\n",
      "           1     0.8635    0.9067    0.8846       300\n",
      "\n",
      "    accuracy                         0.8817       600\n",
      "   macro avg     0.8826    0.8817    0.8816       600\n",
      "weighted avg     0.8826    0.8817    0.8816       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9278    0.8567    0.8908       300\n",
      "           1     0.8669    0.9333    0.8989       300\n",
      "\n",
      "    accuracy                         0.8950       600\n",
      "   macro avg     0.8973    0.8950    0.8948       600\n",
      "weighted avg     0.8973    0.8950    0.8948       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6607    0.8567    0.7460       300\n",
      "           1     0.7962    0.5600    0.6575       300\n",
      "\n",
      "    accuracy                         0.7083       600\n",
      "   macro avg     0.7284    0.7083    0.7018       600\n",
      "weighted avg     0.7284    0.7083    0.7018       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6223    0.8567    0.7209       300\n",
      "           1     0.7701    0.4800    0.5914       300\n",
      "\n",
      "    accuracy                         0.6683       600\n",
      "   macro avg     0.6962    0.6683    0.6561       600\n",
      "weighted avg     0.6962    0.6683    0.6561       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9567    0.8833    0.9185       300\n",
      "           1     0.8916    0.9600    0.9246       300\n",
      "\n",
      "    accuracy                         0.9217       600\n",
      "   macro avg     0.9242    0.9217    0.9216       600\n",
      "weighted avg     0.9242    0.9217    0.9216       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8730    0.9167    0.8943       300\n",
      "           1     0.9123    0.8667    0.8889       300\n",
      "\n",
      "    accuracy                         0.8917       600\n",
      "   macro avg     0.8926    0.8917    0.8916       600\n",
      "weighted avg     0.8926    0.8917    0.8916       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9266    0.8833    0.9044       300\n",
      "           1     0.8885    0.9300    0.9088       300\n",
      "\n",
      "    accuracy                         0.9067       600\n",
      "   macro avg     0.9076    0.9067    0.9066       600\n",
      "weighted avg     0.9076    0.9067    0.9066       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5864    0.9167    0.7152       300\n",
      "           1     0.8092    0.3533    0.4919       300\n",
      "\n",
      "    accuracy                         0.6350       600\n",
      "   macro avg     0.6978    0.6350    0.6035       600\n",
      "weighted avg     0.6978    0.6350    0.6035       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5116    0.8833    0.6479       300\n",
      "           1     0.5732    0.1567    0.2461       300\n",
      "\n",
      "    accuracy                         0.5200       600\n",
      "   macro avg     0.5424    0.5200    0.4470       600\n",
      "weighted avg     0.5424    0.5200    0.4470       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5074    0.9167    0.6532       300\n",
      "           1     0.5690    0.1100    0.1844       300\n",
      "\n",
      "    accuracy                         0.5133       600\n",
      "   macro avg     0.5382    0.5133    0.4188       600\n",
      "weighted avg     0.5382    0.5133    0.4188       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8627    0.8800    0.8713       300\n",
      "           1     0.8776    0.8600    0.8687       300\n",
      "\n",
      "    accuracy                         0.8700       600\n",
      "   macro avg     0.8701    0.8700    0.8700       600\n",
      "weighted avg     0.8701    0.8700    0.8700       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5143    0.4200    0.4624       300\n",
      "           1     0.5099    0.6033    0.5527       300\n",
      "\n",
      "    accuracy                         0.5117       600\n",
      "   macro avg     0.5121    0.5117    0.5075       600\n",
      "weighted avg     0.5121    0.5117    0.5075       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6605    0.3567    0.4632       300\n",
      "           1     0.5594    0.8167    0.6640       300\n",
      "\n",
      "    accuracy                         0.5867       600\n",
      "   macro avg     0.6099    0.5867    0.5636       600\n",
      "weighted avg     0.6099    0.5867    0.5636       600\n",
      "\n",
      "<Fold-2>\n",
      "Train indices: [0 2 3 4 5 6 7 8]\n",
      "Test indices: [1]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.87\n",
      "0.5116666666666667\n",
      "0.5866666666666667\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9444    0.7933    0.8623       300\n",
      "           1     0.8218    0.9533    0.8827       300\n",
      "\n",
      "    accuracy                         0.8733       600\n",
      "   macro avg     0.8831    0.8733    0.8725       600\n",
      "weighted avg     0.8831    0.8733    0.8725       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9767    0.8400    0.9032       300\n",
      "           1     0.8596    0.9800    0.9159       300\n",
      "\n",
      "    accuracy                         0.9100       600\n",
      "   macro avg     0.9182    0.9100    0.9096       600\n",
      "weighted avg     0.9182    0.9100    0.9096       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9225    0.7933    0.8530       300\n",
      "           1     0.8187    0.9333    0.8723       300\n",
      "\n",
      "    accuracy                         0.8633       600\n",
      "   macro avg     0.8706    0.8633    0.8627       600\n",
      "weighted avg     0.8706    0.8633    0.8627       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9299    0.8400    0.8827       300\n",
      "           1     0.8541    0.9367    0.8935       300\n",
      "\n",
      "    accuracy                         0.8883       600\n",
      "   macro avg     0.8920    0.8883    0.8881       600\n",
      "weighted avg     0.8920    0.8883    0.8881       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6648    0.7933    0.7234       300\n",
      "           1     0.7438    0.6000    0.6642       300\n",
      "\n",
      "    accuracy                         0.6967       600\n",
      "   macro avg     0.7043    0.6967    0.6938       600\n",
      "weighted avg     0.7043    0.6967    0.6938       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6161    0.8400    0.7109       300\n",
      "           1     0.7487    0.4767    0.5825       300\n",
      "\n",
      "    accuracy                         0.6583       600\n",
      "   macro avg     0.6824    0.6583    0.6467       600\n",
      "weighted avg     0.6824    0.6583    0.6467       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9594    0.8667    0.9107       300\n",
      "           1     0.8784    0.9633    0.9189       300\n",
      "\n",
      "    accuracy                         0.9150       600\n",
      "   macro avg     0.9189    0.9150    0.9148       600\n",
      "weighted avg     0.9189    0.9150    0.9148       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8635    0.8433    0.8533       300\n",
      "           1     0.8469    0.8667    0.8567       300\n",
      "\n",
      "    accuracy                         0.8550       600\n",
      "   macro avg     0.8552    0.8550    0.8550       600\n",
      "weighted avg     0.8552    0.8550    0.8550       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9319    0.8667    0.8981       300\n",
      "           1     0.8754    0.9367    0.9050       300\n",
      "\n",
      "    accuracy                         0.9017       600\n",
      "   macro avg     0.9036    0.9017    0.9015       600\n",
      "weighted avg     0.9036    0.9017    0.9015       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5789    0.8433    0.6866       300\n",
      "           1     0.7117    0.3867    0.5011       300\n",
      "\n",
      "    accuracy                         0.6150       600\n",
      "   macro avg     0.6453    0.6150    0.5938       600\n",
      "weighted avg     0.6453    0.6150    0.5938       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5098    0.8667    0.6420       300\n",
      "           1     0.5556    0.1667    0.2564       300\n",
      "\n",
      "    accuracy                         0.5167       600\n",
      "   macro avg     0.5327    0.5167    0.4492       600\n",
      "weighted avg     0.5327    0.5167    0.4492       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5206    0.8433    0.6438       300\n",
      "           1     0.5877    0.2233    0.3237       300\n",
      "\n",
      "    accuracy                         0.5333       600\n",
      "   macro avg     0.5541    0.5333    0.4837       600\n",
      "weighted avg     0.5541    0.5333    0.4837       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8627    0.8800    0.8713       300\n",
      "           1     0.8776    0.8600    0.8687       300\n",
      "\n",
      "    accuracy                         0.8700       600\n",
      "   macro avg     0.8701    0.8700    0.8700       600\n",
      "weighted avg     0.8701    0.8700    0.8700       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5143    0.4200    0.4624       300\n",
      "           1     0.5099    0.6033    0.5527       300\n",
      "\n",
      "    accuracy                         0.5117       600\n",
      "   macro avg     0.5121    0.5117    0.5075       600\n",
      "weighted avg     0.5121    0.5117    0.5075       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6605    0.3567    0.4632       300\n",
      "           1     0.5594    0.8167    0.6640       300\n",
      "\n",
      "    accuracy                         0.5867       600\n",
      "   macro avg     0.6099    0.5867    0.5636       600\n",
      "weighted avg     0.6099    0.5867    0.5636       600\n",
      "\n",
      "<Fold-3>\n",
      "Train indices: [0 1 2 3 4 6 7 8]\n",
      "Test indices: [5]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.87\n",
      "0.5116666666666667\n",
      "0.5866666666666667\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9380    0.8567    0.8955       300\n",
      "           1     0.8681    0.9433    0.9042       300\n",
      "\n",
      "    accuracy                         0.9000       600\n",
      "   macro avg     0.9030    0.9000    0.8998       600\n",
      "weighted avg     0.9030    0.9000    0.8998       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9771    0.8533    0.9110       300\n",
      "           1     0.8698    0.9800    0.9216       300\n",
      "\n",
      "    accuracy                         0.9167       600\n",
      "   macro avg     0.9235    0.9167    0.9163       600\n",
      "weighted avg     0.9235    0.9167    0.9163       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9018    0.8567    0.8786       300\n",
      "           1     0.8635    0.9067    0.8846       300\n",
      "\n",
      "    accuracy                         0.8817       600\n",
      "   macro avg     0.8826    0.8817    0.8816       600\n",
      "weighted avg     0.8826    0.8817    0.8816       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9275    0.8533    0.8889       300\n",
      "           1     0.8642    0.9333    0.8974       300\n",
      "\n",
      "    accuracy                         0.8933       600\n",
      "   macro avg     0.8959    0.8933    0.8932       600\n",
      "weighted avg     0.8959    0.8933    0.8932       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6624    0.8567    0.7471       300\n",
      "           1     0.7972    0.5633    0.6602       300\n",
      "\n",
      "    accuracy                         0.7100       600\n",
      "   macro avg     0.7298    0.7100    0.7036       600\n",
      "weighted avg     0.7298    0.7100    0.7036       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6244    0.8533    0.7211       300\n",
      "           1     0.7684    0.4867    0.5959       300\n",
      "\n",
      "    accuracy                         0.6700       600\n",
      "   macro avg     0.6964    0.6700    0.6585       600\n",
      "weighted avg     0.6964    0.6700    0.6585       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9560    0.8700    0.9110       300\n",
      "           1     0.8807    0.9600    0.9187       300\n",
      "\n",
      "    accuracy                         0.9150       600\n",
      "   macro avg     0.9184    0.9150    0.9148       600\n",
      "weighted avg     0.9184    0.9150    0.9148       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8662    0.8633    0.8648       300\n",
      "           1     0.8638    0.8667    0.8652       300\n",
      "\n",
      "    accuracy                         0.8650       600\n",
      "   macro avg     0.8650    0.8650    0.8650       600\n",
      "weighted avg     0.8650    0.8650    0.8650       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9255    0.8700    0.8969       300\n",
      "           1     0.8774    0.9300    0.9029       300\n",
      "\n",
      "    accuracy                         0.9000       600\n",
      "   macro avg     0.9014    0.9000    0.8999       600\n",
      "weighted avg     0.9014    0.9000    0.8999       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5820    0.8633    0.6953       300\n",
      "           1     0.7355    0.3800    0.5011       300\n",
      "\n",
      "    accuracy                         0.6217       600\n",
      "   macro avg     0.6588    0.6217    0.5982       600\n",
      "weighted avg     0.6588    0.6217    0.5982       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5128    0.8700    0.6452       300\n",
      "           1     0.5714    0.1733    0.2660       300\n",
      "\n",
      "    accuracy                         0.5217       600\n",
      "   macro avg     0.5421    0.5217    0.4556       600\n",
      "weighted avg     0.5421    0.5217    0.4556       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5211    0.8633    0.6499       300\n",
      "           1     0.6019    0.2067    0.3077       300\n",
      "\n",
      "    accuracy                         0.5350       600\n",
      "   macro avg     0.5615    0.5350    0.4788       600\n",
      "weighted avg     0.5615    0.5350    0.4788       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8627    0.8800    0.8713       300\n",
      "           1     0.8776    0.8600    0.8687       300\n",
      "\n",
      "    accuracy                         0.8700       600\n",
      "   macro avg     0.8701    0.8700    0.8700       600\n",
      "weighted avg     0.8701    0.8700    0.8700       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5143    0.4200    0.4624       300\n",
      "           1     0.5099    0.6033    0.5527       300\n",
      "\n",
      "    accuracy                         0.5117       600\n",
      "   macro avg     0.5121    0.5117    0.5075       600\n",
      "weighted avg     0.5121    0.5117    0.5075       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6605    0.3567    0.4632       300\n",
      "           1     0.5594    0.8167    0.6640       300\n",
      "\n",
      "    accuracy                         0.5867       600\n",
      "   macro avg     0.6099    0.5867    0.5636       600\n",
      "weighted avg     0.6099    0.5867    0.5636       600\n",
      "\n",
      "<Fold-4>\n",
      "Train indices: [1 2 3 4 5 6 7 8]\n",
      "Test indices: [0]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.87\n",
      "0.5116666666666667\n",
      "0.5866666666666667\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9446    0.8533    0.8967       300\n",
      "           1     0.8663    0.9500    0.9062       300\n",
      "\n",
      "    accuracy                         0.9017       600\n",
      "   macro avg     0.9055    0.9017    0.9014       600\n",
      "weighted avg     0.9055    0.9017    0.9014       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9737    0.8633    0.9152       300\n",
      "           1     0.8772    0.9767    0.9243       300\n",
      "\n",
      "    accuracy                         0.9200       600\n",
      "   macro avg     0.9255    0.9200    0.9197       600\n",
      "weighted avg     0.9255    0.9200    0.9197       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9343    0.8533    0.8920       300\n",
      "           1     0.8650    0.9400    0.9010       300\n",
      "\n",
      "    accuracy                         0.8967       600\n",
      "   macro avg     0.8997    0.8967    0.8965       600\n",
      "weighted avg     0.8997    0.8967    0.8965       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9217    0.8633    0.8916       300\n",
      "           1     0.8715    0.9267    0.8982       300\n",
      "\n",
      "    accuracy                         0.8950       600\n",
      "   macro avg     0.8966    0.8950    0.8949       600\n",
      "weighted avg     0.8966    0.8950    0.8949       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6547    0.8533    0.7410       300\n",
      "           1     0.7895    0.5500    0.6483       300\n",
      "\n",
      "    accuracy                         0.7017       600\n",
      "   macro avg     0.7221    0.7017    0.6946       600\n",
      "weighted avg     0.7221    0.7017    0.6946       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6333    0.8633    0.7306       300\n",
      "           1     0.7853    0.5000    0.6110       300\n",
      "\n",
      "    accuracy                         0.6817       600\n",
      "   macro avg     0.7093    0.6817    0.6708       600\n",
      "weighted avg     0.7093    0.6817    0.6708       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9565    0.8800    0.9167       300\n",
      "           1     0.8889    0.9600    0.9231       300\n",
      "\n",
      "    accuracy                         0.9200       600\n",
      "   macro avg     0.9227    0.9200    0.9199       600\n",
      "weighted avg     0.9227    0.9200    0.9199       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8697    0.8900    0.8797       300\n",
      "           1     0.8874    0.8667    0.8769       300\n",
      "\n",
      "    accuracy                         0.8783       600\n",
      "   macro avg     0.8785    0.8783    0.8783       600\n",
      "weighted avg     0.8785    0.8783    0.8783       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9199    0.8800    0.8995       300\n",
      "           1     0.8850    0.9233    0.9038       300\n",
      "\n",
      "    accuracy                         0.9017       600\n",
      "   macro avg     0.9024    0.9017    0.9016       600\n",
      "weighted avg     0.9024    0.9017    0.9016       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5842    0.8900    0.7054       300\n",
      "           1     0.7692    0.3667    0.4966       300\n",
      "\n",
      "    accuracy                         0.6283       600\n",
      "   macro avg     0.6767    0.6283    0.6010       600\n",
      "weighted avg     0.6767    0.6283    0.6010       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5116    0.8800    0.6471       300\n",
      "           1     0.5714    0.1600    0.2500       300\n",
      "\n",
      "    accuracy                         0.5200       600\n",
      "   macro avg     0.5415    0.5200    0.4485       600\n",
      "weighted avg     0.5415    0.5200    0.4485       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5154    0.8900    0.6528       300\n",
      "           1     0.5976    0.1633    0.2565       300\n",
      "\n",
      "    accuracy                         0.5267       600\n",
      "   macro avg     0.5565    0.5267    0.4547       600\n",
      "weighted avg     0.5565    0.5267    0.4547       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8627    0.8800    0.8713       300\n",
      "           1     0.8776    0.8600    0.8687       300\n",
      "\n",
      "    accuracy                         0.8700       600\n",
      "   macro avg     0.8701    0.8700    0.8700       600\n",
      "weighted avg     0.8701    0.8700    0.8700       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5143    0.4200    0.4624       300\n",
      "           1     0.5099    0.6033    0.5527       300\n",
      "\n",
      "    accuracy                         0.5117       600\n",
      "   macro avg     0.5121    0.5117    0.5075       600\n",
      "weighted avg     0.5121    0.5117    0.5075       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6605    0.3567    0.4632       300\n",
      "           1     0.5594    0.8167    0.6640       300\n",
      "\n",
      "    accuracy                         0.5867       600\n",
      "   macro avg     0.6099    0.5867    0.5636       600\n",
      "weighted avg     0.6099    0.5867    0.5636       600\n",
      "\n",
      "<Fold-5>\n",
      "Train indices: [0 1 2 3 4 5 6 7]\n",
      "Test indices: [8]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.87\n",
      "0.5116666666666667\n",
      "0.5866666666666667\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9455    0.8667    0.9043       300\n",
      "           1     0.8769    0.9500    0.9120       300\n",
      "\n",
      "    accuracy                         0.9083       600\n",
      "   macro avg     0.9112    0.9083    0.9082       600\n",
      "weighted avg     0.9112    0.9083    0.9082       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9736    0.8600    0.9133       300\n",
      "           1     0.8746    0.9767    0.9228       300\n",
      "\n",
      "    accuracy                         0.9183       600\n",
      "   macro avg     0.9241    0.9183    0.9181       600\n",
      "weighted avg     0.9241    0.9183    0.9181       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9091    0.8667    0.8874       300\n",
      "           1     0.8726    0.9133    0.8925       300\n",
      "\n",
      "    accuracy                         0.8900       600\n",
      "   macro avg     0.8909    0.8900    0.8899       600\n",
      "weighted avg     0.8909    0.8900    0.8899       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9149    0.8600    0.8866       300\n",
      "           1     0.8679    0.9200    0.8932       300\n",
      "\n",
      "    accuracy                         0.8900       600\n",
      "   macro avg     0.8914    0.8900    0.8899       600\n",
      "weighted avg     0.8914    0.8900    0.8899       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6468    0.8667    0.7407       300\n",
      "           1     0.7980    0.5267    0.6345       300\n",
      "\n",
      "    accuracy                         0.6967       600\n",
      "   macro avg     0.7224    0.6967    0.6876       600\n",
      "weighted avg     0.7224    0.6967    0.6876       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6262    0.8600    0.7247       300\n",
      "           1     0.7766    0.4867    0.5984       300\n",
      "\n",
      "    accuracy                         0.6733       600\n",
      "   macro avg     0.7014    0.6733    0.6615       600\n",
      "weighted avg     0.7014    0.6733    0.6615       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9529    0.8767    0.9132       300\n",
      "           1     0.8858    0.9567    0.9199       300\n",
      "\n",
      "    accuracy                         0.9167       600\n",
      "   macro avg     0.9194    0.9167    0.9165       600\n",
      "weighted avg     0.9194    0.9167    0.9165       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8617    0.8100    0.8351       300\n",
      "           1     0.8208    0.8700    0.8447       300\n",
      "\n",
      "    accuracy                         0.8400       600\n",
      "   macro avg     0.8412    0.8400    0.8399       600\n",
      "weighted avg     0.8412    0.8400    0.8399       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9359    0.8767    0.9053       300\n",
      "           1     0.8840    0.9400    0.9111       300\n",
      "\n",
      "    accuracy                         0.9083       600\n",
      "   macro avg     0.9100    0.9083    0.9082       600\n",
      "weighted avg     0.9100    0.9083    0.9082       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5800    0.8100    0.6759       300\n",
      "           1     0.6851    0.4133    0.5156       300\n",
      "\n",
      "    accuracy                         0.6117       600\n",
      "   macro avg     0.6325    0.6117    0.5958       600\n",
      "weighted avg     0.6325    0.6117    0.5958       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5127    0.8767    0.6470       300\n",
      "           1     0.5747    0.1667    0.2584       300\n",
      "\n",
      "    accuracy                         0.5217       600\n",
      "   macro avg     0.5437    0.5217    0.4527       600\n",
      "weighted avg     0.5437    0.5217    0.4527       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5294    0.8100    0.6403       300\n",
      "           1     0.5957    0.2800    0.3810       300\n",
      "\n",
      "    accuracy                         0.5450       600\n",
      "   macro avg     0.5626    0.5450    0.5106       600\n",
      "weighted avg     0.5626    0.5450    0.5106       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8627    0.8800    0.8713       300\n",
      "           1     0.8776    0.8600    0.8687       300\n",
      "\n",
      "    accuracy                         0.8700       600\n",
      "   macro avg     0.8701    0.8700    0.8700       600\n",
      "weighted avg     0.8701    0.8700    0.8700       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5143    0.4200    0.4624       300\n",
      "           1     0.5099    0.6033    0.5527       300\n",
      "\n",
      "    accuracy                         0.5117       600\n",
      "   macro avg     0.5121    0.5117    0.5075       600\n",
      "weighted avg     0.5121    0.5117    0.5075       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6605    0.3567    0.4632       300\n",
      "           1     0.5594    0.8167    0.6640       300\n",
      "\n",
      "    accuracy                         0.5867       600\n",
      "   macro avg     0.6099    0.5867    0.5636       600\n",
      "weighted avg     0.6099    0.5867    0.5636       600\n",
      "\n",
      "<Fold-6>\n",
      "Train indices: [0 1 3 4 5 6 7 8]\n",
      "Test indices: [2]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.87\n",
      "0.5116666666666667\n",
      "0.5866666666666667\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9341    0.8500    0.8901       300\n",
      "           1     0.8624    0.9400    0.8995       300\n",
      "\n",
      "    accuracy                         0.8950       600\n",
      "   macro avg     0.8982    0.8950    0.8948       600\n",
      "weighted avg     0.8982    0.8950    0.8948       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9773    0.8600    0.9149       300\n",
      "           1     0.8750    0.9800    0.9245       300\n",
      "\n",
      "    accuracy                         0.9200       600\n",
      "   macro avg     0.9261    0.9200    0.9197       600\n",
      "weighted avg     0.9261    0.9200    0.9197       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8885    0.8500    0.8688       300\n",
      "           1     0.8562    0.8933    0.8744       300\n",
      "\n",
      "    accuracy                         0.8717       600\n",
      "   macro avg     0.8724    0.8717    0.8716       600\n",
      "weighted avg     0.8724    0.8717    0.8716       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9214    0.8600    0.8897       300\n",
      "           1     0.8688    0.9267    0.8968       300\n",
      "\n",
      "    accuracy                         0.8933       600\n",
      "   macro avg     0.8951    0.8933    0.8932       600\n",
      "weighted avg     0.8951    0.8933    0.8932       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6555    0.8500    0.7402       300\n",
      "           1     0.7867    0.5533    0.6497       300\n",
      "\n",
      "    accuracy                         0.7017       600\n",
      "   macro avg     0.7211    0.7017    0.6950       600\n",
      "weighted avg     0.7211    0.7017    0.6950       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6202    0.8600    0.7207       300\n",
      "           1     0.7717    0.4733    0.5868       300\n",
      "\n",
      "    accuracy                         0.6667       600\n",
      "   macro avg     0.6960    0.6667    0.6537       600\n",
      "weighted avg     0.6960    0.6667    0.6537       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9500    0.8867    0.9172       300\n",
      "           1     0.8938    0.9533    0.9226       300\n",
      "\n",
      "    accuracy                         0.9200       600\n",
      "   macro avg     0.9219    0.9200    0.9199       600\n",
      "weighted avg     0.9219    0.9200    0.9199       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8698    0.9133    0.8911       300\n",
      "           1     0.9088    0.8633    0.8855       300\n",
      "\n",
      "    accuracy                         0.8883       600\n",
      "   macro avg     0.8893    0.8883    0.8883       600\n",
      "weighted avg     0.8893    0.8883    0.8883       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9236    0.8867    0.9048       300\n",
      "           1     0.8910    0.9267    0.9085       300\n",
      "\n",
      "    accuracy                         0.9067       600\n",
      "   macro avg     0.9073    0.9067    0.9066       600\n",
      "weighted avg     0.9073    0.9067    0.9066       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5781    0.9133    0.7080       300\n",
      "           1     0.7937    0.3333    0.4695       300\n",
      "\n",
      "    accuracy                         0.6233       600\n",
      "   macro avg     0.6859    0.6233    0.5887       600\n",
      "weighted avg     0.6859    0.6233    0.5887       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5086    0.8867    0.6464       300\n",
      "           1     0.5584    0.1433    0.2281       300\n",
      "\n",
      "    accuracy                         0.5150       600\n",
      "   macro avg     0.5335    0.5150    0.4373       600\n",
      "weighted avg     0.5335    0.5150    0.4373       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5055    0.9133    0.6508       300\n",
      "           1     0.5517    0.1067    0.1788       300\n",
      "\n",
      "    accuracy                         0.5100       600\n",
      "   macro avg     0.5286    0.5100    0.4148       600\n",
      "weighted avg     0.5286    0.5100    0.4148       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8627    0.8800    0.8713       300\n",
      "           1     0.8776    0.8600    0.8687       300\n",
      "\n",
      "    accuracy                         0.8700       600\n",
      "   macro avg     0.8701    0.8700    0.8700       600\n",
      "weighted avg     0.8701    0.8700    0.8700       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5143    0.4200    0.4624       300\n",
      "           1     0.5099    0.6033    0.5527       300\n",
      "\n",
      "    accuracy                         0.5117       600\n",
      "   macro avg     0.5121    0.5117    0.5075       600\n",
      "weighted avg     0.5121    0.5117    0.5075       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6605    0.3567    0.4632       300\n",
      "           1     0.5594    0.8167    0.6640       300\n",
      "\n",
      "    accuracy                         0.5867       600\n",
      "   macro avg     0.6099    0.5867    0.5636       600\n",
      "weighted avg     0.6099    0.5867    0.5636       600\n",
      "\n",
      "<Fold-7>\n",
      "Train indices: [0 1 2 3 5 6 7 8]\n",
      "Test indices: [4]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.87\n",
      "0.5116666666666667\n",
      "0.5866666666666667\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9556    0.8600    0.9053       300\n",
      "           1     0.8727    0.9600    0.9143       300\n",
      "\n",
      "    accuracy                         0.9100       600\n",
      "   macro avg     0.9141    0.9100    0.9098       600\n",
      "weighted avg     0.9141    0.9100    0.9098       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9735    0.8567    0.9113       300\n",
      "           1     0.8720    0.9767    0.9214       300\n",
      "\n",
      "    accuracy                         0.9167       600\n",
      "   macro avg     0.9228    0.9167    0.9164       600\n",
      "weighted avg     0.9228    0.9167    0.9164       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9053    0.8600    0.8821       300\n",
      "           1     0.8667    0.9100    0.8878       300\n",
      "\n",
      "    accuracy                         0.8850       600\n",
      "   macro avg     0.8860    0.8850    0.8849       600\n",
      "weighted avg     0.8860    0.8850    0.8849       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9146    0.8567    0.8847       300\n",
      "           1     0.8652    0.9200    0.8918       300\n",
      "\n",
      "    accuracy                         0.8883       600\n",
      "   macro avg     0.8899    0.8883    0.8882       600\n",
      "weighted avg     0.8899    0.8883    0.8882       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6515    0.8600    0.7414       300\n",
      "           1     0.7941    0.5400    0.6429       300\n",
      "\n",
      "    accuracy                         0.7000       600\n",
      "   macro avg     0.7228    0.7000    0.6921       600\n",
      "weighted avg     0.7228    0.7000    0.6921       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6193    0.8567    0.7189       300\n",
      "           1     0.7676    0.4733    0.5856       300\n",
      "\n",
      "    accuracy                         0.6650       600\n",
      "   macro avg     0.6934    0.6650    0.6522       600\n",
      "weighted avg     0.6934    0.6650    0.6522       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9531    0.8800    0.9151       300\n",
      "           1     0.8885    0.9567    0.9213       300\n",
      "\n",
      "    accuracy                         0.9183       600\n",
      "   macro avg     0.9208    0.9183    0.9182       600\n",
      "weighted avg     0.9208    0.9183    0.9182       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8701    0.8933    0.8816       300\n",
      "           1     0.8904    0.8667    0.8784       300\n",
      "\n",
      "    accuracy                         0.8800       600\n",
      "   macro avg     0.8803    0.8800    0.8800       600\n",
      "weighted avg     0.8803    0.8800    0.8800       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9329    0.8800    0.9057       300\n",
      "           1     0.8864    0.9367    0.9109       300\n",
      "\n",
      "    accuracy                         0.9083       600\n",
      "   macro avg     0.9096    0.9083    0.9083       600\n",
      "weighted avg     0.9096    0.9083    0.9083       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5877    0.8933    0.7090       300\n",
      "           1     0.7778    0.3733    0.5045       300\n",
      "\n",
      "    accuracy                         0.6333       600\n",
      "   macro avg     0.6827    0.6333    0.6067       600\n",
      "weighted avg     0.6827    0.6333    0.6067       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5126    0.8800    0.6479       300\n",
      "           1     0.5765    0.1633    0.2545       300\n",
      "\n",
      "    accuracy                         0.5217       600\n",
      "   macro avg     0.5445    0.5217    0.4512       600\n",
      "weighted avg     0.5445    0.5217    0.4512       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5194    0.8933    0.6569       300\n",
      "           1     0.6190    0.1733    0.2708       300\n",
      "\n",
      "    accuracy                         0.5333       600\n",
      "   macro avg     0.5692    0.5333    0.4638       600\n",
      "weighted avg     0.5692    0.5333    0.4638       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8627    0.8800    0.8713       300\n",
      "           1     0.8776    0.8600    0.8687       300\n",
      "\n",
      "    accuracy                         0.8700       600\n",
      "   macro avg     0.8701    0.8700    0.8700       600\n",
      "weighted avg     0.8701    0.8700    0.8700       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5143    0.4200    0.4624       300\n",
      "           1     0.5099    0.6033    0.5527       300\n",
      "\n",
      "    accuracy                         0.5117       600\n",
      "   macro avg     0.5121    0.5117    0.5075       600\n",
      "weighted avg     0.5121    0.5117    0.5075       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6605    0.3567    0.4632       300\n",
      "           1     0.5594    0.8167    0.6640       300\n",
      "\n",
      "    accuracy                         0.5867       600\n",
      "   macro avg     0.6099    0.5867    0.5636       600\n",
      "weighted avg     0.6099    0.5867    0.5636       600\n",
      "\n",
      "<Fold-8>\n",
      "Train indices: [0 1 2 4 5 6 7 8]\n",
      "Test indices: [3]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.87\n",
      "0.5116666666666667\n",
      "0.5866666666666667\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9483    0.8567    0.9002       300\n",
      "           1     0.8693    0.9533    0.9094       300\n",
      "\n",
      "    accuracy                         0.9050       600\n",
      "   macro avg     0.9088    0.9050    0.9048       600\n",
      "weighted avg     0.9088    0.9050    0.9048       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9734    0.8533    0.9094       300\n",
      "           1     0.8694    0.9767    0.9199       300\n",
      "\n",
      "    accuracy                         0.9150       600\n",
      "   macro avg     0.9214    0.9150    0.9147       600\n",
      "weighted avg     0.9214    0.9150    0.9147       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9146    0.8567    0.8847       300\n",
      "           1     0.8652    0.9200    0.8918       300\n",
      "\n",
      "    accuracy                         0.8883       600\n",
      "   macro avg     0.8899    0.8883    0.8882       600\n",
      "weighted avg     0.8899    0.8883    0.8882       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9242    0.8533    0.8873       300\n",
      "           1     0.8638    0.9300    0.8957       300\n",
      "\n",
      "    accuracy                         0.8917       600\n",
      "   macro avg     0.8940    0.8917    0.8915       600\n",
      "weighted avg     0.8940    0.8917    0.8915       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6539    0.8567    0.7417       300\n",
      "           1     0.7923    0.5467    0.6469       300\n",
      "\n",
      "    accuracy                         0.7017       600\n",
      "   macro avg     0.7231    0.7017    0.6943       600\n",
      "weighted avg     0.7231    0.7017    0.6943       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6169    0.8533    0.7161       300\n",
      "           1     0.7622    0.4700    0.5814       300\n",
      "\n",
      "    accuracy                         0.6617       600\n",
      "   macro avg     0.6895    0.6617    0.6488       600\n",
      "weighted avg     0.6895    0.6617    0.6488       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9373    0.8467    0.8897       300\n",
      "           1     0.8602    0.9433    0.8998       300\n",
      "\n",
      "    accuracy                         0.8950       600\n",
      "   macro avg     0.8987    0.8950    0.8948       600\n",
      "weighted avg     0.8987    0.8950    0.8948       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8621    0.8333    0.8475       300\n",
      "           1     0.8387    0.8667    0.8525       300\n",
      "\n",
      "    accuracy                         0.8500       600\n",
      "   macro avg     0.8504    0.8500    0.8500       600\n",
      "weighted avg     0.8504    0.8500    0.8500       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9203    0.8467    0.8819       300\n",
      "           1     0.8580    0.9267    0.8910       300\n",
      "\n",
      "    accuracy                         0.8867       600\n",
      "   macro avg     0.8892    0.8867    0.8865       600\n",
      "weighted avg     0.8892    0.8867    0.8865       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5787    0.8333    0.6831       300\n",
      "           1     0.7024    0.3933    0.5043       300\n",
      "\n",
      "    accuracy                         0.6133       600\n",
      "   macro avg     0.6405    0.6133    0.5937       600\n",
      "weighted avg     0.6405    0.6133    0.5937       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5248    0.8467    0.6480       300\n",
      "           1     0.6034    0.2333    0.3365       300\n",
      "\n",
      "    accuracy                         0.5400       600\n",
      "   macro avg     0.5641    0.5400    0.4922       600\n",
      "weighted avg     0.5641    0.5400    0.4922       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5230    0.8333    0.6427       300\n",
      "           1     0.5902    0.2400    0.3412       300\n",
      "\n",
      "    accuracy                         0.5367       600\n",
      "   macro avg     0.5566    0.5367    0.4920       600\n",
      "weighted avg     0.5566    0.5367    0.4920       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8627    0.8800    0.8713       300\n",
      "           1     0.8776    0.8600    0.8687       300\n",
      "\n",
      "    accuracy                         0.8700       600\n",
      "   macro avg     0.8701    0.8700    0.8700       600\n",
      "weighted avg     0.8701    0.8700    0.8700       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5143    0.4200    0.4624       300\n",
      "           1     0.5099    0.6033    0.5527       300\n",
      "\n",
      "    accuracy                         0.5117       600\n",
      "   macro avg     0.5121    0.5117    0.5075       600\n",
      "weighted avg     0.5121    0.5117    0.5075       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6605    0.3567    0.4632       300\n",
      "           1     0.5594    0.8167    0.6640       300\n",
      "\n",
      "    accuracy                         0.5867       600\n",
      "   macro avg     0.6099    0.5867    0.5636       600\n",
      "weighted avg     0.6099    0.5867    0.5636       600\n",
      "\n",
      "<Fold-9>\n",
      "Train indices: [0 1 2 3 4 5 7 8]\n",
      "Test indices: [6]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.87\n",
      "0.5116666666666667\n",
      "0.5866666666666667\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9427    0.8767    0.9085       300\n",
      "           1     0.8847    0.9467    0.9147       300\n",
      "\n",
      "    accuracy                         0.9117       600\n",
      "   macro avg     0.9137    0.9117    0.9116       600\n",
      "weighted avg     0.9137    0.9117    0.9116       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9733    0.8500    0.9075       300\n",
      "           1     0.8669    0.9767    0.9185       300\n",
      "\n",
      "    accuracy                         0.9133       600\n",
      "   macro avg     0.9201    0.9133    0.9130       600\n",
      "weighted avg     0.9201    0.9133    0.9130       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9069    0.8767    0.8915       300\n",
      "           1     0.8806    0.9100    0.8951       300\n",
      "\n",
      "    accuracy                         0.8933       600\n",
      "   macro avg     0.8938    0.8933    0.8933       600\n",
      "weighted avg     0.8938    0.8933    0.8933       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9107    0.8500    0.8793       300\n",
      "           1     0.8594    0.9167    0.8871       300\n",
      "\n",
      "    accuracy                         0.8833       600\n",
      "   macro avg     0.8850    0.8833    0.8832       600\n",
      "weighted avg     0.8850    0.8833    0.8832       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6526    0.8767    0.7482       300\n",
      "           1     0.8122    0.5333    0.6439       300\n",
      "\n",
      "    accuracy                         0.7050       600\n",
      "   macro avg     0.7324    0.7050    0.6960       600\n",
      "weighted avg     0.7324    0.7050    0.6960       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6159    0.8500    0.7143       300\n",
      "           1     0.7581    0.4700    0.5802       300\n",
      "\n",
      "    accuracy                         0.6600       600\n",
      "   macro avg     0.6870    0.6600    0.6473       600\n",
      "weighted avg     0.6870    0.6600    0.6473       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9343    0.8533    0.8920       300\n",
      "           1     0.8650    0.9400    0.9010       300\n",
      "\n",
      "    accuracy                         0.8967       600\n",
      "   macro avg     0.8997    0.8967    0.8965       600\n",
      "weighted avg     0.8997    0.8967    0.8965       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8636    0.8233    0.8430       300\n",
      "           1     0.8312    0.8700    0.8502       300\n",
      "\n",
      "    accuracy                         0.8467       600\n",
      "   macro avg     0.8474    0.8467    0.8466       600\n",
      "weighted avg     0.8474    0.8467    0.8466       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9176    0.8533    0.8843       300\n",
      "           1     0.8629    0.9233    0.8921       300\n",
      "\n",
      "    accuracy                         0.8883       600\n",
      "   macro avg     0.8902    0.8883    0.8882       600\n",
      "weighted avg     0.8902    0.8883    0.8882       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5758    0.8233    0.6776       300\n",
      "           1     0.6901    0.3933    0.5011       300\n",
      "\n",
      "    accuracy                         0.6083       600\n",
      "   macro avg     0.6329    0.6083    0.5894       600\n",
      "weighted avg     0.6329    0.6083    0.5894       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5246    0.8533    0.6497       300\n",
      "           1     0.6071    0.2267    0.3301       300\n",
      "\n",
      "    accuracy                         0.5400       600\n",
      "   macro avg     0.5659    0.5400    0.4899       600\n",
      "weighted avg     0.5659    0.5400    0.4899       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5289    0.8233    0.6441       300\n",
      "           1     0.6015    0.2667    0.3695       300\n",
      "\n",
      "    accuracy                         0.5450       600\n",
      "   macro avg     0.5652    0.5450    0.5068       600\n",
      "weighted avg     0.5652    0.5450    0.5068       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8627    0.8800    0.8713       300\n",
      "           1     0.8776    0.8600    0.8687       300\n",
      "\n",
      "    accuracy                         0.8700       600\n",
      "   macro avg     0.8701    0.8700    0.8700       600\n",
      "weighted avg     0.8701    0.8700    0.8700       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5143    0.4200    0.4624       300\n",
      "           1     0.5099    0.6033    0.5527       300\n",
      "\n",
      "    accuracy                         0.5117       600\n",
      "   macro avg     0.5121    0.5117    0.5075       600\n",
      "weighted avg     0.5121    0.5117    0.5075       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6605    0.3567    0.4632       300\n",
      "           1     0.5594    0.8167    0.6640       300\n",
      "\n",
      "    accuracy                         0.5867       600\n",
      "   macro avg     0.6099    0.5867    0.5636       600\n",
      "weighted avg     0.6099    0.5867    0.5636       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cの範囲を指定\n",
    "C_values = {'C': [0.01, 0.1, 1, 10, 100, 1000, 2000, 3000, 4000, 5000]}\n",
    "# C_values = {'C': [100]}\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "kfold = KFold(n_splits=9, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "results = pd.DataFrame(columns=['C_RBF_LQP1','Score_RBF_LQP1', 'tnr_rbf_lqp1', 'tpr_rbf_lqp1',\n",
    "                                'C_RBF_SQP','Score_RBF_SQP', 'tnr_rbf_sqp', 'tpr_rbf_sqp',\n",
    "                                'C_RBF_LQP2','Score_RBF_LQP2', 'tnr_rbf_lqp2', 'tpr_rbf_lqp2',\n",
    "                                'C_LINEAR_LQP1','Score_LINEAR_LQP1', 'tnr_linear_lqp1', 'tpr_linear_lqp1',\n",
    "                                'C_LINEAR_SQP','Score_LINEAR_SQP', 'tnr_linear_sqp', 'tpr_linear_sqp',\n",
    "                                'C_LINEAR_LQP2','Score_LINEAR_LQP2', 'tnr_linear_lqp2', 'tpr_linear_lqp2',\n",
    "                                \n",
    "                                'C_RBF2_LQP1','Score_RBF2_LQP1', 'tnr_rbf2_lqp1', 'tpr_rbf2_lqp1',\n",
    "                                'C_RBF2_SQP','Score_RBF2_SQP', 'tnr_rbf2_sqp', 'tpr_rbf2_sqp',\n",
    "                                'C_RBF2_LQP2','Score_RBF2_LQP2', 'tnr_rbf2_lqp2', 'tpr_rbf2_lqp2',\n",
    "                                'C_LINEAR2_LQP1','Score_LINEAR2_LQP1', 'tnr_linear2_lqp1', 'tpr_linear2_lqp1',\n",
    "                                'C_LINEAR2_SQP','Score_LINEAR2_SQP', 'tnr_linear2_sqp2', 'tpr_linear2_sqp',\n",
    "                                'C_LINEAR2_LQP2','Score_LINEAR2_LQP2', 'tnr_linear2_lqp2', 'tpr_linear2_lqp2',\n",
    "                                \n",
    "                                'Threshold_LQP1', 'LQP1_old', 'tnr_old_lqp1', 'tpr_old_lqp1',\n",
    "                                'Threshold_SQP', 'SQP_old', 'tnr_old_sqp', 'tpr_old_sqp',\n",
    "                                'Threshold_LQP2', 'LQP2_old', 'tnr_old_lqp2', 'tpr_old_lqp2'])\n",
    "\n",
    "\n",
    "# results = pd.DataFrame(columns=['C_RBF_LQP1','Score_RBF_LQP1', 'tnr_rbf_lqp1', 'tpr_rbf_lqp1',\n",
    "#                                 'C_RBF_SQP','Score_RBF_SQP', 'tnr_rbf_sqp', 'tpr_rbf_sqp',\n",
    "#                                 'C_RBF_LQP2','Score_RBF_LQP2', 'tnr_rbf_lqp2', 'tpr_rbf_lqp2',\n",
    "#                                 'C_LINEAR_LQP1','Score_LINEAR_LQP1', 'tnr_linear_lqp1', 'tpr_linear_lqp1',\n",
    "#                                 'C_LINEAR_SQP','Score_LINEAR_SQP', 'tnr_linear_sqp', 'tpr_linear_sqp',\n",
    "#                                 'C_LINEAR_LQP2','Score_LINEAR_LQP2', 'tnr_linear_lqp2', 'tpr_linear_lqp2',\n",
    "                                                        \n",
    "#                                 'Threshold_LQP1', 'LQP1_old', 'tnr_old_lqp1', 'tpr_old_lqp1',\n",
    "#                                 'Threshold_SQP', 'SQP_old', 'tnr_old_sqp', 'tpr_old_sqp',\n",
    "#                                 'Threshold_LQP2', 'LQP2_old', 'tnr_old_lqp2', 'tpr_old_lqp2'])\n",
    "\n",
    "    \n",
    "X_index = np.arange(9)  # インデックスとして0から8までの数字を用意\n",
    "\n",
    "# ループで各分割のtrain_idsとtest_idsを取得\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(X_index)):\n",
    "    print(f\"<Fold-{fold+1}>\")\n",
    "    print(\"Train indices:\", train_ids)\n",
    "    print(\"Test indices:\", test_ids)\n",
    "    \n",
    "    train_data = [X_train_list[i] for i in train_ids]\n",
    "    train_data_OG = [X_train_onlyGhost_list[i] for i in train_ids]\n",
    "    train_label = [Y_train_list[i] for i in train_ids]\n",
    "    \n",
    "    val_data = [X_train_list[i] for i in test_ids]\n",
    "    val_data_OG = [X_train_onlyGhost_list[i] for i in test_ids]\n",
    "    val_label = [Y_train_list[i] for i in test_ids]\n",
    "    \n",
    "    X_train = [item for data in train_data for item in data]\n",
    "    X_train_OG = [item for data in train_data_OG for item in data]\n",
    "    Y_train = [item for data in train_label for item in data]\n",
    "    \n",
    "    X_val = [item for data in val_data for item in data]\n",
    "    X_val_OG = [item for data in val_data_OG for item in data]\n",
    "    Y_val = [item for data in val_label for item in data]\n",
    "    \n",
    "    # print(len(Y_train))\n",
    "    # print(len(Y_val))\n",
    "    \n",
    "    test_data1 = [item for data in X_test_list1 for item in data]\n",
    "    test_data_OG1 = [item for data in X_test_onlyGhost_list1 for item in data]\n",
    "    test_label1 = [item for data in Y_test_list1 for item in data]\n",
    "    MAE_data1 = [item for data in MAE_list_t1 for item in data]\n",
    "    FINAL_QP_data1 = [item for data in FINAL_QP_list_t1 for item in data]\n",
    "    \n",
    "    test_data2 = [item for data in X_test_list2 for item in data]\n",
    "    test_data_OG2 = [item for data in X_test_onlyGhost_list2 for item in data]\n",
    "    test_label2 = [item for data in Y_test_list2 for item in data]\n",
    "    MAE_data2 = [item for data in MAE_list_t2 for item in data]\n",
    "    FINAL_QP_data2 = [item for data in FINAL_QP_list_t2 for item in data]\n",
    "    \n",
    "    test_data3 = [item for data in X_test_list3 for item in data]\n",
    "    test_data_OG3 = [item for data in X_test_onlyGhost_list3 for item in data]\n",
    "    test_label3 = [item for data in Y_test_list3 for item in data]\n",
    "    MAE_data3 = [item for data in MAE_list_t3 for item in data]\n",
    "    FINAL_QP_data3 = [item for data in FINAL_QP_list_t3 for item in data]\n",
    "    \n",
    "    print(len(MAE_data1))\n",
    "    print(len(MAE_data2))\n",
    "    print(len(MAE_data3))\n",
    "    \n",
    "                                                                                   \n",
    "    best_threshold = 0\n",
    "    best_accuracy = 0\n",
    "    best_predicted_labels = []\n",
    "    best_ground_truth_labels = []\n",
    "    \n",
    "    sameQP_best_threshold = 0\n",
    "    sameQP_best_accuracy = 0\n",
    "    sameQP_best_predicted_labels = []\n",
    "    sameQP_best_ground_truth_labels = []\n",
    "    \n",
    "    largeQP_best_threshold = 0\n",
    "    largeQP_best_accuracy = 0\n",
    "    largeQP_best_predicted_labels = []\n",
    "    largeQP_best_ground_truth_labels = []\n",
    "            \n",
    "    for threshold in np.arange(0.00, 1.01, 0.01):\n",
    "        test_old = np.array([is_double_compressed(MAE_data1[i], FINAL_QP_data1[i], threshold) for i in range(600)])\n",
    "        predicted_labels = test_old.astype(int)\n",
    "        ground_truth_labels = np.array(test_label1)\n",
    "        accuracy = np.sum(ground_truth_labels == predicted_labels) / len(ground_truth_labels)\n",
    "    \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_threshold = threshold\n",
    "            best_predicted_labels = predicted_labels\n",
    "            best_ground_truth_labels = ground_truth_labels\n",
    "            \n",
    "    for threshold in np.arange(0.00, 1.01, 0.01):\n",
    "        test_sameQP_old = np.array([is_double_compressed(MAE_data2[i], FINAL_QP_data2[i], threshold) for i in range(600)])\n",
    "        same_predicted_labels = test_sameQP_old.astype(int)\n",
    "        same_ground_truth_labels = np.array(test_label2)\n",
    "        same_accuracy = np.sum(same_ground_truth_labels == same_predicted_labels) / len(same_ground_truth_labels)\n",
    "    \n",
    "        if same_accuracy > sameQP_best_accuracy:\n",
    "            sameQP_best_accuracy = same_accuracy\n",
    "            sameQP_best_threshold = threshold\n",
    "            sameQP_best_predicted_labels = same_predicted_labels\n",
    "            sameQP_best_ground_truth_labels = same_ground_truth_labels\n",
    "                        \n",
    "    for threshold in np.arange(0.00, 1.01, 0.01):\n",
    "        test_largeQP_old = np.array([is_double_compressed(MAE_data3[i], FINAL_QP_data3[i], threshold) for i in range(600)])\n",
    "        large_predicted_labels = test_largeQP_old.astype(int)\n",
    "        large_ground_truth_labels = np.array(test_label3)\n",
    "        large_accuracy = np.sum(large_ground_truth_labels == large_predicted_labels) / len(large_ground_truth_labels)\n",
    "    \n",
    "        if large_accuracy > largeQP_best_accuracy:\n",
    "            largeQP_best_accuracy = large_accuracy\n",
    "            largeQP_best_threshold = threshold\n",
    "            largeQP_best_predicted_labels = large_predicted_labels\n",
    "            largeQP_best_ground_truth_labels = large_ground_truth_labels       \n",
    "            \n",
    "            \n",
    "    print(best_accuracy)\n",
    "    print(sameQP_best_accuracy)\n",
    "    print(largeQP_best_accuracy)\n",
    "            \n",
    "            \n",
    "    best_val_score_RBF, best_svm_model_RBF, best_c_value_RBF = 0, None, None\n",
    "    best_val_score_onlyGhost_RBF, best_svm_model_onlyGhost_RBF, best_c_value_onlyGhost_RBF = 0, None, None\n",
    "    \n",
    "    best_val_score_LINEAR, best_svm_model_LINEAR, best_c_value_LINEAR = 0, None, None\n",
    "    best_val_score_onlyGhost_LINEAR, best_svm_model_onlyGhost_LINEAR, best_c_value_onlyGhost_LINEAR = 0, None, None\n",
    "        \n",
    "    for C_value in C_values['C']:    \n",
    "        # SVMモデルのインスタンスを作成\n",
    "        svm_model_RBF = SVC(kernel='rbf', C=C_value)\n",
    "        svm_model_onlyGhost_RBF = SVC(kernel='rbf', C=C_value)\n",
    "        \n",
    "        svm_model_LINEAR = SVC(kernel='linear', C=C_value)\n",
    "        svm_model_onlyGhost_LINEAR = SVC(kernel='linear', C=C_value)\n",
    "\n",
    "        # 訓練データで訓練\n",
    "        svm_model_RBF.fit(X_train, Y_train)\n",
    "        svm_model_onlyGhost_RBF.fit(X_train_OG, Y_train)\n",
    "        \n",
    "        svm_model_LINEAR.fit(X_train, Y_train)\n",
    "        svm_model_onlyGhost_LINEAR.fit(X_train_OG, Y_train)\n",
    "\n",
    "        \n",
    "        val_accuracy_RBF = accuracy_score(Y_val, svm_model_RBF.predict(X_val))\n",
    "        val_accuracy_onlyGhost_RBF = accuracy_score(Y_val, svm_model_onlyGhost_RBF.predict(X_val_OG))\n",
    "        \n",
    "        val_accuracy_LINEAR = accuracy_score(Y_val, svm_model_LINEAR.predict(X_val))\n",
    "        val_accuracy_onlyGhost_LINEAR = accuracy_score(Y_val, svm_model_onlyGhost_LINEAR.predict(X_val_OG))\n",
    "        \n",
    "\n",
    "        # 検証データでの精度が最も高かった場合、そのモデルを保存\n",
    "        if val_accuracy_RBF > best_val_score_RBF:\n",
    "            best_val_score_RBF, best_svm_model_RBF, best_c_value_RBF = val_accuracy_RBF, svm_model_RBF, C_value\n",
    "\n",
    "        if val_accuracy_onlyGhost_RBF > best_val_score_onlyGhost_RBF:\n",
    "            best_val_score_onlyGhost_RBF, best_svm_model_onlyGhost_RBF, best_c_value_onlyGhost_RBF = val_accuracy_onlyGhost_RBF, svm_model_onlyGhost_RBF, C_value\n",
    "            \n",
    "        if val_accuracy_LINEAR > best_val_score_LINEAR:\n",
    "            best_val_score_LINEAR, best_svm_model_LINEAR, best_c_value_LINEAR = val_accuracy_LINEAR, svm_model_LINEAR, C_value\n",
    "\n",
    "        if val_accuracy_onlyGhost_LINEAR > best_val_score_onlyGhost_LINEAR:\n",
    "            best_val_score_onlyGhost_LINEAR, best_svm_model_onlyGhost_LINEAR, best_c_value_onlyGhost_LINEAR = val_accuracy_onlyGhost_LINEAR, svm_model_onlyGhost_LINEAR, C_value\n",
    "\n",
    "\n",
    "    # テストデータで評価    \n",
    "    predictions_RBF = best_svm_model_RBF.predict(test_data1)\n",
    "    # predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test)\n",
    "    accuracy_RBF = accuracy_score(test_label1, predictions_RBF)\n",
    "    report_RBF = classification_report(test_label1, predictions_RBF, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label1, predictions_RBF)\n",
    "    tnr_rbf_lqp1 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_rbf_lqp1 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'report_RBF:\\n{report_RBF}')\n",
    "    \n",
    "    predictions_LINEAR = best_svm_model_LINEAR.predict(test_data1)\n",
    "    # predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test)\n",
    "    accuracy_LINEAR = accuracy_score(test_label1, predictions_LINEAR)\n",
    "    report_LINEAR = classification_report(test_label1, predictions_LINEAR, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label1, predictions_LINEAR)\n",
    "    tnr_linear_lqp1 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_linear_lqp1 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'report_LINEAR:\\n{report_LINEAR}')\n",
    "    \n",
    "    same_predictions_RBF = best_svm_model_RBF.predict(test_data2)\n",
    "    # same_predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test_sameQP)\n",
    "    same_accuracy_RBF = accuracy_score(test_label2, same_predictions_RBF)\n",
    "    same_report_RBF = classification_report(test_label2, same_predictions_RBF, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label2, same_predictions_RBF)\n",
    "    tnr_rbf_sqp = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_rbf_sqp = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'same_report_RBF:\\n{same_report_RBF}')\n",
    "    \n",
    "    same_predictions_LINEAR = best_svm_model_LINEAR.predict(test_data2)\n",
    "    # same_predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test_sameQP)\n",
    "    same_accuracy_LINEAR = accuracy_score(test_label2, same_predictions_LINEAR)\n",
    "    same_report_LINEAR = classification_report(test_label2, same_predictions_LINEAR, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label2, same_predictions_LINEAR)\n",
    "    tnr_linear_sqp = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_linear_sqp = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'same_report_LINEAR:\\n{same_report_LINEAR}')\n",
    "    \n",
    "    large_predictions_RBF = best_svm_model_RBF.predict(test_data3)\n",
    "    # large_predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test_largeQP)\n",
    "    large_accuracy_RBF = accuracy_score(test_label3, large_predictions_RBF)\n",
    "    large_report_RBF = classification_report(test_label3, large_predictions_RBF, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label3, large_predictions_RBF)\n",
    "    tnr_rbf_lqp2 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_rbf_lqp2 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'large_report_RBF:\\n{large_report_RBF}')\n",
    "    \n",
    "    large_predictions_LINEAR = best_svm_model_LINEAR.predict(test_data3)\n",
    "    # large_predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test_largeQP)\n",
    "    large_accuracy_LINEAR = accuracy_score(test_label3, large_predictions_LINEAR)\n",
    "    large_report_LINEAR = classification_report(test_label3, large_predictions_LINEAR, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label3, large_predictions_LINEAR)\n",
    "    tnr_linear_lqp2 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_linear_lqp2 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'large_report_LINEAR:\\n{large_report_LINEAR}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # テストデータで評価    \n",
    "    predictions_RBF2 = best_svm_model_onlyGhost_RBF.predict(test_data_OG1)\n",
    "    # predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test)\n",
    "    accuracy_RBF2 = accuracy_score(test_label1, predictions_RBF2)\n",
    "    report_RBF2 = classification_report(test_label1, predictions_RBF2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label1, predictions_RBF2)\n",
    "    tnr_rbf2_lqp1 = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_rbf2_lqp1 = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'report_RBF2:\\n{report_RBF2}')\n",
    "    \n",
    "    predictions_LINEAR2 = best_svm_model_onlyGhost_LINEAR.predict(test_data_OG1)\n",
    "    # predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test)\n",
    "    accuracy_LINEAR2 = accuracy_score(test_label1, predictions_LINEAR2)\n",
    "    report_LINEAR2 = classification_report(test_label1, predictions_LINEAR2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label1, predictions_LINEAR2)\n",
    "    tnr_linear2_lqp1 = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_linear2_lqp1 = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'report_LINEAR2:\\n{report_LINEAR2}')\n",
    "    \n",
    "    same_predictions_RBF2 = best_svm_model_onlyGhost_RBF.predict(test_data_OG2)\n",
    "    # same_predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test_sameQP)\n",
    "    same_accuracy_RBF2 = accuracy_score(test_label2, same_predictions_RBF2)\n",
    "    same_report_RBF2 = classification_report(test_label2, same_predictions_RBF2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label2, same_predictions_RBF2)\n",
    "    tnr_rbf2_sqp = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_rbf2_sqp = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'same_report_RBF2:\\n{same_report_RBF2}')\n",
    "    \n",
    "    same_predictions_LINEAR2 = best_svm_model_onlyGhost_LINEAR.predict(test_data_OG2)\n",
    "    # same_predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test_sameQP)\n",
    "    same_accuracy_LINEAR2 = accuracy_score(test_label2, same_predictions_LINEAR2)\n",
    "    same_report_LINEAR2 = classification_report(test_label2, same_predictions_LINEAR2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label2, same_predictions_LINEAR2)\n",
    "    tnr_linear2_sqp = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_linear2_sqp = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'same_report_LINEAR2:\\n{same_report_LINEAR2}')\n",
    "    \n",
    "    large_predictions_RBF2 = best_svm_model_onlyGhost_RBF.predict(test_data_OG3)\n",
    "    # large_predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test_largeQP)\n",
    "    large_accuracy_RBF2 = accuracy_score(test_label3, large_predictions_RBF2)\n",
    "    large_report_RBF2 = classification_report(test_label3, large_predictions_RBF2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label3, large_predictions_RBF2)\n",
    "    tnr_rbf2_lqp2 = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_rbf2_lqp2 = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'large_report_RBF2:\\n{large_report_RBF2}')\n",
    "    \n",
    "    large_predictions_LINEAR2 = best_svm_model_onlyGhost_LINEAR.predict(test_data_OG3)\n",
    "    # large_predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test_largeQP)\n",
    "    large_accuracy_LINEAR2 = accuracy_score(test_label3, large_predictions_LINEAR2)\n",
    "    large_report_LINEAR2 = classification_report(test_label3, large_predictions_LINEAR2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label3, large_predictions_LINEAR2)\n",
    "    tnr_linear2_lqp2 = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_linear2_lqp2 = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'large_report_LINEAR2:\\n{large_report_LINEAR2}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # テストデータで評価\n",
    "    test_old = classification_report(best_ground_truth_labels, best_predicted_labels, labels=[0,1], target_names=['0', '1'], zero_division=0, digits=4)\n",
    "    conf_matrix = confusion_matrix(best_ground_truth_labels, best_predicted_labels)\n",
    "    tnr_old_lqp1 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_old_lqp1 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'Summary old_model:\\n{test_old}')\n",
    "    \n",
    "    test_sameQP_old = classification_report(sameQP_best_ground_truth_labels, sameQP_best_predicted_labels, labels=[0,1], target_names=['0', '1'], zero_division=0, digits=4)\n",
    "    conf_matrix = confusion_matrix(sameQP_best_ground_truth_labels, sameQP_best_predicted_labels)\n",
    "    tnr_old_sqp = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_old_sqp = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'Summary old_model:\\n{test_sameQP_old}')\n",
    "    \n",
    "    test_largeQP_old = classification_report(largeQP_best_ground_truth_labels, largeQP_best_predicted_labels, labels=[0,1], target_names=['0', '1'], zero_division=0, digits=4)\n",
    "    conf_matrix = confusion_matrix(largeQP_best_ground_truth_labels, largeQP_best_predicted_labels)\n",
    "    tnr_old_lqp2 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_old_lqp2 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'Summary old_model:\\n{test_largeQP_old}')\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Test結果を保存\n",
    "    \n",
    "    result_row ={'C_RBF_LQP1':best_c_value_RBF,'Score_RBF_LQP1': accuracy_RBF, 'tnr_rbf_lqp1':tnr_rbf_lqp1, 'tpr_rbf_lqp1':tpr_rbf_lqp1,\n",
    "                'C_RBF_SQP': best_c_value_RBF, 'Score_RBF_SQP': same_accuracy_RBF, 'tnr_rbf_sqp':tnr_rbf_sqp, 'tpr_rbf_sqp':tpr_rbf_sqp,\n",
    "                'C_RBF_LQP2': best_c_value_RBF,'Score_RBF_LQP2': large_accuracy_RBF, 'tnr_rbf_lqp2':tnr_rbf_lqp2, 'tpr_rbf_lqp2':tpr_rbf_lqp2,\n",
    "                                    \n",
    "                'C_LINEAR_LQP1': best_c_value_LINEAR,'Score_LINEAR_LQP1':accuracy_LINEAR, 'tnr_linear_lqp1':tnr_linear_lqp1, 'tpr_linear_lqp1':tpr_linear_lqp1,\n",
    "                'C_LINEAR_SQP': best_c_value_LINEAR,'Score_LINEAR_SQP':same_accuracy_LINEAR, 'tnr_linear_sqp':tnr_linear_sqp, 'tpr_linear_sqp':tpr_linear_sqp,\n",
    "                'C_LINEAR_LQP2': best_c_value_LINEAR,'Score_LINEAR_LQP2':large_accuracy_LINEAR, 'tnr_linear_lqp2':tnr_linear_lqp2, 'tpr_linear_lqp2':tpr_linear_lqp2,\n",
    "                 \n",
    "                'C_RBF2_LQP1':best_c_value_onlyGhost_RBF,'Score_RBF2_LQP1': accuracy_RBF2, 'tnr_rbf2_lqp1':tnr_rbf2_lqp1, 'tpr_rbf2_lqp1':tpr_rbf2_lqp1,\n",
    "                'C_RBF2_SQP': best_c_value_onlyGhost_RBF, 'Score_RBF2_SQP': same_accuracy_RBF2, 'tnr_rbf2_sqp':tnr_rbf2_sqp, 'tpr_rbf2_sqp':tpr_rbf2_sqp,\n",
    "                'C_RBF2_LQP2': best_c_value_onlyGhost_RBF,'Score_RBF2_LQP2': large_accuracy_RBF2, 'tnr_rbf2_lqp2':tnr_rbf2_lqp2, 'tpr_rbf2_lqp2':tpr_rbf2_lqp2,\n",
    "                                    \n",
    "                'C_LINEAR2_LQP1': best_c_value_onlyGhost_LINEAR,'Score_LINEAR2_LQP1':accuracy_LINEAR2, 'tnr_linear2_lqp1':tnr_linear2_lqp1, 'tpr_linear2_lqp1':tpr_linear2_lqp1,\n",
    "                'C_LINEAR2_SQP': best_c_value_onlyGhost_LINEAR,'Score_LINEAR2_SQP':same_accuracy_LINEAR2, 'tnr_linear2_sqp':tnr_linear2_sqp, 'tpr_linear2_sqp':tpr_linear2_sqp,\n",
    "                'C_LINEAR2_LQP2': best_c_value_onlyGhost_LINEAR,'Score_LINEAR2_LQP2':large_accuracy_LINEAR2, 'tnr_linear2_lqp2':tnr_linear2_lqp2, 'tpr_linear2_lqp2':tpr_linear2_lqp2,\n",
    "                                                        \n",
    "                'Threshold_LQP1':best_threshold, 'LQP1_old':best_accuracy, 'tnr_old_lqp1':tnr_old_lqp1, 'tpr_old_lqp1':tpr_old_lqp1,\n",
    "                'Threshold_SQP':sameQP_best_threshold, 'SQP_old':sameQP_best_accuracy, 'tnr_old_sqp':tnr_old_sqp, 'tpr_old_sqp':tpr_old_sqp,\n",
    "                'Threshold_LQP2':largeQP_best_threshold, 'LQP2_old':largeQP_best_accuracy, 'tnr_old_lqp2':tnr_old_lqp2, 'tpr_old_lqp2':tpr_old_lqp2}\n",
    "\n",
    "\n",
    "    results = pd.concat([results, pd.DataFrame([result_row])], ignore_index=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Average TNR  Average TPR  Average Test Score  Standard Deviation  Max Test Score  Min Test Score\n",
      "0     RBF_LQP1        85.22        94.93               90.07                1.16           91.17           87.33\n",
      "1      RBF_SQP        85.22        91.48               88.35                1.06           89.67           86.33\n",
      "2     RBF_LQP2        85.22        55.26               70.24                0.46           71.00           69.67\n",
      "3  LINEAR_LQP1        85.48        97.78               91.63                0.32           92.00           91.00\n",
      "4   LINEAR_SQP        85.48        92.70               89.09                0.38           89.50           88.33\n",
      "5  LINEAR_LQP2        85.48        47.96               66.72                0.73           68.17           65.83\n",
      "6     OLD_LQP1        88.00        86.00               87.00                0.00           87.00           87.00\n",
      "7      OLD_SQP        42.00        60.33               51.17                0.00           51.17           51.17\n",
      "8     OLD_LQP2        35.67        81.67               58.67                0.00           58.67           58.67\n"
     ]
    }
   ],
   "source": [
    "# 各統計情報を100倍して小数点第4位までの表記に変更\n",
    "statistics_data = {\n",
    "    'Model': ['RBF_LQP1', 'RBF_SQP', 'RBF_LQP2', 'LINEAR_LQP1', 'LINEAR_SQP', 'LINEAR_LQP2', 'OLD_LQP1', 'OLD_SQP', 'OLD_LQP2'],\n",
    "    'Average TNR': [round(results['tnr_rbf_lqp1'].mean() * 100, 2), round(results['tnr_rbf_sqp'].mean() * 100, 2), round(results['tnr_rbf_lqp2'].mean() * 100, 2), round(results['tnr_linear_lqp1'].mean() * 100, 2), round(results['tnr_linear_sqp'].mean() * 100, 2), round(results['tnr_linear_lqp2'].mean() * 100, 2),round(results['tnr_old_lqp1'].mean() * 100, 2), round(results['tnr_old_sqp'].mean() * 100, 2), round(results['tnr_old_lqp2'].mean() * 100, 2)],\n",
    "    'Average TPR': [round(results['tpr_rbf_lqp1'].mean() * 100, 2), round(results['tpr_rbf_sqp'].mean() * 100, 2), round(results['tpr_rbf_lqp2'].mean() * 100, 2), round(results['tpr_linear_lqp1'].mean() * 100, 2), round(results['tpr_linear_sqp'].mean() * 100, 2), round(results['tpr_linear_lqp2'].mean() * 100, 2),round(results['tpr_old_lqp1'].mean() * 100, 2), round(results['tpr_old_sqp'].mean() * 100, 2), round(results['tpr_old_lqp2'].mean() * 100, 2)],\n",
    "    'Average Test Score': [round(results['Score_RBF_LQP1'].mean() * 100, 2), round(results['Score_RBF_SQP'].mean() * 100, 2), round(results['Score_RBF_LQP2'].mean() * 100, 2), round(results['Score_LINEAR_LQP1'].mean() * 100, 2), round(results['Score_LINEAR_SQP'].mean() * 100, 2), round(results['Score_LINEAR_LQP2'].mean() * 100, 2),round(results['LQP1_old'].mean() * 100, 2), round(results['SQP_old'].mean() * 100, 2), round(results['LQP2_old'].mean() * 100, 2)],\n",
    "    'Standard Deviation': [round(results['Score_RBF_LQP1'].std() * 100, 2), round(results['Score_RBF_SQP'].std() * 100, 2), round(results['Score_RBF_LQP2'].std() * 100, 2), round(results['Score_LINEAR_LQP1'].std() * 100, 2), round(results['Score_LINEAR_SQP'].std() * 100, 2), round(results['Score_LINEAR_LQP2'].std() * 100, 2),round(results['LQP1_old'].std() * 100, 2), round(results['SQP_old'].std() * 100, 2), round(results['LQP2_old'].std() * 100, 2)],\n",
    "    'Max Test Score': [round(results['Score_RBF_LQP1'].max() * 100, 2), round(results['Score_RBF_SQP'].max() * 100, 2), round(results['Score_RBF_LQP2'].max() * 100, 2), round(results['Score_LINEAR_LQP1'].max() * 100, 2), round(results['Score_LINEAR_SQP'].max() * 100, 2), round(results['Score_LINEAR_LQP2'].max() * 100, 2),round(results['LQP1_old'].max() * 100, 2), round(results['SQP_old'].max() * 100, 2), round(results['LQP2_old'].max() * 100, 2)],\n",
    "    'Min Test Score': [round(results['Score_RBF_LQP1'].min() * 100, 2), round(results['Score_RBF_SQP'].min() * 100, 2), round(results['Score_RBF_LQP2'].min() * 100, 2), round(results['Score_LINEAR_LQP1'].min() * 100, 2), round(results['Score_LINEAR_SQP'].min() * 100, 2), round(results['Score_LINEAR_LQP2'].min() * 100, 2),round(results['LQP1_old'].min() * 100, 2), round(results['SQP_old'].min() * 100, 2), round(results['LQP2_old'].min() * 100, 2)],\n",
    "}\n",
    "\n",
    "# DataFrameを作成\n",
    "statistics_df = pd.DataFrame(statistics_data)\n",
    "\n",
    "# 表示\n",
    "print(statistics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Average TNR  Average TPR  Average Test Score  Standard Deviation  Max Test Score  Min Test Score\n",
      "0     RBF_LQP1        87.15        95.48               91.31                1.01           92.17           89.50\n",
      "1      RBF_SQP        87.15        93.04               90.09                0.82           90.83           88.67\n",
      "2     RBF_LQP2        87.15        17.67               52.41                0.93           54.00           51.50\n",
      "3  LINEAR_LQP1        86.52        86.70               86.61                1.91           89.17           84.00\n",
      "4   LINEAR_SQP        86.52        37.70               62.11                0.97           63.50           60.83\n",
      "5  LINEAR_LQP2        86.52        19.67               53.09                1.24           54.50           51.00\n",
      "6     OLD_LQP1        88.00        86.00               87.00                0.00           87.00           87.00\n",
      "7      OLD_SQP        42.00        60.33               51.17                0.00           51.17           51.17\n",
      "8     OLD_LQP2        35.67        81.67               58.67                0.00           58.67           58.67\n"
     ]
    }
   ],
   "source": [
    "# 各統計情報を100倍して小数点第4位までの表記に変更\n",
    "statistics_data2 = {\n",
    "    'Model': ['RBF_LQP1', 'RBF_SQP', 'RBF_LQP2', 'LINEAR_LQP1', 'LINEAR_SQP', 'LINEAR_LQP2', 'OLD_LQP1', 'OLD_SQP', 'OLD_LQP2'],\n",
    "    'Average TNR': [round(results['tnr_rbf2_lqp1'].mean() * 100, 2), round(results['tnr_rbf2_sqp'].mean() * 100, 2), round(results['tnr_rbf2_lqp2'].mean() * 100, 2), round(results['tnr_linear2_lqp1'].mean() * 100, 2), round(results['tnr_linear2_sqp'].mean() * 100, 2), round(results['tnr_linear2_lqp2'].mean() * 100, 2),round(results['tnr_old_lqp1'].mean() * 100, 2), round(results['tnr_old_sqp'].mean() * 100, 2), round(results['tnr_old_lqp2'].mean() * 100, 2)],\n",
    "    'Average TPR': [round(results['tpr_rbf2_lqp1'].mean() * 100, 2), round(results['tpr_rbf2_sqp'].mean() * 100, 2), round(results['tpr_rbf2_lqp2'].mean() * 100, 2), round(results['tpr_linear2_lqp1'].mean() * 100, 2), round(results['tpr_linear2_sqp'].mean() * 100, 2), round(results['tpr_linear2_lqp2'].mean() * 100, 2),round(results['tpr_old_lqp1'].mean() * 100, 2), round(results['tpr_old_sqp'].mean() * 100, 2), round(results['tpr_old_lqp2'].mean() * 100, 2)],\n",
    "    'Average Test Score': [round(results['Score_RBF2_LQP1'].mean() * 100, 2), round(results['Score_RBF2_SQP'].mean() * 100, 2), round(results['Score_RBF2_LQP2'].mean() * 100, 2), round(results['Score_LINEAR2_LQP1'].mean() * 100, 2), round(results['Score_LINEAR2_SQP'].mean() * 100, 2), round(results['Score_LINEAR2_LQP2'].mean() * 100, 2),round(results['LQP1_old'].mean() * 100, 2), round(results['SQP_old'].mean() * 100, 2), round(results['LQP2_old'].mean() * 100, 2)],\n",
    "    'Standard Deviation': [round(results['Score_RBF2_LQP1'].std() * 100, 2), round(results['Score_RBF2_SQP'].std() * 100, 2), round(results['Score_RBF2_LQP2'].std() * 100, 2), round(results['Score_LINEAR2_LQP1'].std() * 100, 2), round(results['Score_LINEAR2_SQP'].std() * 100, 2), round(results['Score_LINEAR2_LQP2'].std() * 100, 2),round(results['LQP1_old'].std() * 100, 2), round(results['SQP_old'].std() * 100, 2), round(results['LQP2_old'].std() * 100, 2)],\n",
    "    'Max Test Score': [round(results['Score_RBF2_LQP1'].max() * 100, 2), round(results['Score_RBF2_SQP'].max() * 100, 2), round(results['Score_RBF2_LQP2'].max() * 100, 2), round(results['Score_LINEAR2_LQP1'].max() * 100, 2), round(results['Score_LINEAR2_SQP'].max() * 100, 2), round(results['Score_LINEAR2_LQP2'].max() * 100, 2),round(results['LQP1_old'].max() * 100, 2), round(results['SQP_old'].max() * 100, 2), round(results['LQP2_old'].max() * 100, 2)],\n",
    "    'Min Test Score': [round(results['Score_RBF2_LQP1'].min() * 100, 2), round(results['Score_RBF2_SQP'].min() * 100, 2), round(results['Score_RBF2_LQP2'].min() * 100, 2), round(results['Score_LINEAR2_LQP1'].min() * 100, 2), round(results['Score_LINEAR2_SQP'].min() * 100, 2), round(results['Score_LINEAR2_LQP2'].min() * 100, 2),round(results['LQP1_old'].min() * 100, 2), round(results['SQP_old'].min() * 100, 2), round(results['LQP2_old'].min() * 100, 2)],\n",
    "}\n",
    "\n",
    "# DataFrameを作成\n",
    "statistics_df2 = pd.DataFrame(statistics_data2)\n",
    "\n",
    "# 表示\n",
    "print(statistics_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     100\n",
      "1    1000\n",
      "2     100\n",
      "3     100\n",
      "4     100\n",
      "5     100\n",
      "6     100\n",
      "7     100\n",
      "8     100\n",
      "Name: C_RBF_LQP1, dtype: object\n",
      "0    1000\n",
      "1    1000\n",
      "2    1000\n",
      "3    3000\n",
      "4     100\n",
      "5    2000\n",
      "6    4000\n",
      "7    1000\n",
      "8    1000\n",
      "Name: C_LINEAR_LQP1, dtype: object\n",
      "\n",
      "0    2000\n",
      "1    2000\n",
      "2    1000\n",
      "3    5000\n",
      "4    3000\n",
      "5    5000\n",
      "6    2000\n",
      "7      10\n",
      "8      10\n",
      "Name: C_RBF2_LQP1, dtype: object\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "5    1\n",
      "6    1\n",
      "7    1\n",
      "8    1\n",
      "Name: C_LINEAR2_LQP1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(results['C_RBF_LQP1'])\n",
    "print(results['C_LINEAR_LQP1'])\n",
    "print()\n",
    "print(results['C_RBF2_LQP1'])\n",
    "print(results['C_LINEAR2_LQP1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df.to_csv('statistics_data2.csv', index=False)\n",
    "statistics_df2.to_csv('statistics2_data2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
