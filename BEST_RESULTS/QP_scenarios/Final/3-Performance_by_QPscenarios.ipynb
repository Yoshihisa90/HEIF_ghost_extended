{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import os.path as osp\n",
    "import re\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.signal import find_peaks\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import torch\n",
    "import glob\n",
    "from scipy.stats import entropy\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)  # DataFrameを改行せずに表示\n",
    "pd.set_option('display.max_columns', None)  # すべての列を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_finalQP(filename):\n",
    "    match = re.search(r'2ndQP(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    match = re.search(r'1stQP(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_1stQP(filename):\n",
    "    match = re.search(r'1stQP(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def ratio_double_compressed(mean_difference, final_QP):\n",
    "    # mean_difference = mean_difference[0]\n",
    "    # final_QP = final_QP[0]\n",
    "    clamped_mean_difference = np.maximum(mean_difference, -0.01)\n",
    "    \n",
    "    #全体のエネルギーを計算\n",
    "    energy = np.sum(np.square(clamped_mean_difference))\n",
    "    # energy = np.sum(np.square(mean_difference))\n",
    "    \n",
    "    #QP2より右側のエネルギーを計算\n",
    "    right_energy = np.sum(np.square(clamped_mean_difference[final_QP+1:52]))\n",
    "\n",
    "        \n",
    "    # エネルギー比を計算して閾値と比較\n",
    "    if energy > 0:\n",
    "        return right_energy / energy\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def is_double_compressed(mean_difference, final_QP, threshold):\n",
    "    mean_difference = mean_difference[0]\n",
    "    final_QP = final_QP[0]\n",
    "    clamped_mean_difference = np.maximum(mean_difference, -0.01)\n",
    "    \n",
    "    #全体のエネルギーを計算\n",
    "    energy = np.sum(np.square(clamped_mean_difference))\n",
    "    # energy = np.sum(np.square(mean_difference))\n",
    "    \n",
    "    #QP2より右側のエネルギーを計算\n",
    "    right_energy = np.sum(np.square(clamped_mean_difference[final_QP+1:52]))\n",
    "    # right_energy = np.sum(np.square(mean_difference[final_QP+1:52]))\n",
    "    \n",
    "    # print('energy: ', energy)\n",
    "    # print('R-energy: ', right_energy)\n",
    "    # print('Ratio: ', right_energy / energy)\n",
    "    \n",
    "    \n",
    "    # エネルギー比を計算して閾値と比較\n",
    "    if energy <= 0:\n",
    "        return -1\n",
    "    \n",
    "    elif (right_energy / energy) != 0 and (right_energy / energy) > threshold:\n",
    "        return True\n",
    "    \n",
    "    elif (right_energy / energy) != 0 and (right_energy / energy) <= threshold:\n",
    "        return False\n",
    "    \n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def calculate_mae(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            loaded_data, loaded_data_shifted = pickle.load(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # タプル内のリストを抽出\n",
    "    original_mae = np.array(loaded_data)\n",
    "    shifted_mae = np.array(loaded_data_shifted)\n",
    "\n",
    "    # Coding ghostを計算してリストに格納する\n",
    "    mae_difference = shifted_mae - original_mae\n",
    "    \n",
    "    # mae_differenceの各要素においてマイナスの値を0に変換\n",
    "    # mae_difference_positive = np.maximum(mae_difference, 0)\n",
    "    \n",
    "    return mae_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['56', '25', '246', '133', '87', '139', '261', '216', '260', '269', '73', '148', '151', '255', '145', '38', '226', '222', '131', '18', '43', '164', '267', '147', '256', '233', '172', '100', '296', '195'], ['116', '218', '24', '115', '46', '208', '277', '127', '6', '297', '173', '245', '130', '109', '136', '126', '205', '92', '26', '215', '44', '15', '240', '278', '112', '68', '22', '157', '249', '42'], ['21', '273', '3', '290', '242', '14', '206', '75', '118', '166', '53', '236', '231', '280', '132', '93', '239', '122', '78', '81', '66', '142', '58', '86', '170', '251', '137', '281', '141', '289'], ['209', '287', '241', '254', '171', '94', '161', '168', '200', '224', '41', '135', '17', '10', '176', '293', '34', '158', '134', '74', '108', '188', '295', '227', '220', '102', '121', '63', '182', '60'], ['30', '268', '223', '193', '85', '83', '52', '234', '271', '235', '32', '229', '283', '27', '11', '184', '286', '123', '210', '54', '264', '180', '152', '217', '105', '238', '12', '88', '243', '191'], ['23', '77', '106', '186', '211', '213', '129', '64', '29', '99', '250', '89', '33', '124', '202', '49', '259', '247', '48', '248', '2', '113', '284', '103', '288', '299', '153', '155', '69', '232'], ['244', '175', '219', '190', '107', '291', '5', '179', '174', '96', '160', '111', '7', '67', '120', '28', '45', '9', '39', '82', '61', '114', '192', '276', '80', '230', '84', '197', '279', '298'], ['128', '16', '150', '265', '225', '50', '110', '140', '300', '177', '169', '207', '198', '79', '159', '194', '146', '156', '212', '266', '214', '187', '70', '282', '59', '162', '101', '57', '125', '189'], ['201', '19', '62', '104', '292', '237', '31', '51', '119', '252', '196', '20', '47', '270', '138', '97', '167', '272', '163', '294', '181', '8', '203', '55', '13', '149', '98', '285', '76', '95'], ['228', '154', '36', '35', '183', '263', '221', '65', '91', '72', '117', '262', '90', '4', '144', '274', '253', '37', '185', '143', '275', '258', '257', '178', '204', '199', '1', '71', '40', '165']]\n",
      "\n",
      "CSV Single ListsA:\n",
      "CSV List 1A: 300\n",
      "CSV List 2A: 300\n",
      "CSV List 3A: 300\n",
      "CSV List 4A: 300\n",
      "CSV List 5A: 300\n",
      "CSV List 6A: 300\n",
      "CSV List 7A: 300\n",
      "CSV List 8A: 300\n",
      "CSV List 9A: 300\n",
      "CSV List 10A: 300\n",
      "\n",
      "CSV Single Recompress ListsA:\n",
      "CSV List 1A: 300\n",
      "CSV List 2A: 300\n",
      "CSV List 3A: 300\n",
      "CSV List 4A: 300\n",
      "CSV List 5A: 300\n",
      "CSV List 6A: 300\n",
      "CSV List 7A: 300\n",
      "CSV List 8A: 300\n",
      "CSV List 9A: 300\n",
      "CSV List 10A: 300\n",
      "\n",
      "CSV Second Large QP1 ListsA:\n",
      "CSV List 1A: 1710\n",
      "CSV List 2A: 1710\n",
      "CSV List 3A: 1710\n",
      "CSV List 4A: 1710\n",
      "CSV List 5A: 1710\n",
      "CSV List 6A: 1710\n",
      "CSV List 7A: 1710\n",
      "CSV List 8A: 1710\n",
      "CSV List 9A: 1710\n",
      "CSV List 10A: 1710\n",
      "\n",
      "CSV Second Recompress Large QP1 ListsA:\n",
      "CSV List 1A: 1710\n",
      "CSV List 2A: 1710\n",
      "CSV List 3A: 1710\n",
      "CSV List 4A: 1710\n",
      "CSV List 5A: 1710\n",
      "CSV List 6A: 1710\n",
      "CSV List 7A: 1710\n",
      "CSV List 8A: 1710\n",
      "CSV List 9A: 1710\n",
      "CSV List 10A: 1710\n",
      "\n",
      "CSV Second Same QP ListsA:\n",
      "CSV List 1A: 300\n",
      "CSV List 2A: 300\n",
      "CSV List 3A: 300\n",
      "CSV List 4A: 300\n",
      "CSV List 5A: 300\n",
      "CSV List 6A: 300\n",
      "CSV List 7A: 300\n",
      "CSV List 8A: 300\n",
      "CSV List 9A: 300\n",
      "CSV List 10A: 300\n",
      "\n",
      "CSV Second Recompress Same QP ListsA:\n",
      "CSV List 1A: 300\n",
      "CSV List 2A: 300\n",
      "CSV List 3A: 300\n",
      "CSV List 4A: 300\n",
      "CSV List 5A: 300\n",
      "CSV List 6A: 300\n",
      "CSV List 7A: 300\n",
      "CSV List 8A: 300\n",
      "CSV List 9A: 300\n",
      "CSV List 10A: 300\n",
      "\n",
      "CSV Second Large QP2 ListsA:\n",
      "CSV List 1A: 1170\n",
      "CSV List 2A: 1170\n",
      "CSV List 3A: 1170\n",
      "CSV List 4A: 1170\n",
      "CSV List 5A: 1170\n",
      "CSV List 6A: 1170\n",
      "CSV List 7A: 1170\n",
      "CSV List 8A: 1170\n",
      "CSV List 9A: 1170\n",
      "CSV List 10A: 1170\n",
      "\n",
      "CSV Second Recompress Large QP2 ListsA:\n",
      "CSV List 1A: 1170\n",
      "CSV List 2A: 1170\n",
      "CSV List 3A: 1170\n",
      "CSV List 4A: 1170\n",
      "CSV List 5A: 1170\n",
      "CSV List 6A: 1170\n",
      "CSV List 7A: 1170\n",
      "CSV List 8A: 1170\n",
      "CSV List 9A: 1170\n",
      "CSV List 10A: 1170\n",
      "\n",
      "PKL Single ListsA:\n",
      "PKL List 1A: 300\n",
      "PKL List 2A: 300\n",
      "PKL List 3A: 300\n",
      "PKL List 4A: 300\n",
      "PKL List 5A: 300\n",
      "PKL List 6A: 300\n",
      "PKL List 7A: 300\n",
      "PKL List 8A: 300\n",
      "PKL List 9A: 300\n",
      "PKL List 10A: 300\n",
      "\n",
      "PKL Single Recompress ListsA:\n",
      "PKL List 1A: 300\n",
      "PKL List 2A: 300\n",
      "PKL List 3A: 300\n",
      "PKL List 4A: 300\n",
      "PKL List 5A: 300\n",
      "PKL List 6A: 300\n",
      "PKL List 7A: 300\n",
      "PKL List 8A: 300\n",
      "PKL List 9A: 300\n",
      "PKL List 10A: 300\n",
      "\n",
      "PKL Second Large QP1 ListsA:\n",
      "PKL List 1A: 1710\n",
      "PKL List 2A: 1710\n",
      "PKL List 3A: 1710\n",
      "PKL List 4A: 1710\n",
      "PKL List 5A: 1710\n",
      "PKL List 6A: 1710\n",
      "PKL List 7A: 1710\n",
      "PKL List 8A: 1710\n",
      "PKL List 9A: 1710\n",
      "PKL List 10A: 1710\n",
      "\n",
      "PKL Second Recompress Large QP1 ListsA:\n",
      "PKL List 1A: 1710\n",
      "PKL List 2A: 1710\n",
      "PKL List 3A: 1710\n",
      "PKL List 4A: 1710\n",
      "PKL List 5A: 1710\n",
      "PKL List 6A: 1710\n",
      "PKL List 7A: 1710\n",
      "PKL List 8A: 1710\n",
      "PKL List 9A: 1710\n",
      "PKL List 10A: 1710\n",
      "\n",
      "PKL Second Same QP ListsA:\n",
      "PKL List 1A: 300\n",
      "PKL List 2A: 300\n",
      "PKL List 3A: 300\n",
      "PKL List 4A: 300\n",
      "PKL List 5A: 300\n",
      "PKL List 6A: 300\n",
      "PKL List 7A: 300\n",
      "PKL List 8A: 300\n",
      "PKL List 9A: 300\n",
      "PKL List 10A: 300\n",
      "\n",
      "PKL Second Recompress Same QP ListsA:\n",
      "PKL List 1A: 300\n",
      "PKL List 2A: 300\n",
      "PKL List 3A: 300\n",
      "PKL List 4A: 300\n",
      "PKL List 5A: 300\n",
      "PKL List 6A: 300\n",
      "PKL List 7A: 300\n",
      "PKL List 8A: 300\n",
      "PKL List 9A: 300\n",
      "PKL List 10A: 300\n",
      "\n",
      "PKL Second Large QP2 ListsA:\n",
      "PKL List 1A: 1170\n",
      "PKL List 2A: 1170\n",
      "PKL List 3A: 1170\n",
      "PKL List 4A: 1170\n",
      "PKL List 5A: 1170\n",
      "PKL List 6A: 1170\n",
      "PKL List 7A: 1170\n",
      "PKL List 8A: 1170\n",
      "PKL List 9A: 1170\n",
      "PKL List 10A: 1170\n",
      "\n",
      "PKL Second Recompress Large QP2 ListsA:\n",
      "PKL List 1A: 1170\n",
      "PKL List 2A: 1170\n",
      "PKL List 3A: 1170\n",
      "PKL List 4A: 1170\n",
      "PKL List 5A: 1170\n",
      "PKL List 6A: 1170\n",
      "PKL List 7A: 1170\n",
      "PKL List 8A: 1170\n",
      "PKL List 9A: 1170\n",
      "PKL List 10A: 1170\n"
     ]
    }
   ],
   "source": [
    "rootpath_csv = \"/Prove/Yoshihisa/HEIF_ghost/HEIF_IMAGES_CSV/\"\n",
    "rootpath_pkl = \"/Prove/Yoshihisa/HEIF_ghost/PKL/\"\n",
    "\n",
    "train_list1 = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\"]\n",
    "train_list2 = [\"31\", \"32\", \"33\", \"34\", \"35\", \"36\", \"37\", \"38\", \"39\", \"40\", \"41\", \"42\", \"43\", \"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"50\", \"51\", \"52\", \"53\", \"54\", \"55\", \"56\", \"57\", \"58\", \"59\", \"60\"]\n",
    "train_list3 = [\"61\", \"62\", \"63\", \"64\", \"65\", \"66\", \"67\", \"68\", \"69\", \"70\", \"71\", \"72\", \"73\", \"74\", \"75\", \"76\", \"77\", \"78\", \"79\", \"80\", \"81\", \"82\", \"83\", \"84\", \"85\", \"86\", \"87\", \"88\", \"89\", \"90\"]\n",
    "train_list4 = [\"91\", \"92\", \"93\", \"94\", \"95\", \"96\", \"97\", \"98\", \"99\", \"100\", \"101\", \"102\", \"103\", \"104\", \"105\", \"106\", \"107\", \"108\", \"109\", \"110\", \"111\", \"112\", \"113\", \"114\", \"115\", \"116\", \"117\", \"118\", \"119\", \"120\"]\n",
    "train_list5 = [\"121\", \"122\", \"123\", \"124\", \"125\", \"126\", \"127\", \"128\", \"129\", \"130\", \"131\", \"132\", \"133\", \"134\", \"135\", \"136\", \"137\", \"138\", \"139\", \"140\", \"141\", \"142\", \"143\", \"144\", \"145\", \"146\", \"147\", \"148\", \"149\", \"150\"]\n",
    "train_list6 = [\"151\", \"152\", \"153\", \"154\", \"155\", \"156\", \"157\", \"158\", \"159\", \"160\", \"161\", \"162\", \"163\", \"164\", \"165\", \"166\", \"167\", \"168\", \"169\", \"170\", \"171\", \"172\", \"173\", \"174\", \"175\", \"176\", \"177\", \"178\", \"179\", \"180\"]\n",
    "train_list7 = [\"181\", \"182\", \"183\", \"184\", \"185\", \"186\", \"187\", \"188\", \"189\", \"190\", \"191\", \"192\", \"193\", \"194\", \"195\", \"196\", \"197\", \"198\", \"199\", \"200\", \"201\", \"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\"]\n",
    "train_list8 = [\"211\", \"212\", \"213\", \"214\", \"215\", \"216\", \"217\", \"218\", \"219\", \"220\", \"221\", \"222\", \"223\", \"224\", \"225\", \"226\", \"227\", \"228\", \"229\", \"230\", \"231\", \"232\", \"233\", \"234\", \"235\", \"236\", \"237\", \"238\", \"239\", \"240\"]\n",
    "train_list9 = [\"241\", \"242\", \"243\", \"244\", \"245\", \"246\", \"247\", \"248\", \"249\", \"250\", \"251\", \"252\", \"253\", \"254\", \"255\", \"256\", \"257\", \"258\", \"259\", \"260\", \"261\", \"262\", \"263\", \"264\", \"265\", \"266\", \"267\", \"268\", \"269\", \"270\"]\n",
    "train_list10 = [\"271\", \"272\", \"273\", \"274\", \"275\", \"276\", \"277\", \"278\", \"279\", \"280\", \"281\", \"282\", \"283\", \"284\", \"285\", \"286\", \"287\", \"288\", \"289\", \"290\", \"291\", \"292\", \"293\", \"294\", \"295\", \"296\", \"297\", \"298\", \"299\", \"300\"]\n",
    "\n",
    "all_train_lists = [train_list1, train_list2, train_list3, train_list4, train_list5,\n",
    "                   train_list6, train_list7, train_list8, train_list9, train_list10]\n",
    "\n",
    "# すべてのリストを1つのリストに結合する\n",
    "combined_train_list = sum(all_train_lists, [])\n",
    "\n",
    "# リストの順序をランダムにシャッフルする\n",
    "random.shuffle(combined_train_list)\n",
    "\n",
    "# シャッフルされたリストを10個のグループに分割する\n",
    "train_lists = [combined_train_list[i:i+30] for i in range(0, len(combined_train_list), 30)]\n",
    "print(train_lists)\n",
    "\n",
    "\n",
    "\n",
    "# CSV関連のリストを生成\n",
    "csv_single_listsA = [[] for _ in range(10)]\n",
    "csv_single_recompress_listsA = [[] for _ in range(10)]\n",
    "csv_second_largeQP1_listsA = [[] for _ in range(10)]\n",
    "csv_second_recompress_largeQP1_listsA = [[] for _ in range(10)]\n",
    "csv_second_sameQP_listsA = [[] for _ in range(10)]\n",
    "csv_second_recompress_sameQP_listsA = [[] for _ in range(10)]\n",
    "csv_second_largeQP2_listsA = [[] for _ in range(10)]\n",
    "csv_second_recompress_largeQP2_listsA = [[] for _ in range(10)]\n",
    "\n",
    "def process_csv_lists(rootpath, train_list, single_list, single_recompress_list, \n",
    "                      second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                      second_sameQP_list, second_recompress_sameQP_list,\n",
    "                      second_largeQP2_list, second_recompress_largeQP2_list):\n",
    "    \n",
    "    for image in train_list:\n",
    "        single_path = osp.join(rootpath, f'HEIF_images_single_csv/{image}_*')\n",
    "        single_recompress_path = osp.join(rootpath, f'HEIF_images_second_sameQP_csv/{image}_*')\n",
    "        \n",
    "        second_largeQP1_path = osp.join(rootpath, f'HEIF_images_second_csv/{image}_*')\n",
    "        second_recompress_largeQP1_path = osp.join(rootpath, f'HEIF_images_triple_csv/{image}_*')\n",
    "        \n",
    "        second_sameQP_path = osp.join(rootpath, f'HEIF_images_second_sameQP_csv/{image}_*')\n",
    "        second_recompress_sameQP_path = osp.join(rootpath, f'HEIF_images_triple_sameQP_csv/{image}_*')\n",
    "        \n",
    "        second_largeQP2_path = osp.join(rootpath, f'HEIF_images_second_largeQP_csv/{image}_*')\n",
    "        second_recompress_largeQP2_path = osp.join(rootpath, f'HEIF_images_triple_largeQP_csv/{image}_*')\n",
    "        \n",
    "        for path in sorted(glob.glob(single_path)):\n",
    "            single_list.append(path)\n",
    "        for path in sorted(glob.glob(single_recompress_path)):\n",
    "            single_recompress_list.append(path)\n",
    "        for path in sorted(glob.glob(second_largeQP1_path)):\n",
    "            second_largeQP1_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP1_path)):\n",
    "            second_recompress_largeQP1_list.append(path)\n",
    "        for path in sorted(glob.glob(second_sameQP_path)):\n",
    "            second_sameQP_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_sameQP_path)):\n",
    "            second_recompress_sameQP_list.append(path)\n",
    "        for path in sorted(glob.glob(second_largeQP2_path)):\n",
    "            second_largeQP2_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP2_path)):\n",
    "            second_recompress_largeQP2_list.append(path)\n",
    "\n",
    "# 各カテゴリのCSVリストを生成\n",
    "for train_list, single_list, single_recompress_list in zip(train_lists, \n",
    "                                                           csv_single_listsA,\n",
    "                                                           csv_single_recompress_listsA):\n",
    "    process_csv_lists(rootpath_csv, train_list, single_list, single_recompress_list, \n",
    "                      [], [], [], [], [], [])\n",
    "\n",
    "\n",
    "for train_list, second_largeQP1_list, second_recompress_largeQP1_list, second_sameQP_list, second_recompress_sameQP_list, second_largeQP2_list, second_recompress_largeQP2_list in zip(train_lists, \n",
    "                                                                                                                                                                                                                   csv_second_largeQP1_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_recompress_largeQP1_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_sameQP_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_recompress_sameQP_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_largeQP2_listsA,\n",
    "                                                                                                                                                                                                                   csv_second_recompress_largeQP2_listsA):\n",
    "    process_csv_lists(rootpath_csv, train_list, [], [], \n",
    "                      second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                      second_sameQP_list, second_recompress_sameQP_list,\n",
    "                      second_largeQP2_list, second_recompress_largeQP2_list)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "# 出力リストを初期化\n",
    "pkl_single_listsA = [[] for _ in range(10)]\n",
    "pkl_single_recompress_listsA = [[] for _ in range(10)]\n",
    "pkl_second_largeQP1_listsA = [[] for _ in range(10)]\n",
    "pkl_second_recompress_largeQP1_listsA = [[] for _ in range(10)]\n",
    "pkl_second_sameQP_listsA = [[] for _ in range(10)]\n",
    "pkl_second_recompress_sameQP_listsA = [[] for _ in range(10)]\n",
    "pkl_second_largeQP2_listsA = [[] for _ in range(10)]\n",
    "pkl_second_recompress_largeQP2_listsA = [[] for _ in range(10)]    \n",
    "\n",
    "def process_train_lists_pkl(rootpath, train_list, single_list, single_recompress_list, \n",
    "                            second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                            second_sameQP_list, second_recompress_sameQP_list,\n",
    "                            second_largeQP2_list, second_recompress_largeQP2_list):\n",
    "    \n",
    "    for image in train_list:\n",
    "        single_path = osp.join(rootpath, f'pkl_single/{image}_*')\n",
    "        single_recompress_path = osp.join(rootpath, f'pkl_second_sameQP/{image}_*')\n",
    "        \n",
    "        second_largeQP1_path = osp.join(rootpath, f'pkl_second/{image}_*')\n",
    "        second_recompress_largeQP1_path = osp.join(rootpath, f'pkl_triple/{image}_*')\n",
    "        \n",
    "        second_sameQP_path = osp.join(rootpath, f'pkl_second_sameQP/{image}_*')\n",
    "        second_recompress_sameQP_path = osp.join(rootpath, f'pkl_triple_sameQP/{image}_*')\n",
    "        \n",
    "        second_largeQP2_path = osp.join(rootpath, f'pkl_second_largeQP/{image}_*')\n",
    "        second_recompress_largeQP2_path = osp.join(rootpath, f'pkl_triple_largeQP/{image}_*')\n",
    "        \n",
    "\n",
    "        for path in sorted(glob.glob(single_path)):\n",
    "            single_list.append(path)\n",
    "        for path in sorted(glob.glob(single_recompress_path)):\n",
    "            single_recompress_list.append(path)\n",
    "            \n",
    "        for path in sorted(glob.glob(second_largeQP1_path)):\n",
    "            second_largeQP1_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP1_path)):\n",
    "            second_recompress_largeQP1_list.append(path)\n",
    "                \n",
    "        for path in sorted(glob.glob(second_sameQP_path)):\n",
    "            second_sameQP_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_sameQP_path)):\n",
    "            second_recompress_sameQP_list.append(path)\n",
    "            \n",
    "        for path in sorted(glob.glob(second_largeQP2_path)):\n",
    "            second_largeQP2_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP2_path)):\n",
    "            second_recompress_largeQP2_list.append(path)\n",
    "\n",
    "# 各カテゴリのリストを生成\n",
    "for train_list, single_list, single_recompress_list in zip(train_lists, \n",
    "                                                           pkl_single_listsA,\n",
    "                                                           pkl_single_recompress_listsA):\n",
    "    process_train_lists_pkl(rootpath_pkl, train_list, single_list, single_recompress_list, \n",
    "                            [], [], [], [], [], [])\n",
    "\n",
    "\n",
    "for train_list, second_largeQP1_list, second_recompress_largeQP1_list, second_sameQP_list, second_recompress_sameQP_list, second_largeQP2_list, second_recompress_largeQP2_list in zip(train_lists, \n",
    "                                                                                                                                                                                                                   pkl_second_largeQP1_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_recompress_largeQP1_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_sameQP_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_recompress_sameQP_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_largeQP2_listsA,\n",
    "                                                                                                                                                                                                                   pkl_second_recompress_largeQP2_listsA):\n",
    "    process_train_lists_pkl(rootpath_pkl, train_list, [], [], \n",
    "                            second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                            second_sameQP_list, second_recompress_sameQP_list,\n",
    "                            second_largeQP2_list, second_recompress_largeQP2_list)\n",
    "\n",
    "\n",
    "print(\"\\nCSV Single ListsA:\")\n",
    "for i, lst in enumerate(csv_single_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Single Recompress ListsA:\")\n",
    "for i, lst in enumerate(csv_single_recompress_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Large QP1 ListsA:\")\n",
    "for i, lst in enumerate(csv_second_largeQP1_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Recompress Large QP1 ListsA:\")\n",
    "for i, lst in enumerate(csv_second_recompress_largeQP1_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Same QP ListsA:\")\n",
    "for i, lst in enumerate(csv_second_sameQP_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Recompress Same QP ListsA:\")\n",
    "for i, lst in enumerate(csv_second_recompress_sameQP_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Large QP2 ListsA:\")\n",
    "for i, lst in enumerate(csv_second_largeQP2_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nCSV Second Recompress Large QP2 ListsA:\")\n",
    "for i, lst in enumerate(csv_second_recompress_largeQP2_listsA, 1):\n",
    "    print(f\"CSV List {i}A: {len(lst)}\")\n",
    "\n",
    "# 出力リストを表示\n",
    "print(\"\\nPKL Single ListsA:\")\n",
    "for i, lst in enumerate(pkl_single_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Single Recompress ListsA:\")\n",
    "for i, lst in enumerate(pkl_single_recompress_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Large QP1 ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_largeQP1_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Recompress Large QP1 ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_recompress_largeQP1_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Same QP ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_sameQP_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Recompress Same QP ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_recompress_sameQP_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Large QP2 ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_largeQP2_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")\n",
    "\n",
    "print(\"\\nPKL Second Recompress Large QP2 ListsA:\")\n",
    "for i, lst in enumerate(pkl_second_recompress_largeQP2_listsA, 1):\n",
    "    print(f\"PKL List {i}A: {len(lst)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "# single_listsおよびsingle_recompress_listsは初期化されている前提\n",
    "single_csv1 = list(zip(csv_single_listsA[0], pkl_single_listsA[0], csv_single_recompress_listsA[0], pkl_single_recompress_listsA[0]))\n",
    "single_csv2 = list(zip(csv_single_listsA[1], pkl_single_listsA[1], csv_single_recompress_listsA[1], pkl_single_recompress_listsA[1]))\n",
    "single_csv3 = list(zip(csv_single_listsA[2], pkl_single_listsA[2], csv_single_recompress_listsA[2], pkl_single_recompress_listsA[2]))\n",
    "single_csv4 = list(zip(csv_single_listsA[3], pkl_single_listsA[3], csv_single_recompress_listsA[3], pkl_single_recompress_listsA[3]))\n",
    "single_csv5 = list(zip(csv_single_listsA[4], pkl_single_listsA[4], csv_single_recompress_listsA[4], pkl_single_recompress_listsA[4]))\n",
    "single_csv6 = list(zip(csv_single_listsA[5], pkl_single_listsA[5], csv_single_recompress_listsA[5], pkl_single_recompress_listsA[5]))\n",
    "single_csv7 = list(zip(csv_single_listsA[6], pkl_single_listsA[6], csv_single_recompress_listsA[6], pkl_single_recompress_listsA[6]))\n",
    "single_csv8 = list(zip(csv_single_listsA[7], pkl_single_listsA[7], csv_single_recompress_listsA[7], pkl_single_recompress_listsA[7]))\n",
    "single_csv9 = list(zip(csv_single_listsA[8], pkl_single_listsA[8], csv_single_recompress_listsA[8], pkl_single_recompress_listsA[8]))\n",
    "single_csv10 = list(zip(csv_single_listsA[9], pkl_single_listsA[9], csv_single_recompress_listsA[9], pkl_single_recompress_listsA[9]))\n",
    "print(len(single_csv10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1710\n",
      "\n",
      "double images train by QP1>QP2:  100\n",
      "\n",
      "double images test by QP1>QP2:  300\n"
     ]
    }
   ],
   "source": [
    "# Large_QP1\n",
    "second_largeQP1_csv1 = list(zip(csv_second_largeQP1_listsA[0], pkl_second_largeQP1_listsA[0], csv_second_recompress_largeQP1_listsA[0], pkl_second_recompress_largeQP1_listsA[0]))\n",
    "second_largeQP1_csv2 = list(zip(csv_second_largeQP1_listsA[1], pkl_second_largeQP1_listsA[1], csv_second_recompress_largeQP1_listsA[1], pkl_second_recompress_largeQP1_listsA[1]))\n",
    "second_largeQP1_csv3 = list(zip(csv_second_largeQP1_listsA[2], pkl_second_largeQP1_listsA[2], csv_second_recompress_largeQP1_listsA[2], pkl_second_recompress_largeQP1_listsA[2]))\n",
    "second_largeQP1_csv4 = list(zip(csv_second_largeQP1_listsA[3], pkl_second_largeQP1_listsA[3], csv_second_recompress_largeQP1_listsA[3], pkl_second_recompress_largeQP1_listsA[3]))\n",
    "second_largeQP1_csv5 = list(zip(csv_second_largeQP1_listsA[4], pkl_second_largeQP1_listsA[4], csv_second_recompress_largeQP1_listsA[4], pkl_second_recompress_largeQP1_listsA[4]))\n",
    "second_largeQP1_csv6 = list(zip(csv_second_largeQP1_listsA[5], pkl_second_largeQP1_listsA[5], csv_second_recompress_largeQP1_listsA[5], pkl_second_recompress_largeQP1_listsA[5]))\n",
    "second_largeQP1_csv7 = list(zip(csv_second_largeQP1_listsA[6], pkl_second_largeQP1_listsA[6], csv_second_recompress_largeQP1_listsA[6], pkl_second_recompress_largeQP1_listsA[6]))\n",
    "second_largeQP1_csv8 = list(zip(csv_second_largeQP1_listsA[7], pkl_second_largeQP1_listsA[7], csv_second_recompress_largeQP1_listsA[7], pkl_second_recompress_largeQP1_listsA[7]))\n",
    "second_largeQP1_csv9 = list(zip(csv_second_largeQP1_listsA[8], pkl_second_largeQP1_listsA[8], csv_second_recompress_largeQP1_listsA[8], pkl_second_recompress_largeQP1_listsA[8]))\n",
    "second_largeQP1_csv10 = list(zip(csv_second_largeQP1_listsA[9], pkl_second_largeQP1_listsA[9], csv_second_recompress_largeQP1_listsA[9], pkl_second_recompress_largeQP1_listsA[9]))\n",
    "print(len(second_largeQP1_csv1))\n",
    "\n",
    "\n",
    "second_largeQP1_csv1 = random.sample(second_largeQP1_csv1, 100)\n",
    "second_largeQP1_csv2 = random.sample(second_largeQP1_csv2, 100)\n",
    "second_largeQP1_csv3 = random.sample(second_largeQP1_csv3, 100)\n",
    "second_largeQP1_csv4 = random.sample(second_largeQP1_csv4, 100)\n",
    "second_largeQP1_csv5 = random.sample(second_largeQP1_csv5, 100)\n",
    "second_largeQP1_csv6 = random.sample(second_largeQP1_csv6, 100)\n",
    "second_largeQP1_csv7 = random.sample(second_largeQP1_csv7, 100)\n",
    "second_largeQP1_csv8 = random.sample(second_largeQP1_csv8, 100)\n",
    "second_largeQP1_csv9 = random.sample(second_largeQP1_csv9, 100)\n",
    "# second_largeQP1_csv10 = selected_data[9]\n",
    "print('\\ndouble images train by QP1>QP2: ', len(second_largeQP1_csv1))\n",
    "\n",
    "\n",
    "second_largeQP1_csv10 = random.sample(second_largeQP1_csv10, 300)\n",
    "print('\\ndouble images test by QP1>QP2: ', len(second_largeQP1_csv10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "\n",
      "double images train by QP1=QP2:  100\n",
      "\n",
      "double images test by QP1=QP2:  300\n"
     ]
    }
   ],
   "source": [
    "# sameQP\n",
    "second_sameQP_csv1 = list(zip(csv_second_sameQP_listsA[0], pkl_second_sameQP_listsA[0], csv_second_recompress_sameQP_listsA[0], pkl_second_recompress_sameQP_listsA[0]))\n",
    "second_sameQP_csv2 = list(zip(csv_second_sameQP_listsA[1], pkl_second_sameQP_listsA[1], csv_second_recompress_sameQP_listsA[1], pkl_second_recompress_sameQP_listsA[1]))\n",
    "second_sameQP_csv3 = list(zip(csv_second_sameQP_listsA[2], pkl_second_sameQP_listsA[2], csv_second_recompress_sameQP_listsA[2], pkl_second_recompress_sameQP_listsA[2]))\n",
    "second_sameQP_csv4 = list(zip(csv_second_sameQP_listsA[3], pkl_second_sameQP_listsA[3], csv_second_recompress_sameQP_listsA[3], pkl_second_recompress_sameQP_listsA[3]))\n",
    "second_sameQP_csv5 = list(zip(csv_second_sameQP_listsA[4], pkl_second_sameQP_listsA[4], csv_second_recompress_sameQP_listsA[4], pkl_second_recompress_sameQP_listsA[4]))\n",
    "second_sameQP_csv6 = list(zip(csv_second_sameQP_listsA[5], pkl_second_sameQP_listsA[5], csv_second_recompress_sameQP_listsA[5], pkl_second_recompress_sameQP_listsA[5]))\n",
    "second_sameQP_csv7 = list(zip(csv_second_sameQP_listsA[6], pkl_second_sameQP_listsA[6], csv_second_recompress_sameQP_listsA[6], pkl_second_recompress_sameQP_listsA[6]))\n",
    "second_sameQP_csv8 = list(zip(csv_second_sameQP_listsA[7], pkl_second_sameQP_listsA[7], csv_second_recompress_sameQP_listsA[7], pkl_second_recompress_sameQP_listsA[7]))\n",
    "second_sameQP_csv9 = list(zip(csv_second_sameQP_listsA[8], pkl_second_sameQP_listsA[8], csv_second_recompress_sameQP_listsA[8], pkl_second_recompress_sameQP_listsA[8]))\n",
    "second_sameQP_csv10 = list(zip(csv_second_sameQP_listsA[9], pkl_second_sameQP_listsA[9], csv_second_recompress_sameQP_listsA[9], pkl_second_recompress_sameQP_listsA[9]))\n",
    "print(len(second_sameQP_csv10))\n",
    "\n",
    "second_sameQP_csv1 = random.sample(second_sameQP_csv1, 100)\n",
    "second_sameQP_csv2 = random.sample(second_sameQP_csv2, 100)\n",
    "second_sameQP_csv3 = random.sample(second_sameQP_csv3, 100)\n",
    "second_sameQP_csv4 = random.sample(second_sameQP_csv4, 100)\n",
    "second_sameQP_csv5 = random.sample(second_sameQP_csv5, 100)\n",
    "second_sameQP_csv6 = random.sample(second_sameQP_csv6, 100)\n",
    "second_sameQP_csv7 = random.sample(second_sameQP_csv7, 100)\n",
    "second_sameQP_csv8 = random.sample(second_sameQP_csv8, 100)\n",
    "second_sameQP_csv9 = random.sample(second_sameQP_csv9, 100)\n",
    "print('\\ndouble images train by QP1=QP2: ',len(second_sameQP_csv9))\n",
    "\n",
    "second_sameQP_csv10 = random.sample(second_sameQP_csv10, 300)\n",
    "print('\\ndouble images test by QP1=QP2: ',len(second_sameQP_csv10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1170\n",
      "\n",
      "double images train by QP1<QP2:  100\n",
      "\n",
      "double images test by QP1<QP2:  300\n"
     ]
    }
   ],
   "source": [
    "# Large_QP2\n",
    "second_largeQP2_csv1 = list(zip(csv_second_largeQP2_listsA[0], pkl_second_largeQP2_listsA[0], csv_second_recompress_largeQP2_listsA[0], pkl_second_recompress_largeQP2_listsA[0]))\n",
    "second_largeQP2_csv2 = list(zip(csv_second_largeQP2_listsA[1], pkl_second_largeQP2_listsA[1], csv_second_recompress_largeQP2_listsA[1], pkl_second_recompress_largeQP2_listsA[1]))\n",
    "second_largeQP2_csv3 = list(zip(csv_second_largeQP2_listsA[2], pkl_second_largeQP2_listsA[2], csv_second_recompress_largeQP2_listsA[2], pkl_second_recompress_largeQP2_listsA[2]))\n",
    "second_largeQP2_csv4 = list(zip(csv_second_largeQP2_listsA[3], pkl_second_largeQP2_listsA[3], csv_second_recompress_largeQP2_listsA[3], pkl_second_recompress_largeQP2_listsA[3]))\n",
    "second_largeQP2_csv5 = list(zip(csv_second_largeQP2_listsA[4], pkl_second_largeQP2_listsA[4], csv_second_recompress_largeQP2_listsA[4], pkl_second_recompress_largeQP2_listsA[4]))\n",
    "second_largeQP2_csv6 = list(zip(csv_second_largeQP2_listsA[5], pkl_second_largeQP2_listsA[5], csv_second_recompress_largeQP2_listsA[5], pkl_second_recompress_largeQP2_listsA[5]))\n",
    "second_largeQP2_csv7 = list(zip(csv_second_largeQP2_listsA[6], pkl_second_largeQP2_listsA[6], csv_second_recompress_largeQP2_listsA[6], pkl_second_recompress_largeQP2_listsA[6]))\n",
    "second_largeQP2_csv8 = list(zip(csv_second_largeQP2_listsA[7], pkl_second_largeQP2_listsA[7], csv_second_recompress_largeQP2_listsA[7], pkl_second_recompress_largeQP2_listsA[7]))\n",
    "second_largeQP2_csv9 = list(zip(csv_second_largeQP2_listsA[8], pkl_second_largeQP2_listsA[8], csv_second_recompress_largeQP2_listsA[8], pkl_second_recompress_largeQP2_listsA[8]))\n",
    "second_largeQP2_csv10 = list(zip(csv_second_largeQP2_listsA[9], pkl_second_largeQP2_listsA[9], csv_second_recompress_largeQP2_listsA[9], pkl_second_recompress_largeQP2_listsA[9]))\n",
    "print(len(second_largeQP2_csv1))\n",
    "\n",
    "second_largeQP2_csv1 = random.sample(second_largeQP2_csv1, 100)\n",
    "second_largeQP2_csv2 = random.sample(second_largeQP2_csv2, 100)\n",
    "second_largeQP2_csv3 = random.sample(second_largeQP2_csv3, 100)\n",
    "second_largeQP2_csv4 = random.sample(second_largeQP2_csv4, 100)\n",
    "second_largeQP2_csv5 = random.sample(second_largeQP2_csv5, 100)\n",
    "second_largeQP2_csv6 = random.sample(second_largeQP2_csv6, 100)\n",
    "second_largeQP2_csv7 = random.sample(second_largeQP2_csv7, 100)\n",
    "second_largeQP2_csv8 = random.sample(second_largeQP2_csv8, 100)\n",
    "second_largeQP2_csv9 = random.sample(second_largeQP2_csv9, 100)\n",
    "# second_largeQP2_csv10 = selected_data[9]\n",
    "print('\\ndouble images train by QP1<QP2: ', len(second_largeQP2_csv1))\n",
    "\n",
    "second_largeQP2_csv10 = random.sample(second_largeQP2_csv10, 300)\n",
    "print('\\ndouble images test by QP1<QP2: ', len(second_largeQP2_csv10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_csv_list:  600\n",
      "\n",
      "test_csv_largeQP1 600\n",
      "test_csv_sameQP 600\n",
      "test_csv_largeQP2 600\n"
     ]
    }
   ],
   "source": [
    "train_csv_list1 = single_csv1 + second_largeQP1_csv1 + second_sameQP_csv1 + second_largeQP2_csv1\n",
    "train_csv_list2 = single_csv2 + second_largeQP1_csv2 + second_sameQP_csv2 + second_largeQP2_csv2\n",
    "train_csv_list3 = single_csv3 + second_largeQP1_csv3 + second_sameQP_csv3 + second_largeQP2_csv3\n",
    "train_csv_list4 = single_csv4 + second_largeQP1_csv4 + second_sameQP_csv4 + second_largeQP2_csv4\n",
    "train_csv_list5 = single_csv5 + second_largeQP1_csv5 + second_sameQP_csv5 + second_largeQP2_csv5\n",
    "train_csv_list6 = single_csv6 + second_largeQP1_csv6 + second_sameQP_csv6 + second_largeQP2_csv6\n",
    "train_csv_list7 = single_csv7 + second_largeQP1_csv7 + second_sameQP_csv7 + second_largeQP2_csv7\n",
    "train_csv_list8 = single_csv8 + second_largeQP1_csv8 + second_sameQP_csv8 + second_largeQP2_csv8\n",
    "train_csv_list9 = single_csv9 + second_largeQP1_csv9 + second_sameQP_csv9 + second_largeQP2_csv9\n",
    "print(\"train_csv_list: \", len(train_csv_list9))\n",
    "\n",
    "test_csv_largeQP1 = single_csv10 + second_largeQP1_csv10\n",
    "test_csv_sameQP = single_csv10 + second_sameQP_csv10\n",
    "test_csv_largeQP2 = single_csv10 + second_largeQP2_csv10\n",
    "\n",
    "print(\"\\ntest_csv_largeQP1\", len(test_csv_largeQP1))\n",
    "print(\"test_csv_sameQP\", len(test_csv_sameQP))\n",
    "print(\"test_csv_largeQP2\", len(test_csv_largeQP2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_smoothing(probabilities, alpha=1):\n",
    "    \"\"\"\n",
    "    ラプラス平滑化を行う関数\n",
    "    \n",
    "    Args:\n",
    "    probabilities (list): 平滑化する確率分布のリスト\n",
    "    alpha (float): 平滑化パラメータ\n",
    "    \n",
    "    Returns:\n",
    "    smoothed_probabilities (list): 平滑化された確率分布のリスト\n",
    "    \"\"\"\n",
    "    total_count = sum(probabilities)\n",
    "    num_elements = len(probabilities)\n",
    "    \n",
    "    smoothed_probabilities = [(count + alpha) / (total_count + alpha * num_elements) for count in probabilities]\n",
    "    \n",
    "    return smoothed_probabilities\n",
    "\n",
    "\n",
    "def process_train_csv_lists(train_csv_list):\n",
    "    pu_columns = [\"PU1_64\", \"PU1_32\", \"PU1_16\", \"PU1_8\", \"PU1_4\",  \n",
    "                  \"PU2_64\",\"PU2_32\", \"PU2_16\", \"PU2_8\", \"PU2_4\"]\n",
    "\n",
    "#     luminance_columns = [\"LU1_0\",\"LU1_1\",\"LU1_2\",\"LU1_3\",\n",
    "#                          \"LU1_4\",\"LU1_5\",\"LU1_6\",\"LU1_7\",\n",
    "#                          \"LU1_8\",\"LU1_9\",\"LU1_10\",\"LU1_11\",\n",
    "#                          \"LU1_12\",\"LU1_13\",\"LU1_14\",\"LU1_15\",\n",
    "#                          \"LU1_16\",\"LU1_17\",\"LU1_18\",\"LU1_19\",\n",
    "#                          \"LU1_20\",\"LU1_21\",\"LU1_22\",\"LU1_23\",\n",
    "#                          \"LU1_24\",\"LU1_25\",\"LU1_26\",\"LU1_27\",\n",
    "#                          \"LU1_28\",\"LU1_29\",\"LU1_30\",\"LU1_31\",\n",
    "#                          \"LU1_32\",\"LU1_33\",\"LU1_34\",\n",
    "                         \n",
    "#                          \"LU2_0\",\"LU2_1\",\"LU2_2\",\"LU2_3\",\n",
    "#                          \"LU2_4\",\"LU2_5\",\"LU2_6\",\"LU2_7\",\n",
    "#                          \"LU2_8\",\"LU2_9\",\"LU2_10\",\"LU2_11\",\n",
    "#                          \"LU2_12\",\"LU2_13\",\"LU2_14\",\"LU2_15\",\n",
    "#                          \"LU2_16\",\"LU2_17\",\"LU2_18\",\"LU2_19\",\n",
    "#                          \"LU2_20\",\"LU2_21\",\"LU2_22\",\"LU2_23\",\n",
    "#                          \"LU2_24\",\"LU2_25\",\"LU2_26\",\"LU2_27\",\n",
    "#                          \"LU2_28\",\"LU2_29\",\"LU2_30\",\"LU2_31\",\n",
    "#                          \"LU2_32\",\"LU2_33\",\"LU2_34\"]\n",
    "    \n",
    "    luminance_columns = [\"LU1_0\",\"LU1_1\",\"LU1_9\",\"LU1_10\",\"LU1_11\",\"LU1_25\",\"LU1_26\",\"LU1_27\",\n",
    "                         \"LU2_0\",\"LU2_1\",\"LU2_9\",\"LU2_10\",\"LU2_11\", \"LU2_25\",\"LU2_26\",\"LU2_27\"]\n",
    "\n",
    "    chrominance_columns = [\"CH1_0\", \"CH1_1\", \"CH1_10\", \"CH1_26\", \"CH1_34\", \"CH1_36\", \n",
    "                           \"CH2_0\", \"CH2_1\", \"CH2_10\", \"CH2_26\", \"CH2_34\", \"CH2_36\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    label_columns = [\"LABEL\"]\n",
    "    mae1_columns = [f\"MAE1_{i}\" for i in range(52)]\n",
    "    mae2_columns = [f\"MAE2_{i}\" for i in range(52)]\n",
    "    mae_columns = [\"MAE\"]\n",
    "    final_qp_columns = [\"FINAL_QP\"]\n",
    "    kl_divergence1 = [\"KLD_PU\"]\n",
    "    kl_divergence2 = [\"KLD_LUMA\"]\n",
    "    kl_divergence3 = [\"KLD_CHROMA\"]\n",
    "    ratio_columns1 = [\"RATIO1\"]\n",
    "    ratio_columns2 = [\"RATIO2\"]\n",
    "    \n",
    "    train_df1_1 = pd.DataFrame(columns=pu_columns)\n",
    "    train_df1_2 = pd.DataFrame(columns=luminance_columns)\n",
    "    train_df1_3 = pd.DataFrame(columns=chrominance_columns)\n",
    "    LABEL = pd.DataFrame(columns=label_columns)\n",
    "    RATIO1 = pd.DataFrame(columns=ratio_columns1)\n",
    "    RATIO2 = pd.DataFrame(columns=ratio_columns2)\n",
    "    train_df3 = pd.DataFrame(columns=mae1_columns)\n",
    "    train_df4 = pd.DataFrame(columns=mae2_columns)\n",
    "    MAE = pd.DataFrame(columns=mae_columns)\n",
    "    FINAL_QP = pd.DataFrame(columns=final_qp_columns)\n",
    "    kl_divergence_df1 = pd.DataFrame(columns=kl_divergence1)\n",
    "    kl_divergence_df2 = pd.DataFrame(columns=kl_divergence2)\n",
    "    kl_divergence_df3 = pd.DataFrame(columns=kl_divergence3)\n",
    "\n",
    "    for path1, path2, path3, path4 in train_csv_list:\n",
    "        label = 1 if (\"2ndQP\" in path1) and (\"3rdQP\" in path3) else 0\n",
    "        train_pkl_list = [path2, path4]\n",
    "        df1 = pd.read_csv(path1)\n",
    "        df2 = pd.read_csv(path3)\n",
    "        \n",
    "        # 平滑化を行う\n",
    "        probabilities_df1 = laplace_smoothing([df1.loc[i, \"pu_counts\"] for i in [0,1,2,3,4]])\n",
    "        probabilities_df2 = laplace_smoothing([df2.loc[i, \"pu_counts\"] for i in [0,1,2,3,4]])\n",
    "        kl_divergence1 = entropy(probabilities_df1, probabilities_df2)\n",
    "        \n",
    "        probabilities_df3 = laplace_smoothing([df1.loc[i, \"luminance_counts\"] for i in [0,1,9,10,11,25,26,27]])\n",
    "        probabilities_df4 = laplace_smoothing([df2.loc[i, \"luminance_counts\"] for i in [0,1,9,10,11,25,26,27]])\n",
    "        kl_divergence2 = entropy(probabilities_df3, probabilities_df4)\n",
    "        \n",
    "        probabilities_df5 = laplace_smoothing([df1.loc[i, \"chroma_counts\"] for i in [0,1,10,26,34,36]])\n",
    "        probabilities_df6 = laplace_smoothing([df2.loc[i, \"chroma_counts\"] for i in [0,1,10,26,34,36]])\n",
    "        kl_divergence3 = entropy(probabilities_df5, probabilities_df6)\n",
    "        \n",
    "        \n",
    "        pu_values = [df1.loc[i, \"pu_counts\"] for i in range(5)] + [df2.loc[i, \"pu_counts\"] for i in range(5)]\n",
    "        # lu_values = [df1.loc[i, \"luminance_counts\"] for i in range(35)] + [df2.loc[i, \"luminance_counts\"] for i in range(35)]\n",
    "        lu_values = [df1.loc[i, \"luminance_counts\"] for i in [0,1,9,10,11,25,26,27]] + [df2.loc[i, \"luminance_counts\"] for i in [0,1,9,10,11,25,26,27]]\n",
    "        ch_values = [df1.loc[i, \"chroma_counts\"] for i in [0,1,10,26,34,36]] + [df2.loc[i, \"chroma_counts\"] for i in [0,1,10,26,34,36]]\n",
    "        \n",
    "        train_df1_1 = pd.concat([train_df1_1, pd.DataFrame([pu_values], columns=pu_columns)], ignore_index=True)\n",
    "        train_df1_2= pd.concat([train_df1_2, pd.DataFrame([lu_values], columns=luminance_columns)], ignore_index=True)\n",
    "        train_df1_3 = pd.concat([train_df1_3, pd.DataFrame([ch_values], columns=chrominance_columns)], ignore_index=True)\n",
    "        \n",
    "        kl_divergence_df1 = pd.concat([kl_divergence_df1, pd.DataFrame({\"KLD_PU\": [kl_divergence1]})], ignore_index=True)\n",
    "        kl_divergence_df2 = pd.concat([kl_divergence_df2, pd.DataFrame({\"KLD_LUMA\": [kl_divergence2]})], ignore_index=True)\n",
    "        kl_divergence_df3 = pd.concat([kl_divergence_df3, pd.DataFrame({\"KLD_CHROMA\": [kl_divergence3]})], ignore_index=True)\n",
    "\n",
    "\n",
    "        LABEL = pd.concat([LABEL, pd.DataFrame({\"LABEL\": [label]})], ignore_index=True)\n",
    "\n",
    "        final_QP = extract_finalQP(train_pkl_list[0])\n",
    "\n",
    "        mae_d1 = calculate_mae(train_pkl_list[0])\n",
    "        mae_d2 = calculate_mae(train_pkl_list[1])\n",
    "        ratio1 = ratio_double_compressed(mae_d1, final_QP)\n",
    "        ratio2 = ratio_double_compressed(mae_d2, final_QP)\n",
    "\n",
    "        RATIO1 = pd.concat([RATIO1, pd.DataFrame({\"RATIO1\": [ratio1]})], ignore_index=True)\n",
    "        RATIO2 = pd.concat([RATIO2, pd.DataFrame({\"RATIO2\": [ratio2]})], ignore_index=True)\n",
    "\n",
    "        train_df3 = pd.concat([train_df3, pd.DataFrame({f\"MAE1_{i}\": [mae_d1[i]] for i in range(52)})], ignore_index=True)\n",
    "        train_df4 = pd.concat([train_df4, pd.DataFrame({f\"MAE2_{i}\": [mae_d2[i]] for i in range(52)})], ignore_index=True)\n",
    "        MAE = pd.concat([MAE, pd.DataFrame({\"MAE\": [mae_d1]})], ignore_index=True)\n",
    "        FINAL_QP = pd.concat([FINAL_QP, pd.DataFrame({\"FINAL_QP\": [final_QP]})], ignore_index=True)\n",
    "\n",
    "    train_df1_1.reset_index(drop=True, inplace=True)\n",
    "    train_df1_2.reset_index(drop=True, inplace=True)\n",
    "    train_df1_3.reset_index(drop=True, inplace=True)\n",
    "    LABEL.reset_index(drop=True, inplace=True)\n",
    "    RATIO1.reset_index(drop=True, inplace=True)\n",
    "    RATIO2.reset_index(drop=True, inplace=True)\n",
    "    kl_divergence_df1.reset_index(drop=True, inplace=True)\n",
    "    kl_divergence_df2.reset_index(drop=True, inplace=True)\n",
    "    kl_divergence_df3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # train_df = pd.concat([train_df1_1, train_df1_2, train_df1_3, train_df3, train_df4], axis=1)\n",
    "    train_df = pd.concat([FINAL_QP, train_df1_1, train_df1_2, train_df1_3, kl_divergence_df1, kl_divergence_df2, kl_divergence_df3, RATIO1, RATIO2], axis=1)\n",
    "    train_df_onlyGhost = pd.concat([FINAL_QP, kl_divergence_df1, kl_divergence_df2, kl_divergence_df3, RATIO1, RATIO2], axis=1)\n",
    "\n",
    "    return train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1, train_df_onlyGhost1, LABEL1, MAE1, FINAL_QP1 = process_train_csv_lists(train_csv_list1)\n",
    "train_df2, train_df_onlyGhost2, LABEL2, MAE2, FINAL_QP2 = process_train_csv_lists(train_csv_list2)\n",
    "train_df3, train_df_onlyGhost3, LABEL3, MAE3, FINAL_QP3 = process_train_csv_lists(train_csv_list3)\n",
    "train_df4, train_df_onlyGhost4, LABEL4, MAE4, FINAL_QP4 = process_train_csv_lists(train_csv_list4)\n",
    "train_df5, train_df_onlyGhost5, LABEL5, MAE5, FINAL_QP5 = process_train_csv_lists(train_csv_list5)\n",
    "train_df6, train_df_onlyGhost6, LABEL6, MAE6, FINAL_QP6 = process_train_csv_lists(train_csv_list6)\n",
    "train_df7, train_df_onlyGhost7, LABEL7, MAE7, FINAL_QP7 = process_train_csv_lists(train_csv_list7)\n",
    "train_df8, train_df_onlyGhost8, LABEL8, MAE8, FINAL_QP8 = process_train_csv_lists(train_csv_list8)\n",
    "train_df9, train_df_onlyGhost9, LABEL9, MAE9, FINAL_QP9 = process_train_csv_lists(train_csv_list9)\n",
    "\n",
    "test_df1, test_df_onlyGhost1, LABEL_t1, MAE_t1, FINAL_QP_t1 = process_train_csv_lists(test_csv_largeQP1)\n",
    "test_df2, test_df_onlyGhost2, LABEL_t2, MAE_t2, FINAL_QP_t2 = process_train_csv_lists(test_csv_sameQP)\n",
    "test_df3, test_df_onlyGhost3, LABEL_t3, MAE_t3, FINAL_QP_t3 = process_train_csv_lists(test_csv_largeQP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各データフレームを結合\n",
    "combined_train_df = pd.concat([train_df1, train_df2, train_df3, train_df4, train_df5, train_df6, train_df7, train_df8, train_df9], ignore_index=True)\n",
    "combined_train_df_onlyGhost = pd.concat([train_df_onlyGhost1, train_df_onlyGhost2, train_df_onlyGhost3, train_df_onlyGhost4, train_df_onlyGhost5, train_df_onlyGhost6, train_df_onlyGhost7, train_df_onlyGhost8, train_df_onlyGhost9], ignore_index=True)\n",
    "combined_LABEL = pd.concat([LABEL1, LABEL2, LABEL3, LABEL4, LABEL5, LABEL6, LABEL7, LABEL8, LABEL9], ignore_index=True)\n",
    "combined_MAE = pd.concat([MAE1, MAE2, MAE3, MAE4, MAE5, MAE6, MAE7, MAE8, MAE9], ignore_index=True)\n",
    "combined_FINAL_QP = pd.concat([FINAL_QP1, FINAL_QP2, FINAL_QP3, FINAL_QP4, FINAL_QP5, FINAL_QP6, FINAL_QP7, FINAL_QP8, FINAL_QP9], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5400, 44)\n",
      "(5400, 6)\n",
      "(5400, 1)\n",
      "(5400, 1)\n",
      "(5400, 1)\n",
      "(600, 44)\n",
      "(600, 6)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 44)\n",
      "(600, 6)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 44)\n",
      "(600, 6)\n",
      "(600, 1)\n",
      "(600, 1)\n",
      "(600, 1)\n"
     ]
    }
   ],
   "source": [
    "print(combined_train_df.shape)\n",
    "print(combined_train_df_onlyGhost.shape)\n",
    "print(combined_LABEL.shape)\n",
    "print(combined_MAE.shape)\n",
    "print(combined_FINAL_QP.shape)\n",
    "\n",
    "print(test_df1.shape)\n",
    "print(test_df_onlyGhost1.shape)\n",
    "print(LABEL_t1.shape)\n",
    "print(MAE_t1.shape)\n",
    "print(FINAL_QP_t1.shape)\n",
    "\n",
    "print(test_df2.shape)\n",
    "print(test_df_onlyGhost2.shape)\n",
    "print(LABEL_t2.shape)\n",
    "print(MAE_t2.shape)\n",
    "print(FINAL_QP_t2.shape)\n",
    "\n",
    "print(test_df3.shape)\n",
    "print(test_df_onlyGhost3.shape)\n",
    "print(LABEL_t3.shape)\n",
    "print(MAE_t3.shape)\n",
    "print(FINAL_QP_t3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling:\n",
      "Combined Train DF:\n",
      "  FINAL_QP PU1_64 PU1_32 PU1_16  PU1_8  PU1_4 PU2_64 PU2_32 PU2_16  PU2_8  PU2_4 LU1_0 LU1_1 LU1_9 LU1_10 LU1_11 LU1_25 LU1_26 LU1_27  LU2_0 LU2_1 LU2_9 LU2_10 LU2_11 LU2_25 LU2_26 LU2_27  CH1_0  CH1_1 CH1_10 CH1_26 CH1_34 CH1_36  CH2_0  CH2_1 CH2_10 CH2_26 CH2_34 CH2_36    KLD_PU  KLD_LUMA KLD_CHROMA    RATIO1    RATIO2\n",
      "0       10      0   2816   4016  15596  37572      0   2816   3968  14568  38648  7027  5523  1407   1943   1265   1293   2259   1179   6969  5867  1407   1916   1256   1392   2093   1292  14032  10048   6180   6388   2020  21332  14092  10332   6308   6732   1872  20664  0.000847   0.00109   0.000512   0.03525  0.026403\n",
      "1       16      0   5632   6016  17944  30408      0   5568   6016  17256  31160  7799  6432  1075   1767   1221   1427   1959   1121   7695  6867  1128   1780   1290   1487   1928   1007  12896   7760   4788   4468   1448  28640  12488   8572   4744   4524   1312  28360  0.000384  0.000987   0.000918  0.017283  0.010751\n",
      "2       20      0   5952   9056  17732  27260      0   5952   9040  16984  28024  8497  7022  1157   1624   1014   1113   1717   1059   8349  7288  1141   1707   1035   1096   1846    980  11268   6912   4308   3500   1412  32600  11544   7120   4424   3612   1364  31936  0.000446  0.000656   0.000289   0.01265  0.009641\n",
      "3       24      0   8448   9232  18036  24284      0   8448   9264  17764  24524  8967  6997  1135   1463   1047   1145   1673    943   9269  7234  1138   1376   1028   1051   1679    924  10636   5516   3148   3344   1320  36036  10240   6016   3212   3264   1164  36104  0.000055  0.000589   0.000677  0.010567  0.005692\n",
      "4       27      0   8512  10512  19464  21512      0   8640  10512  19232  21616  9566  7223   794   1292    953   1040   1577    787  10017  7506   798   1123   1033   1005   1673    797   9008   4544   2948   2908   1360  39232   8852   4416   2744   2728   1104  40156  0.000043  0.001014   0.000912  0.197713  0.154031\n",
      "Combined Train DF Only Ghost:\n",
      "  FINAL_QP    KLD_PU  KLD_LUMA KLD_CHROMA    RATIO1    RATIO2\n",
      "0       10  0.000847   0.00109   0.000512   0.03525  0.026403\n",
      "1       16  0.000384  0.000987   0.000918  0.017283  0.010751\n",
      "2       20  0.000446  0.000656   0.000289   0.01265  0.009641\n",
      "3       24  0.000055  0.000589   0.000677  0.010567  0.005692\n",
      "4       27  0.000043  0.001014   0.000912  0.197713  0.154031\n",
      "\n",
      "Before scaling:\n",
      "Combined Test DF:\n",
      "  FINAL_QP PU1_64 PU1_32 PU1_16  PU1_8  PU1_4 PU2_64 PU2_32 PU2_16  PU2_8  PU2_4  LU1_0 LU1_1 LU1_9 LU1_10 LU1_11 LU1_25 LU1_26 LU1_27  LU2_0 LU2_1 LU2_9 LU2_10 LU2_11 LU2_25 LU2_26 LU2_27  CH1_0  CH1_1 CH1_10 CH1_26 CH1_34 CH1_36  CH2_0  CH2_1 CH2_10 CH2_26 CH2_34 CH2_36    KLD_PU  KLD_LUMA KLD_CHROMA    RATIO1    RATIO2\n",
      "0       10      0   5568   4480  14348  35604      0   5632   4400  13528  36440   9404  8141  2611   2971   1566   2337   2823   1227   9334  8636  2654   3091   1653   2345   2818   1102  16616  10920   7452   8220   1996  14796  16732  10784   8036   7968   1876  14604  0.000585    0.0007   0.000533  0.039647  0.030034\n",
      "1       16      0   8704   6672  18160  26464      0   8192   7088  17528  27192   9732  8314  2420   3115   1350   2714   2795   1196   9844  8434  2518   3219   1370   2731   2814   1210  16492   8060   6016   4992   1728  22712  16324   8312   6492   5080   1596  22196   0.00082  0.000047   0.000577  0.018075   0.01128\n",
      "2       20      0   9280  12560  16532  21628      0   9344  12416  15988  22252  11950  7921  2647   2615   1116   2178   2636    891  12106  8067  2680   2621   1113   2254   2595    938  13980   7340   4920   3836   1528  28396  13856   7608   4916   3768   1328  28524  0.000317  0.000082   0.000343  0.023231  0.018449\n",
      "3       24      0  14400  10928  15884  18788      0  14528  10672  15684  19116  12506  8800  2637   3503    943   1962   2938    576  12706  8924  2774   3568    920   2023   2880    583  13072   5204   4280   3212   1860  32372  12740   5016   4180   2884   1688  33492  0.000129  0.000132   0.000906  0.005189   0.00334\n",
      "4       27      0  16576  12704  14804  15916      0  16512  12752  14372  16364  14488  9488  2630   3611    827   2002   2315    622  14583  9763  2635   3606    863   2036   2330    673  11208   4356   3472   2664   1888  36412  10880   4440   3016   2380   1628  37656  0.000214  0.000105   0.001589  0.255385  0.221641\n",
      "Combined Test DF Only Ghost:\n",
      "  FINAL_QP    KLD_PU  KLD_LUMA KLD_CHROMA    RATIO1    RATIO2\n",
      "0       10  0.000585    0.0007   0.000533  0.039647  0.030034\n",
      "1       16   0.00082  0.000047   0.000577  0.018075   0.01128\n",
      "2       20  0.000317  0.000082   0.000343  0.023231  0.018449\n",
      "3       24  0.000129  0.000132   0.000906  0.005189   0.00334\n",
      "4       27  0.000214  0.000105   0.001589  0.255385  0.221641\n"
     ]
    }
   ],
   "source": [
    "print(\"Before scaling:\")\n",
    "print(\"Combined Train DF:\")\n",
    "print(combined_train_df.head())\n",
    "print(\"Combined Train DF Only Ghost:\")\n",
    "print(combined_train_df_onlyGhost.head())\n",
    "\n",
    "print(\"\\nBefore scaling:\")\n",
    "print(\"Combined Test DF:\")\n",
    "print(test_df1.head())\n",
    "print(\"Combined Test DF Only Ghost:\")\n",
    "print(test_df_onlyGhost1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After scaling:\n",
      "X_train:\n",
      "      0    1         2         3         4         5    6         7         8         9         10        11        12        13        14        15        16        17        18        19        20        21        22        23        24        25        26        27        28        29        30        31        32        33        34        35        36        37        38        39        40        41        42        43\n",
      "0  0.125  0.0  0.047826  0.126512  0.540627  0.671264  0.0  0.047774  0.124937  0.497269  0.673451  0.132091  0.113719  0.107987  0.090557  0.103296  0.087655  0.073389  0.124171  0.139556  0.116381  0.107895  0.090831  0.104420  0.094366  0.062468  0.140833  0.391387  0.406407  0.322278  0.390369  0.184576  0.308908  0.386336  0.408379  0.319360  0.380167  0.165722  0.297471  0.047515  0.009901  0.007633  0.033186  0.024965\n",
      "1  0.275  0.0  0.095652  0.189516  0.622019  0.543272  0.0  0.094463  0.189421  0.589022  0.542971  0.157464  0.144158  0.082342  0.082337  0.099634  0.096739  0.062722  0.118062  0.165363  0.150232  0.086363  0.084350  0.107256  0.100807  0.056764  0.109767  0.359701  0.313865  0.249687  0.273038  0.132310  0.439520  0.342362  0.338814  0.240178  0.255478  0.116147  0.434919  0.021538  0.008962  0.013756  0.015180  0.009289\n",
      "2  0.375  0.0  0.101087  0.285282  0.614670  0.487029  0.0  0.100977  0.284635  0.579738  0.488325  0.180405  0.163915  0.088676  0.075659  0.082404  0.075453  0.054117  0.111532  0.188611  0.164483  0.087366  0.080871  0.085988  0.074300  0.053929  0.106824  0.314292  0.279566  0.224656  0.213884  0.129020  0.510295  0.316482  0.281423  0.223977  0.203976  0.120751  0.498786  0.025002  0.005939  0.004285  0.010537  0.008177\n",
      "3  0.475  0.0  0.143478  0.290827  0.625208  0.433860  0.0  0.143322  0.291688  0.606363  0.427337  0.195852  0.163078  0.086977  0.068139  0.085151  0.077622  0.052553  0.099315  0.221314  0.162655  0.087134  0.065097  0.085405  0.071249  0.048156  0.100719  0.296664  0.223103  0.164164  0.204351  0.120614  0.571704  0.280733  0.237787  0.162616  0.184323  0.103045  0.573225  0.003088  0.005329  0.010127  0.008449  0.004221\n",
      "4  0.550  0.0  0.144565  0.331149  0.674709  0.384335  0.0  0.146580  0.330982  0.656472  0.376664  0.215539  0.170646  0.060636  0.060153  0.077326  0.070504  0.049140  0.082886  0.247903  0.171863  0.060894  0.053040  0.085822  0.068131  0.047948  0.086876  0.251255  0.183789  0.153734  0.177707  0.124269  0.628825  0.242680  0.174545  0.138923  0.154055  0.097734  0.645592  0.002427  0.009205  0.013670  0.196005  0.152795\n",
      "X_train_onlyGhost:\n",
      "       0         1         2         3         4         5\n",
      "0  0.125  0.047515  0.009901  0.007633  0.033186  0.024965\n",
      "1  0.275  0.021538  0.008962  0.013756  0.015180  0.009289\n",
      "2  0.375  0.025002  0.005939  0.004285  0.010537  0.008177\n",
      "3  0.475  0.003088  0.005329  0.010127  0.008449  0.004221\n",
      "4  0.550  0.002427  0.009205  0.013670  0.196005  0.152795\n",
      "\n",
      "Test data after scaling:\n",
      "X_test_list1:\n",
      "      0    1         2         3         4         5    6         7         8         9         10        11        12        13        14        15        16        17        18        19        20        21        22        23        24        25        26        27        28        29        30        31        32        33        34        35        36        37        38        39        40        41        42        43\n",
      "0  0.125  0.0  0.094565  0.141129  0.497366  0.636104  0.0  0.095548  0.138539  0.461770  0.634976  0.210215  0.201386  0.200989  0.138567  0.128350  0.158430  0.093443  0.129226  0.223624  0.210115  0.204137  0.146826  0.137531  0.158972  0.087531  0.120122  0.463461  0.441676  0.388611  0.502322  0.182383  0.192093  0.458713  0.426245  0.406845  0.449966  0.166076  0.189241  0.032810  0.006342  0.007952  0.037592  0.028602\n",
      "1  0.275  0.0  0.147826  0.210181  0.629506  0.472808  0.0  0.138979  0.223174  0.598307  0.473827  0.220995  0.207179  0.186235  0.145292  0.110371  0.183988  0.092448  0.125961  0.241753  0.203277  0.193641  0.152926  0.113928  0.185140  0.087392  0.131894  0.460002  0.325999  0.313725  0.305060  0.157895  0.333572  0.447527  0.328538  0.328676  0.286876  0.141289  0.324832  0.045989  0.000392  0.008624  0.015973  0.009819\n",
      "2  0.375  0.0  0.157609  0.395665  0.573073  0.386407  0.0  0.158523  0.390932  0.545740  0.387747  0.293893  0.194019  0.203770  0.121941  0.090894  0.147651  0.086794  0.093839  0.322160  0.190853  0.206143  0.124428  0.092494  0.152803  0.079822  0.102245  0.389936  0.296878  0.256571  0.234417  0.139620  0.435159  0.379866  0.300711  0.248886  0.212785  0.117564  0.437848  0.017785  0.000711  0.005090  0.021140  0.016999\n",
      "3  0.475  0.0  0.244565  0.344254  0.550610  0.335668  0.0  0.246471  0.336020  0.535363  0.333101  0.312167  0.223454  0.202997  0.163413  0.076494  0.133008  0.097532  0.060664  0.343488  0.219864  0.213398  0.169558  0.076397  0.137143  0.089674  0.063549  0.364610  0.210484  0.223196  0.196285  0.169956  0.506220  0.349271  0.198261  0.211624  0.162864  0.149433  0.526575  0.007205  0.001164  0.013575  0.003059  0.001865\n",
      "4  0.550  0.0  0.281522  0.400202  0.513172  0.284356  0.0  0.280130  0.401511  0.490579  0.285147  0.377309  0.246492  0.202456  0.168457  0.066839  0.135720  0.075380  0.065508  0.410209  0.248265  0.202670  0.171369  0.071643  0.138025  0.070661  0.073359  0.312619  0.176185  0.181060  0.162796  0.172515  0.578424  0.298278  0.175494  0.152693  0.134403  0.144122  0.600943  0.011989  0.000917  0.023877  0.253804  0.220513\n",
      "X_test_onlyGhost_list1:\n",
      "       0         1         2         3         4         5\n",
      "0  0.125  0.032810  0.006342  0.007952  0.037592  0.028602\n",
      "1  0.275  0.045989  0.000392  0.008624  0.015973  0.009819\n",
      "2  0.375  0.017785  0.000711  0.005090  0.021140  0.016999\n",
      "3  0.475  0.007205  0.001164  0.013575  0.003059  0.001865\n",
      "4  0.550  0.011989  0.000917  0.023877  0.253804  0.220513\n"
     ]
    }
   ],
   "source": [
    "def process_results_to_lists(train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP, scaler_main=None, scaler_ghost=None, fit_scaler=True):\n",
    "    if fit_scaler:\n",
    "        scaler_main = MinMaxScaler()\n",
    "        scaler_ghost = MinMaxScaler()\n",
    "        X_train = scaler_main.fit_transform(train_df)\n",
    "        X_train_onlyGhost = scaler_ghost.fit_transform(train_df_onlyGhost)\n",
    "    else:\n",
    "        X_train = scaler_main.transform(train_df)\n",
    "        X_train_onlyGhost = scaler_ghost.transform(train_df_onlyGhost)\n",
    "\n",
    "    MAE_array = MAE.values\n",
    "    FINAL_QP_array = FINAL_QP.values\n",
    "    Y_train = LABEL['LABEL'].astype(int).values\n",
    "\n",
    "    return X_train, X_train_onlyGhost, MAE_array, FINAL_QP_array, Y_train, scaler_main, scaler_ghost\n",
    "\n",
    "# 訓練データのスケーリング\n",
    "X_train, X_train_onlyGhost, MAE_array, FINAL_QP_array, Y_train, scaler_main, scaler_ghost = process_results_to_lists(\n",
    "    combined_train_df, combined_train_df_onlyGhost, combined_LABEL, combined_MAE, combined_FINAL_QP, fit_scaler=True\n",
    ")\n",
    "\n",
    "# スケーリング後のデータを表示（任意）\n",
    "print(\"After scaling:\")\n",
    "print(\"X_train:\")\n",
    "print(pd.DataFrame(X_train).head())\n",
    "print(\"X_train_onlyGhost:\")\n",
    "print(pd.DataFrame(X_train_onlyGhost).head())\n",
    "\n",
    "# データを元に戻すための関数\n",
    "def restore_data_to_original_order(data, original_lengths):\n",
    "    restored_data = []\n",
    "    start_index = 0\n",
    "    for length in original_lengths:\n",
    "        restored_data.append(data[start_index:start_index + length])\n",
    "        start_index += length\n",
    "    return restored_data\n",
    "\n",
    "# 元のデータフレームの長さ\n",
    "original_lengths = [len(train_df1), len(train_df2), len(train_df3), len(train_df4), len(train_df5), \n",
    "                    len(train_df6), len(train_df7), len(train_df8), len(train_df9)]\n",
    "\n",
    "# データを元の順序に戻す\n",
    "X_train_list = restore_data_to_original_order(X_train, original_lengths)\n",
    "X_train_onlyGhost_list = restore_data_to_original_order(X_train_onlyGhost, original_lengths)\n",
    "MAE_list = restore_data_to_original_order(MAE_array, original_lengths)\n",
    "FINAL_QP_list = restore_data_to_original_order(FINAL_QP_array, original_lengths)\n",
    "Y_train_list = restore_data_to_original_order(Y_train, original_lengths)\n",
    "\n",
    "# テストデータのスケーリング関数\n",
    "def append_results_to_lists(train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP, X_train_list, X_train_onlyGhost_list, MAE_list, FINAL_QP_list, Y_train_list, scaler_main=None, scaler_ghost=None, fit_scaler=True):\n",
    "    X_train, X_train_onlyGhost, MAE_array, FINAL_QP_array, Y_train, _, _ = process_results_to_lists(\n",
    "        train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP, scaler_main, scaler_ghost, fit_scaler)\n",
    "    X_train_list.append(X_train)\n",
    "    X_train_onlyGhost_list.append(X_train_onlyGhost)\n",
    "    MAE_list.append(MAE_array)\n",
    "    FINAL_QP_list.append(FINAL_QP_array)\n",
    "    Y_train_list.append(Y_train)\n",
    "    return X_train_list, X_train_onlyGhost_list, MAE_list, FINAL_QP_list, Y_train_list\n",
    "\n",
    "# テストデータ用のリストの初期化\n",
    "X_test_list1 = []\n",
    "X_test_onlyGhost_list1 = []\n",
    "MAE_list_t1 = []\n",
    "FINAL_QP_list_t1 = []\n",
    "Y_test_list1 = []\n",
    "\n",
    "X_test_list2 = []\n",
    "X_test_onlyGhost_list2 = []\n",
    "MAE_list_t2 = []\n",
    "FINAL_QP_list_t2 = []\n",
    "Y_test_list2 = []\n",
    "\n",
    "X_test_list3 = []\n",
    "X_test_onlyGhost_list3 = []\n",
    "MAE_list_t3 = []\n",
    "FINAL_QP_list_t3 = []\n",
    "Y_test_list3 = []\n",
    "\n",
    "# テストデータの処理とスケーリング\n",
    "X_test_list1, X_test_onlyGhost_list1, MAE_list_t1, FINAL_QP_list_t1, Y_test_list1 = append_results_to_lists(\n",
    "    test_df1, test_df_onlyGhost1, LABEL_t1, MAE_t1, FINAL_QP_t1, X_test_list1, X_test_onlyGhost_list1, MAE_list_t1, FINAL_QP_list_t1, Y_test_list1, scaler_main, scaler_ghost, fit_scaler=False\n",
    ")\n",
    "X_test_list2, X_test_onlyGhost_list2, MAE_list_t2, FINAL_QP_list_t2, Y_test_list2 = append_results_to_lists(\n",
    "    test_df2, test_df_onlyGhost2, LABEL_t2, MAE_t2, FINAL_QP_t2, X_test_list2, X_test_onlyGhost_list2, MAE_list_t2, FINAL_QP_list_t2, Y_test_list2, scaler_main, scaler_ghost, fit_scaler=False\n",
    ")\n",
    "X_test_list3, X_test_onlyGhost_list3, MAE_list_t3, FINAL_QP_list_t3, Y_test_list3 = append_results_to_lists(\n",
    "    test_df3, test_df_onlyGhost3, LABEL_t3, MAE_t3, FINAL_QP_t3, X_test_list3, X_test_onlyGhost_list3, MAE_list_t3, FINAL_QP_list_t3, Y_test_list3, scaler_main, scaler_ghost, fit_scaler=False\n",
    ")\n",
    "\n",
    "# 確認用の出力\n",
    "print(\"\\nTest data after scaling:\")\n",
    "print(\"X_test_list1:\")\n",
    "print(pd.DataFrame(X_test_list1[0]).head())\n",
    "print(\"X_test_onlyGhost_list1:\")\n",
    "print(pd.DataFrame(X_test_onlyGhost_list1[0]).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Fold-1>\n",
      "Train indices: [0 1 2 3 4 5 6 8]\n",
      "Test indices: [7]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8416666666666667\n",
      "0.5016666666666667\n",
      "0.5566666666666666\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9544    0.9067    0.9299       300\n",
      "           1     0.9111    0.9567    0.9333       300\n",
      "\n",
      "    accuracy                         0.9317       600\n",
      "   macro avg     0.9327    0.9317    0.9316       600\n",
      "weighted avg     0.9327    0.9317    0.9316       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9654    0.8367    0.8964       300\n",
      "           1     0.8559    0.9700    0.9094       300\n",
      "\n",
      "    accuracy                         0.9033       600\n",
      "   macro avg     0.9106    0.9033    0.9029       600\n",
      "weighted avg     0.9106    0.9033    0.9029       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8168    0.9067    0.8594       300\n",
      "           1     0.8951    0.7967    0.8430       300\n",
      "\n",
      "    accuracy                         0.8517       600\n",
      "   macro avg     0.8560    0.8517    0.8512       600\n",
      "weighted avg     0.8560    0.8517    0.8512       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8869    0.8367    0.8611       300\n",
      "           1     0.8454    0.8933    0.8687       300\n",
      "\n",
      "    accuracy                         0.8650       600\n",
      "   macro avg     0.8662    0.8650    0.8649       600\n",
      "weighted avg     0.8662    0.8650    0.8649       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5837    0.9067    0.7102       300\n",
      "           1     0.7910    0.3533    0.4885       300\n",
      "\n",
      "    accuracy                         0.6300       600\n",
      "   macro avg     0.6874    0.6300    0.5993       600\n",
      "weighted avg     0.6874    0.6300    0.5993       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6354    0.8367    0.7223       300\n",
      "           1     0.7610    0.5200    0.6178       300\n",
      "\n",
      "    accuracy                         0.6783       600\n",
      "   macro avg     0.6982    0.6783    0.6701       600\n",
      "weighted avg     0.6982    0.6783    0.6701       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9301    0.8433    0.8846       300\n",
      "           1     0.8567    0.9367    0.8949       300\n",
      "\n",
      "    accuracy                         0.8900       600\n",
      "   macro avg     0.8934    0.8900    0.8898       600\n",
      "weighted avg     0.8934    0.8900    0.8898       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8528    0.7533    0.8000       300\n",
      "           1     0.7791    0.8700    0.8220       300\n",
      "\n",
      "    accuracy                         0.8117       600\n",
      "   macro avg     0.8160    0.8117    0.8110       600\n",
      "weighted avg     0.8160    0.8117    0.8110       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8785    0.8433    0.8605       300\n",
      "           1     0.8494    0.8833    0.8660       300\n",
      "\n",
      "    accuracy                         0.8633       600\n",
      "   macro avg     0.8639    0.8633    0.8633       600\n",
      "weighted avg     0.8639    0.8633    0.8633       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5901    0.7533    0.6618       300\n",
      "           1     0.6590    0.4767    0.5532       300\n",
      "\n",
      "    accuracy                         0.6150       600\n",
      "   macro avg     0.6245    0.6150    0.6075       600\n",
      "weighted avg     0.6245    0.6150    0.6075       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5121    0.8433    0.6373       300\n",
      "           1     0.5566    0.1967    0.2906       300\n",
      "\n",
      "    accuracy                         0.5200       600\n",
      "   macro avg     0.5344    0.5200    0.4640       600\n",
      "weighted avg     0.5344    0.5200    0.4640       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5567    0.7533    0.6402       300\n",
      "           1     0.6186    0.4000    0.4858       300\n",
      "\n",
      "    accuracy                         0.5767       600\n",
      "   macro avg     0.5876    0.5767    0.5630       600\n",
      "weighted avg     0.5876    0.5767    0.5630       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8622    0.8133    0.8370       300\n",
      "           1     0.8233    0.8700    0.8460       300\n",
      "\n",
      "    accuracy                         0.8417       600\n",
      "   macro avg     0.8428    0.8417    0.8415       600\n",
      "weighted avg     0.8428    0.8417    0.8415       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5008    0.9900    0.6652       300\n",
      "           1     0.5714    0.0133    0.0261       300\n",
      "\n",
      "    accuracy                         0.5017       600\n",
      "   macro avg     0.5361    0.5017    0.3456       600\n",
      "weighted avg     0.5361    0.5017    0.3456       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6441    0.2533    0.3636       300\n",
      "           1     0.5353    0.8600    0.6598       300\n",
      "\n",
      "    accuracy                         0.5567       600\n",
      "   macro avg     0.5897    0.5567    0.5117       600\n",
      "weighted avg     0.5897    0.5567    0.5117       600\n",
      "\n",
      "<Fold-2>\n",
      "Train indices: [0 2 3 4 5 6 7 8]\n",
      "Test indices: [1]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8416666666666667\n",
      "0.5016666666666667\n",
      "0.5566666666666666\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9573    0.8967    0.9260       300\n",
      "           1     0.9028    0.9600    0.9305       300\n",
      "\n",
      "    accuracy                         0.9283       600\n",
      "   macro avg     0.9301    0.9283    0.9283       600\n",
      "weighted avg     0.9301    0.9283    0.9283       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9648    0.8233    0.8885       300\n",
      "           1     0.8459    0.9700    0.9037       300\n",
      "\n",
      "    accuracy                         0.8967       600\n",
      "   macro avg     0.9054    0.8967    0.8961       600\n",
      "weighted avg     0.9054    0.8967    0.8961       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9057    0.8967    0.9012       300\n",
      "           1     0.8977    0.9067    0.9022       300\n",
      "\n",
      "    accuracy                         0.9017       600\n",
      "   macro avg     0.9017    0.9017    0.9017       600\n",
      "weighted avg     0.9017    0.9017    0.9017       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8759    0.8233    0.8488       300\n",
      "           1     0.8333    0.8833    0.8576       300\n",
      "\n",
      "    accuracy                         0.8533       600\n",
      "   macro avg     0.8546    0.8533    0.8532       600\n",
      "weighted avg     0.8546    0.8533    0.8532       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6374    0.8967    0.7452       300\n",
      "           1     0.8258    0.4900    0.6151       300\n",
      "\n",
      "    accuracy                         0.6933       600\n",
      "   macro avg     0.7316    0.6933    0.6801       600\n",
      "weighted avg     0.7316    0.6933    0.6801       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6301    0.8233    0.7139       300\n",
      "           1     0.7452    0.5167    0.6102       300\n",
      "\n",
      "    accuracy                         0.6700       600\n",
      "   macro avg     0.6876    0.6700    0.6621       600\n",
      "weighted avg     0.6876    0.6700    0.6621       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9296    0.8367    0.8807       300\n",
      "           1     0.8515    0.9367    0.8921       300\n",
      "\n",
      "    accuracy                         0.8867       600\n",
      "   macro avg     0.8906    0.8867    0.8864       600\n",
      "weighted avg     0.8906    0.8867    0.8864       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8555    0.7500    0.7993       300\n",
      "           1     0.7774    0.8733    0.8226       300\n",
      "\n",
      "    accuracy                         0.8117       600\n",
      "   macro avg     0.8165    0.8117    0.8109       600\n",
      "weighted avg     0.8165    0.8117    0.8109       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8746    0.8367    0.8552       300\n",
      "           1     0.8435    0.8800    0.8613       300\n",
      "\n",
      "    accuracy                         0.8583       600\n",
      "   macro avg     0.8590    0.8583    0.8583       600\n",
      "weighted avg     0.8590    0.8583    0.8583       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5906    0.7500    0.6608       300\n",
      "           1     0.6575    0.4800    0.5549       300\n",
      "\n",
      "    accuracy                         0.6150       600\n",
      "   macro avg     0.6240    0.6150    0.6079       600\n",
      "weighted avg     0.6240    0.6150    0.6079       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5112    0.8367    0.6346       300\n",
      "           1     0.5505    0.2000    0.2934       300\n",
      "\n",
      "    accuracy                         0.5183       600\n",
      "   macro avg     0.5308    0.5183    0.4640       600\n",
      "weighted avg     0.5308    0.5183    0.4640       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5556    0.7500    0.6383       300\n",
      "           1     0.6154    0.4000    0.4848       300\n",
      "\n",
      "    accuracy                         0.5750       600\n",
      "   macro avg     0.5855    0.5750    0.5616       600\n",
      "weighted avg     0.5855    0.5750    0.5616       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8622    0.8133    0.8370       300\n",
      "           1     0.8233    0.8700    0.8460       300\n",
      "\n",
      "    accuracy                         0.8417       600\n",
      "   macro avg     0.8428    0.8417    0.8415       600\n",
      "weighted avg     0.8428    0.8417    0.8415       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5008    0.9900    0.6652       300\n",
      "           1     0.5714    0.0133    0.0261       300\n",
      "\n",
      "    accuracy                         0.5017       600\n",
      "   macro avg     0.5361    0.5017    0.3456       600\n",
      "weighted avg     0.5361    0.5017    0.3456       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6441    0.2533    0.3636       300\n",
      "           1     0.5353    0.8600    0.6598       300\n",
      "\n",
      "    accuracy                         0.5567       600\n",
      "   macro avg     0.5897    0.5567    0.5117       600\n",
      "weighted avg     0.5897    0.5567    0.5117       600\n",
      "\n",
      "<Fold-3>\n",
      "Train indices: [0 1 2 3 4 6 7 8]\n",
      "Test indices: [5]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8416666666666667\n",
      "0.5016666666666667\n",
      "0.5566666666666666\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9539    0.8967    0.9244       300\n",
      "           1     0.9025    0.9567    0.9288       300\n",
      "\n",
      "    accuracy                         0.9267       600\n",
      "   macro avg     0.9282    0.9267    0.9266       600\n",
      "weighted avg     0.9282    0.9267    0.9266       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.8267    0.8921       300\n",
      "           1     0.8488    0.9733    0.9068       300\n",
      "\n",
      "    accuracy                         0.9000       600\n",
      "   macro avg     0.9088    0.9000    0.8995       600\n",
      "weighted avg     0.9088    0.9000    0.8995       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8176    0.8967    0.8553       300\n",
      "           1     0.8856    0.8000    0.8406       300\n",
      "\n",
      "    accuracy                         0.8483       600\n",
      "   macro avg     0.8516    0.8483    0.8480       600\n",
      "weighted avg     0.8516    0.8483    0.8480       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9118    0.8267    0.8671       300\n",
      "           1     0.8415    0.9200    0.8790       300\n",
      "\n",
      "    accuracy                         0.8733       600\n",
      "   macro avg     0.8766    0.8733    0.8731       600\n",
      "weighted avg     0.8766    0.8733    0.8731       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5797    0.8967    0.7042       300\n",
      "           1     0.7721    0.3500    0.4817       300\n",
      "\n",
      "    accuracy                         0.6233       600\n",
      "   macro avg     0.6759    0.6233    0.5929       600\n",
      "weighted avg     0.6759    0.6233    0.5929       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6375    0.8267    0.7199       300\n",
      "           1     0.7536    0.5300    0.6223       300\n",
      "\n",
      "    accuracy                         0.6783       600\n",
      "   macro avg     0.6955    0.6783    0.6711       600\n",
      "weighted avg     0.6955    0.6783    0.6711       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9234    0.8433    0.8815       300\n",
      "           1     0.8558    0.9300    0.8914       300\n",
      "\n",
      "    accuracy                         0.8867       600\n",
      "   macro avg     0.8896    0.8867    0.8865       600\n",
      "weighted avg     0.8896    0.8867    0.8865       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8657    0.7733    0.8169       300\n",
      "           1     0.7952    0.8800    0.8354       300\n",
      "\n",
      "    accuracy                         0.8267       600\n",
      "   macro avg     0.8304    0.8267    0.8262       600\n",
      "weighted avg     0.8304    0.8267    0.8262       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8754    0.8433    0.8591       300\n",
      "           1     0.8489    0.8800    0.8642       300\n",
      "\n",
      "    accuracy                         0.8617       600\n",
      "   macro avg     0.8622    0.8617    0.8616       600\n",
      "weighted avg     0.8622    0.8617    0.8616       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5964    0.7733    0.6734       300\n",
      "           1     0.6777    0.4767    0.5597       300\n",
      "\n",
      "    accuracy                         0.6250       600\n",
      "   macro avg     0.6371    0.6250    0.6166       600\n",
      "weighted avg     0.6371    0.6250    0.6166       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5070    0.8433    0.6333       300\n",
      "           1     0.5347    0.1800    0.2693       300\n",
      "\n",
      "    accuracy                         0.5117       600\n",
      "   macro avg     0.5208    0.5117    0.4513       600\n",
      "weighted avg     0.5208    0.5117    0.4513       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5550    0.7733    0.6462       300\n",
      "           1     0.6264    0.3800    0.4730       300\n",
      "\n",
      "    accuracy                         0.5767       600\n",
      "   macro avg     0.5907    0.5767    0.5596       600\n",
      "weighted avg     0.5907    0.5767    0.5596       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8622    0.8133    0.8370       300\n",
      "           1     0.8233    0.8700    0.8460       300\n",
      "\n",
      "    accuracy                         0.8417       600\n",
      "   macro avg     0.8428    0.8417    0.8415       600\n",
      "weighted avg     0.8428    0.8417    0.8415       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5008    0.9900    0.6652       300\n",
      "           1     0.5714    0.0133    0.0261       300\n",
      "\n",
      "    accuracy                         0.5017       600\n",
      "   macro avg     0.5361    0.5017    0.3456       600\n",
      "weighted avg     0.5361    0.5017    0.3456       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6441    0.2533    0.3636       300\n",
      "           1     0.5353    0.8600    0.6598       300\n",
      "\n",
      "    accuracy                         0.5567       600\n",
      "   macro avg     0.5897    0.5567    0.5117       600\n",
      "weighted avg     0.5897    0.5567    0.5117       600\n",
      "\n",
      "<Fold-4>\n",
      "Train indices: [1 2 3 4 5 6 7 8]\n",
      "Test indices: [0]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8416666666666667\n",
      "0.5016666666666667\n",
      "0.5566666666666666\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9510    0.9067    0.9283       300\n",
      "           1     0.9108    0.9533    0.9316       300\n",
      "\n",
      "    accuracy                         0.9300       600\n",
      "   macro avg     0.9309    0.9300    0.9300       600\n",
      "weighted avg     0.9309    0.9300    0.9300       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9651    0.8300    0.8925       300\n",
      "           1     0.8509    0.9700    0.9065       300\n",
      "\n",
      "    accuracy                         0.9000       600\n",
      "   macro avg     0.9080    0.9000    0.8995       600\n",
      "weighted avg     0.9080    0.9000    0.8995       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8119    0.9067    0.8567       300\n",
      "           1     0.8943    0.7900    0.8389       300\n",
      "\n",
      "    accuracy                         0.8483       600\n",
      "   macro avg     0.8531    0.8483    0.8478       600\n",
      "weighted avg     0.8531    0.8483    0.8478       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8768    0.8300    0.8527       300\n",
      "           1     0.8386    0.8833    0.8604       300\n",
      "\n",
      "    accuracy                         0.8567       600\n",
      "   macro avg     0.8577    0.8567    0.8566       600\n",
      "weighted avg     0.8577    0.8567    0.8566       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5775    0.9067    0.7056       300\n",
      "           1     0.7829    0.3367    0.4709       300\n",
      "\n",
      "    accuracy                         0.6217       600\n",
      "   macro avg     0.6802    0.6217    0.5882       600\n",
      "weighted avg     0.6802    0.6217    0.5882       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6256    0.8300    0.7135       300\n",
      "           1     0.7475    0.5033    0.6016       300\n",
      "\n",
      "    accuracy                         0.6667       600\n",
      "   macro avg     0.6866    0.6667    0.6575       600\n",
      "weighted avg     0.6866    0.6667    0.6575       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9299    0.8400    0.8827       300\n",
      "           1     0.8541    0.9367    0.8935       300\n",
      "\n",
      "    accuracy                         0.8883       600\n",
      "   macro avg     0.8920    0.8883    0.8881       600\n",
      "weighted avg     0.8920    0.8883    0.8881       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8571    0.7600    0.8057       300\n",
      "           1     0.7844    0.8733    0.8265       300\n",
      "\n",
      "    accuracy                         0.8167       600\n",
      "   macro avg     0.8208    0.8167    0.8161       600\n",
      "weighted avg     0.8208    0.8167    0.8161       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8750    0.8400    0.8571       300\n",
      "           1     0.8462    0.8800    0.8627       300\n",
      "\n",
      "    accuracy                         0.8600       600\n",
      "   macro avg     0.8606    0.8600    0.8599       600\n",
      "weighted avg     0.8606    0.8600    0.8599       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5907    0.7600    0.6647       300\n",
      "           1     0.6636    0.4733    0.5525       300\n",
      "\n",
      "    accuracy                         0.6167       600\n",
      "   macro avg     0.6271    0.6167    0.6086       600\n",
      "weighted avg     0.6271    0.6167    0.6086       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5060    0.8400    0.6316       300\n",
      "           1     0.5294    0.1800    0.2687       300\n",
      "\n",
      "    accuracy                         0.5100       600\n",
      "   macro avg     0.5177    0.5100    0.4501       600\n",
      "weighted avg     0.5177    0.5100    0.4501       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5521    0.7600    0.6396       300\n",
      "           1     0.6150    0.3833    0.4723       300\n",
      "\n",
      "    accuracy                         0.5717       600\n",
      "   macro avg     0.5835    0.5717    0.5559       600\n",
      "weighted avg     0.5835    0.5717    0.5559       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8622    0.8133    0.8370       300\n",
      "           1     0.8233    0.8700    0.8460       300\n",
      "\n",
      "    accuracy                         0.8417       600\n",
      "   macro avg     0.8428    0.8417    0.8415       600\n",
      "weighted avg     0.8428    0.8417    0.8415       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5008    0.9900    0.6652       300\n",
      "           1     0.5714    0.0133    0.0261       300\n",
      "\n",
      "    accuracy                         0.5017       600\n",
      "   macro avg     0.5361    0.5017    0.3456       600\n",
      "weighted avg     0.5361    0.5017    0.3456       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6441    0.2533    0.3636       300\n",
      "           1     0.5353    0.8600    0.6598       300\n",
      "\n",
      "    accuracy                         0.5567       600\n",
      "   macro avg     0.5897    0.5567    0.5117       600\n",
      "weighted avg     0.5897    0.5567    0.5117       600\n",
      "\n",
      "<Fold-5>\n",
      "Train indices: [0 1 2 3 4 5 6 7]\n",
      "Test indices: [8]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8416666666666667\n",
      "0.5016666666666667\n",
      "0.5566666666666666\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9576    0.9033    0.9297       300\n",
      "           1     0.9085    0.9600    0.9335       300\n",
      "\n",
      "    accuracy                         0.9317       600\n",
      "   macro avg     0.9331    0.9317    0.9316       600\n",
      "weighted avg     0.9331    0.9317    0.9316       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9508    0.8367    0.8901       300\n",
      "           1     0.8542    0.9567    0.9025       300\n",
      "\n",
      "    accuracy                         0.8967       600\n",
      "   macro avg     0.9025    0.8967    0.8963       600\n",
      "weighted avg     0.9025    0.8967    0.8963       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8495    0.9033    0.8756       300\n",
      "           1     0.8968    0.8400    0.8675       300\n",
      "\n",
      "    accuracy                         0.8717       600\n",
      "   macro avg     0.8732    0.8717    0.8715       600\n",
      "weighted avg     0.8732    0.8717    0.8715       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8395    0.8367    0.8381       300\n",
      "           1     0.8372    0.8400    0.8386       300\n",
      "\n",
      "    accuracy                         0.8383       600\n",
      "   macro avg     0.8383    0.8383    0.8383       600\n",
      "weighted avg     0.8383    0.8383    0.8383       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5866    0.9033    0.7113       300\n",
      "           1     0.7899    0.3633    0.4977       300\n",
      "\n",
      "    accuracy                         0.6333       600\n",
      "   macro avg     0.6882    0.6333    0.6045       600\n",
      "weighted avg     0.6882    0.6333    0.6045       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6092    0.8367    0.7051       300\n",
      "           1     0.7394    0.4633    0.5697       300\n",
      "\n",
      "    accuracy                         0.6500       600\n",
      "   macro avg     0.6743    0.6500    0.6374       600\n",
      "weighted avg     0.6743    0.6500    0.6374       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9321    0.8233    0.8743       300\n",
      "           1     0.8418    0.9400    0.8882       300\n",
      "\n",
      "    accuracy                         0.8817       600\n",
      "   macro avg     0.8869    0.8817    0.8813       600\n",
      "weighted avg     0.8869    0.8817    0.8813       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8652    0.7700    0.8148       300\n",
      "           1     0.7928    0.8800    0.8341       300\n",
      "\n",
      "    accuracy                         0.8250       600\n",
      "   macro avg     0.8290    0.8250    0.8245       600\n",
      "weighted avg     0.8290    0.8250    0.8245       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8759    0.8233    0.8488       300\n",
      "           1     0.8333    0.8833    0.8576       300\n",
      "\n",
      "    accuracy                         0.8533       600\n",
      "   macro avg     0.8546    0.8533    0.8532       600\n",
      "weighted avg     0.8546    0.8533    0.8532       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5954    0.7700    0.6715       300\n",
      "           1     0.6745    0.4767    0.5586       300\n",
      "\n",
      "    accuracy                         0.6233       600\n",
      "   macro avg     0.6349    0.6233    0.6151       600\n",
      "weighted avg     0.6349    0.6233    0.6151       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5370    0.8233    0.6500       300\n",
      "           1     0.6214    0.2900    0.3955       300\n",
      "\n",
      "    accuracy                         0.5567       600\n",
      "   macro avg     0.5792    0.5567    0.5227       600\n",
      "weighted avg     0.5792    0.5567    0.5227       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5540    0.7700    0.6444       300\n",
      "           1     0.6230    0.3800    0.4720       300\n",
      "\n",
      "    accuracy                         0.5750       600\n",
      "   macro avg     0.5885    0.5750    0.5582       600\n",
      "weighted avg     0.5885    0.5750    0.5582       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8622    0.8133    0.8370       300\n",
      "           1     0.8233    0.8700    0.8460       300\n",
      "\n",
      "    accuracy                         0.8417       600\n",
      "   macro avg     0.8428    0.8417    0.8415       600\n",
      "weighted avg     0.8428    0.8417    0.8415       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5008    0.9900    0.6652       300\n",
      "           1     0.5714    0.0133    0.0261       300\n",
      "\n",
      "    accuracy                         0.5017       600\n",
      "   macro avg     0.5361    0.5017    0.3456       600\n",
      "weighted avg     0.5361    0.5017    0.3456       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6441    0.2533    0.3636       300\n",
      "           1     0.5353    0.8600    0.6598       300\n",
      "\n",
      "    accuracy                         0.5567       600\n",
      "   macro avg     0.5897    0.5567    0.5117       600\n",
      "weighted avg     0.5897    0.5567    0.5117       600\n",
      "\n",
      "<Fold-6>\n",
      "Train indices: [0 1 3 4 5 6 7 8]\n",
      "Test indices: [2]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8416666666666667\n",
      "0.5016666666666667\n",
      "0.5566666666666666\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9621    0.8467    0.9007       300\n",
      "           1     0.8631    0.9667    0.9119       300\n",
      "\n",
      "    accuracy                         0.9067       600\n",
      "   macro avg     0.9126    0.9067    0.9063       600\n",
      "weighted avg     0.9126    0.9067    0.9063       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9647    0.8200    0.8865       300\n",
      "           1     0.8435    0.9700    0.9023       300\n",
      "\n",
      "    accuracy                         0.8950       600\n",
      "   macro avg     0.9041    0.8950    0.8944       600\n",
      "weighted avg     0.9041    0.8950    0.8944       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8439    0.8467    0.8453       300\n",
      "           1     0.8462    0.8433    0.8447       300\n",
      "\n",
      "    accuracy                         0.8450       600\n",
      "   macro avg     0.8450    0.8450    0.8450       600\n",
      "weighted avg     0.8450    0.8450    0.8450       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8881    0.8200    0.8527       300\n",
      "           1     0.8328    0.8967    0.8636       300\n",
      "\n",
      "    accuracy                         0.8583       600\n",
      "   macro avg     0.8605    0.8583    0.8581       600\n",
      "weighted avg     0.8605    0.8583    0.8581       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6350    0.8467    0.7257       300\n",
      "           1     0.7700    0.5133    0.6160       300\n",
      "\n",
      "    accuracy                         0.6800       600\n",
      "   macro avg     0.7025    0.6800    0.6709       600\n",
      "weighted avg     0.7025    0.6800    0.6709       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6292    0.8200    0.7120       300\n",
      "           1     0.7416    0.5167    0.6090       300\n",
      "\n",
      "    accuracy                         0.6683       600\n",
      "   macro avg     0.6854    0.6683    0.6605       600\n",
      "weighted avg     0.6854    0.6683    0.6605       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9262    0.8367    0.8792       300\n",
      "           1     0.8511    0.9333    0.8903       300\n",
      "\n",
      "    accuracy                         0.8850       600\n",
      "   macro avg     0.8886    0.8850    0.8847       600\n",
      "weighted avg     0.8886    0.8850    0.8847       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8576    0.9633    0.9074       300\n",
      "           1     0.9582    0.8400    0.8952       300\n",
      "\n",
      "    accuracy                         0.9017       600\n",
      "   macro avg     0.9079    0.9017    0.9013       600\n",
      "weighted avg     0.9079    0.9017    0.9013       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8685    0.8367    0.8523       300\n",
      "           1     0.8424    0.8733    0.8576       300\n",
      "\n",
      "    accuracy                         0.8550       600\n",
      "   macro avg     0.8555    0.8550    0.8550       600\n",
      "weighted avg     0.8555    0.8550    0.8550       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5207    0.9633    0.6760       300\n",
      "           1     0.7556    0.1133    0.1971       300\n",
      "\n",
      "    accuracy                         0.5383       600\n",
      "   macro avg     0.6381    0.5383    0.4366       600\n",
      "weighted avg     0.6381    0.5383    0.4366       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5071    0.8367    0.6314       300\n",
      "           1     0.5333    0.1867    0.2765       300\n",
      "\n",
      "    accuracy                         0.5117       600\n",
      "   macro avg     0.5202    0.5117    0.4540       600\n",
      "weighted avg     0.5202    0.5117    0.4540       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4932    0.9633    0.6524       300\n",
      "           1     0.2143    0.0100    0.0191       300\n",
      "\n",
      "    accuracy                         0.4867       600\n",
      "   macro avg     0.3537    0.4867    0.3357       600\n",
      "weighted avg     0.3537    0.4867    0.3357       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8622    0.8133    0.8370       300\n",
      "           1     0.8233    0.8700    0.8460       300\n",
      "\n",
      "    accuracy                         0.8417       600\n",
      "   macro avg     0.8428    0.8417    0.8415       600\n",
      "weighted avg     0.8428    0.8417    0.8415       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5008    0.9900    0.6652       300\n",
      "           1     0.5714    0.0133    0.0261       300\n",
      "\n",
      "    accuracy                         0.5017       600\n",
      "   macro avg     0.5361    0.5017    0.3456       600\n",
      "weighted avg     0.5361    0.5017    0.3456       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6441    0.2533    0.3636       300\n",
      "           1     0.5353    0.8600    0.6598       300\n",
      "\n",
      "    accuracy                         0.5567       600\n",
      "   macro avg     0.5897    0.5567    0.5117       600\n",
      "weighted avg     0.5897    0.5567    0.5117       600\n",
      "\n",
      "<Fold-7>\n",
      "Train indices: [0 1 2 3 5 6 7 8]\n",
      "Test indices: [4]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8416666666666667\n",
      "0.5016666666666667\n",
      "0.5566666666666666\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9580    0.9133    0.9352       300\n",
      "           1     0.9172    0.9600    0.9381       300\n",
      "\n",
      "    accuracy                         0.9367       600\n",
      "   macro avg     0.9376    0.9367    0.9366       600\n",
      "weighted avg     0.9376    0.9367    0.9366       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9582    0.8400    0.8952       300\n",
      "           1     0.8576    0.9633    0.9074       300\n",
      "\n",
      "    accuracy                         0.9017       600\n",
      "   macro avg     0.9079    0.9017    0.9013       600\n",
      "weighted avg     0.9079    0.9017    0.9013       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8228    0.9133    0.8657       300\n",
      "           1     0.9026    0.8033    0.8501       300\n",
      "\n",
      "    accuracy                         0.8583       600\n",
      "   macro avg     0.8627    0.8583    0.8579       600\n",
      "weighted avg     0.8627    0.8583    0.8579       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8842    0.8400    0.8615       300\n",
      "           1     0.8476    0.8900    0.8683       300\n",
      "\n",
      "    accuracy                         0.8650       600\n",
      "   macro avg     0.8659    0.8650    0.8649       600\n",
      "weighted avg     0.8659    0.8650    0.8649       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5805    0.9133    0.7098       300\n",
      "           1     0.7969    0.3400    0.4766       300\n",
      "\n",
      "    accuracy                         0.6267       600\n",
      "   macro avg     0.6887    0.6267    0.5932       600\n",
      "weighted avg     0.6887    0.6267    0.5932       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6396    0.8400    0.7262       300\n",
      "           1     0.7670    0.5267    0.6245       300\n",
      "\n",
      "    accuracy                         0.6833       600\n",
      "   macro avg     0.7033    0.6833    0.6754       600\n",
      "weighted avg     0.7033    0.6833    0.6754       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9321    0.8233    0.8743       300\n",
      "           1     0.8418    0.9400    0.8882       300\n",
      "\n",
      "    accuracy                         0.8817       600\n",
      "   macro avg     0.8869    0.8817    0.8813       600\n",
      "weighted avg     0.8869    0.8817    0.8813       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8539    0.7600    0.8042       300\n",
      "           1     0.7838    0.8700    0.8246       300\n",
      "\n",
      "    accuracy                         0.8150       600\n",
      "   macro avg     0.8189    0.8150    0.8144       600\n",
      "weighted avg     0.8189    0.8150    0.8144       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8821    0.8233    0.8517       300\n",
      "           1     0.8344    0.8900    0.8613       300\n",
      "\n",
      "    accuracy                         0.8567       600\n",
      "   macro avg     0.8583    0.8567    0.8565       600\n",
      "weighted avg     0.8583    0.8567    0.8565       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5907    0.7600    0.6647       300\n",
      "           1     0.6636    0.4733    0.5525       300\n",
      "\n",
      "    accuracy                         0.6167       600\n",
      "   macro avg     0.6271    0.6167    0.6086       600\n",
      "weighted avg     0.6271    0.6167    0.6086       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5267    0.8233    0.6424       300\n",
      "           1     0.5954    0.2600    0.3619       300\n",
      "\n",
      "    accuracy                         0.5417       600\n",
      "   macro avg     0.5610    0.5417    0.5022       600\n",
      "weighted avg     0.5610    0.5417    0.5022       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5575    0.7600    0.6432       300\n",
      "           1     0.6230    0.3967    0.4847       300\n",
      "\n",
      "    accuracy                         0.5783       600\n",
      "   macro avg     0.5902    0.5783    0.5639       600\n",
      "weighted avg     0.5902    0.5783    0.5639       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8622    0.8133    0.8370       300\n",
      "           1     0.8233    0.8700    0.8460       300\n",
      "\n",
      "    accuracy                         0.8417       600\n",
      "   macro avg     0.8428    0.8417    0.8415       600\n",
      "weighted avg     0.8428    0.8417    0.8415       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5008    0.9900    0.6652       300\n",
      "           1     0.5714    0.0133    0.0261       300\n",
      "\n",
      "    accuracy                         0.5017       600\n",
      "   macro avg     0.5361    0.5017    0.3456       600\n",
      "weighted avg     0.5361    0.5017    0.3456       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6441    0.2533    0.3636       300\n",
      "           1     0.5353    0.8600    0.6598       300\n",
      "\n",
      "    accuracy                         0.5567       600\n",
      "   macro avg     0.5897    0.5567    0.5117       600\n",
      "weighted avg     0.5897    0.5567    0.5117       600\n",
      "\n",
      "<Fold-8>\n",
      "Train indices: [0 1 2 4 5 6 7 8]\n",
      "Test indices: [3]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8416666666666667\n",
      "0.5016666666666667\n",
      "0.5566666666666666\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9427    0.8767    0.9085       300\n",
      "           1     0.8847    0.9467    0.9147       300\n",
      "\n",
      "    accuracy                         0.9117       600\n",
      "   macro avg     0.9137    0.9117    0.9116       600\n",
      "weighted avg     0.9137    0.9117    0.9116       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9544    0.8367    0.8917       300\n",
      "           1     0.8546    0.9600    0.9042       300\n",
      "\n",
      "    accuracy                         0.8983       600\n",
      "   macro avg     0.9045    0.8983    0.8979       600\n",
      "weighted avg     0.9045    0.8983    0.8979       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8484    0.8767    0.8623       300\n",
      "           1     0.8724    0.8433    0.8576       300\n",
      "\n",
      "    accuracy                         0.8600       600\n",
      "   macro avg     0.8604    0.8600    0.8600       600\n",
      "weighted avg     0.8604    0.8600    0.8600       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8311    0.8367    0.8339       300\n",
      "           1     0.8356    0.8300    0.8328       300\n",
      "\n",
      "    accuracy                         0.8333       600\n",
      "   macro avg     0.8333    0.8333    0.8333       600\n",
      "weighted avg     0.8333    0.8333    0.8333       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6368    0.8767    0.7377       300\n",
      "           1     0.8021    0.5000    0.6160       300\n",
      "\n",
      "    accuracy                         0.6883       600\n",
      "   macro avg     0.7195    0.6883    0.6769       600\n",
      "weighted avg     0.7195    0.6883    0.6769       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6063    0.8367    0.7031       300\n",
      "           1     0.7366    0.4567    0.5638       300\n",
      "\n",
      "    accuracy                         0.6467       600\n",
      "   macro avg     0.6714    0.6467    0.6334       600\n",
      "weighted avg     0.6714    0.6467    0.6334       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9228    0.8367    0.8776       300\n",
      "           1     0.8506    0.9300    0.8885       300\n",
      "\n",
      "    accuracy                         0.8833       600\n",
      "   macro avg     0.8867    0.8833    0.8831       600\n",
      "weighted avg     0.8867    0.8833    0.8831       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8539    0.7600    0.8042       300\n",
      "           1     0.7838    0.8700    0.8246       300\n",
      "\n",
      "    accuracy                         0.8150       600\n",
      "   macro avg     0.8189    0.8150    0.8144       600\n",
      "weighted avg     0.8189    0.8150    0.8144       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8655    0.8367    0.8508       300\n",
      "           1     0.8419    0.8700    0.8557       300\n",
      "\n",
      "    accuracy                         0.8533       600\n",
      "   macro avg     0.8537    0.8533    0.8533       600\n",
      "weighted avg     0.8537    0.8533    0.8533       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5907    0.7600    0.6647       300\n",
      "           1     0.6636    0.4733    0.5525       300\n",
      "\n",
      "    accuracy                         0.6167       600\n",
      "   macro avg     0.6271    0.6167    0.6086       600\n",
      "weighted avg     0.6271    0.6167    0.6086       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5102    0.8367    0.6338       300\n",
      "           1     0.5463    0.1967    0.2892       300\n",
      "\n",
      "    accuracy                         0.5167       600\n",
      "   macro avg     0.5282    0.5167    0.4615       600\n",
      "weighted avg     0.5282    0.5167    0.4615       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5521    0.7600    0.6396       300\n",
      "           1     0.6150    0.3833    0.4723       300\n",
      "\n",
      "    accuracy                         0.5717       600\n",
      "   macro avg     0.5835    0.5717    0.5559       600\n",
      "weighted avg     0.5835    0.5717    0.5559       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8622    0.8133    0.8370       300\n",
      "           1     0.8233    0.8700    0.8460       300\n",
      "\n",
      "    accuracy                         0.8417       600\n",
      "   macro avg     0.8428    0.8417    0.8415       600\n",
      "weighted avg     0.8428    0.8417    0.8415       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5008    0.9900    0.6652       300\n",
      "           1     0.5714    0.0133    0.0261       300\n",
      "\n",
      "    accuracy                         0.5017       600\n",
      "   macro avg     0.5361    0.5017    0.3456       600\n",
      "weighted avg     0.5361    0.5017    0.3456       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6441    0.2533    0.3636       300\n",
      "           1     0.5353    0.8600    0.6598       300\n",
      "\n",
      "    accuracy                         0.5567       600\n",
      "   macro avg     0.5897    0.5567    0.5117       600\n",
      "weighted avg     0.5897    0.5567    0.5117       600\n",
      "\n",
      "<Fold-9>\n",
      "Train indices: [0 1 2 3 4 5 7 8]\n",
      "Test indices: [6]\n",
      "600\n",
      "600\n",
      "600\n",
      "0.8416666666666667\n",
      "0.5016666666666667\n",
      "0.5566666666666666\n",
      "report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9377    0.9033    0.9202       300\n",
      "           1     0.9068    0.9400    0.9231       300\n",
      "\n",
      "    accuracy                         0.9217       600\n",
      "   macro avg     0.9222    0.9217    0.9216       600\n",
      "weighted avg     0.9222    0.9217    0.9216       600\n",
      "\n",
      "report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9618    0.8400    0.8968       300\n",
      "           1     0.8580    0.9667    0.9091       300\n",
      "\n",
      "    accuracy                         0.9033       600\n",
      "   macro avg     0.9099    0.9033    0.9029       600\n",
      "weighted avg     0.9099    0.9033    0.9029       600\n",
      "\n",
      "same_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8885    0.9033    0.8959       300\n",
      "           1     0.9017    0.8867    0.8941       300\n",
      "\n",
      "    accuracy                         0.8950       600\n",
      "   macro avg     0.8951    0.8950    0.8950       600\n",
      "weighted avg     0.8951    0.8950    0.8950       600\n",
      "\n",
      "same_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8750    0.8400    0.8571       300\n",
      "           1     0.8462    0.8800    0.8627       300\n",
      "\n",
      "    accuracy                         0.8600       600\n",
      "   macro avg     0.8606    0.8600    0.8599       600\n",
      "weighted avg     0.8606    0.8600    0.8599       600\n",
      "\n",
      "large_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6317    0.9033    0.7435       300\n",
      "           1     0.8304    0.4733    0.6030       300\n",
      "\n",
      "    accuracy                         0.6883       600\n",
      "   macro avg     0.7311    0.6883    0.6732       600\n",
      "weighted avg     0.7311    0.6883    0.6732       600\n",
      "\n",
      "large_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6300    0.8400    0.7200       300\n",
      "           1     0.7600    0.5067    0.6080       300\n",
      "\n",
      "    accuracy                         0.6733       600\n",
      "   macro avg     0.6950    0.6733    0.6640       600\n",
      "weighted avg     0.6950    0.6733    0.6640       600\n",
      "\n",
      "report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9370    0.8433    0.8877       300\n",
      "           1     0.8576    0.9433    0.8984       300\n",
      "\n",
      "    accuracy                         0.8933       600\n",
      "   macro avg     0.8973    0.8933    0.8931       600\n",
      "weighted avg     0.8973    0.8933    0.8931       600\n",
      "\n",
      "report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8587    0.7900    0.8229       300\n",
      "           1     0.8056    0.8700    0.8365       300\n",
      "\n",
      "    accuracy                         0.8300       600\n",
      "   macro avg     0.8321    0.8300    0.8297       600\n",
      "weighted avg     0.8321    0.8300    0.8297       600\n",
      "\n",
      "same_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8815    0.8433    0.8620       300\n",
      "           1     0.8498    0.8867    0.8679       300\n",
      "\n",
      "    accuracy                         0.8650       600\n",
      "   macro avg     0.8657    0.8650    0.8649       600\n",
      "weighted avg     0.8657    0.8650    0.8649       600\n",
      "\n",
      "same_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6015    0.7900    0.6830       300\n",
      "           1     0.6942    0.4767    0.5652       300\n",
      "\n",
      "    accuracy                         0.6333       600\n",
      "   macro avg     0.6478    0.6333    0.6241       600\n",
      "weighted avg     0.6478    0.6333    0.6241       600\n",
      "\n",
      "large_report_RBF2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5338    0.8433    0.6537       300\n",
      "           1     0.6270    0.2633    0.3709       300\n",
      "\n",
      "    accuracy                         0.5533       600\n",
      "   macro avg     0.5804    0.5533    0.5123       600\n",
      "weighted avg     0.5804    0.5533    0.5123       600\n",
      "\n",
      "large_report_LINEAR2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5537    0.7900    0.6511       300\n",
      "           1     0.6337    0.3633    0.4619       300\n",
      "\n",
      "    accuracy                         0.5767       600\n",
      "   macro avg     0.5937    0.5767    0.5565       600\n",
      "weighted avg     0.5937    0.5767    0.5565       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8622    0.8133    0.8370       300\n",
      "           1     0.8233    0.8700    0.8460       300\n",
      "\n",
      "    accuracy                         0.8417       600\n",
      "   macro avg     0.8428    0.8417    0.8415       600\n",
      "weighted avg     0.8428    0.8417    0.8415       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5008    0.9900    0.6652       300\n",
      "           1     0.5714    0.0133    0.0261       300\n",
      "\n",
      "    accuracy                         0.5017       600\n",
      "   macro avg     0.5361    0.5017    0.3456       600\n",
      "weighted avg     0.5361    0.5017    0.3456       600\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6441    0.2533    0.3636       300\n",
      "           1     0.5353    0.8600    0.6598       300\n",
      "\n",
      "    accuracy                         0.5567       600\n",
      "   macro avg     0.5897    0.5567    0.5117       600\n",
      "weighted avg     0.5897    0.5567    0.5117       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cの範囲を指定\n",
    "C_values = {'C': [0.01, 0.1, 1, 10, 100, 1000, 2000, 3000, 4000, 5000]}\n",
    "# C_values = {'C': [100]}\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "kfold = KFold(n_splits=9, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "results = pd.DataFrame(columns=['C_RBF_LQP1','Score_RBF_LQP1', 'tnr_rbf_lqp1', 'tpr_rbf_lqp1',\n",
    "                                'C_RBF_SQP','Score_RBF_SQP', 'tnr_rbf_sqp', 'tpr_rbf_sqp',\n",
    "                                'C_RBF_LQP2','Score_RBF_LQP2', 'tnr_rbf_lqp2', 'tpr_rbf_lqp2',\n",
    "                                'C_LINEAR_LQP1','Score_LINEAR_LQP1', 'tnr_linear_lqp1', 'tpr_linear_lqp1',\n",
    "                                'C_LINEAR_SQP','Score_LINEAR_SQP', 'tnr_linear_sqp', 'tpr_linear_sqp',\n",
    "                                'C_LINEAR_LQP2','Score_LINEAR_LQP2', 'tnr_linear_lqp2', 'tpr_linear_lqp2',\n",
    "                                \n",
    "                                'C_RBF2_LQP1','Score_RBF2_LQP1', 'tnr_rbf2_lqp1', 'tpr_rbf2_lqp1',\n",
    "                                'C_RBF2_SQP','Score_RBF2_SQP', 'tnr_rbf2_sqp', 'tpr_rbf2_sqp',\n",
    "                                'C_RBF2_LQP2','Score_RBF2_LQP2', 'tnr_rbf2_lqp2', 'tpr_rbf2_lqp2',\n",
    "                                'C_LINEAR2_LQP1','Score_LINEAR2_LQP1', 'tnr_linear2_lqp1', 'tpr_linear2_lqp1',\n",
    "                                'C_LINEAR2_SQP','Score_LINEAR2_SQP', 'tnr_linear2_sqp2', 'tpr_linear2_sqp',\n",
    "                                'C_LINEAR2_LQP2','Score_LINEAR2_LQP2', 'tnr_linear2_lqp2', 'tpr_linear2_lqp2',\n",
    "                                \n",
    "                                'Threshold_LQP1', 'LQP1_old', 'tnr_old_lqp1', 'tpr_old_lqp1',\n",
    "                                'Threshold_SQP', 'SQP_old', 'tnr_old_sqp', 'tpr_old_sqp',\n",
    "                                'Threshold_LQP2', 'LQP2_old', 'tnr_old_lqp2', 'tpr_old_lqp2'])\n",
    "\n",
    "\n",
    "# results = pd.DataFrame(columns=['C_RBF_LQP1','Score_RBF_LQP1', 'tnr_rbf_lqp1', 'tpr_rbf_lqp1',\n",
    "#                                 'C_RBF_SQP','Score_RBF_SQP', 'tnr_rbf_sqp', 'tpr_rbf_sqp',\n",
    "#                                 'C_RBF_LQP2','Score_RBF_LQP2', 'tnr_rbf_lqp2', 'tpr_rbf_lqp2',\n",
    "#                                 'C_LINEAR_LQP1','Score_LINEAR_LQP1', 'tnr_linear_lqp1', 'tpr_linear_lqp1',\n",
    "#                                 'C_LINEAR_SQP','Score_LINEAR_SQP', 'tnr_linear_sqp', 'tpr_linear_sqp',\n",
    "#                                 'C_LINEAR_LQP2','Score_LINEAR_LQP2', 'tnr_linear_lqp2', 'tpr_linear_lqp2',\n",
    "                                                        \n",
    "#                                 'Threshold_LQP1', 'LQP1_old', 'tnr_old_lqp1', 'tpr_old_lqp1',\n",
    "#                                 'Threshold_SQP', 'SQP_old', 'tnr_old_sqp', 'tpr_old_sqp',\n",
    "#                                 'Threshold_LQP2', 'LQP2_old', 'tnr_old_lqp2', 'tpr_old_lqp2'])\n",
    "\n",
    "    \n",
    "X_index = np.arange(9)  # インデックスとして0から8までの数字を用意\n",
    "\n",
    "# ループで各分割のtrain_idsとtest_idsを取得\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(X_index)):\n",
    "    print(f\"<Fold-{fold+1}>\")\n",
    "    print(\"Train indices:\", train_ids)\n",
    "    print(\"Test indices:\", test_ids)\n",
    "    \n",
    "    train_data = [X_train_list[i] for i in train_ids]\n",
    "    train_data_OG = [X_train_onlyGhost_list[i] for i in train_ids]\n",
    "    train_label = [Y_train_list[i] for i in train_ids]\n",
    "    \n",
    "    val_data = [X_train_list[i] for i in test_ids]\n",
    "    val_data_OG = [X_train_onlyGhost_list[i] for i in test_ids]\n",
    "    val_label = [Y_train_list[i] for i in test_ids]\n",
    "    \n",
    "    X_train = [item for data in train_data for item in data]\n",
    "    X_train_OG = [item for data in train_data_OG for item in data]\n",
    "    Y_train = [item for data in train_label for item in data]\n",
    "    \n",
    "    X_val = [item for data in val_data for item in data]\n",
    "    X_val_OG = [item for data in val_data_OG for item in data]\n",
    "    Y_val = [item for data in val_label for item in data]\n",
    "    \n",
    "    # print(len(Y_train))\n",
    "    # print(len(Y_val))\n",
    "    \n",
    "    test_data1 = [item for data in X_test_list1 for item in data]\n",
    "    test_data_OG1 = [item for data in X_test_onlyGhost_list1 for item in data]\n",
    "    test_label1 = [item for data in Y_test_list1 for item in data]\n",
    "    MAE_data1 = [item for data in MAE_list_t1 for item in data]\n",
    "    FINAL_QP_data1 = [item for data in FINAL_QP_list_t1 for item in data]\n",
    "    \n",
    "    test_data2 = [item for data in X_test_list2 for item in data]\n",
    "    test_data_OG2 = [item for data in X_test_onlyGhost_list2 for item in data]\n",
    "    test_label2 = [item for data in Y_test_list2 for item in data]\n",
    "    MAE_data2 = [item for data in MAE_list_t2 for item in data]\n",
    "    FINAL_QP_data2 = [item for data in FINAL_QP_list_t2 for item in data]\n",
    "    \n",
    "    test_data3 = [item for data in X_test_list3 for item in data]\n",
    "    test_data_OG3 = [item for data in X_test_onlyGhost_list3 for item in data]\n",
    "    test_label3 = [item for data in Y_test_list3 for item in data]\n",
    "    MAE_data3 = [item for data in MAE_list_t3 for item in data]\n",
    "    FINAL_QP_data3 = [item for data in FINAL_QP_list_t3 for item in data]\n",
    "    \n",
    "    print(len(MAE_data1))\n",
    "    print(len(MAE_data2))\n",
    "    print(len(MAE_data3))\n",
    "    \n",
    "                                                                                   \n",
    "    best_threshold = 0\n",
    "    best_accuracy = 0\n",
    "    best_predicted_labels = []\n",
    "    best_ground_truth_labels = []\n",
    "    \n",
    "    sameQP_best_threshold = 0\n",
    "    sameQP_best_accuracy = 0\n",
    "    sameQP_best_predicted_labels = []\n",
    "    sameQP_best_ground_truth_labels = []\n",
    "    \n",
    "    largeQP_best_threshold = 0\n",
    "    largeQP_best_accuracy = 0\n",
    "    largeQP_best_predicted_labels = []\n",
    "    largeQP_best_ground_truth_labels = []\n",
    "            \n",
    "    for threshold in np.arange(0.00, 1.01, 0.01):\n",
    "        test_old = np.array([is_double_compressed(MAE_data1[i], FINAL_QP_data1[i], threshold) for i in range(600)])\n",
    "        predicted_labels = test_old.astype(int)\n",
    "        ground_truth_labels = np.array(test_label1)\n",
    "        accuracy = np.sum(ground_truth_labels == predicted_labels) / len(ground_truth_labels)\n",
    "    \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_threshold = threshold\n",
    "            best_predicted_labels = predicted_labels\n",
    "            best_ground_truth_labels = ground_truth_labels\n",
    "            \n",
    "    for threshold in np.arange(0.00, 1.01, 0.01):\n",
    "        test_sameQP_old = np.array([is_double_compressed(MAE_data2[i], FINAL_QP_data2[i], threshold) for i in range(600)])\n",
    "        same_predicted_labels = test_sameQP_old.astype(int)\n",
    "        same_ground_truth_labels = np.array(test_label2)\n",
    "        same_accuracy = np.sum(same_ground_truth_labels == same_predicted_labels) / len(same_ground_truth_labels)\n",
    "    \n",
    "        if same_accuracy > sameQP_best_accuracy:\n",
    "            sameQP_best_accuracy = same_accuracy\n",
    "            sameQP_best_threshold = threshold\n",
    "            sameQP_best_predicted_labels = same_predicted_labels\n",
    "            sameQP_best_ground_truth_labels = same_ground_truth_labels\n",
    "                        \n",
    "    for threshold in np.arange(0.00, 1.01, 0.01):\n",
    "        test_largeQP_old = np.array([is_double_compressed(MAE_data3[i], FINAL_QP_data3[i], threshold) for i in range(600)])\n",
    "        large_predicted_labels = test_largeQP_old.astype(int)\n",
    "        large_ground_truth_labels = np.array(test_label3)\n",
    "        large_accuracy = np.sum(large_ground_truth_labels == large_predicted_labels) / len(large_ground_truth_labels)\n",
    "    \n",
    "        if large_accuracy > largeQP_best_accuracy:\n",
    "            largeQP_best_accuracy = large_accuracy\n",
    "            largeQP_best_threshold = threshold\n",
    "            largeQP_best_predicted_labels = large_predicted_labels\n",
    "            largeQP_best_ground_truth_labels = large_ground_truth_labels       \n",
    "            \n",
    "            \n",
    "    print(best_accuracy)\n",
    "    print(sameQP_best_accuracy)\n",
    "    print(largeQP_best_accuracy)\n",
    "            \n",
    "            \n",
    "    best_val_score_RBF, best_svm_model_RBF, best_c_value_RBF = 0, None, None\n",
    "    best_val_score_onlyGhost_RBF, best_svm_model_onlyGhost_RBF, best_c_value_onlyGhost_RBF = 0, None, None\n",
    "    \n",
    "    best_val_score_LINEAR, best_svm_model_LINEAR, best_c_value_LINEAR = 0, None, None\n",
    "    best_val_score_onlyGhost_LINEAR, best_svm_model_onlyGhost_LINEAR, best_c_value_onlyGhost_LINEAR = 0, None, None\n",
    "        \n",
    "    for C_value in C_values['C']:    \n",
    "        # SVMモデルのインスタンスを作成\n",
    "        svm_model_RBF = SVC(kernel='rbf', C=C_value)\n",
    "        svm_model_onlyGhost_RBF = SVC(kernel='rbf', C=C_value)\n",
    "        \n",
    "        svm_model_LINEAR = SVC(kernel='linear', C=C_value)\n",
    "        svm_model_onlyGhost_LINEAR = SVC(kernel='linear', C=C_value)\n",
    "\n",
    "        # 訓練データで訓練\n",
    "        svm_model_RBF.fit(X_train, Y_train)\n",
    "        svm_model_onlyGhost_RBF.fit(X_train_OG, Y_train)\n",
    "        \n",
    "        svm_model_LINEAR.fit(X_train, Y_train)\n",
    "        svm_model_onlyGhost_LINEAR.fit(X_train_OG, Y_train)\n",
    "\n",
    "        \n",
    "        val_accuracy_RBF = accuracy_score(Y_val, svm_model_RBF.predict(X_val))\n",
    "        val_accuracy_onlyGhost_RBF = accuracy_score(Y_val, svm_model_onlyGhost_RBF.predict(X_val_OG))\n",
    "        \n",
    "        val_accuracy_LINEAR = accuracy_score(Y_val, svm_model_LINEAR.predict(X_val))\n",
    "        val_accuracy_onlyGhost_LINEAR = accuracy_score(Y_val, svm_model_onlyGhost_LINEAR.predict(X_val_OG))\n",
    "        \n",
    "\n",
    "        # 検証データでの精度が最も高かった場合、そのモデルを保存\n",
    "        if val_accuracy_RBF > best_val_score_RBF:\n",
    "            best_val_score_RBF, best_svm_model_RBF, best_c_value_RBF = val_accuracy_RBF, svm_model_RBF, C_value\n",
    "\n",
    "        if val_accuracy_onlyGhost_RBF > best_val_score_onlyGhost_RBF:\n",
    "            best_val_score_onlyGhost_RBF, best_svm_model_onlyGhost_RBF, best_c_value_onlyGhost_RBF = val_accuracy_onlyGhost_RBF, svm_model_onlyGhost_RBF, C_value\n",
    "            \n",
    "        if val_accuracy_LINEAR > best_val_score_LINEAR:\n",
    "            best_val_score_LINEAR, best_svm_model_LINEAR, best_c_value_LINEAR = val_accuracy_LINEAR, svm_model_LINEAR, C_value\n",
    "\n",
    "        if val_accuracy_onlyGhost_LINEAR > best_val_score_onlyGhost_LINEAR:\n",
    "            best_val_score_onlyGhost_LINEAR, best_svm_model_onlyGhost_LINEAR, best_c_value_onlyGhost_LINEAR = val_accuracy_onlyGhost_LINEAR, svm_model_onlyGhost_LINEAR, C_value\n",
    "\n",
    "\n",
    "    # テストデータで評価    \n",
    "    predictions_RBF = best_svm_model_RBF.predict(test_data1)\n",
    "    # predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test)\n",
    "    accuracy_RBF = accuracy_score(test_label1, predictions_RBF)\n",
    "    report_RBF = classification_report(test_label1, predictions_RBF, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label1, predictions_RBF)\n",
    "    tnr_rbf_lqp1 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_rbf_lqp1 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'report_RBF:\\n{report_RBF}')\n",
    "    \n",
    "    predictions_LINEAR = best_svm_model_LINEAR.predict(test_data1)\n",
    "    # predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test)\n",
    "    accuracy_LINEAR = accuracy_score(test_label1, predictions_LINEAR)\n",
    "    report_LINEAR = classification_report(test_label1, predictions_LINEAR, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label1, predictions_LINEAR)\n",
    "    tnr_linear_lqp1 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_linear_lqp1 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'report_LINEAR:\\n{report_LINEAR}')\n",
    "    \n",
    "    same_predictions_RBF = best_svm_model_RBF.predict(test_data2)\n",
    "    # same_predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test_sameQP)\n",
    "    same_accuracy_RBF = accuracy_score(test_label2, same_predictions_RBF)\n",
    "    same_report_RBF = classification_report(test_label2, same_predictions_RBF, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label2, same_predictions_RBF)\n",
    "    tnr_rbf_sqp = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_rbf_sqp = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'same_report_RBF:\\n{same_report_RBF}')\n",
    "    \n",
    "    same_predictions_LINEAR = best_svm_model_LINEAR.predict(test_data2)\n",
    "    # same_predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test_sameQP)\n",
    "    same_accuracy_LINEAR = accuracy_score(test_label2, same_predictions_LINEAR)\n",
    "    same_report_LINEAR = classification_report(test_label2, same_predictions_LINEAR, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label2, same_predictions_LINEAR)\n",
    "    tnr_linear_sqp = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_linear_sqp = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'same_report_LINEAR:\\n{same_report_LINEAR}')\n",
    "    \n",
    "    large_predictions_RBF = best_svm_model_RBF.predict(test_data3)\n",
    "    # large_predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test_largeQP)\n",
    "    large_accuracy_RBF = accuracy_score(test_label3, large_predictions_RBF)\n",
    "    large_report_RBF = classification_report(test_label3, large_predictions_RBF, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label3, large_predictions_RBF)\n",
    "    tnr_rbf_lqp2 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_rbf_lqp2 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'large_report_RBF:\\n{large_report_RBF}')\n",
    "    \n",
    "    large_predictions_LINEAR = best_svm_model_LINEAR.predict(test_data3)\n",
    "    # large_predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test_largeQP)\n",
    "    large_accuracy_LINEAR = accuracy_score(test_label3, large_predictions_LINEAR)\n",
    "    large_report_LINEAR = classification_report(test_label3, large_predictions_LINEAR, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label3, large_predictions_LINEAR)\n",
    "    tnr_linear_lqp2 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_linear_lqp2 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'large_report_LINEAR:\\n{large_report_LINEAR}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # テストデータで評価    \n",
    "    predictions_RBF2 = best_svm_model_onlyGhost_RBF.predict(test_data_OG1)\n",
    "    # predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test)\n",
    "    accuracy_RBF2 = accuracy_score(test_label1, predictions_RBF2)\n",
    "    report_RBF2 = classification_report(test_label1, predictions_RBF2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label1, predictions_RBF2)\n",
    "    tnr_rbf2_lqp1 = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_rbf2_lqp1 = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'report_RBF2:\\n{report_RBF2}')\n",
    "    \n",
    "    predictions_LINEAR2 = best_svm_model_onlyGhost_LINEAR.predict(test_data_OG1)\n",
    "    # predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test)\n",
    "    accuracy_LINEAR2 = accuracy_score(test_label1, predictions_LINEAR2)\n",
    "    report_LINEAR2 = classification_report(test_label1, predictions_LINEAR2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label1, predictions_LINEAR2)\n",
    "    tnr_linear2_lqp1 = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_linear2_lqp1 = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'report_LINEAR2:\\n{report_LINEAR2}')\n",
    "    \n",
    "    same_predictions_RBF2 = best_svm_model_onlyGhost_RBF.predict(test_data_OG2)\n",
    "    # same_predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test_sameQP)\n",
    "    same_accuracy_RBF2 = accuracy_score(test_label2, same_predictions_RBF2)\n",
    "    same_report_RBF2 = classification_report(test_label2, same_predictions_RBF2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label2, same_predictions_RBF2)\n",
    "    tnr_rbf2_sqp = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_rbf2_sqp = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'same_report_RBF2:\\n{same_report_RBF2}')\n",
    "    \n",
    "    same_predictions_LINEAR2 = best_svm_model_onlyGhost_LINEAR.predict(test_data_OG2)\n",
    "    # same_predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test_sameQP)\n",
    "    same_accuracy_LINEAR2 = accuracy_score(test_label2, same_predictions_LINEAR2)\n",
    "    same_report_LINEAR2 = classification_report(test_label2, same_predictions_LINEAR2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label2, same_predictions_LINEAR2)\n",
    "    tnr_linear2_sqp = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_linear2_sqp = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'same_report_LINEAR2:\\n{same_report_LINEAR2}')\n",
    "    \n",
    "    large_predictions_RBF2 = best_svm_model_onlyGhost_RBF.predict(test_data_OG3)\n",
    "    # large_predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test_largeQP)\n",
    "    large_accuracy_RBF2 = accuracy_score(test_label3, large_predictions_RBF2)\n",
    "    large_report_RBF2 = classification_report(test_label3, large_predictions_RBF2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label3, large_predictions_RBF2)\n",
    "    tnr_rbf2_lqp2 = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_rbf2_lqp2 = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'large_report_RBF2:\\n{large_report_RBF2}')\n",
    "    \n",
    "    large_predictions_LINEAR2 = best_svm_model_onlyGhost_LINEAR.predict(test_data_OG3)\n",
    "    # large_predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test_largeQP)\n",
    "    large_accuracy_LINEAR2 = accuracy_score(test_label3, large_predictions_LINEAR2)\n",
    "    large_report_LINEAR2 = classification_report(test_label3, large_predictions_LINEAR2, digits=4, zero_division=1)\n",
    "    conf_matrix2 = confusion_matrix(test_label3, large_predictions_LINEAR2)\n",
    "    tnr_linear2_lqp2 = conf_matrix2[0, 0] / (conf_matrix2[0, 0] + conf_matrix2[0, 1])\n",
    "    tpr_linear2_lqp2 = conf_matrix2[1, 1] / (conf_matrix2[1, 0] + conf_matrix2[1, 1])\n",
    "    print(f'large_report_LINEAR2:\\n{large_report_LINEAR2}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # テストデータで評価\n",
    "    test_old = classification_report(best_ground_truth_labels, best_predicted_labels, labels=[0,1], target_names=['0', '1'], zero_division=0, digits=4)\n",
    "    conf_matrix = confusion_matrix(best_ground_truth_labels, best_predicted_labels)\n",
    "    tnr_old_lqp1 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_old_lqp1 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'Summary old_model:\\n{test_old}')\n",
    "    \n",
    "    test_sameQP_old = classification_report(sameQP_best_ground_truth_labels, sameQP_best_predicted_labels, labels=[0,1], target_names=['0', '1'], zero_division=0, digits=4)\n",
    "    conf_matrix = confusion_matrix(sameQP_best_ground_truth_labels, sameQP_best_predicted_labels)\n",
    "    tnr_old_sqp = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_old_sqp = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'Summary old_model:\\n{test_sameQP_old}')\n",
    "    \n",
    "    test_largeQP_old = classification_report(largeQP_best_ground_truth_labels, largeQP_best_predicted_labels, labels=[0,1], target_names=['0', '1'], zero_division=0, digits=4)\n",
    "    conf_matrix = confusion_matrix(largeQP_best_ground_truth_labels, largeQP_best_predicted_labels)\n",
    "    tnr_old_lqp2 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_old_lqp2 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'Summary old_model:\\n{test_largeQP_old}')\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Test結果を保存\n",
    "    \n",
    "    result_row ={'C_RBF_LQP1':best_c_value_RBF,'Score_RBF_LQP1': accuracy_RBF, 'tnr_rbf_lqp1':tnr_rbf_lqp1, 'tpr_rbf_lqp1':tpr_rbf_lqp1,\n",
    "                'C_RBF_SQP': best_c_value_RBF, 'Score_RBF_SQP': same_accuracy_RBF, 'tnr_rbf_sqp':tnr_rbf_sqp, 'tpr_rbf_sqp':tpr_rbf_sqp,\n",
    "                'C_RBF_LQP2': best_c_value_RBF,'Score_RBF_LQP2': large_accuracy_RBF, 'tnr_rbf_lqp2':tnr_rbf_lqp2, 'tpr_rbf_lqp2':tpr_rbf_lqp2,\n",
    "                                    \n",
    "                'C_LINEAR_LQP1': best_c_value_LINEAR,'Score_LINEAR_LQP1':accuracy_LINEAR, 'tnr_linear_lqp1':tnr_linear_lqp1, 'tpr_linear_lqp1':tpr_linear_lqp1,\n",
    "                'C_LINEAR_SQP': best_c_value_LINEAR,'Score_LINEAR_SQP':same_accuracy_LINEAR, 'tnr_linear_sqp':tnr_linear_sqp, 'tpr_linear_sqp':tpr_linear_sqp,\n",
    "                'C_LINEAR_LQP2': best_c_value_LINEAR,'Score_LINEAR_LQP2':large_accuracy_LINEAR, 'tnr_linear_lqp2':tnr_linear_lqp2, 'tpr_linear_lqp2':tpr_linear_lqp2,\n",
    "                 \n",
    "                'C_RBF2_LQP1':best_c_value_onlyGhost_RBF,'Score_RBF2_LQP1': accuracy_RBF2, 'tnr_rbf2_lqp1':tnr_rbf2_lqp1, 'tpr_rbf2_lqp1':tpr_rbf2_lqp1,\n",
    "                'C_RBF2_SQP': best_c_value_onlyGhost_RBF, 'Score_RBF2_SQP': same_accuracy_RBF2, 'tnr_rbf2_sqp':tnr_rbf2_sqp, 'tpr_rbf2_sqp':tpr_rbf2_sqp,\n",
    "                'C_RBF2_LQP2': best_c_value_onlyGhost_RBF,'Score_RBF2_LQP2': large_accuracy_RBF2, 'tnr_rbf2_lqp2':tnr_rbf2_lqp2, 'tpr_rbf2_lqp2':tpr_rbf2_lqp2,\n",
    "                                    \n",
    "                'C_LINEAR2_LQP1': best_c_value_onlyGhost_LINEAR,'Score_LINEAR2_LQP1':accuracy_LINEAR2, 'tnr_linear2_lqp1':tnr_linear2_lqp1, 'tpr_linear2_lqp1':tpr_linear2_lqp1,\n",
    "                'C_LINEAR2_SQP': best_c_value_onlyGhost_LINEAR,'Score_LINEAR2_SQP':same_accuracy_LINEAR2, 'tnr_linear2_sqp':tnr_linear2_sqp, 'tpr_linear2_sqp':tpr_linear2_sqp,\n",
    "                'C_LINEAR2_LQP2': best_c_value_onlyGhost_LINEAR,'Score_LINEAR2_LQP2':large_accuracy_LINEAR2, 'tnr_linear2_lqp2':tnr_linear2_lqp2, 'tpr_linear2_lqp2':tpr_linear2_lqp2,\n",
    "                                                        \n",
    "                'Threshold_LQP1':best_threshold, 'LQP1_old':best_accuracy, 'tnr_old_lqp1':tnr_old_lqp1, 'tpr_old_lqp1':tpr_old_lqp1,\n",
    "                'Threshold_SQP':sameQP_best_threshold, 'SQP_old':sameQP_best_accuracy, 'tnr_old_sqp':tnr_old_sqp, 'tpr_old_sqp':tpr_old_sqp,\n",
    "                'Threshold_LQP2':largeQP_best_threshold, 'LQP2_old':largeQP_best_accuracy, 'tnr_old_lqp2':tnr_old_lqp2, 'tpr_old_lqp2':tpr_old_lqp2}\n",
    "\n",
    "\n",
    "    results = pd.concat([results, pd.DataFrame([result_row])], ignore_index=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Average TNR  Average TPR  Average Test Score  Standard Deviation  Max Test Score  Min Test Score\n",
      "0     RBF_LQP1        89.44        95.56               92.50                0.99           93.67           90.67\n",
      "1      RBF_SQP        89.44        83.44               86.44                2.09           90.17           84.50\n",
      "2     RBF_LQP2        89.44        41.33               65.39                3.22           69.33           62.17\n",
      "3  LINEAR_LQP1        83.22        96.67               89.94                0.30           90.33           89.50\n",
      "4   LINEAR_SQP        83.22        87.96               85.59                1.28           87.33           83.33\n",
      "5  LINEAR_LQP2        83.22        50.44               66.83                1.26           68.33           64.67\n",
      "6     OLD_LQP1        81.33        87.00               84.17                0.00           84.17           84.17\n",
      "7      OLD_SQP        99.00         1.33               50.17                0.00           50.17           50.17\n",
      "8     OLD_LQP2        25.33        86.00               55.67                0.00           55.67           55.67\n"
     ]
    }
   ],
   "source": [
    "# 各統計情報を100倍して小数点第4位までの表記に変更\n",
    "statistics_data = {\n",
    "    'Model': ['RBF_LQP1', 'RBF_SQP', 'RBF_LQP2', 'LINEAR_LQP1', 'LINEAR_SQP', 'LINEAR_LQP2', 'OLD_LQP1', 'OLD_SQP', 'OLD_LQP2'],\n",
    "    'Average TNR': [round(results['tnr_rbf_lqp1'].mean() * 100, 2), round(results['tnr_rbf_sqp'].mean() * 100, 2), round(results['tnr_rbf_lqp2'].mean() * 100, 2), round(results['tnr_linear_lqp1'].mean() * 100, 2), round(results['tnr_linear_sqp'].mean() * 100, 2), round(results['tnr_linear_lqp2'].mean() * 100, 2),round(results['tnr_old_lqp1'].mean() * 100, 2), round(results['tnr_old_sqp'].mean() * 100, 2), round(results['tnr_old_lqp2'].mean() * 100, 2)],\n",
    "    'Average TPR': [round(results['tpr_rbf_lqp1'].mean() * 100, 2), round(results['tpr_rbf_sqp'].mean() * 100, 2), round(results['tpr_rbf_lqp2'].mean() * 100, 2), round(results['tpr_linear_lqp1'].mean() * 100, 2), round(results['tpr_linear_sqp'].mean() * 100, 2), round(results['tpr_linear_lqp2'].mean() * 100, 2),round(results['tpr_old_lqp1'].mean() * 100, 2), round(results['tpr_old_sqp'].mean() * 100, 2), round(results['tpr_old_lqp2'].mean() * 100, 2)],\n",
    "    'Average Test Score': [round(results['Score_RBF_LQP1'].mean() * 100, 2), round(results['Score_RBF_SQP'].mean() * 100, 2), round(results['Score_RBF_LQP2'].mean() * 100, 2), round(results['Score_LINEAR_LQP1'].mean() * 100, 2), round(results['Score_LINEAR_SQP'].mean() * 100, 2), round(results['Score_LINEAR_LQP2'].mean() * 100, 2),round(results['LQP1_old'].mean() * 100, 2), round(results['SQP_old'].mean() * 100, 2), round(results['LQP2_old'].mean() * 100, 2)],\n",
    "    'Standard Deviation': [round(results['Score_RBF_LQP1'].std() * 100, 2), round(results['Score_RBF_SQP'].std() * 100, 2), round(results['Score_RBF_LQP2'].std() * 100, 2), round(results['Score_LINEAR_LQP1'].std() * 100, 2), round(results['Score_LINEAR_SQP'].std() * 100, 2), round(results['Score_LINEAR_LQP2'].std() * 100, 2),round(results['LQP1_old'].std() * 100, 2), round(results['SQP_old'].std() * 100, 2), round(results['LQP2_old'].std() * 100, 2)],\n",
    "    'Max Test Score': [round(results['Score_RBF_LQP1'].max() * 100, 2), round(results['Score_RBF_SQP'].max() * 100, 2), round(results['Score_RBF_LQP2'].max() * 100, 2), round(results['Score_LINEAR_LQP1'].max() * 100, 2), round(results['Score_LINEAR_SQP'].max() * 100, 2), round(results['Score_LINEAR_LQP2'].max() * 100, 2),round(results['LQP1_old'].max() * 100, 2), round(results['SQP_old'].max() * 100, 2), round(results['LQP2_old'].max() * 100, 2)],\n",
    "    'Min Test Score': [round(results['Score_RBF_LQP1'].min() * 100, 2), round(results['Score_RBF_SQP'].min() * 100, 2), round(results['Score_RBF_LQP2'].min() * 100, 2), round(results['Score_LINEAR_LQP1'].min() * 100, 2), round(results['Score_LINEAR_SQP'].min() * 100, 2), round(results['Score_LINEAR_LQP2'].min() * 100, 2),round(results['LQP1_old'].min() * 100, 2), round(results['SQP_old'].min() * 100, 2), round(results['LQP2_old'].min() * 100, 2)],\n",
    "}\n",
    "\n",
    "# DataFrameを作成\n",
    "statistics_df = pd.DataFrame(statistics_data)\n",
    "\n",
    "# 表示\n",
    "print(statistics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Average TNR  Average TPR  Average Test Score  Standard Deviation  Max Test Score  Min Test Score\n",
      "0     RBF_LQP1        83.63        93.63               88.63                0.39           89.33           88.17\n",
      "1      RBF_SQP        83.63        88.07               85.85                0.43           86.50           85.33\n",
      "2     RBF_LQP2        83.63        21.70               52.67                1.86           55.67           51.00\n",
      "3  LINEAR_LQP1        78.67        86.96               82.81                2.84           90.17           81.17\n",
      "4   LINEAR_SQP        78.67        43.56               61.11                2.80           63.33           53.83\n",
      "5  LINEAR_LQP2        78.67        34.41               56.54                2.96           57.83           48.67\n",
      "6     OLD_LQP1        81.33        87.00               84.17                0.00           84.17           84.17\n",
      "7      OLD_SQP        99.00         1.33               50.17                0.00           50.17           50.17\n",
      "8     OLD_LQP2        25.33        86.00               55.67                0.00           55.67           55.67\n"
     ]
    }
   ],
   "source": [
    "# 各統計情報を100倍して小数点第4位までの表記に変更\n",
    "statistics_data2 = {\n",
    "    'Model': ['RBF_LQP1', 'RBF_SQP', 'RBF_LQP2', 'LINEAR_LQP1', 'LINEAR_SQP', 'LINEAR_LQP2', 'OLD_LQP1', 'OLD_SQP', 'OLD_LQP2'],\n",
    "    'Average TNR': [round(results['tnr_rbf2_lqp1'].mean() * 100, 2), round(results['tnr_rbf2_sqp'].mean() * 100, 2), round(results['tnr_rbf2_lqp2'].mean() * 100, 2), round(results['tnr_linear2_lqp1'].mean() * 100, 2), round(results['tnr_linear2_sqp'].mean() * 100, 2), round(results['tnr_linear2_lqp2'].mean() * 100, 2),round(results['tnr_old_lqp1'].mean() * 100, 2), round(results['tnr_old_sqp'].mean() * 100, 2), round(results['tnr_old_lqp2'].mean() * 100, 2)],\n",
    "    'Average TPR': [round(results['tpr_rbf2_lqp1'].mean() * 100, 2), round(results['tpr_rbf2_sqp'].mean() * 100, 2), round(results['tpr_rbf2_lqp2'].mean() * 100, 2), round(results['tpr_linear2_lqp1'].mean() * 100, 2), round(results['tpr_linear2_sqp'].mean() * 100, 2), round(results['tpr_linear2_lqp2'].mean() * 100, 2),round(results['tpr_old_lqp1'].mean() * 100, 2), round(results['tpr_old_sqp'].mean() * 100, 2), round(results['tpr_old_lqp2'].mean() * 100, 2)],\n",
    "    'Average Test Score': [round(results['Score_RBF2_LQP1'].mean() * 100, 2), round(results['Score_RBF2_SQP'].mean() * 100, 2), round(results['Score_RBF2_LQP2'].mean() * 100, 2), round(results['Score_LINEAR2_LQP1'].mean() * 100, 2), round(results['Score_LINEAR2_SQP'].mean() * 100, 2), round(results['Score_LINEAR2_LQP2'].mean() * 100, 2),round(results['LQP1_old'].mean() * 100, 2), round(results['SQP_old'].mean() * 100, 2), round(results['LQP2_old'].mean() * 100, 2)],\n",
    "    'Standard Deviation': [round(results['Score_RBF2_LQP1'].std() * 100, 2), round(results['Score_RBF2_SQP'].std() * 100, 2), round(results['Score_RBF2_LQP2'].std() * 100, 2), round(results['Score_LINEAR2_LQP1'].std() * 100, 2), round(results['Score_LINEAR2_SQP'].std() * 100, 2), round(results['Score_LINEAR2_LQP2'].std() * 100, 2),round(results['LQP1_old'].std() * 100, 2), round(results['SQP_old'].std() * 100, 2), round(results['LQP2_old'].std() * 100, 2)],\n",
    "    'Max Test Score': [round(results['Score_RBF2_LQP1'].max() * 100, 2), round(results['Score_RBF2_SQP'].max() * 100, 2), round(results['Score_RBF2_LQP2'].max() * 100, 2), round(results['Score_LINEAR2_LQP1'].max() * 100, 2), round(results['Score_LINEAR2_SQP'].max() * 100, 2), round(results['Score_LINEAR2_LQP2'].max() * 100, 2),round(results['LQP1_old'].max() * 100, 2), round(results['SQP_old'].max() * 100, 2), round(results['LQP2_old'].max() * 100, 2)],\n",
    "    'Min Test Score': [round(results['Score_RBF2_LQP1'].min() * 100, 2), round(results['Score_RBF2_SQP'].min() * 100, 2), round(results['Score_RBF2_LQP2'].min() * 100, 2), round(results['Score_LINEAR2_LQP1'].min() * 100, 2), round(results['Score_LINEAR2_SQP'].min() * 100, 2), round(results['Score_LINEAR2_LQP2'].min() * 100, 2),round(results['LQP1_old'].min() * 100, 2), round(results['SQP_old'].min() * 100, 2), round(results['LQP2_old'].min() * 100, 2)],\n",
    "}\n",
    "\n",
    "# DataFrameを作成\n",
    "statistics_df2 = pd.DataFrame(statistics_data2)\n",
    "\n",
    "# 表示\n",
    "print(statistics_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      10\n",
      "1     100\n",
      "2      10\n",
      "3      10\n",
      "4      10\n",
      "5    1000\n",
      "6      10\n",
      "7    1000\n",
      "8     100\n",
      "Name: C_RBF_LQP1, dtype: object\n",
      "0     100\n",
      "1     100\n",
      "2    1000\n",
      "3     100\n",
      "4      10\n",
      "5    1000\n",
      "6     100\n",
      "7      10\n",
      "8     100\n",
      "Name: C_LINEAR_LQP1, dtype: object\n",
      "\n",
      "0    2000\n",
      "1    1000\n",
      "2    4000\n",
      "3    2000\n",
      "4      10\n",
      "5    4000\n",
      "6     100\n",
      "7    2000\n",
      "8     100\n",
      "Name: C_RBF2_LQP1, dtype: object\n",
      "0      1\n",
      "1    100\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "5    0.1\n",
      "6      1\n",
      "7      1\n",
      "8      1\n",
      "Name: C_LINEAR2_LQP1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(results['C_RBF_LQP1'])\n",
    "print(results['C_LINEAR_LQP1'])\n",
    "print()\n",
    "print(results['C_RBF2_LQP1'])\n",
    "print(results['C_LINEAR2_LQP1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_df.to_csv('statistics_data3.csv', index=False)\n",
    "statistics_df2.to_csv('statistics2_data3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
