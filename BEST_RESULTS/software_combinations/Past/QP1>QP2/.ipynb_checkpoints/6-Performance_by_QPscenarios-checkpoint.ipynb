{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import os.path as osp\n",
    "import re\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.signal import find_peaks\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import torch\n",
    "import glob\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)  # DataFrameを改行せずに表示\n",
    "pd.set_option('display.max_columns', None)  # すべての列を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_finalQP(filename):\n",
    "    match = re.search(r'2ndQP(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    match = re.search(r'1stQP(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_1stQP(filename):\n",
    "    match = re.search(r'1stQP(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "    \n",
    "def is_double_compressed(mean_difference, final_QP, threshold):\n",
    "    mean_difference = mean_difference[0]\n",
    "    final_QP = final_QP[0]\n",
    "    clamped_mean_difference = np.maximum(mean_difference, -0.01)\n",
    "    \n",
    "    #全体のエネルギーを計算\n",
    "    energy = np.sum(np.square(clamped_mean_difference))\n",
    "    # energy = np.sum(np.square(mean_difference))\n",
    "    \n",
    "    #QP2より右側のエネルギーを計算\n",
    "    right_energy = np.sum(np.square(clamped_mean_difference[final_QP+1:52]))\n",
    "    # right_energy = np.sum(np.square(mean_difference[final_QP+1:52]))\n",
    "    \n",
    "    # print('energy: ', energy)\n",
    "    # print('R-energy: ', right_energy)\n",
    "    # print('Ratio: ', right_energy / energy)\n",
    "    \n",
    "    \n",
    "    # エネルギー比を計算して閾値と比較\n",
    "    if energy <= 0:\n",
    "        return -1\n",
    "    \n",
    "    elif (right_energy / energy) != 0 and (right_energy / energy) > threshold:\n",
    "        return True\n",
    "    \n",
    "    elif (right_energy / energy) != 0 and (right_energy / energy) <= threshold:\n",
    "        return False\n",
    "    \n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def calculate_mae(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            loaded_data, loaded_data_shifted = pickle.load(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # タプル内のリストを抽出\n",
    "    original_mae = np.array(loaded_data)\n",
    "    shifted_mae = np.array(loaded_data_shifted)\n",
    "\n",
    "    # Coding ghostを計算してリストに格納する\n",
    "    mae_difference = shifted_mae - original_mae\n",
    "    \n",
    "    # mae_differenceの各要素においてマイナスの値を0に変換\n",
    "    # mae_difference_positive = np.maximum(mae_difference, 0)\n",
    "    \n",
    "    return mae_difference, mae_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['123', '42', '128', '245', '225', '89', '104', '291', '34', '194', '15', '229', '69', '20', '261', '131', '112', '86', '36', '252', '268', '33', '54', '115', '12', '78'], ['232', '87', '233', '130', '209', '144', '258', '231', '81', '260', '133', '25', '58', '118', '275', '129', '114', '214', '140', '286', '276', '300', '273', '215', '250', '85'], ['90', '296', '74', '93', '207', '136', '92', '108', '264', '47', '197', '242', '96', '110', '293', '269', '18', '204', '210', '203', '255', '117', '280', '201', '113', '95'], ['70', '279', '235', '6', '8', '46', '10', '27', '295', '223', '2', '52', '68', '270', '30', '217', '282', '31', '236', '56', '211', '97', '101', '29', '289', '277'], ['94', '285', '145', '48', '267', '198', '43', '122', '199', '262', '67', '234', '139', '205', '125', '138', '19', '80', '82', '116', '53', '281', '121', '55', '124', '14'], ['148', '241', '49', '23', '147', '91', '119', '298', '240', '290', '132', '63', '75', '135', '51', '200', '45', '271', '126', '105', '259', '57', '21', '206', '62', '249'], ['84', '88', '284', '256', '196', '288', '294', '98', '13', '219', '72', '3', '73', '60', '221', '17', '243', '253', '83', '106', '299', '16', '1', '230', '192', '244'], ['66', '127', '9', '266', '216', '71', '193', '134', '195', '37', '24', '228', '202', '22', '44', '146', '218', '111', '7', '35', '237', '141', '222', '224', '61', '28'], ['64', '59', '76', '26', '32', '99', '227', '220', '226', '50', '150', '102', '278', '287', '263', '247', '265', '213', '208', '283', '120', '4', '5', '212', '107', '79'], ['248', '274', '246', '191', '103', '238', '39', '137', '109', '100', '41', '142', '143', '257', '65', '297', '77', '254', '149', '38', '272', '239', '251', '11', '40', '292']]\n"
     ]
    }
   ],
   "source": [
    "rootpath_csv = \"/Prove/Yoshihisa/HEIF_ghost/HEIF_IMAGES_CSV/\"\n",
    "\n",
    "train_list1 = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\"]\n",
    "\n",
    "train_list2 = [\"31\", \"32\", \"33\", \"34\", \"35\", \"36\", \"37\", \"38\", \"39\", \"40\", \"41\", \"42\", \"43\", \"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"50\", \"51\", \"52\", \"53\", \"54\", \"55\", \"56\", \"57\", \"58\", \"59\", \"60\"]\n",
    "\n",
    "train_list3 = [\"61\", \"62\", \"63\", \"64\", \"65\", \"66\", \"67\", \"68\", \"69\", \"70\", \"71\", \"72\", \"73\", \"74\", \"75\", \"76\", \"77\", \"78\", \"79\", \"80\", \"81\", \"82\", \"83\", \"84\", \"85\", \"86\", \"87\", \"88\", \"89\", \"90\"]\n",
    "\n",
    "train_list4 = [\"91\", \"92\", \"93\", \"94\", \"95\", \"96\", \"97\", \"98\", \"99\", \"100\", \"101\", \"102\", \"103\", \"104\", \"105\", \"106\", \"107\", \"108\", \"109\", \"110\", \"111\", \"112\", \"113\", \"114\", \"115\", \"116\", \"117\", \"118\", \"119\", \"120\"]\n",
    "\n",
    "train_list5 = [\"121\", \"122\", \"123\", \"124\", \"125\", \"126\", \"127\", \"128\", \"129\", \"130\", \"131\", \"132\", \"133\", \"134\", \"135\", \"136\", \"137\", \"138\", \"139\", \"140\", \"141\", \"142\", \"143\", \"144\", \"145\", \"146\", \"147\", \"148\", \"149\", \"150\"]\n",
    "\n",
    "train_list6 = [\"191\", \"192\", \"193\", \"194\", \"195\", \"196\", \"197\", \"198\", \"199\", \"200\"]\n",
    "\n",
    "train_list7 = [\"201\", \"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"211\", \"212\", \"213\", \"214\", \"215\", \"216\", \"217\", \"218\", \"219\", \"220\"]\n",
    "\n",
    "train_list8 = [\"221\", \"222\", \"223\", \"224\", \"225\", \"226\", \"227\", \"228\", \"229\", \"230\", \"231\", \"232\", \"233\", \"234\", \"235\", \"236\", \"237\", \"238\", \"239\", \"240\", \"241\", \"242\", \"243\", \"244\", \"245\", \"246\", \"247\", \"248\", \"249\", \"250\"]\n",
    "\n",
    "train_list9 = [\"251\", \"252\", \"253\", \"254\", \"255\", \"256\", \"257\", \"258\", \"259\", \"260\", \"261\", \"262\", \"263\", \"264\", \"265\", \"266\", \"267\", \"268\", \"269\", \"270\", \"271\", \"272\", \"273\", \"274\", \"275\", \"276\", \"277\", \"278\", \"279\", \"280\"]\n",
    "\n",
    "train_list10 = [\"281\", \"282\", \"283\", \"284\", \"285\", \"286\", \"287\", \"288\", \"289\", \"290\", \"291\", \"292\", \"293\", \"294\", \"295\", \"296\", \"297\", \"298\", \"299\", \"300\"]\n",
    "\n",
    "\n",
    "all_train_lists = [train_list1, train_list2, train_list3, train_list4, train_list5,\n",
    "                   train_list6, train_list7, train_list8, train_list9, train_list10]\n",
    "\n",
    "# すべてのリストを1つのリストに結合する\n",
    "combined_train_list = sum(all_train_lists, [])\n",
    "\n",
    "# リストの順序をランダムにシャッフルする\n",
    "random.shuffle(combined_train_list)\n",
    "\n",
    "# シャッフルされたリストを10個のグループに分割する\n",
    "train_lists = [combined_train_list[i:i+26] for i in range(0, len(combined_train_list), 26)]\n",
    "print((train_lists))\n",
    "\n",
    "single_list1 = []\n",
    "single_list2 = []\n",
    "single_list3 = []\n",
    "single_list4 = []\n",
    "single_list5 = []\n",
    "single_list6 = []\n",
    "single_list7 = []\n",
    "single_list8 = []\n",
    "single_list9 = []\n",
    "single_list10 = []\n",
    "\n",
    "single_recompress_list1 = []\n",
    "single_recompress_list2 = []\n",
    "single_recompress_list3 = []\n",
    "single_recompress_list4 = []\n",
    "single_recompress_list5 = []\n",
    "single_recompress_list6 = []\n",
    "single_recompress_list7 = []\n",
    "single_recompress_list8 = []\n",
    "single_recompress_list9 = []\n",
    "single_recompress_list10 = []\n",
    "\n",
    "second_largeQP1_list1 = []\n",
    "second_largeQP1_list2 = []\n",
    "second_largeQP1_list3 = []\n",
    "second_largeQP1_list4 = []\n",
    "second_largeQP1_list5 = []\n",
    "second_largeQP1_list6 = []\n",
    "second_largeQP1_list7 = []\n",
    "second_largeQP1_list8 = []\n",
    "second_largeQP1_list9 = []\n",
    "second_largeQP1_list10 = []\n",
    "\n",
    "second_recompress_largeQP1_list1 = []\n",
    "second_recompress_largeQP1_list2 = []\n",
    "second_recompress_largeQP1_list3 = []\n",
    "second_recompress_largeQP1_list4 = []\n",
    "second_recompress_largeQP1_list5 = []\n",
    "second_recompress_largeQP1_list6 = []\n",
    "second_recompress_largeQP1_list7 = []\n",
    "second_recompress_largeQP1_list8 = []\n",
    "second_recompress_largeQP1_list9 = []\n",
    "second_recompress_largeQP1_list10 = []\n",
    "\n",
    "second_sameQP_list1 = []\n",
    "second_sameQP_list2 = []\n",
    "second_sameQP_list3 = []\n",
    "second_sameQP_list4 = []\n",
    "second_sameQP_list5 = []\n",
    "second_sameQP_list6 = []\n",
    "second_sameQP_list7 = []\n",
    "second_sameQP_list8 = []\n",
    "second_sameQP_list9 = []\n",
    "second_sameQP_list10 = []\n",
    "\n",
    "second_recompress_sameQP_list1 = []\n",
    "second_recompress_sameQP_list2 = []\n",
    "second_recompress_sameQP_list3 = []\n",
    "second_recompress_sameQP_list4 = []\n",
    "second_recompress_sameQP_list5 = []\n",
    "second_recompress_sameQP_list6 = []\n",
    "second_recompress_sameQP_list7 = []\n",
    "second_recompress_sameQP_list8 = []\n",
    "second_recompress_sameQP_list9 = []\n",
    "second_recompress_sameQP_list10 = []\n",
    "\n",
    "second_largeQP2_list1 = []\n",
    "second_largeQP2_list2 = []\n",
    "second_largeQP2_list3 = []\n",
    "second_largeQP2_list4 = []\n",
    "second_largeQP2_list5 = []\n",
    "second_largeQP2_list6 = []\n",
    "second_largeQP2_list7 = []\n",
    "second_largeQP2_list8 = []\n",
    "second_largeQP2_list9 = []\n",
    "second_largeQP2_list10 = []\n",
    "\n",
    "second_recompress_largeQP2_list1 = []\n",
    "second_recompress_largeQP2_list2 = []\n",
    "second_recompress_largeQP2_list3 = []\n",
    "second_recompress_largeQP2_list4 = []\n",
    "second_recompress_largeQP2_list5 = []\n",
    "second_recompress_largeQP2_list6 = []\n",
    "second_recompress_largeQP2_list7 = []\n",
    "second_recompress_largeQP2_list8 = []\n",
    "second_recompress_largeQP2_list9 = []\n",
    "second_recompress_largeQP2_list10 = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_lists(train_list, single_list, single_recompress_list, \n",
    "                        second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                        second_sameQP_list, second_recompress_sameQP_list,\n",
    "                        second_largeQP2_list, second_recompress_largeQP2_list):\n",
    "    \n",
    "    for image in train_list:\n",
    "        single_path = osp.join(rootpath_csv+f'HEIF_images_single_csv/{image}_*')\n",
    "        single_recompress_path = osp.join(rootpath_csv+f'HEIF_images_second_sameQP_csv/{image}_*')\n",
    "        \n",
    "        second_largeQP1_path = osp.join(rootpath_csv+f'HEIF_images_second_csv/{image}_*')\n",
    "        second_recompress_largeQP1_path = osp.join(rootpath_csv+f'HEIF_images_triple_csv/{image}_*')\n",
    "        \n",
    "        second_sameQP_path = osp.join(rootpath_csv+f'HEIF_images_second_sameQP_csv/{image}_*')\n",
    "        second_recompress_sameQP_path = osp.join(rootpath_csv+f'HEIF_images_triple_sameQP_csv/{image}_*')\n",
    "        \n",
    "        second_largeQP2_path = osp.join(rootpath_csv+f'HEIF_images_second_largeQP_csv/{image}_*')\n",
    "        second_recompress_largeQP2_path = osp.join(rootpath_csv+f'HEIF_images_triple_largeQP_csv/{image}_*')\n",
    "        \n",
    "\n",
    "        for path in sorted(glob.glob(single_path)):\n",
    "            single_list.append(path)\n",
    "        for path in sorted(glob.glob(single_recompress_path)):\n",
    "            single_recompress_list.append(path)\n",
    "            \n",
    "        for path in sorted(glob.glob(second_largeQP1_path)):\n",
    "            second_largeQP1_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP1_path)):\n",
    "            second_recompress_largeQP1_list.append(path)\n",
    "                \n",
    "        for path in sorted(glob.glob(second_sameQP_path)):\n",
    "            second_sameQP_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_sameQP_path)):\n",
    "            second_recompress_sameQP_list.append(path)\n",
    "            \n",
    "        for path in sorted(glob.glob(second_largeQP2_path)):\n",
    "            second_largeQP2_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP2_path)):\n",
    "            second_recompress_largeQP2_list.append(path)\n",
    "            \n",
    "\n",
    "# train_lists = [train_list1, train_list2, train_list3, train_list4, train_list5, train_list6, train_list7, train_list8, train_list9, train_list10]\n",
    "\n",
    "single_lists = [single_list1, single_list2,\n",
    "                single_list3, single_list4,\n",
    "                single_list5, single_list6,\n",
    "                single_list7, single_list8,\n",
    "                single_list9, single_list10]\n",
    "\n",
    "single_recompress_lists = [single_recompress_list1, single_recompress_list2,\n",
    "                           single_recompress_list3, single_recompress_list4,\n",
    "                           single_recompress_list5, single_recompress_list6,\n",
    "                           single_recompress_list7, single_recompress_list8,\n",
    "                           single_recompress_list9, single_recompress_list10]\n",
    "\n",
    "\n",
    "second_largeQP1_lists = [second_largeQP1_list1, second_largeQP1_list2,\n",
    "                        second_largeQP1_list3, second_largeQP1_list4,\n",
    "                        second_largeQP1_list5, second_largeQP1_list6,\n",
    "                        second_largeQP1_list7, second_largeQP1_list8,\n",
    "                        second_largeQP1_list9, second_largeQP1_list10]\n",
    "\n",
    "second_recompress_largeQP1_lists = [second_recompress_largeQP1_list1, second_recompress_largeQP1_list2,\n",
    "                           second_recompress_largeQP1_list3, second_recompress_largeQP1_list4,\n",
    "                           second_recompress_largeQP1_list5, second_recompress_largeQP1_list6,\n",
    "                           second_recompress_largeQP1_list7, second_recompress_largeQP1_list8,\n",
    "                           second_recompress_largeQP1_list9, second_recompress_largeQP1_list10]\n",
    "\n",
    "\n",
    "second_sameQP_lists = [second_sameQP_list1, second_sameQP_list2,\n",
    "                        second_sameQP_list3, second_sameQP_list4,\n",
    "                        second_sameQP_list5, second_sameQP_list6,\n",
    "                        second_sameQP_list7, second_sameQP_list8,\n",
    "                        second_sameQP_list9, second_sameQP_list10]\n",
    "\n",
    "second_recompress_sameQP_lists = [second_recompress_sameQP_list1, second_recompress_sameQP_list2,\n",
    "                           second_recompress_sameQP_list3, second_recompress_sameQP_list4,\n",
    "                           second_recompress_sameQP_list5, second_recompress_sameQP_list6,\n",
    "                           second_recompress_sameQP_list7, second_recompress_sameQP_list8,\n",
    "                           second_recompress_sameQP_list9, second_recompress_sameQP_list10]\n",
    "\n",
    "\n",
    "second_largeQP2_lists = [second_largeQP2_list1, second_largeQP2_list2,\n",
    "                        second_largeQP2_list3, second_largeQP2_list4,\n",
    "                        second_largeQP2_list5, second_largeQP2_list6,\n",
    "                        second_largeQP2_list7, second_largeQP2_list8,\n",
    "                        second_largeQP2_list9, second_largeQP2_list10]\n",
    "\n",
    "second_recompress_largeQP2_lists = [second_recompress_largeQP2_list1, second_recompress_largeQP2_list2,\n",
    "                           second_recompress_largeQP2_list3, second_recompress_largeQP2_list4,\n",
    "                           second_recompress_largeQP2_list5, second_recompress_largeQP2_list6,\n",
    "                           second_recompress_largeQP2_list7, second_recompress_largeQP2_list8,\n",
    "                           second_recompress_largeQP2_list9, second_recompress_largeQP2_list10]\n",
    "\n",
    "\n",
    "\n",
    "for train_list, single_list, single_recompress_list, second_largeQP1_list, second_recompress_largeQP1_list, second_sameQP_list, second_recompress_sameQP_list, second_largeQP2_list, second_recompress_largeQP2_list in zip(train_lists, \n",
    "                                                                                                                                                                                                                           single_lists,\n",
    "                                                                                                                                                                                                                           single_recompress_lists,\n",
    "                                                                                                                                                                                                                           second_largeQP1_lists,\n",
    "                                                                                                                                                                                                                           second_recompress_largeQP1_lists,\n",
    "                                                                                                                                                                                                                           second_sameQP_lists,\n",
    "                                                                                                                                                                                                                           second_recompress_sameQP_lists,\n",
    "                                                                                                                                                                                                                           second_largeQP2_lists,\n",
    "                                                                                                                                                                                                                           second_recompress_largeQP2_lists\n",
    "                                                                                                                                                                                                                          ):\n",
    "    process_train_lists(train_list, single_list, single_recompress_list, \n",
    "                        second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                        second_sameQP_list, second_recompress_sameQP_list,\n",
    "                        second_largeQP2_list, second_recompress_largeQP2_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(single_lists[6]))\n",
    "# print(len(single_recompress_lists[6]))\n",
    "# print(len(second_largeQP1_lists[6]))\n",
    "# print(len(second_recompress_largeQP1_lists[6]))\n",
    "# print(len(second_sameQP_lists[6]))\n",
    "# print(len(second_recompress_sameQP_lists[6]))\n",
    "# print(len(second_largeQP2_lists[6]))\n",
    "# print(len(second_recompress_largeQP2_lists[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list1 = []\n",
    "single_list2 = []\n",
    "single_list3 = []\n",
    "single_list4 = []\n",
    "single_list5 = []\n",
    "single_list6 = []\n",
    "single_list7 = []\n",
    "single_list8 = []\n",
    "single_list9 = []\n",
    "single_list10 = []\n",
    "\n",
    "single_recompress_list1 = []\n",
    "single_recompress_list2 = []\n",
    "single_recompress_list3 = []\n",
    "single_recompress_list4 = []\n",
    "single_recompress_list5 = []\n",
    "single_recompress_list6 = []\n",
    "single_recompress_list7 = []\n",
    "single_recompress_list8 = []\n",
    "single_recompress_list9 = []\n",
    "single_recompress_list10 = []\n",
    "\n",
    "second_largeQP1_list1 = []\n",
    "second_largeQP1_list2 = []\n",
    "second_largeQP1_list3 = []\n",
    "second_largeQP1_list4 = []\n",
    "second_largeQP1_list5 = []\n",
    "second_largeQP1_list6 = []\n",
    "second_largeQP1_list7 = []\n",
    "second_largeQP1_list8 = []\n",
    "second_largeQP1_list9 = []\n",
    "second_largeQP1_list10 = []\n",
    "\n",
    "second_recompress_largeQP1_list1 = []\n",
    "second_recompress_largeQP1_list2 = []\n",
    "second_recompress_largeQP1_list3 = []\n",
    "second_recompress_largeQP1_list4 = []\n",
    "second_recompress_largeQP1_list5 = []\n",
    "second_recompress_largeQP1_list6 = []\n",
    "second_recompress_largeQP1_list7 = []\n",
    "second_recompress_largeQP1_list8 = []\n",
    "second_recompress_largeQP1_list9 = []\n",
    "second_recompress_largeQP1_list10 = []\n",
    "\n",
    "second_sameQP_list1 = []\n",
    "second_sameQP_list2 = []\n",
    "second_sameQP_list3 = []\n",
    "second_sameQP_list4 = []\n",
    "second_sameQP_list5 = []\n",
    "second_sameQP_list6 = []\n",
    "second_sameQP_list7 = []\n",
    "second_sameQP_list8 = []\n",
    "second_sameQP_list9 = []\n",
    "second_sameQP_list10 = []\n",
    "\n",
    "second_recompress_sameQP_list1 = []\n",
    "second_recompress_sameQP_list2 = []\n",
    "second_recompress_sameQP_list3 = []\n",
    "second_recompress_sameQP_list4 = []\n",
    "second_recompress_sameQP_list5 = []\n",
    "second_recompress_sameQP_list6 = []\n",
    "second_recompress_sameQP_list7 = []\n",
    "second_recompress_sameQP_list8 = []\n",
    "second_recompress_sameQP_list9 = []\n",
    "second_recompress_sameQP_list10 = []\n",
    "\n",
    "second_largeQP2_list1 = []\n",
    "second_largeQP2_list2 = []\n",
    "second_largeQP2_list3 = []\n",
    "second_largeQP2_list4 = []\n",
    "second_largeQP2_list5 = []\n",
    "second_largeQP2_list6 = []\n",
    "second_largeQP2_list7 = []\n",
    "second_largeQP2_list8 = []\n",
    "second_largeQP2_list9 = []\n",
    "second_largeQP2_list10 = []\n",
    "\n",
    "second_recompress_largeQP2_list1 = []\n",
    "second_recompress_largeQP2_list2 = []\n",
    "second_recompress_largeQP2_list3 = []\n",
    "second_recompress_largeQP2_list4 = []\n",
    "second_recompress_largeQP2_list5 = []\n",
    "second_recompress_largeQP2_list6 = []\n",
    "second_recompress_largeQP2_list7 = []\n",
    "second_recompress_largeQP2_list8 = []\n",
    "second_recompress_largeQP2_list9 = []\n",
    "second_recompress_largeQP2_list10 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootpath_pkl = \"/Prove/Yoshihisa/HEIF_ghost/PKL/\"\n",
    "\n",
    "\n",
    "def process_train_lists2(train_list, single_list, single_recompress_list, \n",
    "                        second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                        second_sameQP_list, second_recompress_sameQP_list,\n",
    "                        second_largeQP2_list, second_recompress_largeQP2_list):\n",
    "    \n",
    "    for image in train_list:\n",
    "        single_path = osp.join(rootpath_pkl+f'pkl_single/{image}_*')\n",
    "        single_recompress_path = osp.join(rootpath_pkl+f'pkl_second_sameQP/{image}_*')\n",
    "        \n",
    "        second_largeQP1_path = osp.join(rootpath_pkl+f'pkl_second/{image}_*')\n",
    "        second_recompress_largeQP1_path = osp.join(rootpath_pkl+f'pkl_triple/{image}_*')\n",
    "        \n",
    "        second_sameQP_path = osp.join(rootpath_pkl+f'pkl_second_sameQP/{image}_*')\n",
    "        second_recompress_sameQP_path = osp.join(rootpath_pkl+f'pkl_triple_sameQP/{image}_*')\n",
    "        \n",
    "        second_largeQP2_path = osp.join(rootpath_pkl+f'pkl_second_largeQP/{image}_*')\n",
    "        second_recompress_largeQP2_path = osp.join(rootpath_pkl+f'pkl_triple_largeQP/{image}_*')\n",
    "        \n",
    "\n",
    "        for path in sorted(glob.glob(single_path)):\n",
    "            single_list.append(path)\n",
    "        for path in sorted(glob.glob(single_recompress_path)):\n",
    "            single_recompress_list.append(path)\n",
    "            \n",
    "        for path in sorted(glob.glob(second_largeQP1_path)):\n",
    "            second_largeQP1_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP1_path)):\n",
    "            second_recompress_largeQP1_list.append(path)\n",
    "                \n",
    "        for path in sorted(glob.glob(second_sameQP_path)):\n",
    "            second_sameQP_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_sameQP_path)):\n",
    "            second_recompress_sameQP_list.append(path)\n",
    "            \n",
    "        for path in sorted(glob.glob(second_largeQP2_path)):\n",
    "            second_largeQP2_list.append(path)\n",
    "        for path in sorted(glob.glob(second_recompress_largeQP2_path)):\n",
    "            second_recompress_largeQP2_list.append(path)\n",
    "            \n",
    "\n",
    "# train_lists = [train_list1, train_list2, train_list3, train_list4, train_list5, train_list6, train_list7, train_list8, train_list9, train_list10]\n",
    "\n",
    "single_listsA = [single_list1, single_list2,\n",
    "                single_list3, single_list4,\n",
    "                single_list5, single_list6,\n",
    "                single_list7, single_list8,\n",
    "                single_list9, single_list10]\n",
    "\n",
    "single_recompress_listsA = [single_recompress_list1, single_recompress_list2,\n",
    "                           single_recompress_list3, single_recompress_list4,\n",
    "                           single_recompress_list5, single_recompress_list6,\n",
    "                           single_recompress_list7, single_recompress_list8,\n",
    "                           single_recompress_list9, single_recompress_list10]\n",
    "\n",
    "\n",
    "second_largeQP1_listsA = [second_largeQP1_list1, second_largeQP1_list2,\n",
    "                        second_largeQP1_list3, second_largeQP1_list4,\n",
    "                        second_largeQP1_list5, second_largeQP1_list6,\n",
    "                        second_largeQP1_list7, second_largeQP1_list8,\n",
    "                        second_largeQP1_list9, second_largeQP1_list10]\n",
    "\n",
    "second_recompress_largeQP1_listsA = [second_recompress_largeQP1_list1, second_recompress_largeQP1_list2,\n",
    "                           second_recompress_largeQP1_list3, second_recompress_largeQP1_list4,\n",
    "                           second_recompress_largeQP1_list5, second_recompress_largeQP1_list6,\n",
    "                           second_recompress_largeQP1_list7, second_recompress_largeQP1_list8,\n",
    "                           second_recompress_largeQP1_list9, second_recompress_largeQP1_list10]\n",
    "\n",
    "\n",
    "second_sameQP_listsA = [second_sameQP_list1, second_sameQP_list2,\n",
    "                        second_sameQP_list3, second_sameQP_list4,\n",
    "                        second_sameQP_list5, second_sameQP_list6,\n",
    "                        second_sameQP_list7, second_sameQP_list8,\n",
    "                        second_sameQP_list9, second_sameQP_list10]\n",
    "\n",
    "second_recompress_sameQP_listsA = [second_recompress_sameQP_list1, second_recompress_sameQP_list2,\n",
    "                           second_recompress_sameQP_list3, second_recompress_sameQP_list4,\n",
    "                           second_recompress_sameQP_list5, second_recompress_sameQP_list6,\n",
    "                           second_recompress_sameQP_list7, second_recompress_sameQP_list8,\n",
    "                           second_recompress_sameQP_list9, second_recompress_sameQP_list10]\n",
    "\n",
    "\n",
    "second_largeQP2_listsA = [second_largeQP2_list1, second_largeQP2_list2,\n",
    "                        second_largeQP2_list3, second_largeQP2_list4,\n",
    "                        second_largeQP2_list5, second_largeQP2_list6,\n",
    "                        second_largeQP2_list7, second_largeQP2_list8,\n",
    "                        second_largeQP2_list9, second_largeQP2_list10]\n",
    "\n",
    "second_recompress_largeQP2_listsA = [second_recompress_largeQP2_list1, second_recompress_largeQP2_list2,\n",
    "                           second_recompress_largeQP2_list3, second_recompress_largeQP2_list4,\n",
    "                           second_recompress_largeQP2_list5, second_recompress_largeQP2_list6,\n",
    "                           second_recompress_largeQP2_list7, second_recompress_largeQP2_list8,\n",
    "                           second_recompress_largeQP2_list9, second_recompress_largeQP2_list10]\n",
    "\n",
    "\n",
    "\n",
    "for train_list, single_list, single_recompress_list, second_largeQP1_list, second_recompress_largeQP1_list, second_sameQP_list, second_recompress_sameQP_list, second_largeQP2_list, second_recompress_largeQP2_list in zip(train_lists, \n",
    "                                                                                                                                                                                                                           single_listsA,\n",
    "                                                                                                                                                                                                                           single_recompress_listsA,\n",
    "                                                                                                                                                                                                                           second_largeQP1_listsA,\n",
    "                                                                                                                                                                                                                           second_recompress_largeQP1_listsA,\n",
    "                                                                                                                                                                                                                           second_sameQP_listsA,\n",
    "                                                                                                                                                                                                                           second_recompress_sameQP_listsA,\n",
    "                                                                                                                                                                                                                           second_largeQP2_listsA,\n",
    "                                                                                                                                                                                                                           second_recompress_largeQP2_listsA\n",
    "                                                                                                                                                                                                                          ):\n",
    "    process_train_lists2(train_list, single_list, single_recompress_list, \n",
    "                        second_largeQP1_list, second_recompress_largeQP1_list, \n",
    "                        second_sameQP_list, second_recompress_sameQP_list,\n",
    "                        second_largeQP2_list, second_recompress_largeQP2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(single_listsA[6]))\n",
    "# print(len(single_recompress_listsA[6]))\n",
    "# print(len(second_largeQP1_listsA[6]))\n",
    "# print(len(second_recompress_largeQP1_listsA[6]))\n",
    "# print(len(second_sameQP_listsA[6]))\n",
    "# print(len(second_recompress_sameQP_listsA[6]))\n",
    "# print(len(second_largeQP2_listsA[6]))\n",
    "# print(len(second_recompress_largeQP2_listsA[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "train_csv_list:  480\n"
     ]
    }
   ],
   "source": [
    "single_csv1 = list(zip(single_lists[0], single_listsA[0], single_recompress_lists[0], single_recompress_listsA[0]))\n",
    "single_csv2 = list(zip(single_lists[1], single_listsA[1], single_recompress_lists[1], single_recompress_listsA[1]))\n",
    "single_csv3 = list(zip(single_lists[2], single_listsA[2], single_recompress_lists[2], single_recompress_listsA[2]))\n",
    "single_csv4 = list(zip(single_lists[3], single_listsA[3], single_recompress_lists[3], single_recompress_listsA[3]))\n",
    "single_csv5 = list(zip(single_lists[4], single_listsA[4], single_recompress_lists[4], single_recompress_listsA[4]))\n",
    "single_csv6 = list(zip(single_lists[5], single_listsA[5], single_recompress_lists[5], single_recompress_listsA[5]))\n",
    "single_csv7 = list(zip(single_lists[6], single_listsA[6], single_recompress_lists[6], single_recompress_listsA[6]))\n",
    "single_csv8 = list(zip(single_lists[7], single_listsA[7], single_recompress_lists[7], single_recompress_listsA[7]))\n",
    "single_csv9 = list(zip(single_lists[8], single_listsA[8], single_recompress_lists[8], single_recompress_listsA[8]))\n",
    "single_csv10 = list(zip(single_lists[9], single_listsA[9], single_recompress_lists[9], single_recompress_listsA[9]))\n",
    "\n",
    "single_csv1 = random.sample(single_csv1, 240)\n",
    "single_csv2 = random.sample(single_csv2, 240)\n",
    "single_csv3 = random.sample(single_csv3, 240)\n",
    "single_csv4 = random.sample(single_csv4, 240)\n",
    "single_csv5 = random.sample(single_csv5, 240)\n",
    "single_csv6 = random.sample(single_csv6, 240)\n",
    "single_csv7 = random.sample(single_csv7, 240)\n",
    "single_csv8 = random.sample(single_csv8, 240)\n",
    "single_csv9 = random.sample(single_csv9, 240)\n",
    "single_csv10 = random.sample(single_csv10, 240)\n",
    "print(len(single_csv1))\n",
    "\n",
    "second_largeQP1_csv1 = list(zip(second_largeQP1_lists[0], second_largeQP1_listsA[0], second_recompress_largeQP1_lists[0], second_recompress_largeQP1_listsA[0]))\n",
    "second_largeQP1_csv2 = list(zip(second_largeQP1_lists[1], second_largeQP1_listsA[1], second_recompress_largeQP1_lists[1], second_recompress_largeQP1_listsA[1]))\n",
    "second_largeQP1_csv3 = list(zip(second_largeQP1_lists[2], second_largeQP1_listsA[2], second_recompress_largeQP1_lists[2], second_recompress_largeQP1_listsA[2]))\n",
    "second_largeQP1_csv4 = list(zip(second_largeQP1_lists[3], second_largeQP1_listsA[3], second_recompress_largeQP1_lists[3], second_recompress_largeQP1_listsA[3]))\n",
    "second_largeQP1_csv5 = list(zip(second_largeQP1_lists[4], second_largeQP1_listsA[4], second_recompress_largeQP1_lists[4], second_recompress_largeQP1_listsA[4]))\n",
    "second_largeQP1_csv6 = list(zip(second_largeQP1_lists[5], second_largeQP1_listsA[5], second_recompress_largeQP1_lists[5], second_recompress_largeQP1_listsA[5]))\n",
    "second_largeQP1_csv7 = list(zip(second_largeQP1_lists[6], second_largeQP1_listsA[6], second_recompress_largeQP1_lists[6], second_recompress_largeQP1_listsA[6]))\n",
    "second_largeQP1_csv8 = list(zip(second_largeQP1_lists[7], second_largeQP1_listsA[7], second_recompress_largeQP1_lists[7], second_recompress_largeQP1_listsA[7]))\n",
    "second_largeQP1_csv9 = list(zip(second_largeQP1_lists[8], second_largeQP1_listsA[8], second_recompress_largeQP1_lists[8], second_recompress_largeQP1_listsA[8]))\n",
    "second_largeQP1_csv10 = list(zip(second_largeQP1_lists[9], second_largeQP1_listsA[9], second_recompress_largeQP1_lists[9], second_recompress_largeQP1_listsA[9]))\n",
    "\n",
    "second_largeQP1_csv1 = random.sample(second_largeQP1_csv1, 80)\n",
    "second_largeQP1_csv2 = random.sample(second_largeQP1_csv2, 80)\n",
    "second_largeQP1_csv3 = random.sample(second_largeQP1_csv3, 80)\n",
    "second_largeQP1_csv4 = random.sample(second_largeQP1_csv4, 80)\n",
    "second_largeQP1_csv5 = random.sample(second_largeQP1_csv5, 80)\n",
    "second_largeQP1_csv6 = random.sample(second_largeQP1_csv6, 80)\n",
    "second_largeQP1_csv7 = random.sample(second_largeQP1_csv7, 80)\n",
    "second_largeQP1_csv8 = random.sample(second_largeQP1_csv8, 80)\n",
    "second_largeQP1_csv9 = random.sample(second_largeQP1_csv9, 80)\n",
    "second_largeQP1_csv10 = random.sample(second_largeQP1_csv10, 80)\n",
    "# print(len(second_largeQP1_csv1))\n",
    "# print(len(second_largeQP1_csv10))\n",
    "\n",
    "second_sameQP_csv1 = list(zip(second_sameQP_lists[0], second_sameQP_listsA[0], second_recompress_sameQP_lists[0], second_recompress_sameQP_listsA[0]))\n",
    "second_sameQP_csv2 = list(zip(second_sameQP_lists[1], second_sameQP_listsA[1], second_recompress_sameQP_lists[1], second_recompress_sameQP_listsA[1]))\n",
    "second_sameQP_csv3 = list(zip(second_sameQP_lists[2], second_sameQP_listsA[2], second_recompress_sameQP_lists[2], second_recompress_sameQP_listsA[2]))\n",
    "second_sameQP_csv4 = list(zip(second_sameQP_lists[3], second_sameQP_listsA[3], second_recompress_sameQP_lists[3], second_recompress_sameQP_listsA[3]))\n",
    "second_sameQP_csv5 = list(zip(second_sameQP_lists[4], second_sameQP_listsA[4], second_recompress_sameQP_lists[4], second_recompress_sameQP_listsA[4]))\n",
    "second_sameQP_csv6 = list(zip(second_sameQP_lists[5], second_sameQP_listsA[5], second_recompress_sameQP_lists[5], second_recompress_sameQP_listsA[5]))\n",
    "second_sameQP_csv7 = list(zip(second_sameQP_lists[6], second_sameQP_listsA[6], second_recompress_sameQP_lists[6], second_recompress_sameQP_listsA[6]))\n",
    "second_sameQP_csv8 = list(zip(second_sameQP_lists[7], second_sameQP_listsA[7], second_recompress_sameQP_lists[7], second_recompress_sameQP_listsA[7]))\n",
    "second_sameQP_csv9 = list(zip(second_sameQP_lists[8], second_sameQP_listsA[8], second_recompress_sameQP_lists[8], second_recompress_sameQP_listsA[8]))\n",
    "second_sameQP_csv10 = list(zip(second_sameQP_lists[9], second_sameQP_listsA[9], second_recompress_sameQP_lists[9], second_recompress_sameQP_listsA[9]))\n",
    "\n",
    "second_sameQP_csv1 = random.sample(second_sameQP_csv1, 80)\n",
    "second_sameQP_csv2 = random.sample(second_sameQP_csv2, 80)\n",
    "second_sameQP_csv3 = random.sample(second_sameQP_csv3, 80)\n",
    "second_sameQP_csv4 = random.sample(second_sameQP_csv4, 80)\n",
    "second_sameQP_csv5 = random.sample(second_sameQP_csv5, 80)\n",
    "second_sameQP_csv6 = random.sample(second_sameQP_csv6, 80)\n",
    "second_sameQP_csv7 = random.sample(second_sameQP_csv7, 80)\n",
    "second_sameQP_csv8 = random.sample(second_sameQP_csv8, 80)\n",
    "second_sameQP_csv9 = random.sample(second_sameQP_csv9, 80)\n",
    "second_sameQP_csv10 = random.sample(second_sameQP_csv10, 80)\n",
    "# print(len(second_sameQP_csv1))\n",
    "# print(len(second_sameQP_csv10))\n",
    "\n",
    "second_largeQP2_csv1 = list(zip(second_largeQP2_lists[0], second_largeQP2_listsA[0], second_recompress_largeQP2_lists[0], second_recompress_largeQP2_listsA[0]))\n",
    "second_largeQP2_csv2 = list(zip(second_largeQP2_lists[1], second_largeQP2_listsA[1], second_recompress_largeQP2_lists[1], second_recompress_largeQP2_listsA[1]))\n",
    "second_largeQP2_csv3 = list(zip(second_largeQP2_lists[2], second_largeQP2_listsA[2], second_recompress_largeQP2_lists[2], second_recompress_largeQP2_listsA[2]))\n",
    "second_largeQP2_csv4 = list(zip(second_largeQP2_lists[3], second_largeQP2_listsA[3], second_recompress_largeQP2_lists[3], second_recompress_largeQP2_listsA[3]))\n",
    "second_largeQP2_csv5 = list(zip(second_largeQP2_lists[4], second_largeQP2_listsA[4], second_recompress_largeQP2_lists[4], second_recompress_largeQP2_listsA[4]))\n",
    "second_largeQP2_csv6 = list(zip(second_largeQP2_lists[5], second_largeQP2_listsA[5], second_recompress_largeQP2_lists[5], second_recompress_largeQP2_listsA[5]))\n",
    "second_largeQP2_csv7 = list(zip(second_largeQP2_lists[6], second_largeQP2_listsA[6], second_recompress_largeQP2_lists[6], second_recompress_largeQP2_listsA[6]))\n",
    "second_largeQP2_csv8 = list(zip(second_largeQP2_lists[7], second_largeQP2_listsA[7], second_recompress_largeQP2_lists[7], second_recompress_largeQP2_listsA[7]))\n",
    "second_largeQP2_csv9 = list(zip(second_largeQP2_lists[8], second_largeQP2_listsA[8], second_recompress_largeQP2_lists[8], second_recompress_largeQP2_listsA[8]))\n",
    "second_largeQP2_csv10 = list(zip(second_largeQP2_lists[9], second_largeQP2_listsA[9], second_recompress_largeQP2_lists[9], second_recompress_largeQP2_listsA[9]))\n",
    "\n",
    "second_largeQP2_csv1 = random.sample(second_largeQP2_csv1, 80)\n",
    "second_largeQP2_csv2 = random.sample(second_largeQP2_csv2, 80)\n",
    "second_largeQP2_csv3 = random.sample(second_largeQP2_csv3, 80)\n",
    "second_largeQP2_csv4 = random.sample(second_largeQP2_csv4, 80)\n",
    "second_largeQP2_csv5 = random.sample(second_largeQP2_csv5, 80)\n",
    "second_largeQP2_csv6 = random.sample(second_largeQP2_csv6, 80)\n",
    "second_largeQP2_csv7 = random.sample(second_largeQP2_csv7, 80)\n",
    "second_largeQP2_csv8 = random.sample(second_largeQP2_csv8, 80)\n",
    "second_largeQP2_csv9 = random.sample(second_largeQP2_csv9, 80)\n",
    "second_largeQP2_csv10 = random.sample(second_largeQP2_csv10, 80)\n",
    "# print(len(second_largeQP2_csv1))\n",
    "# print(len(second_largeQP2_csv10))\n",
    "\n",
    "\n",
    "train_csv_list1 = single_csv1 + second_largeQP1_csv1 + second_sameQP_csv1 + second_largeQP2_csv1\n",
    "train_csv_list2 = single_csv2 + second_largeQP1_csv2 + second_sameQP_csv2 + second_largeQP2_csv2\n",
    "train_csv_list3 = single_csv3 + second_largeQP1_csv3 + second_sameQP_csv3 + second_largeQP2_csv3\n",
    "train_csv_list4 = single_csv4 + second_largeQP1_csv4 + second_sameQP_csv4 + second_largeQP2_csv4\n",
    "train_csv_list5 = single_csv5 + second_largeQP1_csv5 + second_sameQP_csv5 + second_largeQP2_csv5\n",
    "train_csv_list6 = single_csv6 + second_largeQP1_csv6 + second_sameQP_csv6 + second_largeQP2_csv6\n",
    "train_csv_list7 = single_csv7 + second_largeQP1_csv7 + second_sameQP_csv7 + second_largeQP2_csv7\n",
    "train_csv_list8 = single_csv8 + second_largeQP1_csv8 + second_sameQP_csv8 + second_largeQP2_csv8\n",
    "train_csv_list9 = single_csv9 + second_largeQP1_csv9 + second_sameQP_csv9 + second_largeQP2_csv9\n",
    "train_csv_list10 = single_csv10 + second_largeQP1_csv10 + second_sameQP_csv9 + second_largeQP2_csv10\n",
    "print(\"train_csv_list: \", len(train_csv_list1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootpath2 = \"/Prove/Yoshihisa/HEIF_ghost/EXPERIMENT_DIFFERENT_SOFTWARE/\"\n",
    "\n",
    "# SINGLE\n",
    "GIMP_path1 = os.path.join(rootpath2, 'GIMP_csv')\n",
    "GIMP_path2 = os.path.join(rootpath2, 'GIMP_RECOMPRESSED_csv')\n",
    "\n",
    "GIMP_path1_csv = [os.path.join(GIMP_path1, file) for file in sorted(os.listdir(GIMP_path1))]\n",
    "GIMP_path2_csv = [os.path.join(GIMP_path2, file) for file in sorted(os.listdir(GIMP_path2))]\n",
    "\n",
    "LIBHEIF_path1 = os.path.join(rootpath2, 'LIBHEIF_csv')\n",
    "LIBHEIF_path2 = os.path.join(rootpath2, 'LIBHEIF_RECOMPRESSED_csv')\n",
    "\n",
    "LIBHEIF_path1_csv = [os.path.join(LIBHEIF_path1, file) for file in sorted(os.listdir(LIBHEIF_path1))]\n",
    "LIBHEIF_path2_csv = [os.path.join(LIBHEIF_path2, file) for file in sorted(os.listdir(LIBHEIF_path2))]\n",
    "\n",
    "\n",
    "# DOUBLE\n",
    "GIMP_GIMP_path1 = os.path.join(rootpath2, 'GIMP_GIMP_csv')\n",
    "GIMP_GIMP_path2 = os.path.join(rootpath2, 'GIMP_GIMP_RECOMPRESSED_csv')\n",
    "\n",
    "GIMP_GIMP_path1_csv = [os.path.join(GIMP_GIMP_path1, file) for file in sorted(os.listdir(GIMP_GIMP_path1))]\n",
    "GIMP_GIMP_path2_csv = [os.path.join(GIMP_GIMP_path2, file) for file in sorted(os.listdir(GIMP_GIMP_path2))]\n",
    "\n",
    "LIBHEIF_GIMP_path1 = os.path.join(rootpath2, 'LIBHEIF_GIMP_csv')\n",
    "LIBHEIF_GIMP_path2 = os.path.join(rootpath2, 'LIBHEIF_GIMP_RECOMPRESSED_csv')\n",
    "\n",
    "LIBHEIF_GIMP_path1_csv = [os.path.join(LIBHEIF_GIMP_path1, file) for file in sorted(os.listdir(LIBHEIF_GIMP_path1))]\n",
    "LIBHEIF_GIMP_path2_csv = [os.path.join(LIBHEIF_GIMP_path2, file) for file in sorted(os.listdir(LIBHEIF_GIMP_path2))]\n",
    "\n",
    "GIMP_LIBHEIF_path1 = os.path.join(rootpath2, 'GIMP_LIBHEIF_csv')\n",
    "GIMP_LIBHEIF_path2 = os.path.join(rootpath2, 'GIMP_LIBHEIF_RECOMPRESSED_csv')\n",
    "\n",
    "GIMP_LIBHEIF_path1_csv = [os.path.join(GIMP_LIBHEIF_path1, file) for file in sorted(os.listdir(GIMP_LIBHEIF_path1))]\n",
    "GIMP_LIBHEIF_path2_csv = [os.path.join(GIMP_LIBHEIF_path2, file) for file in sorted(os.listdir(GIMP_LIBHEIF_path2))]\n",
    "\n",
    "\n",
    "# print(\"GIMP_path1_csv: \", len(GIMP_path1_csv))\n",
    "# print(\"GIMP_path2_csv: \", len(GIMP_path2_csv))\n",
    "# print(\"GIMP_GIMP_path1_csv: \", len(GIMP_GIMP_path1_csv))\n",
    "# print(\"GIMP_GIMP_path2_csv: \", len(GIMP_GIMP_path2_csv))\n",
    "# print()\n",
    "# print(\"GIMP_path1_csv: \", len(GIMP_path1_csv))\n",
    "# print(\"GIMP_path2_csv: \", len(GIMP_path2_csv))\n",
    "# print(\"LIBHEIF_GIMP_path1_csv: \", len(LIBHEIF_GIMP_path1_csv))\n",
    "# print(\"LIBHEIF_GIMP_path2_csv: \", len(LIBHEIF_GIMP_path2_csv))\n",
    "# print()\n",
    "# print(\"LIBHEIF_path1_csv: \", len(LIBHEIF_path1_csv))\n",
    "# print(\"LIBHEIF_path2_csv: \", len(LIBHEIF_path2_csv))\n",
    "# print(\"GIMP_LIBHEIF_path1_csv: \", len(GIMP_LIBHEIF_path1_csv))\n",
    "# print(\"GIMP_LIBHEIF_path2_csv: \", len(GIMP_LIBHEIF_path2_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootpath3 = \"/Prove/Yoshihisa/HEIF_ghost/EXPERIMENT_DIFFERENT_SOFTWARE/PKL/\"\n",
    "\n",
    "# SINGLE\n",
    "GIMP_path1 = os.path.join(rootpath3, 'pkl_GIMP')\n",
    "GIMP_path2 = os.path.join(rootpath3, 'pkl_GIMP_RECOMPRESSED')\n",
    "\n",
    "GIMP_path1_pkl = [os.path.join(GIMP_path1, file) for file in sorted(os.listdir(GIMP_path1))]\n",
    "GIMP_path2_pkl = [os.path.join(GIMP_path2, file) for file in sorted(os.listdir(GIMP_path2))]\n",
    "\n",
    "LIBHEIF_path1 = os.path.join(rootpath3, 'pkl_LIBHEIF')\n",
    "LIBHEIF_path2 = os.path.join(rootpath3, 'pkl_LIBHEIF_RECOMPRESSED')\n",
    "\n",
    "LIBHEIF_path1_pkl = [os.path.join(LIBHEIF_path1, file) for file in sorted(os.listdir(LIBHEIF_path1))]\n",
    "LIBHEIF_path2_pkl = [os.path.join(LIBHEIF_path2, file) for file in sorted(os.listdir(LIBHEIF_path2))]\n",
    "\n",
    "\n",
    "# DOUBLE\n",
    "GIMP_GIMP_path1 = os.path.join(rootpath3, 'pkl_GIMP_GIMP')\n",
    "GIMP_GIMP_path2 = os.path.join(rootpath3, 'pkl_GIMP_GIMP_RECOMPRESSED')\n",
    "\n",
    "GIMP_GIMP_path1_pkl = [os.path.join(GIMP_GIMP_path1, file) for file in sorted(os.listdir(GIMP_GIMP_path1))]\n",
    "GIMP_GIMP_path2_pkl = [os.path.join(GIMP_GIMP_path2, file) for file in sorted(os.listdir(GIMP_GIMP_path2))]\n",
    "\n",
    "LIBHEIF_GIMP_path1 = os.path.join(rootpath3, 'pkl_LIBHEIF_GIMP')\n",
    "LIBHEIF_GIMP_path2 = os.path.join(rootpath3, 'pkl_LIBHEIF_GIMP_RECOMPRESSED')\n",
    "\n",
    "LIBHEIF_GIMP_path1_pkl = [os.path.join(LIBHEIF_GIMP_path1, file) for file in sorted(os.listdir(LIBHEIF_GIMP_path1))]\n",
    "LIBHEIF_GIMP_path2_pkl = [os.path.join(LIBHEIF_GIMP_path2, file) for file in sorted(os.listdir(LIBHEIF_GIMP_path2))]\n",
    "\n",
    "GIMP_LIBHEIF_path1 = os.path.join(rootpath3, 'pkl_GIMP_LIBHEIF')\n",
    "GIMP_LIBHEIF_path2 = os.path.join(rootpath3, 'pkl_GIMP_LIBHEIF_RECOMPRESSED')\n",
    "\n",
    "GIMP_LIBHEIF_path1_pkl = [os.path.join(GIMP_LIBHEIF_path1, file) for file in sorted(os.listdir(GIMP_LIBHEIF_path1))]\n",
    "GIMP_LIBHEIF_path2_pkl = [os.path.join(GIMP_LIBHEIF_path2, file) for file in sorted(os.listdir(GIMP_LIBHEIF_path2))]\n",
    "\n",
    "\n",
    "# print(\"GIMP_path1_pkl: \", len(GIMP_path1_pkl))\n",
    "# print(\"GIMP_path2_pkl: \", len(GIMP_path2_pkl))\n",
    "# print(\"GIMP_GIMP_path1_pkl: \", len(GIMP_GIMP_path1_pkl))\n",
    "# print(\"GIMP_GIMP_path2_pkl: \", len(GIMP_GIMP_path2_pkl))\n",
    "# print()\n",
    "# print(\"GIMP_path1_pkl: \", len(GIMP_path1_pkl))\n",
    "# print(\"GIMP_path2_pkl: \", len(GIMP_path2_pkl))\n",
    "# print(\"LIBHEIF_GIMP_path1_pkl: \", len(LIBHEIF_GIMP_path1_pkl))\n",
    "# print(\"LIBHEIF_GIMP_path2_pkl: \", len(LIBHEIF_GIMP_path2_pkl))\n",
    "# print()\n",
    "# print(\"LIBHEIF_path1_pkl: \", len(LIBHEIF_path1_pkl))\n",
    "# print(\"LIBHEIF_path2_pkl: \", len(LIBHEIF_path2_pkl))\n",
    "# print(\"GIMP_LIBHEIF_path1_pkl: \", len(GIMP_LIBHEIF_path1_pkl))\n",
    "# print(\"GIMP_LIBHEIF_path2_pkl: \", len(GIMP_LIBHEIF_path2_pkl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIMP_GIMP_list:  60\n",
      "LIBHEIF_GIMP_list:  60\n",
      "GIMP_LIBHEIF_list:  60\n"
     ]
    }
   ],
   "source": [
    "GIMP_csv = list(zip(GIMP_path1_csv, GIMP_path1_pkl, GIMP_path2_csv, GIMP_path2_pkl))\n",
    "GIMP_csv1 = random.sample(GIMP_csv, 30)\n",
    "LIBHEIF_csv = list(zip(LIBHEIF_path1_csv, LIBHEIF_path1_pkl, LIBHEIF_path2_csv, LIBHEIF_path2_pkl))\n",
    "LIBHEIF_csv1 = random.sample(LIBHEIF_csv, 30)\n",
    "\n",
    "GIMP_GIMP_csv = list(zip(GIMP_GIMP_path1_csv, GIMP_GIMP_path1_pkl, GIMP_GIMP_path2_csv, GIMP_GIMP_path2_pkl))\n",
    "LIBHEIF_GIMP_csv = list(zip(LIBHEIF_GIMP_path1_csv, LIBHEIF_GIMP_path1_pkl, LIBHEIF_GIMP_path2_csv, LIBHEIF_GIMP_path2_pkl))\n",
    "GIMP_LIBHEIF_csv = list(zip(GIMP_LIBHEIF_path1_csv, GIMP_LIBHEIF_path1_pkl, GIMP_LIBHEIF_path2_csv, GIMP_LIBHEIF_path2_pkl))\n",
    "\n",
    "# GIMP_GIMP_list = GIMP_csv + GIMP_GIMP_csv\n",
    "# LIBHEIF_GIMP_list = GIMP_csv + LIBHEIF_GIMP_csv\n",
    "# GIMP_LIBHEIF_list = LIBHEIF_csv + GIMP_LIBHEIF_csv\n",
    "\n",
    "LARGEQP1 = [\"_1stQP4_2ndQP2\", \"_1stQP12_2ndQP2\", \"_1stQP12_2ndQP4\"]\n",
    "\n",
    "GIMP_GIMP_largeQP1_csv = [item for item in GIMP_GIMP_csv if any(qp in item[0] for qp in LARGEQP1)]\n",
    "LIBHEIF_GIMP_largeQP1_csv = [item for item in LIBHEIF_GIMP_csv if any(qp in item[0] for qp in LARGEQP1)]\n",
    "GIMP_LIBHEIF_largeQP1_csv = [item for item in GIMP_LIBHEIF_csv if any(qp in item[0] for qp in LARGEQP1)]\n",
    "\n",
    "GIMP_GIMP_list = GIMP_csv1 + GIMP_GIMP_largeQP1_csv\n",
    "LIBHEIF_GIMP_list = GIMP_csv1 + LIBHEIF_GIMP_largeQP1_csv\n",
    "GIMP_LIBHEIF_list = LIBHEIF_csv1 + GIMP_LIBHEIF_largeQP1_csv\n",
    "\n",
    "print(\"GIMP_GIMP_list: \", len(GIMP_GIMP_list))\n",
    "print(\"LIBHEIF_GIMP_list: \", len(LIBHEIF_GIMP_list))\n",
    "print(\"GIMP_LIBHEIF_list: \", len(GIMP_LIBHEIF_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_csv_lists(train_csv_list):\n",
    "    pu_columns = [\"PU1_64\", \"PU1_32\", \"PU1_16\", \"PU1_8\", \"PU1_4\",  \n",
    "                  \"PU2_64\",\"PU2_32\", \"PU2_16\", \"PU2_8\", \"PU2_4\"]\n",
    "\n",
    "#     luminance_columns = [\"LU1_0\",\"LU1_1\",\"LU1_2\",\"LU1_3\",\n",
    "#                          \"LU1_4\",\"LU1_5\",\"LU1_6\",\"LU1_7\",\n",
    "#                          \"LU1_8\",\"LU1_9\",\"LU1_10\",\"LU1_11\",\n",
    "#                          \"LU1_12\",\"LU1_13\",\"LU1_14\",\"LU1_15\",\n",
    "#                          \"LU1_16\",\"LU1_17\",\"LU1_18\",\"LU1_19\",\n",
    "#                          \"LU1_20\",\"LU1_21\",\"LU1_22\",\"LU1_23\",\n",
    "#                          \"LU1_24\",\"LU1_25\",\"LU1_26\",\"LU1_27\",\n",
    "#                          \"LU1_28\",\"LU1_29\",\"LU1_30\",\"LU1_31\",\n",
    "#                          \"LU1_32\",\"LU1_33\",\"LU1_34\",\n",
    "                         \n",
    "#                          \"LU2_0\",\"LU2_1\",\"LU2_2\",\"LU2_3\",\n",
    "#                          \"LU2_4\",\"LU2_5\",\"LU2_6\",\"LU2_7\",\n",
    "#                          \"LU2_8\",\"LU2_9\",\"LU2_10\",\"LU2_11\",\n",
    "#                          \"LU2_12\",\"LU2_13\",\"LU2_14\",\"LU2_15\",\n",
    "#                          \"LU2_16\",\"LU2_17\",\"LU2_18\",\"LU2_19\",\n",
    "#                          \"LU2_20\",\"LU2_21\",\"LU2_22\",\"LU2_23\",\n",
    "#                          \"LU2_24\",\"LU2_25\",\"LU2_26\",\"LU2_27\",\n",
    "#                          \"LU2_28\",\"LU2_29\",\"LU2_30\",\"LU2_31\",\n",
    "#                          \"LU2_32\",\"LU2_33\",\"LU2_34\"]\n",
    "    \n",
    "    luminance_columns = [\"LU1_0\",\"LU1_1\",\"LU1_9\",\"LU1_10\",\"LU1_11\",\"LU1_25\",\"LU1_26\",\"LU1_27\",\n",
    "                         \"LU2_0\",\"LU2_1\",\"LU2_9\",\"LU2_10\",\"LU2_11\", \"LU2_25\",\"LU2_26\",\"LU2_27\"]\n",
    "\n",
    "    chrominance_columns = [\"CH1_0\", \"CH1_1\", \"CH1_10\", \"CH1_26\", \"CH1_34\", \"CH1_36\", \n",
    "                           \"CH2_0\", \"CH2_1\", \"CH2_10\", \"CH2_26\", \"CH2_34\", \"CH2_36\"]\n",
    "\n",
    "    label_columns = [\"LABEL\"]\n",
    "    mae1_columns = [f\"MAE1_{i}\" for i in range(52)]\n",
    "    mae2_columns = [f\"MAE2_{i}\" for i in range(52)]\n",
    "    mae_columns = [\"MAE\"]\n",
    "    final_qp_columns = [\"FINAL_QP\"]\n",
    "\n",
    "    train_df1_1 = pd.DataFrame(columns=pu_columns)\n",
    "    train_df1_2 = pd.DataFrame(columns=luminance_columns)\n",
    "    train_df1_3 = pd.DataFrame(columns=chrominance_columns)\n",
    "    LABEL = pd.DataFrame(columns=label_columns)\n",
    "    train_df3 = pd.DataFrame(columns=mae1_columns)\n",
    "    train_df4 = pd.DataFrame(columns=mae2_columns)\n",
    "    MAE = pd.DataFrame(columns=mae_columns)\n",
    "    FINAL_QP = pd.DataFrame(columns=final_qp_columns)\n",
    "\n",
    "    for path1, path2, path3, path4 in train_csv_list:\n",
    "        label = 1 if (\"2ndQP\" in path1) and (\"3rdQP\" in path3) else 0\n",
    "        train_pkl_list = [path2, path4]\n",
    "        df1 = pd.read_csv(path1)\n",
    "        df2 = pd.read_csv(path3)\n",
    "        \n",
    "        pu_values = [df1.loc[i, \"pu_counts\"] for i in range(5)] + [df2.loc[i, \"pu_counts\"] for i in range(5)]\n",
    "        # lu_values = [df1.loc[i, \"luminance_counts\"] for i in range(35)] + [df2.loc[i, \"luminance_counts\"] for i in range(35)]\n",
    "        lu_values = [df1.loc[i, \"luminance_counts\"] for i in [0,1,9,10,11,25,26,27]] + [df2.loc[i, \"luminance_counts\"] for i in [0,1,9,10,11,25,26,27]]\n",
    "        ch_values = [df1.loc[i, \"chroma_counts\"] for i in [0,1,10,26,34,36]] + [df2.loc[i, \"chroma_counts\"] for i in [0,1,10,26,34,36]]\n",
    "        \n",
    "        train_df1_1 = pd.concat([train_df1_1, pd.DataFrame([pu_values], columns=pu_columns)], ignore_index=True)\n",
    "        train_df1_2= pd.concat([train_df1_2, pd.DataFrame([lu_values], columns=luminance_columns)], ignore_index=True)\n",
    "        train_df1_3 = pd.concat([train_df1_3, pd.DataFrame([ch_values], columns=chrominance_columns)], ignore_index=True)\n",
    "\n",
    "        LABEL = pd.concat([LABEL, pd.DataFrame({\"LABEL\": [label]})], ignore_index=True)\n",
    "\n",
    "        final_QP = extract_finalQP(train_pkl_list[0])\n",
    "\n",
    "        mae_d1, mae_d1_positive = calculate_mae(train_pkl_list[0])\n",
    "        _, mae_d2_positive = calculate_mae(train_pkl_list[1])\n",
    "\n",
    "        train_df3 = pd.concat([train_df3, pd.DataFrame({f\"MAE1_{i}\": [mae_d1_positive[i]] for i in range(52)})], ignore_index=True)\n",
    "        train_df4 = pd.concat([train_df4, pd.DataFrame({f\"MAE2_{i}\": [mae_d2_positive[i]] for i in range(52)})], ignore_index=True)\n",
    "        MAE = pd.concat([MAE, pd.DataFrame({\"MAE\": [mae_d1]})], ignore_index=True)\n",
    "        FINAL_QP = pd.concat([FINAL_QP, pd.DataFrame({\"FINAL_QP\": [final_QP]})], ignore_index=True)\n",
    "\n",
    "    train_df1_1.reset_index(drop=True, inplace=True)\n",
    "    train_df1_2.reset_index(drop=True, inplace=True)\n",
    "    train_df1_3.reset_index(drop=True, inplace=True)\n",
    "    LABEL.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    train_df = pd.concat([train_df1_1, train_df1_2, train_df1_3, train_df3, train_df4], axis=1)\n",
    "    train_df_onlyGhost = pd.concat([train_df3, train_df4], axis=1)\n",
    "\n",
    "    return train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1, train_df_onlyGhost1, LABEL1, MAE1, FINAL_QP1 = process_train_csv_lists(train_csv_list1)\n",
    "train_df2, train_df_onlyGhost2, LABEL2, MAE2, FINAL_QP2 = process_train_csv_lists(train_csv_list2)\n",
    "train_df3, train_df_onlyGhost3, LABEL3, MAE3, FINAL_QP3 = process_train_csv_lists(train_csv_list3)\n",
    "train_df4, train_df_onlyGhost4, LABEL4, MAE4, FINAL_QP4 = process_train_csv_lists(train_csv_list4)\n",
    "train_df5, train_df_onlyGhost5, LABEL5, MAE5, FINAL_QP5 = process_train_csv_lists(train_csv_list5)\n",
    "train_df6, train_df_onlyGhost6, LABEL6, MAE6, FINAL_QP6 = process_train_csv_lists(train_csv_list6)\n",
    "train_df7, train_df_onlyGhost7, LABEL7, MAE7, FINAL_QP7 = process_train_csv_lists(train_csv_list7)\n",
    "train_df8, train_df_onlyGhost8, LABEL8, MAE8, FINAL_QP8 = process_train_csv_lists(train_csv_list8)\n",
    "train_df9, train_df_onlyGhost9, LABEL9, MAE9, FINAL_QP9 = process_train_csv_lists(train_csv_list9)\n",
    "train_df10, train_df_onlyGhost10, LABEL10, MAE10, FINAL_QP10 = process_train_csv_lists(train_csv_list10)\n",
    "\n",
    "test_df1, test_df_onlyGhost1, LABEL_t1, MAE_t1, FINAL_QP_t1 = process_train_csv_lists(GIMP_GIMP_list)\n",
    "test_df2, test_df_onlyGhost2, LABEL_t2, MAE_t2, FINAL_QP_t2 = process_train_csv_lists(LIBHEIF_GIMP_list)\n",
    "test_df3, test_df_onlyGhost3, LABEL_t3, MAE_t3, FINAL_QP_t3 = process_train_csv_lists(GIMP_LIBHEIF_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results_to_lists(train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP):\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # スケーラーを使って結合したデータをスケーリング\n",
    "    X_train = scaler.fit_transform(train_df)\n",
    "    X_train_onlyGhost = scaler.fit_transform(train_df_onlyGhost)\n",
    "\n",
    "    # pandasをndarrayに変換\n",
    "    MAE_array = MAE.values\n",
    "    FINAL_QP_array = FINAL_QP.values\n",
    "\n",
    "    # ラベルの準備\n",
    "    Y_train = LABEL['LABEL'].astype(int)\n",
    "\n",
    "    return X_train, X_train_onlyGhost, MAE_array, FINAL_QP_array, Y_train\n",
    "\n",
    "def append_results_to_lists(train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP,\n",
    "                            X_train_list, X_train_onlyGhost_list, MAE_list, FINAL_QP_list, Y_train_list):\n",
    "    X_train, X_train_onlyGhost, MAE_array, FINAL_QP_array, Y_train = process_results_to_lists(train_df, train_df_onlyGhost, LABEL, MAE, FINAL_QP)\n",
    "    X_train_list.append(X_train)\n",
    "    X_train_onlyGhost_list.append(X_train_onlyGhost)\n",
    "    MAE_list.append(MAE_array)\n",
    "    FINAL_QP_list.append(FINAL_QP_array)\n",
    "    Y_train_list.append(Y_train)\n",
    "\n",
    "# リストを初期化\n",
    "X_train_list = []\n",
    "X_train_onlyGhost_list = []\n",
    "MAE_list = []\n",
    "FINAL_QP_list = []\n",
    "Y_train_list = []\n",
    "\n",
    "X_test_list1 = []\n",
    "X_test_onlyGhost_list1 = []\n",
    "MAE_list_t1 = []\n",
    "FINAL_QP_list_t1 = []\n",
    "Y_test_list1 = []\n",
    "\n",
    "X_test_list2 = []\n",
    "X_test_onlyGhost_list2 = []\n",
    "MAE_list_t2 = []\n",
    "FINAL_QP_list_t2 = []\n",
    "Y_test_list2 = []\n",
    "\n",
    "X_test_list3 = []\n",
    "X_test_onlyGhost_list3 = []\n",
    "MAE_list_t3 = []\n",
    "FINAL_QP_list_t3 = []\n",
    "Y_test_list3 = []\n",
    "\n",
    "\n",
    "# データを処理してリストに追加\n",
    "append_results_to_lists(train_df1, train_df_onlyGhost1, LABEL1, MAE1, FINAL_QP1, X_train_list, X_train_onlyGhost_list, MAE_list, FINAL_QP_list, Y_train_list)\n",
    "append_results_to_lists(train_df2, train_df_onlyGhost2, LABEL2, MAE2, FINAL_QP2, X_train_list, X_train_onlyGhost_list, MAE_list, FINAL_QP_list, Y_train_list)\n",
    "append_results_to_lists(train_df3, train_df_onlyGhost3, LABEL3, MAE3, FINAL_QP3, X_train_list, X_train_onlyGhost_list, MAE_list, FINAL_QP_list, Y_train_list)\n",
    "append_results_to_lists(train_df4, train_df_onlyGhost4, LABEL4, MAE4, FINAL_QP4, X_train_list, X_train_onlyGhost_list, MAE_list, FINAL_QP_list, Y_train_list)\n",
    "append_results_to_lists(train_df5, train_df_onlyGhost5, LABEL5, MAE5, FINAL_QP5, X_train_list, X_train_onlyGhost_list, MAE_list, FINAL_QP_list, Y_train_list)\n",
    "append_results_to_lists(train_df6, train_df_onlyGhost6, LABEL6, MAE6, FINAL_QP6, X_train_list, X_train_onlyGhost_list, MAE_list, FINAL_QP_list, Y_train_list)\n",
    "append_results_to_lists(train_df7, train_df_onlyGhost7, LABEL7, MAE7, FINAL_QP7, X_train_list, X_train_onlyGhost_list, MAE_list, FINAL_QP_list, Y_train_list)\n",
    "append_results_to_lists(train_df8, train_df_onlyGhost8, LABEL8, MAE8, FINAL_QP8, X_train_list, X_train_onlyGhost_list, MAE_list, FINAL_QP_list, Y_train_list)\n",
    "append_results_to_lists(train_df9, train_df_onlyGhost9, LABEL9, MAE9, FINAL_QP9, X_train_list, X_train_onlyGhost_list, MAE_list, FINAL_QP_list, Y_train_list)\n",
    "append_results_to_lists(train_df10, train_df_onlyGhost10, LABEL10, MAE10, FINAL_QP10, X_train_list, X_train_onlyGhost_list, MAE_list, FINAL_QP_list, Y_train_list)\n",
    "\n",
    "append_results_to_lists(test_df1, test_df_onlyGhost1, LABEL_t1, MAE_t1, FINAL_QP_t1, X_test_list1, X_test_onlyGhost_list1, MAE_list_t1, FINAL_QP_list_t1, Y_test_list1)\n",
    "append_results_to_lists(test_df2, test_df_onlyGhost2, LABEL_t2, MAE_t2, FINAL_QP_t2, X_test_list2, X_test_onlyGhost_list2, MAE_list_t2, FINAL_QP_list_t2, Y_test_list2)\n",
    "append_results_to_lists(test_df3, test_df_onlyGhost3, LABEL_t3, MAE_t3, FINAL_QP_t3, X_test_list3, X_test_onlyGhost_list3, MAE_list_t3, FINAL_QP_list_t3, Y_test_list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "[0.84359582 0.82598474 0.68167678 0.64815855 0.59825212 0.32887013\n",
      " 0.50507987 0.65488262 0.67780943 0.68768002 0.41944508 0.72722264\n",
      " 0.77873516 0.8001656  0.70715316 0.67648268 0.43137421 0.80376973\n",
      " 0.71326579 0.79880388 0.43407905 0.7240887  0.74221362 0.65376735\n",
      " 0.50141855 0.62827208 0.59879582 0.47389277 0.4404852  0.37897171\n",
      " 0.25436978 0.17703908 0.11712057 0.14458777 0.20171298 0.14227984\n",
      " 0.1923726  0.12385619 0.08711533 0.07406861 0.09188604 0.07171303\n",
      " 0.05502152 0.0826821  0.07867715 0.05294245 0.08042251 0.13437958\n",
      " 0.11245006 0.10338145 0.0833901  0.18516759 0.76530537 0.7420388\n",
      " 0.62878684 0.57699969 0.5201471  0.2576     0.44834438 0.63522263\n",
      " 0.67634025 0.68760945 0.39190319 0.73279837 0.78636398 0.80824698\n",
      " 0.71396985 0.74873231 0.41816    0.81399762 0.71744902 0.80381425\n",
      " 0.42210582 0.73708057 0.74269988 0.65319732 0.47456125 0.65372893\n",
      " 0.59426047 0.50801898 0.45722663 0.38766134 0.263746   0.17622042\n",
      " 0.11147401 0.14316283 0.19879727 0.15315385 0.19937344 0.12676677\n",
      " 0.08067002 0.06943399 0.08397989 0.06944149 0.05299409 0.07857413\n",
      " 0.08884989 0.0503194  0.06235183 0.12018882 0.09587463 0.12596124\n",
      " 0.11633561 0.24309285]\n",
      "[array([ 0.00099665,  0.00143266,  0.00364072,  0.00268181, -0.00152836,\n",
      "        -0.00468127, -0.00885767, -0.01249626, -0.01894097, -0.02175535,\n",
      "        -0.02942074, -0.03406391, -0.03688904, -0.04261411, -0.04716296,\n",
      "        -0.04684029, -0.05157662, -0.03644826, -0.04611911, -0.04751946,\n",
      "        -0.0353577 , -0.01673094, -0.09164767, -0.09789949, -0.04326732,\n",
      "         0.05314844,  0.22328212,  0.53061402,  0.22906552,  0.11999798,\n",
      "         0.02770055, -0.05071117, -0.07532378, -0.06461161, -0.02470173,\n",
      "        -0.01443714, -0.01937397, -0.07092459, -0.05049673, -0.01259662,\n",
      "        -0.04714225, -0.03376132, -0.00895579, -0.00943273,  0.01885322,\n",
      "        -0.0033413 , -0.02423891,  0.00337389,  0.05449097,  0.02088002,\n",
      "        -0.01120486,  0.05355854])                                      ]\n",
      "[27]\n",
      "0\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "[array([ 0.00287376,  0.0033696 ,  0.00433564,  0.00785698,  0.01157709,\n",
      "         0.01470123,  0.0205584 ,  0.02414503,  0.03015652,  0.02941844,\n",
      "         0.01484449,  0.00457328,  0.00508438,  0.00671943,  0.01335169,\n",
      "        -0.0021909 , -0.08297994, -0.17734284, -0.25554216, -0.32598803,\n",
      "        -0.3777943 , -0.42879491, -0.48827063, -0.55383035, -0.6031479 ,\n",
      "        -0.63153855, -0.56920029, -0.46608914, -0.37923164, -0.31567856,\n",
      "        -0.28398145, -0.27886897, -0.27671971, -0.26908783, -0.25183408,\n",
      "        -0.24782672, -0.22650192, -0.22574572, -0.2051765 , -0.20660583,\n",
      "        -0.20092674, -0.19963021, -0.21500049, -0.20069385, -0.17104854,\n",
      "        -0.21183147, -0.13639864, -0.19080269, -0.15258795, -0.17530152,\n",
      "        -0.20432885, -0.23517643])                                      ]\n",
      "[12]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 各リストの長さを確認\n",
    "print(len(X_train_list[0]))\n",
    "print((X_train_onlyGhost_list[0])[0])\n",
    "print((MAE_list[0])[0])\n",
    "print((FINAL_QP_list[0])[0])\n",
    "print((Y_train_list[0])[0])\n",
    "\n",
    "print(len(X_test_list1[0]))\n",
    "print(len(X_test_onlyGhost_list1[0]))\n",
    "print(len(X_test_onlyGhost_list2[0]))\n",
    "print(len(X_test_onlyGhost_list3[0]))\n",
    "print((MAE_list_t1[0])[0])\n",
    "print((FINAL_QP_list_t1[0])[0])\n",
    "print((Y_test_list1[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Fold-1>\n",
      "Train indices: [0 1 2 3 4 5 6 7 9]\n",
      "Test indices: [8]\n",
      "4320\n",
      "480\n",
      "60\n",
      "60\n",
      "60\n",
      "0.7\n",
      "0.7166666666666667\n",
      "0.7666666666666667\n",
      "GIMP_GIMP_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6000    0.1000    0.1714        30\n",
      "           1     0.5091    0.9333    0.6588        30\n",
      "\n",
      "    accuracy                         0.5167        60\n",
      "   macro avg     0.5545    0.5167    0.4151        60\n",
      "weighted avg     0.5545    0.5167    0.4151        60\n",
      "\n",
      "GIMP_GIMP_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.0000    0.0000        30\n",
      "           1     0.5000    1.0000    0.6667        30\n",
      "\n",
      "    accuracy                         0.5000        60\n",
      "   macro avg     0.7500    0.5000    0.3333        60\n",
      "weighted avg     0.7500    0.5000    0.3333        60\n",
      "\n",
      "LIBHEIF_GIMP_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.1000    0.1667        30\n",
      "           1     0.5000    0.9000    0.6429        30\n",
      "\n",
      "    accuracy                         0.5000        60\n",
      "   macro avg     0.5000    0.5000    0.4048        60\n",
      "weighted avg     0.5000    0.5000    0.4048        60\n",
      "\n",
      "LIBHEIF_GIMP_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.0000    0.0000        30\n",
      "           1     0.5000    1.0000    0.6667        30\n",
      "\n",
      "    accuracy                         0.5000        60\n",
      "   macro avg     0.7500    0.5000    0.3333        60\n",
      "weighted avg     0.7500    0.5000    0.3333        60\n",
      "\n",
      "GIMP_LIBHEIF_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.0333    0.0645        30\n",
      "           1     0.5085    1.0000    0.6742        30\n",
      "\n",
      "    accuracy                         0.5167        60\n",
      "   macro avg     0.7542    0.5167    0.3693        60\n",
      "weighted avg     0.7542    0.5167    0.3693        60\n",
      "\n",
      "GIMP_LIBHEIF_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.0333    0.0645        30\n",
      "           1     0.5085    1.0000    0.6742        30\n",
      "\n",
      "    accuracy                         0.5167        60\n",
      "   macro avg     0.7542    0.5167    0.3693        60\n",
      "weighted avg     0.7542    0.5167    0.3693        60\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9286    0.4333    0.5909        30\n",
      "           1     0.6304    0.9667    0.7632        30\n",
      "\n",
      "    accuracy                         0.7000        60\n",
      "   macro avg     0.7795    0.7000    0.6770        60\n",
      "weighted avg     0.7795    0.7000    0.6770        60\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7407    0.6667    0.7018        30\n",
      "           1     0.6970    0.7667    0.7302        30\n",
      "\n",
      "    accuracy                         0.7167        60\n",
      "   macro avg     0.7189    0.7167    0.7160        60\n",
      "weighted avg     0.7189    0.7167    0.7160        60\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.5333    0.6957        30\n",
      "           1     0.6818    1.0000    0.8108        30\n",
      "\n",
      "    accuracy                         0.7667        60\n",
      "   macro avg     0.8409    0.7667    0.7532        60\n",
      "weighted avg     0.8409    0.7667    0.7532        60\n",
      "\n",
      "<Fold-2>\n",
      "Train indices: [0 2 3 4 5 6 7 8 9]\n",
      "Test indices: [1]\n",
      "4320\n",
      "480\n",
      "60\n",
      "60\n",
      "60\n",
      "0.7\n",
      "0.7166666666666667\n",
      "0.7666666666666667\n",
      "GIMP_GIMP_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    0.1333    0.2222        30\n",
      "           1     0.5185    0.9333    0.6667        30\n",
      "\n",
      "    accuracy                         0.5333        60\n",
      "   macro avg     0.5926    0.5333    0.4444        60\n",
      "weighted avg     0.5926    0.5333    0.4444        60\n",
      "\n",
      "GIMP_GIMP_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.0667    0.1250        30\n",
      "           1     0.5172    1.0000    0.6818        30\n",
      "\n",
      "    accuracy                         0.5333        60\n",
      "   macro avg     0.7586    0.5333    0.4034        60\n",
      "weighted avg     0.7586    0.5333    0.4034        60\n",
      "\n",
      "LIBHEIF_GIMP_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.1000    0.1667        30\n",
      "           1     0.5000    0.9000    0.6429        30\n",
      "\n",
      "    accuracy                         0.5000        60\n",
      "   macro avg     0.5000    0.5000    0.4048        60\n",
      "weighted avg     0.5000    0.5000    0.4048        60\n",
      "\n",
      "LIBHEIF_GIMP_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.0667    0.1250        30\n",
      "           1     0.5172    1.0000    0.6818        30\n",
      "\n",
      "    accuracy                         0.5333        60\n",
      "   macro avg     0.7586    0.5333    0.4034        60\n",
      "weighted avg     0.7586    0.5333    0.4034        60\n",
      "\n",
      "GIMP_LIBHEIF_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.0333    0.0645        30\n",
      "           1     0.5085    1.0000    0.6742        30\n",
      "\n",
      "    accuracy                         0.5167        60\n",
      "   macro avg     0.7542    0.5167    0.3693        60\n",
      "weighted avg     0.7542    0.5167    0.3693        60\n",
      "\n",
      "GIMP_LIBHEIF_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.0000    0.0000        30\n",
      "           1     0.5000    1.0000    0.6667        30\n",
      "\n",
      "    accuracy                         0.5000        60\n",
      "   macro avg     0.7500    0.5000    0.3333        60\n",
      "weighted avg     0.7500    0.5000    0.3333        60\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9286    0.4333    0.5909        30\n",
      "           1     0.6304    0.9667    0.7632        30\n",
      "\n",
      "    accuracy                         0.7000        60\n",
      "   macro avg     0.7795    0.7000    0.6770        60\n",
      "weighted avg     0.7795    0.7000    0.6770        60\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7407    0.6667    0.7018        30\n",
      "           1     0.6970    0.7667    0.7302        30\n",
      "\n",
      "    accuracy                         0.7167        60\n",
      "   macro avg     0.7189    0.7167    0.7160        60\n",
      "weighted avg     0.7189    0.7167    0.7160        60\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.5333    0.6957        30\n",
      "           1     0.6818    1.0000    0.8108        30\n",
      "\n",
      "    accuracy                         0.7667        60\n",
      "   macro avg     0.8409    0.7667    0.7532        60\n",
      "weighted avg     0.8409    0.7667    0.7532        60\n",
      "\n",
      "<Fold-3>\n",
      "Train indices: [0 1 2 3 4 6 7 8 9]\n",
      "Test indices: [5]\n",
      "4320\n",
      "480\n",
      "60\n",
      "60\n",
      "60\n",
      "0.7\n",
      "0.7166666666666667\n",
      "0.7666666666666667\n",
      "GIMP_GIMP_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7500    0.2000    0.3158        30\n",
      "           1     0.5385    0.9333    0.6829        30\n",
      "\n",
      "    accuracy                         0.5667        60\n",
      "   macro avg     0.6442    0.5667    0.4994        60\n",
      "weighted avg     0.6442    0.5667    0.4994        60\n",
      "\n",
      "GIMP_GIMP_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.0667    0.1250        30\n",
      "           1     0.5172    1.0000    0.6818        30\n",
      "\n",
      "    accuracy                         0.5333        60\n",
      "   macro avg     0.7586    0.5333    0.4034        60\n",
      "weighted avg     0.7586    0.5333    0.4034        60\n",
      "\n",
      "LIBHEIF_GIMP_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    0.2000    0.3077        30\n",
      "           1     0.5294    0.9000    0.6667        30\n",
      "\n",
      "    accuracy                         0.5500        60\n",
      "   macro avg     0.5980    0.5500    0.4872        60\n",
      "weighted avg     0.5980    0.5500    0.4872        60\n",
      "\n",
      "LIBHEIF_GIMP_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.0000    0.0000        30\n",
      "           1     0.5000    1.0000    0.6667        30\n",
      "\n",
      "    accuracy                         0.5000        60\n",
      "   macro avg     0.7500    0.5000    0.3333        60\n",
      "weighted avg     0.7500    0.5000    0.3333        60\n",
      "\n",
      "GIMP_LIBHEIF_report_RBF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.0667    0.1250        30\n",
      "           1     0.5172    1.0000    0.6818        30\n",
      "\n",
      "    accuracy                         0.5333        60\n",
      "   macro avg     0.7586    0.5333    0.4034        60\n",
      "weighted avg     0.7586    0.5333    0.4034        60\n",
      "\n",
      "GIMP_LIBHEIF_report_LINEAR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.0333    0.0645        30\n",
      "           1     0.5085    1.0000    0.6742        30\n",
      "\n",
      "    accuracy                         0.5167        60\n",
      "   macro avg     0.7542    0.5167    0.3693        60\n",
      "weighted avg     0.7542    0.5167    0.3693        60\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9286    0.4333    0.5909        30\n",
      "           1     0.6304    0.9667    0.7632        30\n",
      "\n",
      "    accuracy                         0.7000        60\n",
      "   macro avg     0.7795    0.7000    0.6770        60\n",
      "weighted avg     0.7795    0.7000    0.6770        60\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7407    0.6667    0.7018        30\n",
      "           1     0.6970    0.7667    0.7302        30\n",
      "\n",
      "    accuracy                         0.7167        60\n",
      "   macro avg     0.7189    0.7167    0.7160        60\n",
      "weighted avg     0.7189    0.7167    0.7160        60\n",
      "\n",
      "Summary old_model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.5333    0.6957        30\n",
      "           1     0.6818    1.0000    0.8108        30\n",
      "\n",
      "    accuracy                         0.7667        60\n",
      "   macro avg     0.8409    0.7667    0.7532        60\n",
      "weighted avg     0.8409    0.7667    0.7532        60\n",
      "\n",
      "<Fold-4>\n",
      "Train indices: [1 2 3 4 5 6 7 8 9]\n",
      "Test indices: [0]\n",
      "4320\n",
      "480\n",
      "60\n",
      "60\n",
      "60\n",
      "0.7\n",
      "0.7166666666666667\n",
      "0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Cの範囲を指定\n",
    "# C_values = {'C': [0.01, 0.1, 1, 10, 100, 1000, 2000, 3000, 4000, 5000]}\n",
    "# C_values = {'C': [10]}\n",
    "C_values = {'C': [0.01, 0.1, 1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500]}\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# results = pd.DataFrame(columns=['C_RBF_LQP1','Score_RBF_LQP1', 'tnr_rbf_lqp1', 'tpr_rbf_lqp1',\n",
    "#                                 'C_RBF_SQP','Score_RBF_SQP', 'tnr_rbf_sqp', 'tpr_rbf_sqp',\n",
    "#                                 'C_RBF_LQP2','Score_RBF_LQP2', 'tnr_rbf_lqp2', 'tpr_rbf_lqp2',\n",
    "#                                 'C_LINEAR_LQP1','Score_LINEAR_LQP1', 'tnr_linear_lqp1', 'tpr_linear_lqp1',\n",
    "#                                 'C_LINEAR_SQP','Score_LINEAR_SQP', 'tnr_linear_sqp', 'tpr_linear_sqp',\n",
    "#                                 'C_LINEAR_LQP2','Score_LINEAR_LQP2', 'tnr_linear_lqp2', 'tpr_linear_lqp2',\n",
    "                                \n",
    "#                                 'C_RBF_OG_LQP1','Score_RBF_OG_LQP1', 'tnr_og_rbf_lqp1', 'tpr_og_rbf_lqp1',\n",
    "#                                 'C_RBF_OG_SQP','Score_RBF_OG_SQP', 'tnr_og_rbf_sqp', 'tpr_og_rbf_sqp',\n",
    "#                                 'C_RBF_OG_LQP2','Score_RBF_OG_LQP2', 'tnr_og_rbf_lqp2', 'tpr_og_rbf_lqp2',\n",
    "#                                 'C_LINEAR_OG_LQP1','Score_LINEAR_OG_LQP1', 'tnr_og_linear_lqp1', 'tpr_og_linear_lqp1',\n",
    "#                                 'C_LINEAR_OG_SQP','Score_LINEAR_OG_SQP', 'tnr_og_linear_sqp', 'tpr_og_linear_sqp',\n",
    "#                                 'C_LINEAR_OG_LQP2','Score_LINEAR_OG_LQP2', 'tnr_og_linear_lqp2', 'tpr_og_linear_lqp2',\n",
    "                                \n",
    "#                                 'Threshold_LQP1', 'LQP1_old', 'tnr_old_lqp1', 'tpr_old_lqp1',\n",
    "#                                 'Threshold_SQP', 'SQP_old', 'tnr_old_sqp', 'tpr_old_sqp',\n",
    "#                                 'Threshold_LQP2', 'LQP2_old', 'tnr_old_lqp2', 'tpr_old_lqp2'])\n",
    "\n",
    "\n",
    "results = pd.DataFrame(columns=['C_RBF_GG','Score_RBF_GG', 'tnr_rbf_GG', 'tpr_rbf_GG',\n",
    "                                'C_RBF_LG','Score_RBF_LG', 'tnr_rbf_LG', 'tpr_rbf_LG',\n",
    "                                'C_RBF_GL','Score_RBF_GL', 'tnr_rbf_GL', 'tpr_rbf_GL',\n",
    "                                'C_LINEAR_GG','Score_LINEAR_GG', 'tnr_linear_GG', 'tpr_linear_GG',\n",
    "                                'C_LINEAR_LG','Score_LINEAR_LG', 'tnr_linear_LG', 'tpr_linear_LG',\n",
    "                                'C_LINEAR_GL','Score_LINEAR_GL', 'tnr_linear_GL', 'tpr_linear_GL',\n",
    "                                                        \n",
    "                                'Threshold_GG', 'GG_old', 'tnr_old_GG', 'tpr_old_GG',\n",
    "                                'Threshold_LG', 'LG_old', 'tnr_old_LG', 'tpr_old_LG',\n",
    "                                'Threshold_GL', 'GL_old', 'tnr_old_GL', 'tpr_old_GL'])\n",
    "\n",
    "    \n",
    "X_index = np.arange(10)  # インデックスとして0から8までの数字を用意\n",
    "\n",
    "# ループで各分割のtrain_idsとtest_idsを取得\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(X_index)):\n",
    "    print(f\"<Fold-{fold+1}>\")\n",
    "    print(\"Train indices:\", train_ids)\n",
    "    print(\"Test indices:\", test_ids)\n",
    "    \n",
    "    train_data = [X_train_list[i] for i in train_ids]\n",
    "    train_data_OG = [X_train_onlyGhost_list[i] for i in train_ids]\n",
    "    train_label = [Y_train_list[i] for i in train_ids]\n",
    "    \n",
    "    val_data = [X_train_list[i] for i in test_ids]\n",
    "    val_data_OG = [X_train_onlyGhost_list[i] for i in test_ids]\n",
    "    val_label = [Y_train_list[i] for i in test_ids]\n",
    "    \n",
    "    X_train = [item for data in train_data for item in data]\n",
    "    X_train_OG = [item for data in train_data_OG for item in data]\n",
    "    Y_train = [item for data in train_label for item in data]\n",
    "    \n",
    "    X_val = [item for data in val_data for item in data]\n",
    "    X_val_OG = [item for data in val_data_OG for item in data]\n",
    "    Y_val = [item for data in val_label for item in data]\n",
    "    \n",
    "    print(len(Y_train))\n",
    "    print(len(Y_val))\n",
    "    \n",
    "    test_data1 = [item for data in X_test_list1 for item in data]\n",
    "    test_data_OG1 = [item for data in X_test_onlyGhost_list1 for item in data]\n",
    "    test_label1 = [item for data in Y_test_list1 for item in data]\n",
    "    MAE_data1 = [item for data in MAE_list_t1 for item in data]\n",
    "    FINAL_QP_data1 = [item for data in FINAL_QP_list_t1 for item in data]\n",
    "    \n",
    "    test_data2 = [item for data in X_test_list2 for item in data]\n",
    "    test_data_OG2 = [item for data in X_test_onlyGhost_list2 for item in data]\n",
    "    test_label2 = [item for data in Y_test_list2 for item in data]\n",
    "    MAE_data2 = [item for data in MAE_list_t2 for item in data]\n",
    "    FINAL_QP_data2 = [item for data in FINAL_QP_list_t2 for item in data]\n",
    "    \n",
    "    test_data3 = [item for data in X_test_list3 for item in data]\n",
    "    test_data_OG3 = [item for data in X_test_onlyGhost_list3 for item in data]\n",
    "    test_label3 = [item for data in Y_test_list3 for item in data]\n",
    "    MAE_data3 = [item for data in MAE_list_t3 for item in data]\n",
    "    FINAL_QP_data3 = [item for data in FINAL_QP_list_t3 for item in data]\n",
    "    \n",
    "    print(len(MAE_data1))\n",
    "    print(len(MAE_data2))\n",
    "    print(len(MAE_data3))\n",
    "    \n",
    "                                                                                   \n",
    "    best_threshold = 0\n",
    "    best_accuracy = 0\n",
    "    best_predicted_labels = []\n",
    "    best_ground_truth_labels = []\n",
    "    \n",
    "    sameQP_best_threshold = 0\n",
    "    sameQP_best_accuracy = 0\n",
    "    sameQP_best_predicted_labels = []\n",
    "    sameQP_best_ground_truth_labels = []\n",
    "    \n",
    "    largeQP_best_threshold = 0\n",
    "    largeQP_best_accuracy = 0\n",
    "    largeQP_best_predicted_labels = []\n",
    "    largeQP_best_ground_truth_labels = []\n",
    "            \n",
    "    for threshold in np.arange(0.01, 1.00, 0.01):\n",
    "        test_old = np.array([is_double_compressed(MAE_data1[i], FINAL_QP_data1[i], threshold) for i in range(60)])\n",
    "        predicted_labels = test_old.astype(int)\n",
    "        ground_truth_labels = np.array(test_label1)\n",
    "        accuracy = np.sum(ground_truth_labels == predicted_labels) / len(ground_truth_labels)\n",
    "    \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_threshold = threshold\n",
    "            best_predicted_labels = predicted_labels\n",
    "            best_ground_truth_labels = ground_truth_labels\n",
    "            \n",
    "    for threshold in np.arange(0.01, 1.00, 0.01):\n",
    "        test_sameQP_old = np.array([is_double_compressed(MAE_data2[i], FINAL_QP_data2[i], threshold) for i in range(60)])\n",
    "        same_predicted_labels = test_sameQP_old.astype(int)\n",
    "        same_ground_truth_labels = np.array(test_label2)\n",
    "        same_accuracy = np.sum(same_ground_truth_labels == same_predicted_labels) / len(same_ground_truth_labels)\n",
    "    \n",
    "        if same_accuracy > sameQP_best_accuracy:\n",
    "            sameQP_best_accuracy = same_accuracy\n",
    "            sameQP_best_threshold = threshold\n",
    "            sameQP_best_predicted_labels = same_predicted_labels\n",
    "            sameQP_best_ground_truth_labels = same_ground_truth_labels\n",
    "                        \n",
    "    for threshold in np.arange(0.01, 1.00, 0.01):\n",
    "        test_largeQP_old = np.array([is_double_compressed(MAE_data3[i], FINAL_QP_data3[i], threshold) for i in range(60)])\n",
    "        large_predicted_labels = test_largeQP_old.astype(int)\n",
    "        large_ground_truth_labels = np.array(test_label3)\n",
    "        large_accuracy = np.sum(large_ground_truth_labels == large_predicted_labels) / len(large_ground_truth_labels)\n",
    "    \n",
    "        if large_accuracy > largeQP_best_accuracy:\n",
    "            largeQP_best_accuracy = large_accuracy\n",
    "            largeQP_best_threshold = threshold\n",
    "            largeQP_best_predicted_labels = large_predicted_labels\n",
    "            largeQP_best_ground_truth_labels = large_ground_truth_labels       \n",
    "            \n",
    "            \n",
    "    print(best_accuracy)\n",
    "    print(sameQP_best_accuracy)\n",
    "    print(largeQP_best_accuracy)\n",
    "            \n",
    "            \n",
    "    best_val_score_RBF, best_svm_model_RBF, best_c_value_RBF = 0, None, None\n",
    "    # best_val_score_onlyGhost_RBF, best_svm_model_onlyGhost_RBF, best_c_value_onlyGhost_RBF = 0, None, None\n",
    "    \n",
    "    best_val_score_LINEAR, best_svm_model_LINEAR, best_c_value_LINEAR = 0, None, None\n",
    "    # best_val_score_onlyGhost_LINEAR, best_svm_model_onlyGhost_LINEAR, best_c_value_onlyGhost_LINEAR = 0, None, None\n",
    "        \n",
    "    for C_value in C_values['C']:    \n",
    "        # SVMモデルのインスタンスを作成\n",
    "        svm_model_RBF = SVC(kernel='rbf', C=C_value)\n",
    "        # svm_model_onlyGhost_RBF = SVC(kernel='rbf', C=C_value)\n",
    "        \n",
    "        svm_model_LINEAR = SVC(kernel='linear', C=C_value)\n",
    "        # svm_model_onlyGhost_LINEAR = SVC(kernel='linear', C=C_value)\n",
    "\n",
    "        # 訓練データで訓練\n",
    "        svm_model_RBF.fit(X_train, Y_train)\n",
    "        # svm_model_onlyGhost_RBF.fit(X_train_OG, Y_train)\n",
    "        \n",
    "        svm_model_LINEAR.fit(X_train, Y_train)\n",
    "        # svm_model_onlyGhost_LINEAR.fit(X_train_OG, Y_train)\n",
    "\n",
    "        \n",
    "        val_accuracy_RBF = accuracy_score(Y_val, svm_model_RBF.predict(X_val))\n",
    "        # val_accuracy_onlyGhost_RBF = accuracy_score(Y_val, svm_model_onlyGhost_RBF.predict(X_val_OG))\n",
    "        \n",
    "        val_accuracy_LINEAR = accuracy_score(Y_val, svm_model_LINEAR.predict(X_val))\n",
    "        # val_accuracy_onlyGhost_LINEAR = accuracy_score(Y_val, svm_model_onlyGhost_LINEAR.predict(X_val_OG))\n",
    "        \n",
    "\n",
    "        # 検証データでの精度が最も高かった場合、そのモデルを保存\n",
    "        if val_accuracy_RBF > best_val_score_RBF:\n",
    "            best_val_score_RBF, best_svm_model_RBF, best_c_value_RBF = val_accuracy_RBF, svm_model_RBF, C_value\n",
    "\n",
    "        # if val_accuracy_onlyGhost_RBF > best_val_score_onlyGhost_RBF:\n",
    "        #     best_val_score_onlyGhost_RBF, best_svm_model_onlyGhost_RBF, best_c_value_onlyGhost_RBF = val_accuracy_onlyGhost_RBF, svm_model_onlyGhost_RBF, C_value\n",
    "            \n",
    "        if val_accuracy_LINEAR > best_val_score_LINEAR:\n",
    "            best_val_score_LINEAR, best_svm_model_LINEAR, best_c_value_LINEAR = val_accuracy_LINEAR, svm_model_LINEAR, C_value\n",
    "\n",
    "        # if val_accuracy_onlyGhost_LINEAR > best_val_score_onlyGhost_LINEAR:\n",
    "        #     best_val_score_onlyGhost_LINEAR, best_svm_model_onlyGhost_LINEAR, best_c_value_onlyGhost_LINEAR = val_accuracy_onlyGhost_LINEAR, svm_model_onlyGhost_LINEAR, C_value\n",
    "\n",
    "\n",
    "    # テストデータで評価    \n",
    "    predictions_RBF = best_svm_model_RBF.predict(test_data1)\n",
    "    # predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test)\n",
    "    accuracy_RBF = accuracy_score(test_label1, predictions_RBF)\n",
    "    report_RBF = classification_report(test_label1, predictions_RBF, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label1, predictions_RBF)\n",
    "    tnr_rbf_lqp1 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_rbf_lqp1 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'GIMP_GIMP_report_RBF:\\n{report_RBF}')\n",
    "    \n",
    "    predictions_LINEAR = best_svm_model_LINEAR.predict(test_data1)\n",
    "    # predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test)\n",
    "    accuracy_LINEAR = accuracy_score(test_label1, predictions_LINEAR)\n",
    "    report_LINEAR = classification_report(test_label1, predictions_LINEAR, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label1, predictions_LINEAR)\n",
    "    tnr_linear_lqp1 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_linear_lqp1 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'GIMP_GIMP_report_LINEAR:\\n{report_LINEAR}')\n",
    "    \n",
    "    same_predictions_RBF = best_svm_model_RBF.predict(test_data2)\n",
    "    # same_predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test_sameQP)\n",
    "    same_accuracy_RBF = accuracy_score(test_label2, same_predictions_RBF)\n",
    "    same_report_RBF = classification_report(test_label2, same_predictions_RBF, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label2, same_predictions_RBF)\n",
    "    tnr_rbf_sqp = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_rbf_sqp = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'LIBHEIF_GIMP_report_RBF:\\n{same_report_RBF}')\n",
    "    \n",
    "    same_predictions_LINEAR = best_svm_model_LINEAR.predict(test_data2)\n",
    "    # same_predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test_sameQP)\n",
    "    same_accuracy_LINEAR = accuracy_score(test_label2, same_predictions_LINEAR)\n",
    "    same_report_LINEAR = classification_report(test_label2, same_predictions_LINEAR, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label2, same_predictions_LINEAR)\n",
    "    tnr_linear_sqp = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_linear_sqp = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'LIBHEIF_GIMP_report_LINEAR:\\n{same_report_LINEAR}')\n",
    "    \n",
    "    large_predictions_RBF = best_svm_model_RBF.predict(test_data3)\n",
    "    # large_predictions_prob_RBF = best_svm_model_RBF.decision_function(X_test_largeQP)\n",
    "    large_accuracy_RBF = accuracy_score(test_label3, large_predictions_RBF)\n",
    "    large_report_RBF = classification_report(test_label3, large_predictions_RBF, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label3, large_predictions_RBF)\n",
    "    tnr_rbf_lqp2 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_rbf_lqp2 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'GIMP_LIBHEIF_report_RBF:\\n{large_report_RBF}')\n",
    "    \n",
    "    large_predictions_LINEAR = best_svm_model_LINEAR.predict(test_data3)\n",
    "    # large_predictions_prob_LINEAR = best_svm_model_LINEAR.decision_function(X_test_largeQP)\n",
    "    large_accuracy_LINEAR = accuracy_score(test_label3, large_predictions_LINEAR)\n",
    "    large_report_LINEAR = classification_report(test_label3, large_predictions_LINEAR, digits=4, zero_division=1)\n",
    "    conf_matrix = confusion_matrix(test_label3, large_predictions_LINEAR)\n",
    "    tnr_linear_lqp2 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_linear_lqp2 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'GIMP_LIBHEIF_report_LINEAR:\\n{large_report_LINEAR}')\n",
    "    \n",
    "\n",
    "    # テストデータで評価\n",
    "    test_old = classification_report(best_ground_truth_labels, best_predicted_labels, labels=[0,1], target_names=['0', '1'], zero_division=0, digits=4)\n",
    "    conf_matrix = confusion_matrix(best_ground_truth_labels, best_predicted_labels)\n",
    "    tnr_old_lqp1 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_old_lqp1 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'Summary old_model:\\n{test_old}')\n",
    "    \n",
    "    test_sameQP_old = classification_report(sameQP_best_ground_truth_labels, sameQP_best_predicted_labels, labels=[0,1], target_names=['0', '1'], zero_division=0, digits=4)\n",
    "    conf_matrix = confusion_matrix(sameQP_best_ground_truth_labels, sameQP_best_predicted_labels)\n",
    "    tnr_old_sqp = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_old_sqp = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'Summary old_model:\\n{test_sameQP_old}')\n",
    "    \n",
    "    test_largeQP_old = classification_report(largeQP_best_ground_truth_labels, largeQP_best_predicted_labels, labels=[0,1], target_names=['0', '1'], zero_division=0, digits=4)\n",
    "    conf_matrix = confusion_matrix(largeQP_best_ground_truth_labels, largeQP_best_predicted_labels)\n",
    "    tnr_old_lqp2 = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    tpr_old_lqp2 = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    print(f'Summary old_model:\\n{test_largeQP_old}')\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Test結果を保存\n",
    "    \n",
    "    result_row ={'C_RBF_GG':best_c_value_RBF,'Score_RBF_GG': accuracy_RBF, 'tnr_rbf_GG':tnr_rbf_lqp1, 'tpr_rbf_GG':tpr_rbf_lqp1,\n",
    "                'C_RBF_LG': best_c_value_RBF, 'Score_RBF_LG': same_accuracy_RBF, 'tnr_rbf_LG':tnr_rbf_sqp, 'tpr_rbf_LG':tpr_rbf_sqp,\n",
    "                'C_RBF_GL': best_c_value_RBF,'Score_RBF_GL': large_accuracy_RBF, 'tnr_rbf_GL':tnr_rbf_lqp2, 'tpr_rbf_GL':tpr_rbf_lqp2,\n",
    "                                    \n",
    "                'C_LINEAR_GG': best_c_value_LINEAR,'Score_LINEAR_GG':accuracy_LINEAR, 'tnr_linear_GG':tnr_linear_lqp1, 'tpr_linear_GG':tpr_linear_lqp1,\n",
    "                'C_LINEAR_LG': best_c_value_LINEAR,'Score_LINEAR_LG':same_accuracy_LINEAR, 'tnr_linear_LG':tnr_linear_sqp, 'tpr_linear_LG':tpr_linear_sqp,\n",
    "                'C_LINEAR_GL': best_c_value_LINEAR,'Score_LINEAR_GL':large_accuracy_LINEAR, 'tnr_linear_GL':tnr_linear_lqp2, 'tpr_linear_GL':tpr_linear_lqp2,\n",
    "                                                        \n",
    "                'Threshold_GG':best_threshold, 'GG_old':best_accuracy, 'tnr_old_GG':tnr_old_lqp1, 'tpr_old_GG':tpr_old_lqp1,\n",
    "                'Threshold_LG':sameQP_best_threshold, 'LG_old':sameQP_best_accuracy, 'tnr_old_LG':tnr_old_sqp, 'tpr_old_LG':tpr_old_sqp,\n",
    "                'Threshold_GL':largeQP_best_threshold, 'GL_old':largeQP_best_accuracy, 'tnr_old_GL':tnr_old_lqp2, 'tpr_old_GL':tpr_old_lqp2}\n",
    "\n",
    "\n",
    "    results = pd.concat([results, pd.DataFrame([result_row])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各統計情報を100倍して小数点第4位までの表記に変更\n",
    "statistics_data = {\n",
    "    'Model': ['RBF_GG', 'RBF_LG', 'RBF_GL', 'LINEAR_GG', 'LINEAR_LG', 'LINEAR_GL', 'OLD_GG', 'OLD_LG', 'OLD_GL'],\n",
    "    'Average TNR': [round(results['tnr_rbf_GG'].mean() * 100, 2), round(results['tnr_rbf_LG'].mean() * 100, 2), round(results['tnr_rbf_GL'].mean() * 100, 2), round(results['tnr_linear_GG'].mean() * 100, 2), round(results['tnr_linear_LG'].mean() * 100, 2), round(results['tnr_linear_GL'].mean() * 100, 2),round(results['tnr_old_GG'].mean() * 100, 2), round(results['tnr_old_LG'].mean() * 100, 2), round(results['tnr_old_GL'].mean() * 100, 2)],\n",
    "    'Average TPR': [round(results['tpr_rbf_GG'].mean() * 100, 2), round(results['tpr_rbf_LG'].mean() * 100, 2), round(results['tpr_rbf_GL'].mean() * 100, 2), round(results['tpr_linear_GG'].mean() * 100, 2), round(results['tpr_linear_LG'].mean() * 100, 2), round(results['tpr_linear_GL'].mean() * 100, 2),round(results['tpr_old_GG'].mean() * 100, 2), round(results['tpr_old_LG'].mean() * 100, 2), round(results['tpr_old_GL'].mean() * 100, 2)],\n",
    "    'Average Test Score': [round(results['Score_RBF_GG'].mean() * 100, 2), round(results['Score_RBF_LG'].mean() * 100, 2), round(results['Score_RBF_GL'].mean() * 100, 2), round(results['Score_LINEAR_GG'].mean() * 100, 2), round(results['Score_LINEAR_LG'].mean() * 100, 2), round(results['Score_LINEAR_GL'].mean() * 100, 2),round(results['GG_old'].mean() * 100, 2), round(results['LG_old'].mean() * 100, 2), round(results['GL_old'].mean() * 100, 2)],\n",
    "    'Standard Deviation': [round(results['Score_RBF_GG'].std() * 100, 2), round(results['Score_RBF_LG'].std() * 100, 2), round(results['Score_RBF_GL'].std() * 100, 2), round(results['Score_LINEAR_GG'].std() * 100, 2), round(results['Score_LINEAR_LG'].std() * 100, 2), round(results['Score_LINEAR_GL'].std() * 100, 2),round(results['GG_old'].std() * 100, 2), round(results['LG_old'].std() * 100, 2), round(results['GL_old'].std() * 100, 2)],\n",
    "    'Max Test Score': [round(results['Score_RBF_GG'].max() * 100, 2), round(results['Score_RBF_LG'].max() * 100, 2), round(results['Score_RBF_GL'].max() * 100, 2), round(results['Score_LINEAR_GG'].max() * 100, 2), round(results['Score_LINEAR_LG'].max() * 100, 2), round(results['Score_LINEAR_GL'].max() * 100, 2),round(results['GG_old'].max() * 100, 2), round(results['LG_old'].max() * 100, 2), round(results['GL_old'].max() * 100, 2)],\n",
    "    'Min Test Score': [round(results['Score_RBF_GG'].min() * 100, 2), round(results['Score_RBF_LG'].min() * 100, 2), round(results['Score_RBF_GL'].min() * 100, 2), round(results['Score_LINEAR_GG'].min() * 100, 2), round(results['Score_LINEAR_LG'].min() * 100, 2), round(results['Score_LINEAR_GL'].min() * 100, 2),round(results['GG_old'].min() * 100, 2), round(results['LG_old'].min() * 100, 2), round(results['GL_old'].min() * 100, 2)],\n",
    "}\n",
    "\n",
    "# DataFrameを作成\n",
    "statistics_df = pd.DataFrame(statistics_data)\n",
    "\n",
    "# 表示\n",
    "print(statistics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results['C_RBF_GG'])\n",
    "print(results['C_LINEAR_GG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 40\n",
    "plt.rcParams[\"figure.figsize\"] = (10.0, 5.0)\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "\n",
    "# DataFrameをMatplotlibでプロット\n",
    "plt.axis('off')  # 軸を非表示にする\n",
    "table = plt.table(cellText=statistics_df.values,\n",
    "                  colLabels=statistics_df.columns,\n",
    "                  cellLoc='center', rowLoc='center',\n",
    "                  loc='center')  # 表の文字サイズを調整\n",
    "\n",
    "plt.tight_layout()  # レイアウトを調整\n",
    "plt.savefig('table6.png', bbox_inches=\"tight\", pad_inches=0.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
